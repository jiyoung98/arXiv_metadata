{
	"0": {
		"title": "Kernels on Sample Sets via Nonparametric Divergence Estimates",
		"creator": [
			"Sutherland, Danica J.",
			"Xiong, Liang",
			"Póczos, Barnabás",
			"Schneider, Jeff"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  Most machine learning algorithms, such as classification or regression, treat\nthe individual data point as the object of interest. Here we consider extending\nmachine learning algorithms to operate on groups of data points. We suggest\ntreating a group of data points as an i.i.d. sample set from an underlying\nfeature distribution for that group. Our approach employs kernel machines with\na kernel on i.i.d. sample sets of vectors. We define certain kernel functions\non pairs of distributions, and then use a nonparametric estimator to\nconsistently estimate those functions based on sample sets. The projection of\nthe estimated Gram matrix to the cone of symmetric positive semi-definite\nmatrices enables us to use kernel machines for classification, regression,\nanomaly detection, and low-dimensional embedding in the space of distributions.\nWe present several numerical experiments both on real and simulated datasets to\ndemonstrate the advantages of our new approach.\n",
		"date": [
			"2012-02-01",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1202.0302",
		"pdf_url": "http://arxiv.org/pdf/1202.0302.pdf"
	},
	"1": {
		"title": "Evaluating Visual Properties via Robust HodgeRank",
		"creator": [
			"Xu, Qianqian",
			"Xiong, Jiechao",
			"Cao, Xiaochun",
			"Huang, Qingming",
			"Yao, Yuan"
		],
		"subject": [
			"Statistics - Methodology",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Nowadays, how to effectively evaluate visual properties has become a popular\ntopic for fine-grained visual comprehension. In this paper we study the problem\nof how to estimate such visual properties from a ranking perspective with the\nhelp of the annotators from online crowdsourcing platforms. The main challenges\nof our task are two-fold. On one hand, the annotations often contain\ncontaminated information, where a small fraction of label flips might ruin the\nglobal ranking of the whole dataset. On the other hand, considering the large\ndata capacity, the annotations are often far from being complete. What is\nworse, there might even exist imbalanced annotations where a small subset of\nsamples are frequently annotated. Facing such challenges, we propose a robust\nranking framework based on the principle of Hodge decomposition of imbalanced\nand incomplete ranking data. According to the HodgeRank theory, we find that\nthe major source of the contamination comes from the cyclic ranking component\nof the Hodge decomposition. This leads us to an outlier detection formulation\nas sparse approximations of the cyclic ranking projection. Taking a step\nfurther, it facilitates a novel outlier detection model as Huber's LASSO in\nrobust statistics. Moreover, simple yet scalable algorithms are developed based\non Linearized Bregman Iteration to achieve an even less biased estimator.\nStatistical consistency of outlier detection is established in both cases under\nnearly the same conditions. Our studies are supported by experiments with both\nsimulated examples and real-world data. The proposed framework provides us a\npromising tool for robust ranking with large scale crowdsourcing data arising\nfrom computer vision.\n",
			"Comment: 25 pages, 24 figures"
		],
		"date": [
			"2014-08-15",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1408.3467",
		"pdf_url": "http://arxiv.org/pdf/1408.3467.pdf"
	},
	"2": {
		"title": "Simple strategies versus optimal schedules in multi-agent patrolling",
		"creator": [
			"Kawamura, Akitoshi",
			"Soejima, Makoto"
		],
		"subject": [
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Computational Geometry",
			"Computer Science - Discrete Mathematics"
		],
		"description": [
			"  Suppose that a set of mobile agents, each with a predefined maximum speed,\nwant to patrol a fence together so as to minimize the longest time interval\nduring which a point on the fence is left unvisited. In 2011, Czyzowicz,\nG\\k{a}sieniec, Kosowski and Kranakis studied this problem for the settings\nwhere the fence is an interval (a line segment) and a circle, and conjectured\nthat the following simple strategies are always optimal: for Interval\nPatrolling, the simple strategy partitions the fence into subintervals, one for\neach agent, and lets each agent move back and forth in the assigned subinterval\nwith its maximum speed; for Circle Patrolling, the simple strategy is to choose\na number r, place the r fastest agents equidistantly around the circle, and\nmove them at the speed of the rth agent. Surprisingly, these conjectures were\nthen proved false: schedules were found (for some settings of maximum speeds)\nthat slightly outperform the simple strategies. In this paper, we are\ninterested in the ratio between the performances of optimal schedules and\nsimple strategies. For the two problems, we construct schedules that are 4/3\ntimes (for Interval Patrolling) and 21/20 times (for Circle Patrolling) as\ngood, respectively, as the simple strategies. We also propose a new variant, in\nwhich we want to patrol a single point under the constraint that each agent can\nonly visit the point some predefined time after its previous visit. We obtain\nsome similar ratio bounds and NP-hardness results related to this problem.\n",
			"Comment: 20 pages, 3 figures"
		],
		"date": [
			"2014-11-25",
			"2021-01-18"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1411.6853",
			"Theoretical Computer Science 839 (2020) 195-206",
			"doi:10.1016/j.tcs.2020.07.037"
		],
		"pdf_url": "http://arxiv.org/pdf/1411.6853.pdf"
	},
	"3": {
		"title": "A Concurrency-Optimal List-Based Set",
		"creator": [
			"Aksenov, Vitaly",
			"Gramoli, Vincent",
			"Kuznetsov, Petr",
			"Ravi, Srivatsan",
			"Shang, Di"
		],
		"subject": "Computer Science - Distributed, Parallel, and Cluster Computing",
		"description": "  Designing an efficient concurrent data structure is an important challenge\nthat is not easy to meet. Intuitively, efficiency of an implementation is\ndefined, in the first place, by its ability to process applied operations in\nparallel, without using unnecessary synchronization. As we show in this paper,\neven for a data structure as simple as a linked list used to implement the set\ntype, the most efficient algorithms known so far are not concurrency-optimal:\nthey may reject correct concurrent schedules.\n  We propose a new algorithm for the list-based set based on a value-aware\ntry-lock that we show to achieve optimal concurrency: it only rejects\nconcurrent schedules that violate correctness of the implemented set type. We\nshow empirically that reaching optimality does not induce a significant\noverhead. In fact, our implementation of the concurrency-optimal algorithm\noutperforms both the Lazy Linked List and the Harris-Michael state-of-the-art\nalgorithms.\n",
		"date": [
			"2015-02-05",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1502.01633",
		"pdf_url": "http://arxiv.org/pdf/1502.01633.pdf"
	},
	"4": {
		"title": "Memetics and Neural Models of Conspiracy Theories",
		"creator": "Duch, Włodzisław",
		"subject": [
			"Quantitative Biology - Neurons and Cognition",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Neural and Evolutionary Computing",
			"91E40",
			"I.2.6"
		],
		"description": [
			"  Conspiracy theories, or in general seriously distorted beliefs, are\nwidespread. How and why are they formed in the brain is still more a matter of\nspeculation rather than science. In this paper one plausible mechanisms is\ninvestigated: rapid freezing of high neuroplasticity (RFHN). Emotional arousal\nincreases neuroplasticity and leads to creation of new pathways spreading\nneural activation. Using the language of neurodynamics a meme is defined as\nquasi-stable associative memory attractor state. Depending on the temporal\ncharacteristics of the incoming information and the plasticity of the network,\nmemory may self-organize creating memes with large attractor basins, linking\nmany unrelated input patterns. Memes with fake rich associations distort\nrelations between memory states. Simulations of various neural network models\ntrained with competitive Hebbian learning (CHL) on stationary and\nnon-stationary data lead to the same conclusion: short learning with high\nplasticity followed by rapid decrease of plasticity leads to memes with large\nattraction basins, distorting input pattern representations in associative\nmemory. Such system-level models may be used to understand creation of\ndistorted beliefs and formation of conspiracy memes, understood as strong\nattractor states of the neurodynamics.\n",
			"Comment: 14 pages, 7 figures"
		],
		"date": [
			"2015-08-19",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1508.04561",
		"pdf_url": "http://arxiv.org/pdf/1508.04561.pdf"
	},
	"5": {
		"title": "Linear-time Learning on Distributions with Approximate Kernel Embeddings",
		"creator": [
			"Sutherland, Danica J.",
			"Oliva, Junier B.",
			"Póczos, Barnabás",
			"Schneider, Jeff"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": "  Many interesting machine learning problems are best posed by considering\ninstances that are distributions, or sample sets drawn from distributions.\nPrevious work devoted to machine learning tasks with distributional inputs has\ndone so through pairwise kernel evaluations between pdfs (or sample sets).\nWhile such an approach is fine for smaller datasets, the computation of an $N\n\\times N$ Gram matrix is prohibitive in large datasets. Recent scalable\nestimators that work over pdfs have done so only with kernels that use\nEuclidean metrics, like the $L_2$ distance. However, there are a myriad of\nother useful metrics available, such as total variation, Hellinger distance,\nand the Jensen-Shannon divergence. This work develops the first random features\nfor pdfs whose dot product approximates kernels using these non-Euclidean\nmetrics, allowing estimators using such kernels to scale to large datasets by\nworking in a primal space, without computing large Gram matrices. We provide an\nanalysis of the approximation error in using our proposed random features and\nshow empirically the quality of our approximation both in estimating a Gram\nmatrix and in solving learning tasks in real-world and synthetic data.\n",
		"date": [
			"2015-09-24",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1509.07553",
			"AAAI'16: Proceedings of the Thirtieth AAAI Conference on\n  Artificial Intelligence, February 2016, 2073-2079"
		],
		"pdf_url": "http://arxiv.org/pdf/1509.07553.pdf"
	},
	"6": {
		"title": "Deep Mean Maps",
		"creator": [
			"Oliva, Junier B.",
			"Sutherland, Danica J.",
			"Póczos, Barnabás",
			"Schneider, Jeff"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  The use of distributions and high-level features from deep architecture has\nbecome commonplace in modern computer vision. Both of these methodologies have\nseparately achieved a great deal of success in many computer vision tasks.\nHowever, there has been little work attempting to leverage the power of these\nto methodologies jointly. To this end, this paper presents the Deep Mean Maps\n(DMMs) framework, a novel family of methods to non-parametrically represent\ndistributions of features in convolutional neural network models.\n  DMMs are able to both classify images using the distribution of top-level\nfeatures, and to tune the top-level features for performing this task. We show\nhow to implement DMMs using a special mean map layer composed of typical CNN\noperations, making both forward and backward propagation simple.\n  We illustrate the efficacy of DMMs at analyzing distributional patterns in\nimage data in a synthetic data experiment. We also show that we extending\nexisting deep architectures with DMMs improves the performance of existing CNNs\non several challenging real-world datasets.\n",
		"date": [
			"2015-11-12",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1511.04150",
		"pdf_url": "http://arxiv.org/pdf/1511.04150.pdf"
	},
	"7": {
		"title": "Density Modeling of Images using a Generalized Normalization\n  Transformation",
		"creator": [
			"Ballé, Johannes",
			"Laparra, Valero",
			"Simoncelli, Eero P."
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  We introduce a parametric nonlinear transformation that is well-suited for\nGaussianizing data from natural images. The data are linearly transformed, and\neach component is then normalized by a pooled activity measure, computed by\nexponentiating a weighted sum of rectified and exponentiated components and a\nconstant. We optimize the parameters of the full transformation (linear\ntransform, exponents, weights, constant) over a database of natural images,\ndirectly minimizing the negentropy of the responses. The optimized\ntransformation substantially Gaussianizes the data, achieving a significantly\nsmaller mutual information between transformed components than alternative\nmethods including ICA and radial Gaussianization. The transformation is\ndifferentiable and can be efficiently inverted, and thus induces a density\nmodel on images. We show that samples of this model are visually similar to\nsamples of natural image patches. We demonstrate the use of the model as a\nprior probability density that can be used to remove additive noise. Finally,\nwe show that the transformation can be cascaded, with each layer optimized\nusing the same Gaussianization objective, thus offering an unsupervised method\nof optimizing a deep network architecture.\n",
			"Comment: published as a conference paper at ICLR 2016"
		],
		"date": [
			"2015-11-19",
			"2016-02-29"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1511.06281",
			"Int'l Conf on Learning Representations (ICLR), San Juan, Puerto\n  Rico, May 2016"
		],
		"pdf_url": "http://arxiv.org/pdf/1511.06281.pdf"
	},
	"8": {
		"title": "Nominal Automata with Name Binding",
		"creator": [
			"Schröder, Lutz",
			"Kozen, Dexter",
			"Milius, Stefan",
			"Wißmann, Thorsten"
		],
		"subject": [
			"Computer Science - Formal Languages and Automata Theory",
			"Computer Science - Logic in Computer Science",
			"F.1.1",
			"F.4.3"
		],
		"description": [
			"  Automata models for data languages (i.e. languages over infinite alphabets)\noften feature either global or local freshness operators. We show that Bollig\net al.'s session automata, which focus on global freshness, are equivalent to\nregular nondeterministic nominal automata (RNNA), a natural nominal automaton\nmodel with explicit name binding that has appeared implicitly in the semantics\nof nominal Kleene algebra (NKA), an extension of Kleene algebra with name\nbinding. The expected Kleene theorem for NKA is known to fail in one direction,\ni.e. there are nominal languages that can be accepted by an RNNA but are not\ndefinable in NKA; via session automata, we obtain a full Kleene theorem for\nRNNAs for an expression language that extends NKA with unscoped name binding.\nBased on the equivalence with RNNAs, we then slightly rephrase the known\nequivalence checking algorithm for session automata. Reinterpreting the data\nlanguage semantics of name binding by unrestricted instead of clean\nalpha-equivalence, we obtain a local freshness semantics as a quotient of the\nglobal freshness semantics. Under local freshness semantics, RNNAs turn out to\nbe equivalent to a natural subclass of Bojanczyk et al.'s nondeterministic\norbit-finite automata. We establish decidability of inclusion under local\nfreshness by modifying the RNNA-based algorithm; in summary, we obtain a\nformalism for local freshness in data languages that is reasonably expressive\nand has a decidable inclusion problem.\n",
			"Comment: Updated arguments A.26/A.27; rest unchanged"
		],
		"date": [
			"2016-03-04",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1603.01455",
		"pdf_url": "http://arxiv.org/pdf/1603.01455.pdf"
	},
	"9": {
		"title": "Predicting Shot Making in Basketball Learnt from Adversarial Multiagent\n  Trajectories",
		"creator": [
			"Harmon, Mark",
			"Ebrahimi, Abdolghani",
			"Lucey, Patrick",
			"Klabjan, Diego"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": "  In this paper, we predict the likelihood of a player making a shot in\nbasketball from multiagent trajectories. Previous approaches to similar\nproblems center on hand-crafting features to capture domain specific knowledge.\nAlthough intuitive, recent work in deep learning has shown this approach is\nprone to missing important predictive features. To circumvent this issue, we\npresent a convolutional neural network (CNN) approach where we initially\nrepresent the multiagent behavior as an image. To encode the adversarial nature\nof basketball, we use a multi-channel image which we then feed into a CNN.\nAdditionally, to capture the temporal aspect of the trajectories we \"fade\" the\nplayer trajectories. We find that this approach is superior to a traditional\nFFN model. By using gradient ascent to create images using an already trained\nCNN, we discover what features the CNN filters learn. Last, we find that a\ncombined CNN+FFN is the best performing network with an error rate of 39%.\n",
		"date": [
			"2016-09-15",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1609.04849",
		"pdf_url": "http://arxiv.org/pdf/1609.04849.pdf"
	},
	"10": {
		"title": "Distributed Searching of Partial Grids",
		"creator": [
			"Dereniowski, Dariusz",
			"Urbańska, Dorota"
		],
		"subject": [
			"Computer Science - Discrete Mathematics",
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Mathematics - Combinatorics",
			"05C85, 68R05",
			"G.2.2"
		],
		"description": "  We consider the following distributed pursuit-evasion problem. A team of\nmobile agents called searchers starts at an arbitrary node of an unknown\n$n$-node network. Their goal is to execute a search strategy that guarantees\ncapturing a fast and invisible intruder regardless of its movements using as\nfew agents as possible. We restrict our attention to networks that are embedded\ninto partial grids: nodes are placed on the plane at integer coordinates and\nonly nodes at distance one can be adjacent. We give a distributed algorithm for\nthe searchers that allow them to compute a connected and monotone strategy that\nguarantees searching any unknown partial grid with the use of $O(\\sqrt{n})$\nsearchers. As for a lower bound, not only there exist partial grids that\nrequire $\\Omega(\\sqrt{n})$ searchers, but we prove that for each distributed\nsearching algorithm there is a partial grid that forces the algorithm to use\n$\\Omega(\\sqrt{n})$ searchers but $O(\\log n)$ searchers are sufficient in the\noffline scenario. This gives a lower bound of $\\Omega(\\sqrt{n}/\\log n)$ in\nterms of achievable competitive ratio of any distributed algorithm.\n",
		"date": "2016-10-05",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1610.01458",
			"Theory of Computing Systems 63(8): 1819-1848 (2019)",
			"doi:10.1007/s00224-019-09948-6"
		],
		"pdf_url": "http://arxiv.org/pdf/1610.01458.pdf"
	},
	"11": {
		"title": "The reversible negacyclic codes over finite fields",
		"creator": [
			"Zhu, Shixin",
			"Pang, Binbin",
			"Sun, Zhonghua"
		],
		"subject": "Computer Science - Information Theory",
		"description": "  In this paper, by investigating the factor of the $x^n+1$, we deduce that the\nstructure of the reversible negacyclic code over the finite field\n$\\mathbb{F}_{q}$, where $q$ is an odd prime power. Though studying\n$q-$cyclotomic cosets modulo $2n$, we obtain the parameters of negacyclic BCH\ncode of length $n=\\frac{q^\\ell+1}{2}$ , $n=\\frac{q^m-1}{2(q-1)}$ and\n$n=\\frac{q^{t\\cdot2^\\tau}-1}{2(q^t+1)}$. Some optimal linear codes from\nnegacyclic codes are given. Finally, we discuss a class of MDS LCD negacyclic\ncodes.\n",
		"date": "2016-10-26",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1610.08206",
			"J Syst Sci Complex 31, 1065-1077 (2018)",
			"doi:10.1007/s11424-017-6301-7"
		],
		"pdf_url": "http://arxiv.org/pdf/1610.08206.pdf"
	},
	"12": {
		"title": "XCSP3: An Integrated Format for Benchmarking Combinatorial Constrained\n  Problems",
		"creator": [
			"Boussemart, Frederic",
			"Lecoutre, Christophe",
			"Audemard, Gilles",
			"Piette, Cédric"
		],
		"subject": "Computer Science - Artificial Intelligence",
		"description": [
			"  We propose a major revision of the format XCSP 2.1, called XCSP3, to build\nintegrated representations of combinatorial constrained problems. This new\nformat is able to deal with mono/multi optimization, many types of variables,\ncost functions, reification, views, annotations, variable quantification,\ndistributed, probabilistic and qualitative reasoning. The new format is made\ncompact, highly readable, and rather easy to parse. Interestingly, it captures\nthe structure of the problem models, through the possibilities of declaring\narrays of variables, and identifying syntactic and semantic groups of\nconstraints. The number of constraints is kept under control by introducing a\nlimited set of basic constraint forms, and producing almost automatically some\nof their variations through lifting, restriction, sliding, logical combination\nand relaxation mechanisms. As a result, XCSP3 encompasses practically all\nconstraints that can be found in major constraint solvers developed by the CP\ncommunity. A website, which is developed conjointly with the format, contains\nmany models and series of instances. The user can make sophisticated queries\nfor selecting instances from very precise criteria. The objective of XCSP3 is\nto ease the effort required to test and compare different algorithms by\nproviding a common test-bed of combinatorial constrained instances.\n",
			"Comment: 238 pages"
		],
		"date": [
			"2016-11-10",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1611.03398",
		"pdf_url": "http://arxiv.org/pdf/1611.03398.pdf"
	},
	"13": {
		"title": "Generative Models and Model Criticism via Optimized Maximum Mean\n  Discrepancy",
		"creator": [
			"Sutherland, Danica J.",
			"Tung, Hsiao-Yu",
			"Strathmann, Heiko",
			"De, Soumyajit",
			"Ramdas, Aaditya",
			"Smola, Alex",
			"Gretton, Arthur"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning",
			"Computer Science - Neural and Evolutionary Computing",
			"Statistics - Methodology"
		],
		"description": [
			"  We propose a method to optimize the representation and distinguishability of\nsamples from two probability distributions, by maximizing the estimated power\nof a statistical test based on the maximum mean discrepancy (MMD). This\noptimized MMD is applied to the setting of unsupervised learning by generative\nadversarial networks (GAN), in which a model attempts to generate realistic\nsamples, and a discriminator attempts to tell these apart from data samples. In\nthis context, the MMD may be used in two roles: first, as a discriminator,\neither directly on the samples, or on features of the samples. Second, the MMD\ncan be used to evaluate the performance of a generative model, by testing the\nmodel's samples against a reference data set. In the latter role, the optimized\nMMD is particularly helpful, as it gives an interpretable indication of how the\nmodel and data distributions differ, even in cases where individual model\nsamples are not easily distinguished either by eye or by classifier.\n",
			"Comment: Published at ICLR 2017 (public comments:\n  http://openreview.net/forum?id=HJWHIKqgl )"
		],
		"date": [
			"2016-11-14",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1611.04488",
		"pdf_url": "http://arxiv.org/pdf/1611.04488.pdf"
	},
	"14": {
		"title": "Metric Distortion of Social Choice Rules: Lower Bounds and Fairness\n  Properties",
		"creator": [
			"Goel, Ashish",
			"Krishnaswamy, Anilesh Kollagunta",
			"Munagala, Kamesh"
		],
		"subject": [
			"Computer Science - Computer Science and Game Theory",
			"Computer Science - Data Structures and Algorithms"
		],
		"description": "  We study social choice rules under the utilitarian distortion framework, with\nan additional metric assumption on the agents' costs over the alternatives. In\nthis approach, these costs are given by an underlying metric on the set of all\nagents plus alternatives. Social choice rules have access to only the ordinal\npreferences of agents but not the latent cardinal costs that induce them.\nDistortion is then defined as the ratio between the social cost (typically the\nsum of agent costs) of the alternative chosen by the mechanism at hand, and\nthat of the optimal alternative chosen by an omniscient algorithm. The\nworst-case distortion of a social choice rule is, therefore, a measure of how\nclose it always gets to the optimal alternative without any knowledge of the\nunderlying costs. Under this model, it has been conjectured that Ranked Pairs,\nthe well-known weighted-tournament rule, achieves a distortion of at most 3\n[Anshelevich et al. 2015]. We disprove this conjecture by constructing a\nsequence of instances which shows that the worst-case distortion of Ranked\nPairs is at least 5. Our lower bound on the worst case distortion of Ranked\nPairs matches a previously known upper bound for the Copeland rule, proving\nthat in the worst case, the simpler Copeland rule is at least as good as Ranked\nPairs. And as long as we are limited to (weighted or unweighted) tournament\nrules, we demonstrate that randomization cannot help achieve an expected\nworst-case distortion of less than 3. Using the concept of approximate\nmajorization within the distortion framework, we prove that Copeland and\nRandomized Dictatorship achieve low constant factor fairness-ratios (5 and 3\nrespectively), which is a considerable generalization of similar results for\nthe sum of costs and single largest cost objectives. In addition to all of the\nabove, we outline several interesting directions for further research in this\nspace.\n",
		"date": [
			"2016-12-08",
			"2017-05-08"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1612.02912",
		"pdf_url": "http://arxiv.org/pdf/1612.02912.pdf"
	},
	"15": {
		"title": "Integrating Reviews into Personalized Ranking for Cold Start\n  Recommendation",
		"creator": [
			"Hu, Guang-Neng",
			"Dai, Xin-Yu"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computation and Language"
		],
		"description": [
			"  Item recommendation task predicts a personalized ranking over a set of items\nfor each individual user. One paradigm is the rating-based methods that\nconcentrate on explicit feedbacks and hence face the difficulties in collecting\nthem. Meanwhile, the ranking-based methods are presented with rated items and\nthen rank the rated above the unrated. This paradigm takes advantage of widely\navailable implicit feedback. It, however, usually ignores a kind of important\ninformation: item reviews. Item reviews not only justify the preferences of\nusers, but also help alleviate the cold-start problem that fails the\ncollaborative filtering. In this paper, we propose two novel and simple models\nto integrate item reviews into Bayesian personalized ranking. In each model, we\nmake use of text features extracted from item reviews using word embeddings. On\ntop of text features we uncover the review dimensions that explain the\nvariation in users' feedback and these review factors represent a prior\npreference of users. Experiments on six real-world data sets show the benefits\nof leveraging item reviews on ranking prediction. We also conduct analyses to\nunderstand the proposed models.\n",
			"Comment: TextBPR"
		],
		"date": [
			"2017-01-30",
			"2018-12-05"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1701.08888",
			"PAKDD 2017",
			"doi:10.1007/978-3-319-57529-2_55"
		],
		"pdf_url": "http://arxiv.org/pdf/1701.08888.pdf"
	},
	"16": {
		"title": "Fixing an error in Caponnetto and de Vito (2007)",
		"creator": "Sutherland, Danica J.",
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning",
			"Mathematics - Statistics Theory"
		],
		"description": "  The seminal paper of Caponnetto and de Vito (2007) provides minimax-optimal\nrates for kernel ridge regression in a very general setting. Its proof,\nhowever, contains an error in its bound on the effective dimensionality. In\nthis note, we explain the mistake, provide a correct bound, and show that the\nmain theorem remains true.\n",
		"date": [
			"2017-02-09",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1702.02982",
		"pdf_url": "http://arxiv.org/pdf/1702.02982.pdf"
	},
	"17": {
		"title": "Founsure 1.0: An Erasure Code Library with Efficient Repair and Update\n  Features",
		"creator": "Arslan, Şuayb Ş.",
		"subject": "Computer Science - Information Theory",
		"description": [
			"  Founsure is an open-source software library that implements a\nmulti-dimensional graph-based erasure coding entirely based on fast exclusive\nOR (XOR) logic. Its implementation utilizes compiler optimizations and\nmulti-threading to generate the right assembly code for the given multi-core\nCPU architecture with vector processing capabilities. Founsure possesses\nimportant features that shall find various applications in modern data storage,\ncommunication, and networked computer systems, in which the data needs\nprotection against device, hardware, and node failures. As data size reached\nunprecedented levels, these systems have become hungry for network bandwidth,\ncomputational resources, and average consumed power. To address that, the\nproposed library provides a three-dimensional design space that trades off the\ncomputational complexity, coding overhead, and data/node repair bandwidth to\nmeet different requirements of modern distributed data storage and processing\nsystems. Founsure library enables efficient encoding, decoding,\nrepairs/rebuilds, and updates while all the required data storage and\ncomputations are distributed across the network nodes.\n",
			"Comment: Accepted to Elsevier SoftwareX, 2021"
		],
		"date": [
			"2017-02-23",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1702.07409",
		"pdf_url": "http://arxiv.org/pdf/1702.07409.pdf"
	},
	"18": {
		"title": "Unifying Message Passing Algorithms Under the Framework of Constrained\n  Bethe Free Energy Minimization",
		"creator": [
			"Zhang, Dan",
			"Song, Xiaohang",
			"Wang, Wenjin",
			"Fettweis, Gerhard",
			"Gao, Xiqi"
		],
		"subject": "Computer Science - Information Theory",
		"description": "  Variational message passing (VMP), belief propagation (BP) and expectation\npropagation (EP) have found their wide applications in complex statistical\nsignal processing problems. In addition to viewing them as a class of\nalgorithms operating on graphical models, this paper unifies them under an\noptimization framework, namely, Bethe free energy minimization with differently\nand appropriately imposed constraints. This new perspective in terms of\nconstraint manipulation can offer additional insights on the connection between\ndifferent message passing algorithms and is valid for a generic statistical\nmodel. It also founds a theoretical framework to systematically derive message\npassing variants. Taking the sparse signal recovery (SSR) problem as an\nexample, a low-complexity EP variant can be obtained by simple constraint\nreformulation, delivering better estimation performance with lower complexity\nthan the standard EP algorithm. Furthermore, we can resort to the framework for\nthe systematic derivation of hybrid message passing for complex inference\ntasks. Notably, a hybrid message passing algorithm is exemplarily derived for\njoint SSR and statistical model learning with near-optimal inference\nperformance and scalable complexity.\n",
		"date": [
			"2017-03-31",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1703.10932",
		"pdf_url": "http://arxiv.org/pdf/1703.10932.pdf"
	},
	"19": {
		"title": "Shared processor scheduling",
		"creator": [
			"Dereniowski, Dariusz",
			"Kubiak, Wieslaw"
		],
		"subject": [
			"Computer Science - Discrete Mathematics",
			"Computer Science - Data Structures and Algorithms",
			"90B35",
			"F.2.2"
		],
		"description": "  We study the shared processor scheduling problem with a single shared\nprocessor where a unit time saving (weight) obtained by processing a job on the\nshared processor depends on the job. A polynomial-time optimization algorithm\nhas been given for the problem with equal weights in the literature. This paper\nextends that result by showing an $O(n \\log n)$ optimization algorithm for a\nclass of instances in which non-decreasing order of jobs with respect to\nprocessing times provides a non-increasing order with respect to weights ---\nthis instance generalizes the unweighted case of the problem. This algorithm\nalso leads to a $\\frac{1}{2}$-approximation algorithm for the general weighted\nproblem. The complexity of the weighted problem remains open.\n",
		"date": "2017-04-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1704.06361",
			"Journal of Scheduling 21(6): 583-593 (2018)",
			"doi:10.1007/s10951-018-0566-0"
		],
		"pdf_url": "http://arxiv.org/pdf/1704.06361.pdf"
	},
	"20": {
		"title": "Asynchronous Announcements",
		"creator": [
			"Balbiani, Philippe",
			"van Ditmarsch, Hans",
			"González, Saúl Fernández"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Logic in Computer Science"
		],
		"description": [
			"  We propose a multi-agent epistemic logic of asynchronous announcements, where\ntruthful announcements are publicly sent but individually received by agents,\nand in the order in which they were sent. Additional to epistemic modalities\nthe logic contains dynamic modalities for making announcements and for\nreceiving them. What an agent believes is a function of her initial uncertainty\nand of the announcements she has received. Beliefs need not be truthful,\nbecause announcements already made may not yet have been received. As\nannouncements are true when sent, certain message sequences can be ruled out,\njust like inconsistent cuts in distributed computing.\n  We provide a complete axiomatization for this \\emph{asynchronous announcement\nlogic} (AA). It is a reduction system that also demonstrates that any formula\nin $AA$ is equivalent to one without dynamic modalities, just as for public\nannouncement logic. A detailed example modelling message exchanging processes\nin distributed computing in $AA$ closes our investigation.\n",
			"Comment: Originally presented at workshop Strategic Reasoning 2017 Liverpool"
		],
		"date": [
			"2017-05-08",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1705.03392",
		"pdf_url": "http://arxiv.org/pdf/1705.03392.pdf"
	},
	"21": {
		"title": "Bayesian Approaches to Distribution Regression",
		"creator": [
			"Law, Ho Chung Leon",
			"Sutherland, Danica J.",
			"Sejdinovic, Dino",
			"Flaxman, Seth"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": "  Distribution regression has recently attracted much interest as a generic\nsolution to the problem of supervised learning where labels are available at\nthe group level, rather than at the individual level. Current approaches,\nhowever, do not propagate the uncertainty in observations due to sampling\nvariability in the groups. This effectively assumes that small and large groups\nare estimated equally well, and should have equal weight in the final\nregression. We account for this uncertainty with a Bayesian distribution\nregression formalism, improving the robustness and performance of the model\nwhen group sizes vary. We frame our models in a neural network style, allowing\nfor simple MAP inference using backpropagation to learn the parameters, as well\nas MCMC-based inference which can fully propagate uncertainty. We demonstrate\nour approach on illustrative toy datasets, as well as on a challenging problem\nof predicting age from images.\n",
		"date": [
			"2017-05-11",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1705.04293",
			"Proceedings of the Twenty-First International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2018), PMLR 84:1167-1176"
		],
		"pdf_url": "http://arxiv.org/pdf/1705.04293.pdf"
	},
	"22": {
		"title": "Efficient and principled score estimation with Nystr\\\"om kernel\n  exponential families",
		"creator": [
			"Sutherland, Danica J.",
			"Strathmann, Heiko",
			"Arbel, Michael",
			"Gretton, Arthur"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning",
			"Statistics - Methodology"
		],
		"description": "  We propose a fast method with statistical guarantees for learning an\nexponential family density model where the natural parameter is in a\nreproducing kernel Hilbert space, and may be infinite-dimensional. The model is\nlearned by fitting the derivative of the log density, the score, thus avoiding\nthe need to compute a normalization constant. Our approach improves the\ncomputational efficiency of an earlier solution by using a low-rank,\nNystr\\\"om-like solution. The new solution retains the consistency and\nconvergence rates of the full-rank solution (exactly in Fisher distance, and\nnearly in other distances), with guarantees on the degree of cost and storage\nreduction. We evaluate the method in experiments on density estimation and in\nthe construction of an adaptive Hamiltonian Monte Carlo sampler. Compared to an\nexisting score learning approach using a denoising autoencoder, our estimator\nis empirically more data-efficient when estimating the score, runs faster, and\nhas fewer parameters (which can be tuned in a principled and interpretable\nway), in addition to providing statistical guarantees.\n",
		"date": [
			"2017-05-23",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1705.08360",
			"Proceedings of the Twenty-First International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2018), PMLR 84:652-660"
		],
		"pdf_url": "http://arxiv.org/pdf/1705.08360.pdf"
	},
	"23": {
		"title": "Learning the structure of Bayesian Networks via the bootstrap",
		"creator": [
			"Caravagna, Giulio",
			"Ramazzotti, Daniele"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  Learning the structure of dependencies among multiple random variables is a\nproblem of considerable theoretical and practical interest. Within the context\nof Bayesian Networks, a practical and surprisingly successful solution to this\nlearning problem is achieved by adopting score-functions optimisation schema,\naugmented with multiple restarts to avoid local optima. Yet, the conditions\nunder which such strategies work well are poorly understood, and there are also\nsome intrinsic limitations to learning the directionality of the interaction\namong the variables. Following an early intuition of Friedman and Koller, we\npropose to decouple the learning problem into two steps: first, we identify a\npartial ordering among input variables which constrains the structural learning\nproblem, and then propose an effective bootstrap-based algorithm to simulate\naugmented data sets, and select the most important dependencies among the\nvariables. By using several synthetic data sets, we show that our algorithm\nyields better recovery performance than the state of the art, increasing the\nchances of identifying a globally-optimal solution to the learning problem, and\nsolving also well-known identifiability issues that affect the standard\napproach. We use our new algorithm to infer statistical dependencies between\ncancer driver somatic mutations detected by high-throughput genome sequencing\ndata of multiple colorectal cancer patients. In this way, we also show how the\nproposed methods can shade new insights about cancer initiation, and\nprogression. Code: https://github.com/caravagn/Bootstrap-based-Learning\n",
		"date": [
			"2017-06-07",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1706.02386",
		"pdf_url": "http://arxiv.org/pdf/1706.02386.pdf"
	},
	"24": {
		"title": "User-centric Performance Optimization with Remote Radio Head Cooperation\n  in C-RAN",
		"creator": [
			"You, Lei",
			"Yuan, Di"
		],
		"subject": "Computer Science - Information Theory",
		"description": "  In a cloud radio access network (C-RAN), distributed remote radio heads\n(RRHs) are coordinated by baseband units (BBUs) in the cloud. The\ncentralization of signal processing provides flexibility for coordinated\nmulti-point transmission (CoMP) of RRHs to cooperatively serve user equipments\n(UEs). We target enhancing UEs' capacity performance, by jointly optimizing the\nselection of RRHs for serving UEs, i.e., resource allocation (and CoMP\nselection). We analyze the computational complexity of the problem. Next, we\nprove that under fixed CoMP selection, the optimal resource allocation amounts\nto solving a so-called iterated function. Towards user-centric network\noptimization, we propose an algorithm for the joint optimization problem,\naiming at maximumly scaling up the capacity for any target UE group of\ninterest. The proposed algorithm enables network-level performance evaluation\nfor quality of experience.\n",
		"date": [
			"2017-08-17",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1708.05311",
		"pdf_url": "http://arxiv.org/pdf/1708.05311.pdf"
	},
	"25": {
		"title": "V1: A Visual Query Language for Property Graphs",
		"creator": "Kogan, Lior",
		"subject": [
			"Computer Science - Databases",
			"H.2.3",
			"H.3.3"
		],
		"description": [
			"  The property graph is an increasingly popular data model. Pattern\nconstruction and pattern matching are important tasks when dealing with\nproperty graphs. Given a property graph schema S, a property graph G, and a\nquery pattern P, all expressed in language L, pattern matching is the process\nof finding, merging, and annotating subgraphs of G that match P. Expressive\npattern languages support topological constraints, property values constraints,\nnegations, quantifications, aggregations, and path semantics. Calculated\nproperties may be defined for vertices, edges, and subgraphs, and constraints\nmay be imposed on their evaluation result.\n  Query posers would like to construct patterns with minimal effort, minimal\ntrial and error, and in a manner that is coherent with the way they think. The\nability to express patterns in a way that is aligned with their mental\nprocesses is crucial to the flow of their work and to the quality of the\ninsights they can draw.\n  Since the capabilities of the human visual system with respect to pattern\nperception are remarkable, it is a matter of course that query patterns were to\nbe expressed visually. Visual query languages have the potential to be much\nmore 'user-friendly' than their textual counterparts in the sense that patterns\nmay be constructed and understood much more quickly and with much less mental\neffort. A long-standing challenge is to design a visual query language that is\ngeneric, has rich expressive power, and is highly receptive and productive. V1\nattempts to answer this challenge.\n  V1 is a declarative visual pattern query language for schema-based property\ngraphs. V1 supports property graphs with mixed (both directed and undirected)\nedges and unary edges, with multivalued and composite properties, and with null\nproperty values. V1 is generic, concise, has rich expressive power, and is\nhighly receptive and productive.\n",
			"Comment: 193 pages, 502 figures"
		],
		"date": [
			"2017-10-12",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1710.04470",
		"pdf_url": "http://arxiv.org/pdf/1710.04470.pdf"
	},
	"26": {
		"title": "MARGIN: Uncovering Deep Neural Networks using Graph Signal Analysis",
		"creator": [
			"Anirudh, Rushil",
			"Thiagarajan, Jayaraman J.",
			"Sridhar, Rahul",
			"Bremer, Peer-Timo"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Interpretability has emerged as a crucial aspect of building trust in machine\nlearning systems, aimed at providing insights into the working of complex\nneural networks that are otherwise opaque to a user. There are a plethora of\nexisting solutions addressing various aspects of interpretability ranging from\nidentifying prototypical samples in a dataset to explaining image predictions\nor explaining mis-classifications. While all of these diverse techniques\naddress seemingly different aspects of interpretability, we hypothesize that a\nlarge family of interepretability tasks are variants of the same central\nproblem which is identifying \\emph{relative} change in a model's prediction.\nThis paper introduces MARGIN, a simple yet general approach to address a large\nset of interpretability tasks MARGIN exploits ideas rooted in graph signal\nanalysis to determine influential nodes in a graph, which are defined as those\nnodes that maximally describe a function defined on the graph. By carefully\ndefining task-specific graphs and functions, we demonstrate that MARGIN\noutperforms existing approaches in a number of disparate interpretability\nchallenges.\n",
			"Comment: Technical Report"
		],
		"date": [
			"2017-11-14",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1711.05407",
		"pdf_url": "http://arxiv.org/pdf/1711.05407.pdf"
	},
	"27": {
		"title": "The Snow Team Problem (Clearing Directed Subgraphs by Mobile Agents)",
		"creator": [
			"Dereniowski, Dariusz",
			"Lingas, Andrzej",
			"Osula, Dorota",
			"Persson, Mia",
			"Zylinski, Pawel"
		],
		"subject": [
			"Computer Science - Discrete Mathematics",
			"05C85, 68W20, 68R10"
		],
		"description": [
			"  We study several problems of clearing subgraphs by mobile agents in digraphs.\nThe agents can move only along directed walks of a digraph and, depending on\nthe variant, their initial positions may be pre-specified. In general, for a\ngiven subset~$\\mathcal{S}$ of vertices of a digraph $D$ and a positive integer\n$k$, the objective is to determine whether there is a subgraph\n$H=(\\mathcal{V}_H,\\mathcal{A}_H)$ of $D$ such that (a) $\\mathcal{S} \\subseteq\n\\mathcal{V}_H$, (b) $H$ is the union of $k$ directed walks in $D$, and (c) the\nunderlying graph of $H$ includes a Steiner tree for $\\mathcal{S}$ in $D$. We\nprovide several results on the polynomial time tractability, hardness, and\nparameterized complexity of the problem.\n",
			"Comment: An extended abstract published in: Dariusz Dereniowski, Andrzej\n  Lingas, Mia Persson, Dorota Urbanska, Pawel Zylinski, The Snow Team Problem -\n  (Clearing Directed Subgraphs by Mobile Agents). FCT 2017: 190-203"
		],
		"date": "2017-12-01",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1712.00316",
			"Journal of Computer and System Sciences 102: 57-68 (2019)",
			"doi:10.1016/j.jcss.2018.11.002"
		],
		"pdf_url": "http://arxiv.org/pdf/1712.00316.pdf"
	},
	"28": {
		"title": "Atomic Norm Based Localization of Far-Field and Near-Field Signals with\n  Generalized Symmetric Arrays",
		"creator": [
			"Wu, Xiaohuan",
			"Zhu, Wei-Ping",
			"Yan, Jun"
		],
		"subject": [
			"Computer Science - Information Theory",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": "  Most localization methods for mixed far-field (FF) and near-field (NF)\nsources are based on uniform linear array (ULA) rather than sparse linear array\n(SLA). In this paper, we propose a localization method for mixed FF and NF\nsources based on the generalized symmetric linear arrays, which include ULAs,\nCantor array, Fractal array and many other SLAs. Our method consists of two\nsteps. In the first step, the high-order statistics of the array output is\nexploited to increase the degree of freedom. Then the direction-of-arrivals\n(DOAs) of the FF and NF sources are jointly estimated by using the recently\nproposed atomic norm minimization (ANM), which belongs to the gridless\nsuper-resolution method since the discretization of the parameter space is not\nrequired. In the second step, the ranges are given by MUSIC-like\none-dimensional searching. Simulations results are provided to demonstrate the\nadvantages of our method.\n",
		"date": [
			"2017-12-05",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1712.01497",
		"pdf_url": "http://arxiv.org/pdf/1712.01497.pdf"
	},
	"29": {
		"title": "Demystifying MMD GANs",
		"creator": [
			"Bińkowski, Mikołaj",
			"Sutherland, Danica J.",
			"Arbel, Michael",
			"Gretton, Arthur"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  We investigate the training and performance of generative adversarial\nnetworks using the Maximum Mean Discrepancy (MMD) as critic, termed MMD GANs.\nAs our main theoretical contribution, we clarify the situation with bias in GAN\nloss functions raised by recent work: we show that gradient estimators used in\nthe optimization process for both MMD GANs and Wasserstein GANs are unbiased,\nbut learning a discriminator based on samples leads to biased gradients for the\ngenerator parameters. We also discuss the issue of kernel choice for the MMD\ncritic, and characterize the kernel corresponding to the energy distance used\nfor the Cramer GAN critic. Being an integral probability metric, the MMD\nbenefits from training strategies recently developed for Wasserstein GANs. In\nexperiments, the MMD GAN is able to employ a smaller critic network than the\nWasserstein GAN, resulting in a simpler and faster-training algorithm with\nmatching performance. We also propose an improved measure of GAN convergence,\nthe Kernel Inception Distance, and show how to use it to dynamically adapt\nlearning rates during GAN training.\n",
			"Comment: Published at ICLR 2018: https://openreview.net/forum?id=r1lUOzWCW"
		],
		"date": [
			"2018-01-04",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1801.01401",
		"pdf_url": "http://arxiv.org/pdf/1801.01401.pdf"
	},
	"30": {
		"title": "Facebook Use of Sensitive Data for Advertising in Europe",
		"creator": [
			"Cabañas, José González",
			"Cuevas, Ángel",
			"Cuevas, Rubén"
		],
		"subject": [
			"Computer Science - Social and Information Networks",
			"Computer Science - Computers and Society"
		],
		"description": "  The upcoming European General Data Protection Regulation (GDPR) prohibits the\nprocessing and exploitation of some categories of personal data (health,\npolitical orientation, sexual preferences, religious beliefs, ethnic origin,\netc.) due to the obvious privacy risks that may be derived from a malicious use\nof such type of information. These categories are referred to as sensitive\npersonal data. Facebook has been recently fined EUR 1.2M in Spain for\ncollecting, storing and processing sensitive personal data for advertising\npurposes. This paper quantifies the portion of Facebook users in the European\nUnion (EU) who are labeled with interests linked to sensitive personal data.\nThe results of our study reveal that Facebook labels 73% EU users with\nsensitive interests. This corresponds to 40% of the overall EU population. We\nalso estimate that a malicious third-party could unveil the identity of\nFacebook users that have been assigned a sensitive interest at a cost as low as\nEUR 0.015 per user. Finally, we propose and implement a web browser extension\nto inform Facebook users of the sensitive interests Facebook has assigned them.\n",
		"date": "2018-02-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1802.05030",
			"27th USENIX Security Symposium (2018) 479-495"
		],
		"pdf_url": "http://arxiv.org/pdf/1802.05030.pdf"
	},
	"31": {
		"title": "Finding small-width connected path decompositions in polynomial time",
		"creator": [
			"Dereniowski, Dariusz",
			"Osula, Dorota",
			"Rzążewski, Paweł"
		],
		"subject": [
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Computational Complexity",
			"Computer Science - Discrete Mathematics"
		],
		"description": "  A connected path decomposition of a simple graph $G$ is a path decomposition\n$(X_1,\\ldots,X_l)$ such that the subgraph of $G$ induced by $X_1\\cup\\cdots\\cup\nX_i$ is connected for each $i\\in\\{1,\\ldots,l\\}$. The connected pathwidth of $G$\nis then the minimum width over all connected path decompositions of $G$. We\nprove that for each fixed $k$, the connected pathwidth of any input graph can\nbe computed in polynomial-time. This answers an open question raised by Fedor\nV. Fomin during the GRASTA 2017 workshop, since connected pathwidth is\nequivalent to the connected (monotone) node search game.\n",
		"date": [
			"2018-02-15",
			"2018-07-27"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1802.05501",
			"Theoretical Computer Science 794: 85-100 (2019)",
			"doi:10.1016/j.tcs.2019.03.039"
		],
		"pdf_url": "http://arxiv.org/pdf/1802.05501.pdf"
	},
	"32": {
		"title": "On tradeoffs between width- and fill-like graph parameters",
		"creator": [
			"Dereniowski, Dariusz",
			"Stański, Adam"
		],
		"subject": [
			"Computer Science - Discrete Mathematics",
			"Computer Science - Data Structures and Algorithms",
			"68R10, 68W05"
		],
		"description": "  In this work we consider two two-criteria optimization problems: given an\ninput graph, the goal is to find its interval (or chordal) supergraph that\nminimizes the number of edges and its clique number simultaneously. For the\ninterval supergraph, the problem can be restated as simultaneous minimization\nof the pathwidth $pw(G)$ and the profile $p(G)$ of the input graph $G$. We\nprove that for an arbitrary graph $G$ and an integer\n$t\\in\\{1,\\ldots,pw(G)+1\\}$, there exists an interval supergraph $G'$ of $G$\nsuch that for its clique number it holds\n$\\omega(G')\\leq(1+\\frac{2}{t})(pw(G)+1)$ and the number of its edges is bounded\nby $|E(G')|\\leq(t+2)p(G)$. In other words, the pathwidth and the profile of a\ngraph can be simultaneously minimized within the factors of $1+\\frac{2}{t}$\n(plus a small constant) and $t+2$, respectively. Note that for a fixed $t$,\nboth upper bounds provide constant factor approximations. On the negative side,\nwe show an example that proves that, for some graphs, there is no solution in\nwhich both parameters are optimal.\n  In case of finding a chordal supergraph, the two corresponding graph\nparameters that reflect its clique size and number of edges are the treewidth\nand fill-in. We obtain that the treewidth and the fill-in problems are also\n`orthogonal' in the sense that for some graphs, a solution that minimizes one\nof those parameters cannot minimize the other. As a motivating example, we\nrecall graph searching games which illustrates a need of simultaneous\nminimization of these pairs of graph parameters.\n",
		"date": "2018-02-26",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1802.09620",
			"Theory of Computing Systems 63(3): 450-465 (2019)",
			"doi:10.1007/s00224-018-9882-1"
		],
		"pdf_url": "http://arxiv.org/pdf/1802.09620.pdf"
	},
	"33": {
		"title": "Collaborative Filtering with Topic and Social Latent Factors\n  Incorporating Implicit Feedback",
		"creator": [
			"Hu, Guang-Neng",
			"Dai, Xin-Yu",
			"Qiu, Feng-Yu",
			"Xia, Rui",
			"Li, Tao",
			"Huang, Shu-Jian",
			"Chen, Jia-Jun"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Recommender systems (RSs) provide an effective way of alleviating the\ninformation overload problem by selecting personalized items for different\nusers. Latent factors based collaborative filtering (CF) has become the popular\napproaches for RSs due to its accuracy and scalability. Recently, online social\nnetworks and user-generated content provide diverse sources for recommendation\nbeyond ratings. Although {\\em social matrix factorization} (Social MF) and {\\em\ntopic matrix factorization} (Topic MF) successfully exploit social relations\nand item reviews, respectively, both of them ignore some useful information. In\nthis paper, we investigate the effective data fusion by combining the\naforementioned approaches. First, we propose a novel model {\\em \\mbox{MR3}} to\njointly model three sources of information (i.e., ratings, item reviews, and\nsocial relations) effectively for rating prediction by aligning the latent\nfactors and hidden topics. Second, we incorporate the implicit feedback from\nratings into the proposed model to enhance its capability and to demonstrate\nits flexibility. We achieve more accurate rating prediction on real-life\ndatasets over various state-of-the-art methods. Furthermore, we measure the\ncontribution from each of the three data sources and the impact of implicit\nfeedback from ratings, followed by the sensitivity analysis of hyperparameters.\nEmpirical studies demonstrate the effectiveness and efficacy of our proposed\nmodel and its extension.\n",
			"Comment: 27 pages, 11 figures, 6 tables, ACM TKDD 2018"
		],
		"date": "2018-03-26",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1803.09551",
			"doi:10.1145/3127873"
		],
		"pdf_url": "http://arxiv.org/pdf/1803.09551.pdf"
	},
	"34": {
		"title": "Some new bounds on LCD codes over finite fields",
		"creator": [
			"Pang, Binbin",
			"Zhu, Shixin",
			"Kai, Xiaoshan"
		],
		"subject": "Computer Science - Information Theory",
		"description": "  In this paper, we show that LCD codes are not equivalent to linear codes over\nsmall finite fields. The enumeration of binary optimal LCD codes is obtained.\nWe also get the exact value of LD$(n,2)$ over $\\mathbb{F}_3$ and\n$\\mathbb{F}_4$. We study the bound of LCD codes over $\\mathbb{F}_q$.\n",
		"date": "2018-04-02",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1804.00799",
			"Cryptogr. Commun. 12, 743-755 (2020)",
			"doi:10.1007/s12095-019-00417-y"
		],
		"pdf_url": "http://arxiv.org/pdf/1804.00799.pdf"
	},
	"35": {
		"title": "A second-order numerical method for the aggregation equations",
		"creator": [
			"Carrillo, José A.",
			"Fjordholm, Ulrik Skre",
			"Solem, Susanne"
		],
		"subject": "Mathematics - Numerical Analysis",
		"description": [
			"  Inspired by so-called TVD limiter-based second-order schemes for hyperbolic\nconservation laws, we develop a second-order accurate numerical method for\nmulti-dimensional aggregation equations. The method allows for simulations to\nbe continued after the first blow-up time of the solution. In the case of\nsymmetric, lambda-convex potentials with a possible Lipschitz singularity at\nthe origin we prove that the method converges in the Monge--Kantorovich\ndistance towards the unique gradient flow solution. Several numerical\nexperiments are presented to validate the second-order convergence rate and to\nexplore the performance of the scheme.\n",
			"Comment: Improved manuscript"
		],
		"date": [
			"2018-04-20",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1804.07796",
		"pdf_url": "http://arxiv.org/pdf/1804.07796.pdf"
	},
	"36": {
		"title": "Excitation Dropout: Encouraging Plasticity in Deep Neural Networks",
		"creator": [
			"Zunino, Andrea",
			"Bargal, Sarah Adel",
			"Morerio, Pietro",
			"Zhang, Jianming",
			"Sclaroff, Stan",
			"Murino, Vittorio"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  We propose a guided dropout regularizer for deep networks based on the\nevidence of a network prediction defined as the firing of neurons in specific\npaths. In this work, we utilize the evidence at each neuron to determine the\nprobability of dropout, rather than dropping out neurons uniformly at random as\nin standard dropout. In essence, we dropout with higher probability those\nneurons which contribute more to decision making at training time. This\napproach penalizes high saliency neurons that are most relevant for model\nprediction, i.e. those having stronger evidence. By dropping such high-saliency\nneurons, the network is forced to learn alternative paths in order to maintain\nloss minimization, resulting in a plasticity-like behavior, a characteristic of\nhuman brains too. We demonstrate better generalization ability, an increased\nutilization of network neurons, and a higher resilience to network compression\nusing several metrics over four image/video recognition benchmarks.\n",
			"Comment: This work is published in the International Journal of Computer\n  Vision (IJCV) in 2021"
		],
		"date": [
			"2018-05-23",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1805.09092",
		"pdf_url": "http://arxiv.org/pdf/1805.09092.pdf"
	},
	"37": {
		"title": "On gradient regularizers for MMD GANs",
		"creator": [
			"Arbel, Michael",
			"Sutherland, Danica J.",
			"Bińkowski, Mikołaj",
			"Gretton, Arthur"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  We propose a principled method for gradient-based regularization of the\ncritic of GAN-like models trained by adversarially optimizing the kernel of a\nMaximum Mean Discrepancy (MMD). We show that controlling the gradient of the\ncritic is vital to having a sensible loss function, and devise a method to\nenforce exact, analytical gradient constraints at no additional cost compared\nto existing approximate techniques based on additive regularizers. The new loss\nfunction is provably continuous, and experiments show that it stabilizes and\naccelerates training, giving image generation models that outperform\nstate-of-the art methods on $160 \\times 160$ CelebA and $64 \\times 64$\nunconditional ImageNet.\n",
			"Comment: Code at https://github.com/MichaelArbel/Scaled-MMD-GAN"
		],
		"date": [
			"2018-05-29",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1805.11565",
			"Advances in Neural Information Processing Systems 31 (NeurIPS\n  2018), 6700-6710"
		],
		"pdf_url": "http://arxiv.org/pdf/1805.11565.pdf"
	},
	"38": {
		"title": "Impersonation Detection in Line-of-Sight Underwater Acoustic Sensor\n  Networks",
		"creator": [
			"Aman, Waqas",
			"Rahman, Muhammad Mahboob Ur",
			"Qadir, Junaid",
			"Pervaiz, Haris",
			"Ni, Qiang"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": [
			"  This work considers a line-of-sight underwater acoustic sensor network\n(UWASN) consisting of $M$ underwater sensor nodes randomly deployed according\nto uniform distribution within a vertical half-disc (the so-called trusted\nzone). The sensor nodes report their sensed data to a sink node on water\nsurface on a shared underwater acoustic (UWA) reporting channel in a\ntime-division multiple-access (TDMA) fashion, while an active-yet-invisible\nadversary (so-called Eve) is present in the close vicinity who aims to inject\nmalicious data into the system by impersonating some Alice node. To this end,\nthis work first considers an additive white Gaussian noise (AWGN) UWA channel,\nand proposes a novel, multiple-features based, two-step method at the sink node\nto thwart the potential impersonation attack by Eve. Specifically, the sink\nnode exploits the noisy estimates of the distance, the angle of arrival, and\nthe location of the transmit node as device fingerprints to carry out a number\nof binary hypothesis tests (for impersonation detection) as well as a number of\nmaximum likelihood hypothesis tests (for transmitter identification when no\nimpersonation is detected). We provide closed-form expressions for the error\nprobabilities (i.e., the performance) of most of the hypothesis tests. We then\nconsider the case of a UWA with colored noise and frequency-dependent pathloss,\nand derive a maximum-likelihood (ML) distance estimator as well as the\ncorresponding Cramer-Rao bound (CRB). We then invoke the proposed two-step,\nimpersonation detection framework by utilizing distance as the sole feature.\nFinally, we provide detailed simulation results for both AWGN UWA channel and\nthe UWA channel with colored noise. Simulation results verify that the proposed\nscheme is indeed effective for a UWA channel with colored noise and\nfrequency-dependent pathloss.\n",
			"Comment: 13 pages and 13 figures. Accepted in IEEE Access 2018"
		],
		"date": [
			"2018-05-31",
			"2018-08-07"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1805.12403",
			"IEEE Access 2018",
			"doi:10.1109/ACCESS.2018.2863945"
		],
		"pdf_url": "http://arxiv.org/pdf/1805.12403.pdf"
	},
	"39": {
		"title": "Minimax Learning for Remote Prediction",
		"creator": [
			"Li, Cheuk Ting",
			"Wu, Xiugang",
			"Ozgur, Ayfer",
			"Gamal, Abbas El"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  The classical problem of supervised learning is to infer an accurate\npredictor of a target variable $Y$ from a measured variable $X$ by using a\nfinite number of labeled training samples. Motivated by the increasingly\ndistributed nature of data and decision making, in this paper we consider a\nvariation of this classical problem in which the prediction is performed\nremotely based on a rate-constrained description $M$ of $X$. Upon receiving\n$M$, the remote node computes an estimate $\\hat Y$ of $Y$. We follow the recent\nminimax approach to study this learning problem and show that it corresponds to\na one-shot minimax noisy source coding problem. We then establish information\ntheoretic bounds on the risk-rate Lagrangian cost and a general method to\ndesign a near-optimal descriptor-estimator pair, which can be viewed as a\nrate-constrained analog to the maximum conditional entropy principle used in\nthe classical minimax learning problem. Our results show that a naive\nestimate-compress scheme for rate-constrained prediction is not in general\noptimal.\n",
			"Comment: 10 pages, 4 figures, presented in part at ISIT 2018"
		],
		"date": [
			"2018-05-31",
			"2018-11-04"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1806.00071",
			"IEEE Transactions on Information Theory (Volume: 66, Issue: 12,\n  Dec. 2020)"
		],
		"pdf_url": "http://arxiv.org/pdf/1806.00071.pdf"
	},
	"40": {
		"title": "Droplet: Decentralized Authorization and Access Control for Encrypted\n  Data Streams",
		"creator": [
			"Shafagh, Hossein",
			"Burkhalter, Lukas",
			"Hithnawi, Anwar",
			"Ratnasamy, Sylvia"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": "  This paper presents Droplet, a decentralized data access control service.\nDroplet enables data owners to securely and selectively share their encrypted\ndata while guaranteeing data confidentiality in the presence of unauthorized\nparties and compromised data servers. Droplet's contribution lies in coupling\ntwo key ideas: (i) a cryptographically-enforced access control construction for\nencrypted data streams which enables users to define fine-grained\nstream-specific access policies, and (ii) a decentralized authorization service\nthat serves user-defined access policies. In this paper, we present Droplet's\ndesign, the reference implementation of Droplet, and the experimental results\nof three case-study applications deployed with Droplet: Fitbit activity\ntracker, Ava health tracker, and ECOviz smart meter dashboard, demonstrating\nDroplet's applicability for secure sharing of IoT streams.\n",
		"date": [
			"2018-06-06",
			"2021-01-21"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1806.02057",
			"USENIX Security 2020"
		],
		"pdf_url": "http://arxiv.org/pdf/1806.02057.pdf"
	},
	"41": {
		"title": "Explainable AI as a Social Microscope: A Case Study on Academic\n  Performance",
		"creator": [
			"Sargsyan, Anahit",
			"Karapetyan, Areg",
			"Woon, Wei Lee",
			"Alshamsi, Aamena"
		],
		"subject": "Computer Science - Computers and Society",
		"description": "  Academic performance is perceived as a product of complex interactions\nbetween students' overall experience, personal characteristics and upbringing.\nData science techniques, most commonly involving regression analysis and\nrelated approaches, serve as a viable means to explore this interplay. However,\nthese tend to extract factors with wide-ranging impact, while overlooking\nvariations specific to individual students. Focusing on each student's\npeculiarities is generally impossible with thousands or even hundreds of\nsubjects, yet data mining methods might prove effective in devising more\ntargeted approaches. For instance, subjects with shared characteristics can be\nassigned to clusters, which can then be examined separately with machine\nlearning algorithms, thereby providing a more nuanced view of the factors\naffecting individuals in a particular group. In this context, we introduce a\ndata science workflow allowing for fine-grained analysis of academic\nperformance correlates that captures the subtle differences in students'\nsensitivities to these factors. Leveraging the Local Interpretable\nModel-Agnostic Explanations (LIME) algorithm from the toolbox of Explainable\nArtificial Intelligence (XAI) techniques, the proposed pipeline yields groups\nof students having similar academic attainment indicators, rather than similar\nfeatures (e.g. familial background) as typically practiced in prior studies. As\na proof-of-concept case study, a rich longitudinal dataset is selected to\nevaluate the effectiveness of the proposed approach versus a standard\nregression model.\n",
		"date": [
			"2018-06-07",
			"2020-06-04"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1806.02615",
			"doi:10.1007/978-3-030-64583-0_24"
		],
		"pdf_url": "http://arxiv.org/pdf/1806.02615.pdf"
	},
	"42": {
		"title": "Ensemble Pruning based on Objection Maximization with a General\n  Distributed Framework",
		"creator": [
			"Bian, Yijun",
			"Wang, Yijun",
			"Yao, Yaqiang",
			"Chen, Huanhuan"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Ensemble pruning, selecting a subset of individual learners from an original\nensemble, alleviates the deficiencies of ensemble learning on the cost of time\nand space. Accuracy and diversity serve as two crucial factors while they\nusually conflict with each other. To balance both of them, we formalize the\nensemble pruning problem as an objection maximization problem based on\ninformation entropy. Then we propose an ensemble pruning method including a\ncentralized version and a distributed version, in which the latter is to speed\nup the former. At last, we extract a general distributed framework for ensemble\npruning, which can be widely suitable for most of the existing ensemble pruning\nmethods and achieve less time consuming without much accuracy degradation.\nExperimental results validate the efficiency of our framework and methods,\nparticularly concerning a remarkable improvement of the execution speed,\naccompanied by gratifying accuracy performance.\n",
			"Comment: Accepted by TNNLS"
		],
		"date": [
			"2018-06-13",
			"2019-09-30"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1806.04899",
			"doi:10.1109/TNNLS.2019.2945116"
		],
		"pdf_url": "http://arxiv.org/pdf/1806.04899.pdf"
	},
	"43": {
		"title": "Calamari - A High-Performance Tensorflow-based Deep Learning Package for\n  Optical Character Recognition",
		"creator": [
			"Wick, Christoph",
			"Reul, Christian",
			"Puppe, Frank"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Optical Character Recognition (OCR) on contemporary and historical data is\nstill in the focus of many researchers. Especially historical prints require\nbook specific trained OCR models to achieve applicable results (Springmann and\nL\\\"udeling, 2016, Reul et al., 2017a). To reduce the human effort for manually\nannotating ground truth (GT) various techniques such as voting and pretraining\nhave shown to be very efficient (Reul et al., 2018a, Reul et al., 2018b).\nCalamari is a new open source OCR line recognition software that both uses\nstate-of-the art Deep Neural Networks (DNNs) implemented in Tensorflow and\ngiving native support for techniques such as pretraining and voting. The\ncustomizable network architectures constructed of Convolutional Neural Networks\n(CNNS) and Long-ShortTerm-Memory (LSTM) layers are trained by the so-called\nConnectionist Temporal Classification (CTC) algorithm of Graves et al. (2006).\nOptional usage of a GPU drastically reduces the computation times for both\ntraining and prediction. We use two different datasets to compare the\nperformance of Calamari to OCRopy, OCRopus3, and Tesseract 4. Calamari reaches\na Character Error Rate (CER) of 0.11% on the UW3 dataset written in modern\nEnglish and 0.18% on the DTA19 dataset written in German Fraktur, which\nconsiderably outperforms the results of the existing softwares.\n",
			"Comment: 11 pages, 3 figures"
		],
		"date": [
			"2018-07-05",
			"2018-08-06"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1807.02004",
			"Digital Humanities Quarterly 14 (2), 2020"
		],
		"pdf_url": "http://arxiv.org/pdf/1807.02004.pdf"
	},
	"44": {
		"title": "An Adaptive Groundtrack Maintenance Scheme for Spacecraft with Electric\n  Propulsion",
		"creator": [
			"Leomanni, Mirko",
			"Garulli, Andrea",
			"Giannitrapani, Antonio",
			"Scortecci, Fabrizio"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": "  In this paper, the repeat-groundtrack orbit maintenance problem is addressed\nfor spacecraft driven by electric propulsion. An adaptive solution is proposed,\nwhich combines an hysteresis controller and a recursive least squares filter.\nThe controller provides a pulse-width modulated command to the thruster, in\ncompliance with the peculiarities of the electric propulsion technology. The\nfilter takes care of estimating a set of environmental disturbance parameters,\nfrom inertial position and velocity measurements. The resulting control scheme\nis able to compensate for the groundtrack drift due to atmospheric drag, in a\nfully autonomous manner. A numerical study of a low Earth orbit mission\nconfirms the effectiveness of the proposed method.\n",
		"date": [
			"2018-07-21",
			"2019-06-03"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1807.08109",
			"Acta Astronautica, Vol. 167, 2020",
			"doi:10.1016/j.actaastro.2019.11.035"
		],
		"pdf_url": "http://arxiv.org/pdf/1807.08109.pdf"
	},
	"45": {
		"title": "Proof Simplification and Automated Theorem Proving",
		"creator": "Kinyon, Michael",
		"subject": [
			"Computer Science - Logic in Computer Science",
			"Mathematics - Logic"
		],
		"description": "  The proofs first generated by automated theorem provers are far from optimal\nby any measure of simplicity. In this paper I describe a technique for\nsimplifying automated proofs. Hopefully this discussion will stimulate interest\nin the larger, still open, question of what reasonable measures of proof\nsimplicity might be.\n",
		"date": "2018-08-09",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1808.04251",
			"Philosophical Transactions of the Royal Society A, 377 (2018)",
			"doi:10.1098/rsta.2018.0034"
		],
		"pdf_url": "http://arxiv.org/pdf/1808.04251.pdf"
	},
	"46": {
		"title": "zoNNscan : a boundary-entropy index for zone inspection of neural models",
		"creator": [
			"Jaouen, Adel",
			"Merrer, Erwan Le"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  The training of deep neural network classifiers results in decision\nboundaries which geometry is still not well understood. This is in direct\nrelation with classification problems such as so called adversarial examples.\nWe introduce zoNNscan, an index that is intended to inform on the boundary\nuncertainty (in terms of the presence of other classes) around one given input\ndatapoint. It is based on confidence entropy, and is implemented through\nsampling in the multidimensional ball surrounding that input. We detail the\nzoNNscan index, give an algorithm for approximating it, and finally illustrate\nits benefits on four applications, including two important problems for the\nadoption of deep networks in critical systems: adversarial examples and corner\ncase inputs. We highlight that zoNNscan exhibits significantly higher values\nthan for standard inputs in those two problem classes.\n",
		"date": "2018-08-21",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1808.06797",
			"Springer CCIS 1379, 2020"
		],
		"pdf_url": "http://arxiv.org/pdf/1808.06797.pdf"
	},
	"47": {
		"title": "Exact entanglement cost of quantum states and channels under\n  PPT-preserving operations",
		"creator": [
			"Wang, Xin",
			"Wilde, Mark M."
		],
		"subject": [
			"Quantum Physics",
			"Computer Science - Information Theory"
		],
		"description": [
			"  This paper establishes single-letter formulas for the exact entanglement cost\nof generating bipartite quantum states and simulating quantum channels under\nfree quantum operations that completely preserve positivity of the partial\ntranspose (PPT). First, we establish that the exact entanglement cost of any\nbipartite quantum state under PPT-preserving operations is given by a\nsingle-letter formula, here called the $\\kappa$-entanglement of a quantum\nstate. This formula is calculable by a semidefinite program, thus allowing for\nan efficiently computable solution for general quantum states. Notably, this is\nthe first time that an entanglement measure for general bipartite states has\nbeen proven not only to possess a direct operational meaning but also to be\nefficiently computable, thus solving a question that has remained open since\nthe inception of entanglement theory over two decades ago. Next, we introduce\nand solve the exact entanglement cost for simulating quantum channels in both\nthe parallel and sequential settings, along with the assistance of free\nPPT-preserving operations. The entanglement cost in both cases is given by the\nsame single-letter formula and is equal to the largest $\\kappa$-entanglement\nthat can be shared by the sender and receiver of the channel. It is also\nefficiently computable by a semidefinite program.\n",
			"Comment: 54 pages, 8 figures; comments are welcome!"
		],
		"date": "2018-09-25",
		"type": "text",
		"identifier": "http://arxiv.org/abs/1809.09592",
		"pdf_url": "http://arxiv.org/pdf/1809.09592.pdf"
	},
	"48": {
		"title": "Deep Neural Networks for Estimation and Inference",
		"creator": [
			"Farrell, Max H.",
			"Liang, Tengyuan",
			"Misra, Sanjog"
		],
		"subject": [
			"Economics - Econometrics",
			"Computer Science - Machine Learning",
			"Mathematics - Statistics Theory",
			"Statistics - Machine Learning"
		],
		"description": "  We study deep neural networks and their use in semiparametric inference. We\nestablish novel rates of convergence for deep feedforward neural nets. Our new\nrates are sufficiently fast (in some cases minimax optimal) to allow us to\nestablish valid second-step inference after first-step estimation with deep\nlearning, a result also new to the literature. Our estimation rates and\nsemiparametric inference results handle the current standard architecture:\nfully connected feedforward neural networks (multi-layer perceptrons), with the\nnow-common rectified linear unit activation function and a depth explicitly\ndiverging with the sample size. We discuss other architectures as well,\nincluding fixed-width, very deep networks. We establish nonasymptotic bounds\nfor these deep nets for a general class of nonparametric regression-type loss\nfunctions, which includes as special cases least squares, logistic regression,\nand other generalized linear models. We then apply our theory to develop\nsemiparametric inference, focusing on causal parameters for concreteness, such\nas treatment effects, expected welfare, and decomposition effects. Inference in\nmany other semiparametric contexts can be readily obtained. We demonstrate the\neffectiveness of deep learning with a Monte Carlo analysis and an empirical\napplication to direct mail marketing.\n",
		"date": [
			"2018-09-26",
			"2019-09-18"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1809.09953",
			"Econometrica, vol 89, no 1, 181-213, 2021",
			"doi:10.3982/ECTA16901"
		],
		"pdf_url": "http://arxiv.org/pdf/1809.09953.pdf"
	},
	"49": {
		"title": "Optimal Energy Distribution with Energy Packet Networks",
		"creator": "Zhang, Yunxiao",
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": [
			"  We use Energy Packet Network paradigms to investigate energy distribution\nproblems in a computer system with energy harvesting and storages units. Our\ngoal is to minimize both the overall average response time of jobs at\nworkstations and the total rate of energy lost in the network. Energy is lost\nwhen it arrives at idle workstations which are empty. Energy is also lost in\nstorage leakages. We assume that the total rate of energy harvesting and the\nrate of jobs arriving at workstations are known. We also consider a special\ncase in which the total rate of energy harvesting is sufficiently large so that\nworkstations are less busy. In this case, energy is more likely to be sent to\nan idle workstation. Optimal solutions are obtained which minimize both the\noverall response time and energy loss under the constraint of a fixed energy\nharvesting rate.\n",
			"Comment: 17 pages, pre-print manuscript"
		],
		"date": "2018-09-26",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1810.07798",
			"Prob. Eng. Inf. Sci. 35 (2021) 75-91",
			"doi:10.1017/S0269964818000566"
		],
		"pdf_url": "http://arxiv.org/pdf/1810.07798.pdf"
	},
	"50": {
		"title": "Combining Similarity Features and Deep Representation Learning for\n  Stance Detection in the Context of Checking Fake News",
		"creator": [
			"Borges, Luís",
			"Martins, Bruno",
			"Calado, Pável"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Information Retrieval",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Fake news are nowadays an issue of pressing concern, given their recent rise\nas a potential threat to high-quality journalism and well-informed public\ndiscourse. The Fake News Challenge (FNC-1) was organized in 2017 to encourage\nthe development of machine learning-based classification systems for stance\ndetection (i.e., for identifying whether a particular news article agrees,\ndisagrees, discusses, or is unrelated to a particular news headline), thus\nhelping in the detection and analysis of possible instances of fake news. This\narticle presents a new approach to tackle this stance detection problem, based\non the combination of string similarity features with a deep neural\narchitecture that leverages ideas previously advanced in the context of\nlearning efficient text representations, document classification, and natural\nlanguage inference. Specifically, we use bi-directional Recurrent Neural\nNetworks, together with max-pooling over the temporal/sequential dimension and\nneural attention, for representing (i) the headline, (ii) the first two\nsentences of the news article, and (iii) the entire news article. These\nrepresentations are then combined/compared, complemented with similarity\nfeatures inspired on other FNC-1 approaches, and passed to a final layer that\npredicts the stance of the article towards the headline. We also explore the\nuse of external sources of information, specifically large datasets of sentence\npairs originally proposed for training and evaluating natural language\ninference methods, in order to pre-train specific components of the neural\nnetwork architecture (e.g., the RNNs used for encoding sentences). The obtained\nresults attest to the effectiveness of the proposed ideas and show that our\nmodel, particularly when considering pre-training and the combination of neural\nrepresentations together with similarity features, slightly outperforms the\nprevious state-of-the-art.\n",
			"Comment: Accepted for publication in the special issue of the ACM Journal of\n  Data and Information Quality (ACM JDIQ) on Combating Digital Misinformation\n  and Disinformation"
		],
		"date": "2018-11-01",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1811.00706",
			"Journal of Data and Information Quality (JDIQ) 11 (3), 1-26, 2019"
		],
		"pdf_url": "http://arxiv.org/pdf/1811.00706.pdf"
	},
	"51": {
		"title": "Estimation of Relationship between Stimulation Current and Force Exerted\n  during Isometric Contraction",
		"creator": [
			"Kitamura, Tomoya",
			"Hasegawa, Yuu",
			"Sakaino, Sho",
			"Tsuji, Toshiaki"
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Quantitative Biology - Neurons and Cognition"
		],
		"description": [
			"  In this study, we developed a method to estimate the relationship between\nstimulation current and volatility during isometric contraction. In functional\nelectrical stimulation (FES), joints are driven by applying voltage to muscles.\nThis technology has been used for a long time in the field of rehabilitation,\nand recently application oriented research has been reported. However,\nestimation of the relationship between stimulus value and exercise capacity has\nnot been discussed to a great extent. Therefore, in this study, a human muscle\nmodel was estimated using the transfer function estimation method with fast\nFourier transform. It was found that the relationship between stimulation\ncurrent and force exerted could be expressed by a first-order lag system. In\nverification of the force estimate, the ability of the proposed model to\nestimate the exerted force under steady state response was found to be good.\n",
			"Comment: (C) 2018 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material for advertising or\n  promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"
		],
		"date": [
			"2018-11-07",
			"2021-01-20"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1811.02795",
			"The 44th International Conference on Industrial Electronics,\n  Control and Instrumentation, pp. 5080-5085 (2018)",
			"doi:10.1109/IECON.2018.8591190"
		],
		"pdf_url": "http://arxiv.org/pdf/1811.02795.pdf"
	},
	"52": {
		"title": "Multilevel Schwarz preconditioners for singularly perturbed symmetric\n  reaction-diffusion systems",
		"creator": [
			"Lorca, Jose Pablo Lucero",
			"Kanschat, Guido"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"65N55 (Primary) 65N30, 65J10, 65F08 (Secondary)"
		],
		"description": [
			"  We present robust and highly parallel multilevel non-overlapping Schwarz\npreconditioners, to solve an interior penalty discontinuous Galerkin finite\nelement discretization of a system of steady state, singularly perturbed\nreaction-diffusion equations with a singular reaction operator, using a GMRES\nsolver. We provide proofs of convergence for the two-level setting and the\nmultigrid V-cycle as well as numerical results for a wide range of regimes.\n",
			"Comment: 19 pages, 5 tables"
		],
		"date": [
			"2018-11-09",
			"2020-09-05"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1811.03839",
			"Electron. Trans. Numer. Anal. Volume 54, pp. 89-107, 2021",
			"doi:10.1553/etna_vol54s89"
		],
		"pdf_url": "http://arxiv.org/pdf/1811.03839.pdf"
	},
	"53": {
		"title": "Learning deep kernels for exponential family densities",
		"creator": [
			"Wenliang, Li",
			"Sutherland, Danica J.",
			"Strathmann, Heiko",
			"Gretton, Arthur"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning",
			"Statistics - Methodology"
		],
		"description": "  The kernel exponential family is a rich class of distributions, which can be\nfit efficiently and with statistical guarantees by score matching. Being\nrequired to choose a priori a simple kernel such as the Gaussian, however,\nlimits its practical applicability. We provide a scheme for learning a kernel\nparameterized by a deep network, which can find complex location-dependent\nlocal features of the data geometry. This gives a very rich class of density\nmodels, capable of fitting complex structures on moderate-dimensional problems.\nCompared to deep density models fit via maximum likelihood, our approach\nprovides a complementary set of strengths and tradeoffs: in empirical studies,\nthe former can yield higher likelihoods, whereas the latter gives better\nestimates of the gradient of the log density, the score, which describes the\ndistribution's shape.\n",
		"date": [
			"2018-11-20",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1811.08357",
			"Proceedings of the 36th International Conference on Machine\n  Learning (ICML 2019), PMLR 97:6737-6746"
		],
		"pdf_url": "http://arxiv.org/pdf/1811.08357.pdf"
	},
	"54": {
		"title": "Stable Opponent Shaping in Differentiable Games",
		"creator": [
			"Letcher, Alistair",
			"Foerster, Jakob",
			"Balduzzi, David",
			"Rocktäschel, Tim",
			"Whiteson, Shimon"
		],
		"subject": [
			"Computer Science - Multiagent Systems",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  A growing number of learning methods are actually differentiable games whose\nplayers optimise multiple, interdependent objectives in parallel -- from GANs\nand intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful\napproach to improve learning dynamics in these games, accounting for player\ninfluence on others' updates. Learning with Opponent-Learning Awareness (LOLA)\nis a recent algorithm that exploits this response and leads to cooperation in\nsettings like the Iterated Prisoner's Dilemma. Although experimentally\nsuccessful, we show that LOLA agents can exhibit 'arrogant' behaviour directly\nat odds with convergence. In fact, remarkably few algorithms have theoretical\nguarantees applying across all (n-player, non-convex) games. In this paper we\npresent Stable Opponent Shaping (SOS), a new method that interpolates between\nLOLA and a stable variant named LookAhead. We prove that LookAhead converges\nlocally to equilibria and avoids strict saddles in all differentiable games.\nSOS inherits these essential guarantees, while also shaping the learning of\nopponents and consistently either matching or outperforming LOLA\nexperimentally.\n",
			"Comment: 20 pages, 7 figures"
		],
		"date": [
			"2018-11-20",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1811.08469",
		"pdf_url": "http://arxiv.org/pdf/1811.08469.pdf"
	},
	"55": {
		"title": "Unsupervised brain lesion segmentation from MRI using a convolutional\n  autoencoder",
		"creator": [
			"Atlason, Hans E.",
			"Love, Askell",
			"Sigurdsson, Sigurdur",
			"Gudnason, Vilmundur",
			"Ellingsen, Lotta M."
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  Lesions that appear hyperintense in both Fluid Attenuated Inversion Recovery\n(FLAIR) and T2-weighted magnetic resonance images (MRIs) of the human brain are\ncommon in the brains of the elderly population and may be caused by ischemia or\ndemyelination. Lesions are biomarkers for various neurodegenerative diseases,\nmaking accurate quantification of them important for both disease diagnosis and\nprogression. Automatic lesion detection using supervised learning requires\nmanually annotated images, which can often be impractical to acquire.\nUnsupervised lesion detection, on the other hand, does not require any manual\ndelineation; however, these methods can be challenging to construct due to the\nvariability in lesion load, placement of lesions, and voxel intensities. Here\nwe present a novel approach to address this problem using a convolutional\nautoencoder, which learns to segment brain lesions as well as the white matter,\ngray matter, and cerebrospinal fluid by reconstructing FLAIR images as conical\ncombinations of softmax layer outputs generated from the corresponding T1, T2,\nand FLAIR images. Some of the advantages of this model are that it accurately\nlearns to segment lesions regardless of lesion load, and it can be used to\nquickly and robustly segment new images that were not in the training set.\nComparisons with state-of-the-art segmentation methods evaluated on ground\ntruth manual labels indicate that the proposed method works well for generating\naccurate lesion segmentations without the need for manual annotations.\n",
		"date": "2018-11-23",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1811.09655",
			"doi:10.1117/12.2512953"
		],
		"pdf_url": "http://arxiv.org/pdf/1811.09655.pdf"
	},
	"56": {
		"title": "A Proof of Non-stationary Channel Polarization",
		"creator": [
			"Zhao, Yizhi",
			"Chi, Hongmei",
			"Xu, Shiwei",
			"Wu, Lingjuan",
			"Fan, Yuling"
		],
		"subject": "Computer Science - Information Theory",
		"description": "  In this letter, we consider the proof of non-stationary channel polarization\ntheory. First we construct a multi-channel stochastic process for the\nnon-stationary channel polarization operation. Then based on this stochastic\nprocess, we extend Ar{\\i}kan's standard martingale proof method on the average\nchannel capacity and average channel Bhattacharyya parameter, by which we have\nproved the non-stationary channel polarization theory.\n",
		"date": [
			"2018-12-01",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1812.00160",
		"pdf_url": "http://arxiv.org/pdf/1812.00160.pdf"
	},
	"57": {
		"title": "Determinant Codes with Helper-Independent Repair for Single and Multiple\n  Failures",
		"creator": [
			"Elyasi, Mehran",
			"Mohajer, Soheil"
		],
		"subject": "Computer Science - Information Theory",
		"description": "  Determinant codes are a class of exact-repair regenerating codes for\ndistributed storage systems with parameters (n, k = d, d). These codes cover\nthe entire trade-off between per-node storage and repair-bandwidth. In an\nearlier work of the authors, the repair data of the determinant code sent by a\nhelper node to repair a failed node depends on the identity of the other helper\nnodes participating in the process, which is practically undesired. In this\nwork, a new repair mechanism is proposed for determinant codes, which relaxes\nthis dependency, while preserving all other properties of the code. Moreover,\nit is shown that the determinant codes are capable of repairing multiple\nfailures, with a per-node repair-bandwidth which scales sub-linearly with the\nnumber of failures.\n",
		"date": [
			"2018-12-03",
			"2019-03-07"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1812.01142",
			"doi:10.1109/TIT.2019.2904294"
		],
		"pdf_url": "http://arxiv.org/pdf/1812.01142.pdf"
	},
	"58": {
		"title": "Deep Learning Model for Finding New Superconductors",
		"creator": [
			"Konno, Tomohiko",
			"Kurokawa, Hodaka",
			"Nabeshima, Fuyuki",
			"Sakishita, Yuki",
			"Ogawa, Ryo",
			"Hosako, Iwao",
			"Maeda, Atsutaka"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Condensed Matter - Materials Science",
			"Condensed Matter - Superconductivity",
			"Computer Science - Computation and Language",
			"Physics - Computational Physics"
		],
		"description": [
			"  Exploration of new superconductors still relies on the experience and\nintuition of experts and is largely a process of experimental trial and error.\nIn one study, only 3% of the candidate materials showed superconductivity.\nHere, we report the first deep learning model for finding new superconductors.\nWe introduced the method named \"reading periodic table\" which represented the\nperiodic table in a way that allows deep learning to learn to read the periodic\ntable and to learn the law of elements for the purpose of discovering novel\nsuperconductors that are outside the training data. It is recognized that it is\ndifficult for deep learning to predict something outside the training data.\nAlthough we used only the chemical composition of materials as information, we\nobtained an $R^{2}$ value of 0.92 for predicting $T_\\text{c}$ for materials in\na database of superconductors. We also introduced the method named \"garbage-in\"\nto create synthetic data of non-superconductors that do not exist.\nNon-superconductors are not reported, but the data must be required for deep\nlearning to distinguish between superconductors and non-superconductors. We\nobtained three remarkable results. The deep learning can predict\nsuperconductivity for a material with a precision of 62%, which shows the\nusefulness of the model; it found the recently discovered superconductor CaBi2\nand another one Hf0.5Nb0.2V2Zr0.3, neither of which is in the superconductor\ndatabase; and it found Fe-based high-temperature superconductors (discovered in\n2008) from the training data before 2008. These results open the way for the\ndiscovery of new high-temperature superconductor families. The candidate\nmaterials list, data, and method are openly available from the link\nhttps://github.com/tomo835g/Deep-Learning-to-find-Superconductors.\n",
			"Comment: 10 pages in main text. Deep learning, Machine learning, Material\n  search, Superconductors"
		],
		"date": [
			"2018-12-03",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1812.01995",
			"Phys. Rev. B 103, 014509 (2021)",
			"doi:10.1103/PhysRevB.103.014509"
		],
		"pdf_url": "http://arxiv.org/pdf/1812.01995.pdf"
	},
	"59": {
		"title": "Physics-Based Learning for Robotic Environmental Sensing",
		"creator": [
			"Khodayi-mehr, Reza",
			"Zavlanos, Michael M."
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  We propose a physics-based method to learn environmental fields (EFs) using a\nmobile robot. Common purely data-driven methods require prohibitively many\nmeasurements to accurately learn such complex EFs. Alternatively, physics-based\nmodels provide global knowledge of EFs but require experimental validation,\ndepend on uncertain parameters, and are intractable for mobile robots. To\naddress these challenges, we propose a Bayesian framework to select the most\nlikely physics-based models of EFs in real-time, from a pool of numerical\nsolutions generated offline as a function of the uncertain parameters.\nSpecifically, we focus on turbulent flow fields and utilize Gaussian processes\n(GPs) to construct statistical models for them, using the pool of numerical\nsolutions to inform their prior mean. To incorporate flow measurements into\nthese GPs, we control a custom-built mobile robot through a sequence of\nwaypoints that maximize the information content of the measurements. We\nexperimentally demonstrate that our proposed framework constructs a posterior\ndistribution of the flow field that better approximates the real flow compared\nto the prior numerical solutions and purely data-driven methods.\n",
			"Comment: 20 pages, 26 figures"
		],
		"date": [
			"2018-12-10",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1812.03894",
		"pdf_url": "http://arxiv.org/pdf/1812.03894.pdf"
	},
	"60": {
		"title": "Sparse evolutionary Deep Learning with over one million artificial\n  neurons on commodity hardware",
		"creator": [
			"Liu, Shiwei",
			"Mocanu, Decebal Constantin",
			"Matavalam, Amarsagar Reddy Ramapuram",
			"Pei, Yulong",
			"Pechenizkiy, Mykola"
		],
		"subject": [
			"Computer Science - Neural and Evolutionary Computing",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Artificial Neural Networks (ANNs) have emerged as hot topics in the research\ncommunity. Despite the success of ANNs, it is challenging to train and deploy\nmodern ANNs on commodity hardware due to the ever-increasing model size and the\nunprecedented growth in the data volumes. Particularly for microarray data, the\nvery-high dimensionality and the small number of samples make it difficult for\nmachine learning techniques to handle. Furthermore, specialized hardware such\nas Graphics Processing Unit (GPU) is expensive. Sparse neural networks are the\nleading approaches to address these challenges. However, off-the-shelf sparsity\ninducing techniques either operate from a pre-trained model or enforce the\nsparse structure via binary masks. The training efficiency of sparse neural\nnetworks cannot be obtained practically. In this paper, we introduce a\ntechnique allowing us to train truly sparse neural networks with fixed\nparameter count throughout training. Our experimental results demonstrate that\nour method can be applied directly to handle high dimensional data, while\nachieving higher accuracy than the traditional two phases approaches. Moreover,\nwe have been able to create truly sparse MultiLayer Perceptrons (MLPs) models\nwith over one million neurons and to train them on a typical laptop without\nGPU, this being way beyond what is possible with any state-of-the-art\ntechniques.\n",
			"Comment: 16 pages"
		],
		"date": [
			"2019-01-26",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1901.09181",
		"pdf_url": "http://arxiv.org/pdf/1901.09181.pdf"
	},
	"61": {
		"title": "Paracosm: A Language and Tool for Testing Autonomous Driving Systems",
		"creator": [
			"Majumdar, Rupak",
			"Mathur, Aman",
			"Pirron, Marcus",
			"Stegner, Laura",
			"Zufferey, Damien"
		],
		"subject": "Computer Science - Software Engineering",
		"description": [
			"  Systematic testing of autonomous vehicles operating in complex real-world\nscenarios is a difficult and expensive problem. We present Paracosm, a reactive\nlanguage for writing test scenarios for autonomous driving systems. Paracosm\nallows users to programmatically describe complex driving situations with\nspecific visual features, e.g., road layout in an urban environment, as well as\nreactive temporal behaviors of cars and pedestrians. Paracosm programs are\nexecuted on top of a game engine that provides realistic physics simulation and\nvisual rendering. The infrastructure allows systematic exploration of the state\nspace, both for visual features (lighting, shadows, fog) and for reactive\ninteractions with the environment (pedestrians, other traffic). We define a\nnotion of test coverage for Paracosm configurations based on combinatorial\ntesting and low dispersion sequences. Paracosm comes with an automatic test\ncase generator that uses random sampling for discrete parameters and\ndeterministic quasi-Monte Carlo generation for continuous parameters. Through\nan empirical evaluation, we demonstrate the modeling and testing capabilities\nof Paracosm on a suite of autonomous driving systems implemented using deep\nneural networks developed in research and education. We show how Paracosm can\nexpose incorrect behaviors or degraded performance.\n",
			"Comment: Technical Report to complement paper at FASE 2021"
		],
		"date": [
			"2019-02-04",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1902.01084",
		"pdf_url": "http://arxiv.org/pdf/1902.01084.pdf"
	},
	"62": {
		"title": "Local minimax rates for closeness testing of discrete distributions",
		"creator": [
			"Lam-Weil, Joseph",
			"Carpentier, Alexandra",
			"Sriperumbudur, Bharath K."
		],
		"subject": [
			"Mathematics - Statistics Theory",
			"Computer Science - Information Theory",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning",
			"62F03, 62G10, 62F35",
			"G.3",
			"I.2.6"
		],
		"description": "  We consider the closeness testing problem for discrete distributions. The\ngoal is to distinguish whether two samples are drawn from the same unspecified\ndistribution, or whether their respective distributions are separated in\n$L_1$-norm. In this paper, we focus on adapting the rate to the shape of the\nunderlying distributions, i.e. we consider \\textit{a local minimax setting}. We\nprovide, to the best of our knowledge, the first local minimax rate for the\nseparation distance up to logarithmic factors, together with a test that\nachieves it. In view of the rate, closeness testing turns out to be\nsubstantially harder than the related one-sample testing problem over a wide\nrange of cases.\n",
		"date": [
			"2019-02-01",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1902.01219",
		"pdf_url": "http://arxiv.org/pdf/1902.01219.pdf"
	},
	"63": {
		"title": "Consistent Risk Estimation in Moderately High-Dimensional Linear\n  Regression",
		"creator": [
			"Xu, Ji",
			"Maleki, Arian",
			"Rad, Kamiar Rahnama",
			"Hsu, Daniel"
		],
		"subject": [
			"Mathematics - Statistics Theory",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  Risk estimation is at the core of many learning systems. The importance of\nthis problem has motivated researchers to propose different schemes, such as\ncross validation, generalized cross validation, and Bootstrap. The theoretical\nproperties of such estimates have been extensively studied in the\nlow-dimensional settings, where the number of predictors $p$ is much smaller\nthan the number of observations $n$. However, a unifying methodology\naccompanied with a rigorous theory is lacking in high-dimensional settings.\nThis paper studies the problem of risk estimation under the moderately\nhigh-dimensional asymptotic setting $n,p \\rightarrow \\infty$ and $n/p\n\\rightarrow \\delta>1$ ($\\delta$ is a fixed number), and proves the consistency\nof three risk estimates that have been successful in numerical studies, i.e.,\nleave-one-out cross validation (LOOCV), approximate leave-one-out (ALO), and\napproximate message passing (AMP)-based techniques. A corner stone of our\nanalysis is a bound that we obtain on the discrepancy of the `residuals'\nobtained from AMP and LOOCV. This connection not only enables us to obtain a\nmore refined information on the estimates of AMP, ALO, and LOOCV, but also\noffers an upper bound on the convergence rate of each estimate.\n",
		"date": [
			"2019-02-05",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1902.01753",
		"pdf_url": "http://arxiv.org/pdf/1902.01753.pdf"
	},
	"64": {
		"title": "Fast Pedestrian Detection based on T-CENTRIST in infrared image",
		"creator": [
			"Ni, Hongyin",
			"Li, Fengping"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Pedestrian detection is a research hotspot and a difficult issue in the\ncomputer vision such as the Intelligent Surveillance System, the Intelligent\nTransport System, robotics, and automotive safety. However, the human body's\nposition, angle, and dress in a video scene are complicated and changeable,\nwhich have a great influence on the detection accuracy. In this paper, through\nthe analysis on the pros and cons of Census Transform Histogram (CENTRIST), a\nnovel feature is presented for human detection Ternary CENTRIST (T-CENTRIST).\nThe T-CENTRIST feature takes the relationship between each pixel and its\nneighborhood pixels into account. Meanwhile, it also considers the relevancy\namong these neighborhood pixels. Therefore, the proposed feature description\nmethod can reflect the silhouette of pedestrian more adequately and accurately\nthan that of CENTRIST. Second, we propose a fast pedestrian detection framework\nbased on T-CENTRIST in infrared image, which introduces the idea of extended\nblocks and the integral image. Finally, experimental results verify the\neffectiveness of the proposed pedestrian detection method.\n",
			"Comment: 14 pages, 6 figures"
		],
		"date": [
			"2019-02-17",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1902.06218",
		"pdf_url": "http://arxiv.org/pdf/1902.06218.pdf"
	},
	"65": {
		"title": "clusterNOR: A NUMA-Optimized Clustering Framework",
		"creator": [
			"Mhembere, Disa",
			"Zheng, Da",
			"Priebe, Carey E.",
			"Vogelstein, Joshua T.",
			"Burns, Randal"
		],
		"subject": "Computer Science - Distributed, Parallel, and Cluster Computing",
		"description": [
			"  Clustering algorithms are iterative and have complex data access patterns\nthat result in many small random memory accesses. The performance of parallel\nimplementations suffer from synchronous barriers for each iteration and skewed\nworkloads. We rethink the parallelization of clustering for modern non-uniform\nmemory architectures (NUMA) to maximizes independent, asynchronous computation.\nWe eliminate many barriers, reduce remote memory accesses, and maximize cache\nreuse. We implement the 'Clustering NUMA Optimized Routines' (clusterNOR)\nextensible parallel framework that provides algorithmic building blocks. The\nsystem is generic, we demonstrate nine modern clustering algorithms that have\nsimple implementations. clusterNOR includes (i) in-memory, (ii) semi-external\nmemory, and (iii) distributed memory execution, enabling computation for\nvarying memory and hardware budgets. For algorithms that rely on Euclidean\ndistance, clusterNOR defines an updated Elkan's triangle inequality pruning\nalgorithm that uses asymptotically less memory so that it works on\nbillion-point data sets. clusterNOR extends and expands the scope of the 'knor'\nlibrary for k-means clustering by generalizing underlying principles, providing\na uniform programming interface and expanding the scope to hierarchical and\nlinear algebraic classes of algorithms. The compound effect of our\noptimizations is an order of magnitude improvement in speed over other\nstate-of-the-art solutions, such as Spark's MLlib and Apple's Turi.\n",
			"Comment: arXiv admin note: Journal version of arXiv:1606.08905"
		],
		"date": [
			"2019-02-24",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1902.09527",
		"pdf_url": "http://arxiv.org/pdf/1902.09527.pdf"
	},
	"66": {
		"title": "Female Students in Computer Science Education: Understanding\n  Stereotypes, Negative Impacts, and Positive Motivation",
		"creator": [
			"Spieler, Bernadette",
			"Oates-Indruchova, Libora",
			"Slany, Wolfgang"
		],
		"subject": "Computer Science - Computers and Society",
		"description": [
			"  Although female students engage in coding courses, only a small percentage of\nthem plan to pursue computer science (CS) as a major when choosing a career\npath. Gender differences in interests, sense-of belonging, self-efficacy, and\nengagement in CS are already present at an early age. This article presents an\noverview of gender stereotypes in CS and summarizes negative impressions female\nstudents between 12 and 15 experience during CS classes, as well as influences\nthat may be preventing girls from taking an interest in CS. The study herein\ndraws on a systematic review of 28 peer-reviewed articles published since 2006.\nThe findings of the review point to the existence of the stereotypical image of\na helpless, uninterested, and unhappy \"Girl in Computer Science\". It may be\neven more troubling a construct than that of the geeky, nerdy male counterpart,\nas it is rooted in the notion that women are technologically inept and\nill-suited for CS careers. Thus, girls think they must be naturally\nhyper-intelligent in order to pursue studies in CS, as opposed to motivated,\ninterested, and focused to succeed in those fields. Second, based on the\nreview, suggestions for inclusive CS education were summarized. The authors\nargue that in order to make CS more inclusive for girls, cultural implications,\nas well as stereotypization in CS classrooms and CS education, need to be\nrecognized as harmful. These stereotypes and cultural ideas should be\neliminated by empowering female students through direct encouragement,\nmentoring programs, or girls-only initiatives.\n",
			"Comment: 22 pages"
		],
		"date": [
			"2019-03-04",
			"2021-01-08"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1903.01190",
			"doi:10.1615/JWomenMinorScienEng.2020028567"
		],
		"pdf_url": "http://arxiv.org/pdf/1903.01190.pdf"
	},
	"67": {
		"title": "A behavior driven approach for sampling rare event situations for\n  autonomous vehicles",
		"creator": [
			"Sarkar, Atrisha",
			"Czarnecki, Krzysztof"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Computer Science - Multiagent Systems",
			"Computer Science - Robotics"
		],
		"description": "  Performance evaluation of urban autonomous vehicles requires a realistic\nmodel of the behavior of other road users in the environment. Learning such\nmodels from data involves collecting naturalistic data of real-world human\nbehavior. In many cases, acquisition of this data can be prohibitively\nexpensive or intrusive. Additionally, the available data often contain only\ntypical behaviors and exclude behaviors that are classified as rare events. To\nevaluate the performance of AV in such situations, we develop a model of\ntraffic behavior based on the theory of bounded rationality. Based on the\nexperiments performed on a large naturalistic driving data, we show that the\ndeveloped model can be applied to estimate probability of rare events, as well\nas to generate new traffic situations.\n",
		"date": "2019-03-04",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1903.01539",
			"doi:10.1109/iros40897.2019.8967715"
		],
		"pdf_url": "http://arxiv.org/pdf/1903.01539.pdf"
	},
	"68": {
		"title": "Complexity Results and Algorithms for Bipolar Argumentation",
		"creator": [
			"Karamlou, Amin",
			"Čyras, Kristijonas",
			"Toni, Francesca"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computational Complexity"
		],
		"description": [
			"  Bipolar Argumentation Frameworks (BAFs) admit several interpretations of the\nsupport relation and diverging definitions of semantics. Recently, several\nclasses of BAFs have been captured as instances of bipolar Assumption-Based\nArgumentation, a class of Assumption-Based Argumentation (ABA). In this paper,\nwe establish the complexity of bipolar ABA, and consequently of several classes\nof BAFs. In addition to the standard five complexity problems, we analyse the\nrarely-addressed extension enumeration problem too. We also advance\nbacktracking-driven algorithms for enumerating extensions of bipolar ABA\nframeworks, and consequently of BAFs under several interpretations. We prove\nsoundness and completeness of our algorithms, describe their implementation and\nprovide a scalability evaluation. We thus contribute to the study of the as yet\nuninvestigated complexity problems of (variously interpreted) BAFs as well as\nof bipolar ABA, and provide the lacking implementations thereof.\n",
			"Comment: Paper accepted for publication at AAMAS 2019"
		],
		"date": "2019-03-05",
		"type": "text",
		"identifier": "http://arxiv.org/abs/1903.01964",
		"pdf_url": "http://arxiv.org/pdf/1903.01964.pdf"
	},
	"69": {
		"title": "Heterogeneous Graph Attention Network",
		"creator": [
			"Wang, Xiao",
			"Ji, Houye",
			"Shi, Chuan",
			"Wang, Bai",
			"Cui, Peng",
			"Yu, P.",
			"Ye, Yanfang"
		],
		"subject": "Computer Science - Social and Information Networks",
		"description": [
			"  Graph neural network, as a powerful graph representation technique based on\ndeep learning, has shown superior performance and attracted considerable\nresearch interest. However, it has not been fully considered in graph neural\nnetwork for heterogeneous graph which contains different types of nodes and\nlinks. The heterogeneity and rich semantic information bring great challenges\nfor designing a graph neural network for heterogeneous graph. Recently, one of\nthe most exciting advancements in deep learning is the attention mechanism,\nwhose great potential has been well demonstrated in various areas. In this\npaper, we first propose a novel heterogeneous graph neural network based on the\nhierarchical attention, including node-level and semantic-level attentions.\nSpecifically, the node-level attention aims to learn the importance between a\nnode and its metapath based neighbors, while the semantic-level attention is\nable to learn the importance of different meta-paths. With the learned\nimportance from both node-level and semantic-level attention, the importance of\nnode and meta-path can be fully considered. Then the proposed model can\ngenerate node embedding by aggregating features from meta-path based neighbors\nin a hierarchical manner. Extensive experimental results on three real-world\nheterogeneous graphs not only show the superior performance of our proposed\nmodel over the state-of-the-arts, but also demonstrate its potentially good\ninterpretability for graph analysis.\n",
			"Comment: 10 pages"
		],
		"date": [
			"2019-03-18",
			"2021-01-20"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1903.07293",
			"WWW 2019"
		],
		"pdf_url": "http://arxiv.org/pdf/1903.07293.pdf"
	},
	"70": {
		"title": "Capacity of Quantum Private Information Retrieval with Multiple Servers",
		"creator": [
			"Song, Seunghoan",
			"Hayashi, Masahito"
		],
		"subject": [
			"Quantum Physics",
			"Computer Science - Cryptography and Security",
			"Computer Science - Information Theory"
		],
		"description": "  We study the capacity of quantum private information retrieval (QPIR) with\nmultiple servers. In the QPIR problem with multiple servers, a user retrieves a\nclassical file by downloading quantum systems from multiple servers each of\nwhich contains the copy of a classical file set while the identity of the\ndownloaded file is not leaked to each server. The QPIR capacity is defined as\nthe maximum rate of the file size over the whole dimension of the downloaded\nquantum systems. When the servers are assumed to share prior entanglement, we\nprove that the QPIR capacity with multiple servers is 1 regardless of the\nnumber of servers and files. We construct a rate-one protocol only with two\nservers. This capacity-achieving protocol outperforms its classical counterpart\nin the sense of capacity, server secrecy, and upload cost. The strong converse\nbound is derived concisely without using any secrecy condition. We also prove\nthat the capacity of multi-round QPIR is 1.\n",
		"date": [
			"2019-03-25",
			"2021-01-19"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1903.10209",
			"IEEE Transactions on Information Theory, vol. 67, no. 1, pp.\n  452-463, Jan. 2021",
			"doi:10.1109/TIT.2020.3022515."
		],
		"pdf_url": "http://arxiv.org/pdf/1903.10209.pdf"
	},
	"71": {
		"title": "A linear bound on the k-rendezvous time for primitive sets of NZ\n  matrices",
		"creator": [
			"Catalano, Costanza",
			"Azfar, Umer",
			"Charlier, Ludovic",
			"Jungers, Raphaël"
		],
		"subject": [
			"Computer Science - Discrete Mathematics",
			"Computer Science - Computation and Language",
			"Mathematics - Combinatorics",
			"05C50, 15B36, 68R05",
			"G.2.1"
		],
		"description": [
			"  A set of nonnegative matrices is called primitive if there exists a product\nof these matrices that is entrywise positive. Motivated by recent results\nrelating synchronizing automata and primitive sets, we study the length of the\nshortest product of a primitive set having a column or a row with k positive\nentries, called its k-rendezvous time (k-RT}), in the case of sets of matrices\nhaving no zero rows and no zero columns. We prove that the k-RT is at most\nlinear w.r.t. the matrix size n for small k, while the problem is still open\nfor synchronizing automata. We provide two upper bounds on the k-RT: the second\nis an improvement of the first one, although the latter can be written in\nclosed form. We then report numerical results comparing our upper bounds on the\nk-RT with heuristic approximation methods.\n",
			"Comment: 27 pages, 10 figure"
		],
		"date": [
			"2019-03-25",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1903.10421",
		"pdf_url": "http://arxiv.org/pdf/1903.10421.pdf"
	},
	"72": {
		"title": "Hybrid Satellite-Terrestrial Communication Networks for the Maritime\n  Internet of Things: Key Technologies, Opportunities, and Challenges",
		"creator": [
			"Wei, Te",
			"Feng, Wei",
			"Chen, Yunfei",
			"Wang, Cheng-Xiang",
			"Ge, Ning",
			"Lu, Jianhua"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": "  With the rapid development of marine activities, there has been an increasing\nnumber of maritime mobile terminals, as well as a growing demand for high-speed\nand ultra-reliable maritime communications to keep them connected.\nTraditionally, the maritime Internet of Things (IoT) is enabled by maritime\nsatellites. However, satellites are seriously restricted by their high latency\nand relatively low data rate. As an alternative, shore & island-based base\nstations (BSs) can be built to extend the coverage of terrestrial networks\nusing fourth-generation (4G), fifth-generation (5G), and beyond 5G services.\nUnmanned aerial vehicles can also be exploited to serve as aerial maritime BSs.\nDespite of all these approaches, there are still open issues for an efficient\nmaritime communication network (MCN). For example, due to the complicated\nelectromagnetic propagation environment, the limited geometrically available BS\nsites, and rigorous service demands from mission-critical applications,\nconventional communication and networking theories and methods should be\ntailored for maritime scenarios. Towards this end, we provide a survey on the\ndemand for maritime communications, the state-of-the-art MCNs, and key\ntechnologies for enhancing transmission efficiency, extending network coverage,\nand provisioning maritime-specific services. Future challenges in developing an\nenvironment-aware, service-driven, and integrated satellite-air-ground MCN to\nbe smart enough to utilize external auxiliary information, e.g., sea state and\natmosphere conditions, are also discussed.\n",
		"date": [
			"2019-03-28",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1903.11814",
		"pdf_url": "http://arxiv.org/pdf/1903.11814.pdf"
	},
	"73": {
		"title": "High Fidelity Face Manipulation with Extreme Poses and Expressions",
		"creator": [
			"Fu, Chaoyou",
			"Hu, Yibo",
			"Wu, Xiang",
			"Wang, Guoli",
			"Zhang, Qian",
			"He, Ran"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Face manipulation has shown remarkable advances with the flourish of\nGenerative Adversarial Networks. However, due to the difficulties of\ncontrolling structures and textures, it is challenging to model poses and\nexpressions simultaneously, especially for the extreme manipulation at\nhigh-resolution. In this paper, we propose a novel framework that simplifies\nface manipulation into two correlated stages: a boundary prediction stage and a\ndisentangled face synthesis stage. The first stage models poses and expressions\njointly via boundary images. Specifically, a conditional encoder-decoder\nnetwork is employed to predict the boundary image of the target face in a\nsemi-supervised way. Pose and expression estimators are introduced to improve\nthe prediction performance. In the second stage, the predicted boundary image\nand the input face image are encoded into the structure and the texture latent\nspace by two encoder networks, respectively. A proxy network and a feature\nthreshold loss are further imposed to disentangle the latent space.\nFurthermore, due to the lack of high-resolution face manipulation databases to\nverify the effectiveness of our method, we collect a new high-quality\nMulti-View Face (MVF-HQ) database. It contains 120,283 images at 6000x4000\nresolution from 479 identities with diverse poses, expressions, and\nilluminations. MVF-HQ is much larger in scale and much higher in resolution\nthan publicly available high-resolution face manipulation databases. We will\nrelease MVF-HQ soon to push forward the advance of face manipulation.\nQualitative and quantitative experiments on four databases show that our method\ndramatically improves the synthesis quality.\n",
			"Comment: Accepted by IEEE Transactions on Information Forensics and Security\n  (TIFS)"
		],
		"date": [
			"2019-03-28",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1903.12003",
		"pdf_url": "http://arxiv.org/pdf/1903.12003.pdf"
	},
	"74": {
		"title": "Nonlinear fourth order Taylor expansion of lattice Boltzmann schemes",
		"creator": "Dubois, François",
		"subject": [
			"Mathematics - Numerical Analysis",
			"Computer Science - Discrete Mathematics",
			"Physics - Classical Physics"
		],
		"description": "  We propose a formal expansion of multiple relaxation times lattice Boltzmann\nschemes in terms of a single infinitesimal numerical variable. The result is a\nsystem of partial differential equations for the conserved moments of the\nlattice Boltzmann scheme. The expansion is presented in the nonlinear case up\nto fourth order accuracy. The asymptotic corrections of the nonconserved\nmoments are developed in terms of equilibrium values and partial differentials\nof the conserved moments. Both expansions are coupled and conduct to explicit\ncompact formulas. The new algebraic expressions are validated with previous\nresults obtained with this approach. The example of isothermal D2Q9 lattice\nBoltzmann scheme illustrates the theoretical framework.\n",
		"date": [
			"2019-03-29",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1903.12417",
		"pdf_url": "http://arxiv.org/pdf/1903.12417.pdf"
	},
	"75": {
		"title": "DNA: Deeply-supervised Nonlinear Aggregation for Salient Object\n  Detection",
		"creator": [
			"Liu, Yun",
			"Cheng, Ming-Ming",
			"Zhang, Xinyu",
			"Nie, Guang-Yu",
			"Wang, Meng"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Recent progress on salient object detection mainly aims at exploiting how to\neffectively integrate multi-scale convolutional features in convolutional\nneural networks (CNNs). Many popular methods impose deep supervision to perform\nside-output predictions that are linearly aggregated for final saliency\nprediction. In this paper, we theoretically and experimentally demonstrate that\nlinear aggregation of side-output predictions is suboptimal, and it only makes\nlimited use of the side-output information obtained by deep supervision. To\nsolve this problem, we propose Deeply-supervised Nonlinear Aggregation (DNA)\nfor better leveraging the complementary information of various side-outputs.\nCompared with existing methods, it i) aggregates side-output features rather\nthan predictions, and ii) adopts nonlinear instead of linear transformations.\nExperiments demonstrate that DNA can successfully break through the bottleneck\nof current linear approaches. Specifically, the proposed saliency detector, a\nmodified U-Net architecture with DNA, performs favorably against\nstate-of-the-art methods on various datasets and evaluation metrics without\nbells and whistles.\n",
			"Comment: arXiv admin note: text overlap with arXiv:1812.10956"
		],
		"date": [
			"2019-03-27",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1903.12476",
		"pdf_url": "http://arxiv.org/pdf/1903.12476.pdf"
	},
	"76": {
		"title": "Rank Reduction in Bimatrix Games",
		"creator": [
			"Heyman, Joseph L.",
			"Gupta, Abhishek"
		],
		"subject": "Computer Science - Computer Science and Game Theory",
		"description": [
			"  The rank of a bimatrix game is defined as the rank of the sum of the payoff\nmatrices of the two players. The rank of a game is known to impact both the\nmost suitable computation methods for determining a solution and the expressive\npower of the game. Under certain conditions on the payoff matrices, we devise a\nmethod that reduces the rank of the game without changing the equilibrium of\nthe game. We leverage matrix pencil theory and the Wedderburn rank reduction\nformula to arrive at our results. We also present a constructive proof of the\nfact that in a generic square game, the rank of the game can be reduced by 1,\nand in generic rectangular game, the rank of the game can be reduced by 2 under\ncertain assumptions.\n",
			"Comment: arXiv admin note: text overlap with arXiv:1904.00450; submitted to\n  International Journal of Game Theory"
		],
		"date": [
			"2019-03-31",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1904.00457",
		"pdf_url": "http://arxiv.org/pdf/1904.00457.pdf"
	},
	"77": {
		"title": "Experimental Comparison of Open Source Visual-Inertial-Based State\n  Estimation Algorithms in the Underwater Domain",
		"creator": [
			"Joshi, Bharat",
			"Rahman, Sharmin",
			"Kalaitzakis, Michail",
			"Cain, Brennan",
			"Johnson, James",
			"Xanthidis, Marios",
			"Karapetyan, Nare",
			"Hernandez, Alan",
			"Li, Alberto Quattrini",
			"Vitzilaios, Nikolaos",
			"Rekleitis, Ioannis"
		],
		"subject": "Computer Science - Robotics",
		"description": "  A plethora of state estimation techniques have appeared in the last decade\nusing visual data, and more recently with added inertial data. Datasets\ntypically used for evaluation include indoor and urban environments, where\nsupporting videos have shown impressive performance. However, such techniques\nhave not been fully evaluated in challenging conditions, such as the marine\ndomain. In this paper, we compare ten recent open-source packages to provide\ninsights on their performance and guidelines on addressing current challenges.\nSpecifically, we selected direct methods and tightly-coupled optimization\ntechniques that fuse camera and Inertial Measurement Unit (IMU) data together.\nExperiments are conducted by testing all packages on datasets collected over\nthe years with underwater robots in our laboratory. All the datasets are made\navailable online.\n",
		"date": [
			"2019-04-03",
			"2021-01-21"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1904.02215",
			"doi:10.1109/IROS40897.2019"
		],
		"pdf_url": "http://arxiv.org/pdf/1904.02215.pdf"
	},
	"78": {
		"title": "Towards Analyzing Semantic Robustness of Deep Neural Networks",
		"creator": [
			"Hamdi, Abdullah",
			"Ghanem, Bernard"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Cryptography and Security",
			"Computer Science - Machine Learning",
			"I.2.10",
			"I.4",
			"I.4",
			"I.2.6",
			"D.4.6",
			"E.3"
		],
		"description": [
			"  Despite the impressive performance of Deep Neural Networks (DNNs) on various\nvision tasks, they still exhibit erroneous high sensitivity toward semantic\nprimitives (e.g. object pose). We propose a theoretically grounded analysis for\nDNN robustness in the semantic space. We qualitatively analyze different DNNs'\nsemantic robustness by visualizing the DNN global behavior as semantic maps and\nobserve interesting behavior of some DNNs. Since generating these semantic maps\ndoes not scale well with the dimensionality of the semantic space, we develop a\nbottom-up approach to detect robust regions of DNNs. To achieve this, we\nformalize the problem of finding robust semantic regions of the network as\noptimizing integral bounds and we develop expressions for update directions of\nthe region bounds. We use our developed formulations to quantitatively evaluate\nthe semantic robustness of different popular network architectures. We show\nthrough extensive experimentation that several networks, while trained on the\nsame dataset and enjoying comparable accuracy, do not necessarily perform\nsimilarly in semantic robustness. For example, InceptionV3 is more accurate\ndespite being less semantically robust than ResNet50. We hope that this tool\nwill serve as a milestone towards understanding the semantic robustness of\nDNNs.\n",
			"Comment: Presented at European conference on computer vision (ECCV 2020)\n  Workshop on Adversarial Robustness in the Real World (\n  https://eccv20-adv-workshop.github.io/ ) [best paper award]. The code is\n  available at https://github.com/ajhamdi/semantic-robustness"
		],
		"date": [
			"2019-04-09",
			"2020-09-08"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1904.04621",
			"ECCV 2020 Workshops",
			"doi:10.1007/978-3-030-66415-2_2"
		],
		"pdf_url": "http://arxiv.org/pdf/1904.04621.pdf"
	},
	"79": {
		"title": "Fast multipole networks",
		"creator": "Huntsman, Steve",
		"subject": [
			"Computer Science - Multiagent Systems",
			"Electrical Engineering and Systems Science - Systems and Control",
			"Nonlinear Sciences - Adaptation and Self-Organizing Systems"
		],
		"description": "  Two prerequisites for robotic multiagent systems are mobility and\ncommunication. Fast multipole networks (FMNs) enable both ends within a unified\nframework. FMNs can be organized very efficiently in a distributed way from\nlocal information and are ideally suited for motion planning using artificial\npotentials. We compare FMNs to conventional communication topologies, and find\nthat FMNs offer competitive communication performance (including higher network\nefficiency per edge at marginal energy cost) in addition to advantages for\nmobility.\n",
		"date": [
			"2019-04-09",
			"2020-08-27"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1904.04869",
			"doi:10.1007/978-3-030-65351-4_34"
		],
		"pdf_url": "http://arxiv.org/pdf/1904.04869.pdf"
	},
	"80": {
		"title": "Sample-Based Learning Model Predictive Control for Linear Uncertain\n  Systems",
		"creator": [
			"Rosolia, Ugo",
			"Borrelli, Francesco"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": "  We present a sample-based Learning Model Predictive Controller (LMPC) for\nconstrained uncertain linear systems subject to bounded additive disturbances.\nThe proposed controller builds on earlier work on LMPC for deterministic\nsystems. First, we introduce the design of the safe set and value function used\nto guarantee safety and performance improvement. Afterwards, we show how these\nquantities can be approximated using noisy historical data. The effectiveness\nof the proposed approach is demonstrated on a numerical example. We show that\nthe proposed LMPC is able to safely explore the state space and to iteratively\nimprove the worst-case closed-loop performance, while robustly satisfying state\nand input constraints.\n",
		"date": [
			"2019-04-12",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1904.06432",
		"pdf_url": "http://arxiv.org/pdf/1904.06432.pdf"
	},
	"81": {
		"title": "Maximizing Drift is Not Optimal for Solving OneMax",
		"creator": [
			"Buskulic, Nathan",
			"Doerr, Carola"
		],
		"subject": "Computer Science - Neural and Evolutionary Computing",
		"description": [
			"  It may seem very intuitive that for the maximization of the OneMax problem\n$\\OM(x):=\\sum_{i=1}^n{x_i}$ the best that an elitist unary unbiased search\nalgorithm can do is to store a best so far solution, and to modify it with the\noperator that yields the best possible expected progress in function value.\nThis assumption has been implicitly used in several empirical works. In [Doerr,\nDoerr, Yang: Optimal parameter choices via precise black-box analysis, TCS,\n2020] it was formally proven that this approach is indeed almost optimal.\n  In this work we prove that drift maximization is not optimal. More precisely,\nwe show that for most fitness levels between $n/2$ and $2n/3$ the optimal\nmutation strengths are larger than the drift-maximizing ones. This implies that\nthe optimal RLS is more risk-affine than the variant maximizing the step-wise\nexpected progress. We show similar results for the mutation rates of the\nclassic (1+1) Evolutionary Algorithm (EA) and its resampling variant, the (1+1)\nEA$_{>0}$.\n  As a result of independent interest we show that the optimal mutation\nstrengths, unlike the drift-maximizing ones, can be even.\n",
			"Comment: To appear in Evolutionary Computation"
		],
		"date": [
			"2019-04-16",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1904.07818",
		"pdf_url": "http://arxiv.org/pdf/1904.07818.pdf"
	},
	"82": {
		"title": "The MineRL 2019 Competition on Sample Efficient Reinforcement Learning\n  using Human Priors",
		"creator": [
			"Guss, William H.",
			"Codel, Cayden",
			"Hofmann, Katja",
			"Houghton, Brandon",
			"Kuno, Noboru",
			"Milani, Stephanie",
			"Mohanty, Sharada",
			"Liebana, Diego Perez",
			"Salakhutdinov, Ruslan",
			"Topin, Nicholay",
			"Veloso, Manuela",
			"Wang, Phillip"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Though deep reinforcement learning has led to breakthroughs in many difficult\ndomains, these successes have required an ever-increasing number of samples. As\nstate-of-the-art reinforcement learning (RL) systems require an exponentially\nincreasing number of samples, their development is restricted to a continually\nshrinking segment of the AI community. Likewise, many of these systems cannot\nbe applied to real-world problems, where environment samples are expensive.\nResolution of these limitations requires new, sample-efficient methods. To\nfacilitate research in this direction, we introduce the MineRL Competition on\nSample Efficient Reinforcement Learning using Human Priors.\n  The primary goal of the competition is to foster the development of\nalgorithms which can efficiently leverage human demonstrations to drastically\nreduce the number of samples needed to solve complex, hierarchical, and sparse\nenvironments. To that end, we introduce: (1) the Minecraft ObtainDiamond task,\na sequential decision making environment requiring long-term planning,\nhierarchical control, and efficient exploration methods; and (2) the MineRL-v0\ndataset, a large-scale collection of over 60 million state-action pairs of\nhuman demonstrations that can be resimulated into embodied trajectories with\narbitrary modifications to game state and visuals.\n  Participants will compete to develop systems which solve the ObtainDiamond\ntask with a limited number of samples from the environment simulator, Malmo.\nThe competition is structured into two rounds in which competitors are provided\nseveral paired versions of the dataset and environment with different game\ntextures. At the end of each round, competitors will submit containerized\nversions of their learning algorithms and they will then be trained/evaluated\nfrom scratch on a hold-out dataset-environment pair for a total of 4-days on a\nprespecified hardware platform.\n",
			"Comment: accepted at NeurIPS 2019, 28 pages"
		],
		"date": [
			"2019-04-22",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1904.10079",
		"pdf_url": "http://arxiv.org/pdf/1904.10079.pdf"
	},
	"83": {
		"title": "Parameterised Counting in Logspace",
		"creator": [
			"Haak, Anselm",
			"Meier, Arne",
			"Prakash, Om",
			"Rao, B. V. Raghavendra"
		],
		"subject": [
			"Computer Science - Logic in Computer Science",
			"Computer Science - Computational Complexity"
		],
		"description": [
			"  In this paper, we introduce a new framework for parameterised counting in\nlogspace, inspired by the parameterised space bounded models developed by\nElberfeld, Stockhusen and Tantau (IPEC 2013, Algorithmica 2015). They defined\nthe operators paraW and paraBeta for parameterised space complexity classes by\nallowing bounded nondeterminism with multiple-read and read-once access,\nrespectively. Using these operators, they characterised the parameterised\ncomplexity of natural problems on graphs. In the spirit of the operators paraW\nand paraBeta by Stockhusen and Tantau, we introduce variants based on\ntail-nondeterminism, paraW[1] and paraBeta-Tail. Then, we consider counting\nversions of all four operators applied to logspace and obtain several natural\ncomplete problems for the resulting classes: counting of paths in digraphs,\ncounting first-order models for formulas, and counting graph homomorphisms.\nFurthermore, we show that the complexity of a parameterised variant of the\ndeterminant function for (0,1)-matrices is #paraBeta-Tail-L-hard and can be\nwritten as the difference of two functions in #paraBetaTail-L. For example, we\nshow that the closure of #paraBetaTail-L under parameterised logspace\nparsimonious reductions coincides with #paraBeta-L, that is, modulo\nparameterised reductions, tail-nondeterminism with read-once access is the same\nas read-once nondeterminism. We show that all introduced classes are closed\nunder addition and multiplication, and those without tail-nondeterminism are\nclosed under parameterised logspace parsimonious reductions. Finally, we\nunderline the significance of this topic by providing a promising outlook\nshowing several open problems and options for further directions of research.\n",
			"Comment: Updated technical report to final version at STACS21"
		],
		"date": [
			"2019-04-27",
			"2021-01-15"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1904.12156",
			"doi:10.4230/LIPIcs.STACS.2021.45"
		],
		"pdf_url": "http://arxiv.org/pdf/1904.12156.pdf"
	},
	"84": {
		"title": "Online Decision Process based on Machine Learning Techniques",
		"creator": "Saba, Tanzila",
		"subject": "Computer Science - Computers and Society",
		"description": "  This paper analyses role of internet in marketing and its influences on\nbusiness decision-making process. It explains how the decision maker collect\nvariety of information about customers through internet and analysis this data\nto better use it in enhancing the processes and the overall performance of the\norganization. In addition, how each department in an organization collaborates\nand use these information through data warehousing. Accordingly, a business\nintelligence model is proposed for web segmentation that divides potential\nmarkets or consumers into specific groups and analysis them for better decision\nmaking. The model further plans to push the significance of web opportunities\nin directing the web division and gathering client information. It is exhibited\nhow marketing information system include customers, equipment and procedures\nanalysis contribute to help decision makers make better decision.\n",
		"date": [
			"2019-03-23",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1905.00487",
		"pdf_url": "http://arxiv.org/pdf/1905.00487.pdf"
	},
	"85": {
		"title": "Visually-aware Recommendation with Aesthetic Features",
		"creator": [
			"Yu, Wenhui",
			"He, Xiangnan",
			"Pei, Jian",
			"Chen, Xu",
			"Xiong, Li",
			"Liu, Jinfei",
			"Qin, Zheng"
		],
		"subject": "Computer Science - Information Retrieval",
		"description": [
			"  Visual information plays a critical role in human decision-making process.\nWhile recent developments on visually-aware recommender systems have taken the\nproduct image into account, none of them has considered the aesthetic aspect.\nWe argue that the aesthetic factor is very important in modeling and predicting\nusers' preferences, especially for some fashion-related domains like clothing\nand jewelry. This work addresses the need of modeling aesthetic information in\nvisually-aware recommender systems. Technically speaking, we make three key\ncontributions in leveraging deep aesthetic features: (1) To describe the\naesthetics of products, we introduce the aesthetic features extracted from\nproduct images by a deep aesthetic network. We incorporate these features into\nrecommender system to model users' preferences in the aesthetic aspect. (2)\nSince in clothing recommendation, time is very important for users to make\ndecision, we design a new tensor decomposition model for implicit feedback\ndata. The aesthetic features are then injected to the basic tensor model to\ncapture the temporal dynamics of aesthetic preferences (e.g., seasonal\npatterns). (3) We also use the aesthetic features to optimize the learning\nstrategy on implicit feedback data. We enrich the pairwise training samples by\nconsidering the similarity among items in the visual space and graph space; the\nkey idea is that a user may likely have similar perception on similar items. We\nperform extensive experiments on several real-world datasets and demonstrate\nthe usefulness of aesthetic features and the effectiveness of our proposed\nmethods.\n",
			"Comment: Accepted by VLDBJ. arXiv admin note: substantial text overlap with\n  arXiv:1809.05822"
		],
		"date": [
			"2019-05-02",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1905.02009",
		"pdf_url": "http://arxiv.org/pdf/1905.02009.pdf"
	},
	"86": {
		"title": "A stable semi-implicit algorithm",
		"creator": [
			"Bizarro, João P. S.",
			"Venâncio, L.",
			"Mendes, R. Vilela"
		],
		"subject": [
			"Physics - Plasma Physics",
			"Mathematics - Numerical Analysis",
			"Physics - Computational Physics"
		],
		"description": [
			"  When the singular values of the evolution operator are all smaller or all\ngreater than one, stable integration algorithms are obtained either by explicit\nor implicit methods. When the singular spectrum mixes greater and smaller than\none values, neither explicit nor implicit methods insure stabilty. The problem\nis solved by using a splitting of the evolution operator and a semi-implicit\nscheme. The method is illustrated in the study of a two-field model of the\ntokamak scrape-off layer.\n",
			"Comment: Although the matrix decomposition results are correct, they are only\n  applicable to the integration of differential systems when the decomposition\n  matrices M_1 and M_2 are of order \\delta_t"
		],
		"date": [
			"2019-05-11",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1905.04520",
		"pdf_url": "http://arxiv.org/pdf/1905.04520.pdf"
	},
	"87": {
		"title": "A stabilized nonconforming Nitsche's extended finite element method for\n  Stokes interface problems",
		"creator": [
			"He, Xiaoxiao",
			"Song, Fei",
			"Deng, Weibing"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"65N12, 65N15, 65N30"
		],
		"description": [
			"  In this paper, a stabilized extended finite element method is proposed for\nStokes interface problems on unfitted triangulation elements which do not\nrequire the interface align with the triangulation. The velocity solution and\npressure solution on each side of the interface are separately expanded in the\nstandard nonconforming piecewise linear polynomials and the piecewise constant\npolynomials, respectively. Harmonic weighted fluxes and arithmetic fluxes are\nused across the interface and cut edges (segment of the edges cut by the\ninterface), respectively. Extra stabilization terms involving velocity and\npressure are added to ensure the stable inf-sup condition. We show a priori\nerror estimates under additional regularity hypothesis. Moreover, the errors\n{in energy and $L^2$ norms for velocity and the error in $L^2$ norm for\npressure} are robust with respect to the viscosity {and independent of the\nlocation of the interface}. Results of numerical experiments are presented to\n{support} the theoretical analysis.\n",
			"Comment: 36 pages"
		],
		"date": [
			"2019-05-12",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1905.04844",
		"pdf_url": "http://arxiv.org/pdf/1905.04844.pdf"
	},
	"88": {
		"title": "Limitation of capsule networks",
		"creator": [
			"Peer, David",
			"Stabinger, Sebastian",
			"Rodriguez-Sanchez, Antonio"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  A recently proposed method in deep learning groups multiple neurons to\ncapsules such that each capsule represents an object or part of an object.\nRouting algorithms route the output of capsules from lower-level layers to\nupper-level layers. In this paper, we prove that state-of-the-art routing\nprocedures decrease the expressivity of capsule networks. More precisely, it is\nshown that EM-routing and routing-by-agreement prevent capsule networks from\ndistinguishing inputs and their negative counterpart. Therefore, only symmetric\nfunctions can be expressed by capsule networks, and it can be concluded that\nthey are not universal approximators. We also theoretically motivate and\nempirically show that this limitation affects the training of deep capsule\nnetworks negatively. Therefore, we present an incremental improvement for\nstate-of-the-art routing algorithms that solves the aforementioned limitation\nand stabilizes the training of capsule networks.\n",
		"date": [
			"2019-05-21",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1905.08744",
		"pdf_url": "http://arxiv.org/pdf/1905.08744.pdf"
	},
	"89": {
		"title": "Adversarial Policies: Attacking Deep Reinforcement Learning",
		"creator": [
			"Gleave, Adam",
			"Dennis, Michael",
			"Wild, Cody",
			"Kant, Neel",
			"Levine, Sergey",
			"Russell, Stuart"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Cryptography and Security",
			"Statistics - Machine Learning",
			"I.2.6"
		],
		"description": [
			"  Deep reinforcement learning (RL) policies are known to be vulnerable to\nadversarial perturbations to their observations, similar to adversarial\nexamples for classifiers. However, an attacker is not usually able to directly\nmodify another agent's observations. This might lead one to wonder: is it\npossible to attack an RL agent simply by choosing an adversarial policy acting\nin a multi-agent environment so as to create natural observations that are\nadversarial? We demonstrate the existence of adversarial policies in zero-sum\ngames between simulated humanoid robots with proprioceptive observations,\nagainst state-of-the-art victims trained via self-play to be robust to\nopponents. The adversarial policies reliably win against the victims but\ngenerate seemingly random and uncoordinated behavior. We find that these\npolicies are more successful in high-dimensional environments, and induce\nsubstantially different activations in the victim policy network than when the\nvictim plays against a normal opponent. Videos are available at\nhttps://adversarialpolicies.github.io/.\n",
			"Comment: Presented at ICLR 2020"
		],
		"date": [
			"2019-05-25",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1905.10615",
		"pdf_url": "http://arxiv.org/pdf/1905.10615.pdf"
	},
	"90": {
		"title": "On Mixing Eventual and Strong Consistency: Acute Cloud Types",
		"creator": [
			"Kokociński, Maciej",
			"Kobus, Tadeusz",
			"Wojciechowski, Paweł T."
		],
		"subject": "Computer Science - Distributed, Parallel, and Cluster Computing",
		"description": "  In this article we study the properties of distributed systems that mix\neventual and strong consistency. We formalize such systems through acute cloud\ntypes (ACTs), abstractions similar to conflict-free replicated data types\n(CRDTs), which by default work in a highly available, eventually consistent\nfashion, but which also feature strongly consistent operations for tasks which\nrequire global agreement. Unlike other mixed-consistency solutions, ACTs can\nrely on efficient quorum-based protocols, such as Paxos. Hence, ACTs gracefully\ntolerate machine and network failures also for the strongly consistent\noperations. We formally study ACTs and demonstrate phenomena which are neither\npresent in purely eventually consistent nor strongly consistent systems. In\nparticular, we identify temporary operation reordering, which implies interim\ndisagreement between replicas on the relative order in which the client\nrequests were executed. When not handled carefully, this phenomenon may lead to\nundesired anomalies, including circular causality. We prove an impossibility\nresult which states that temporary operation reordering is unavoidable in\nmixed-consistency systems with sufficiently complex semantics. Our result is\nstartling, because it shows that apparent strengthening of the semantics of a\nsystem (by introducing strongly consistent operations to an eventually\nconsistent system) results in the weakening of the guarantees on the eventually\nconsistent operations.\n",
		"date": [
			"2019-05-28",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1905.11762",
		"pdf_url": "http://arxiv.org/pdf/1905.11762.pdf"
	},
	"91": {
		"title": "Bayesian Evidential Deep Learning with PAC Regularization",
		"creator": [
			"Haussmann, Manuel",
			"Gerwinn, Sebastian",
			"Kandemir, Melih"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  We propose a novel method for closed-form predictive distribution modeling\nwith neural nets. In quantifying prediction uncertainty, we build on Evidential\nDeep Learning, which has been impactful as being both simple to implement and\ngiving closed-form access to predictive uncertainty. We employ it to model\naleatoric uncertainty and extend it to account also for epistemic uncertainty\nby converting it to a Bayesian Neural Net. While extending its uncertainty\nquantification capabilities, we maintain its analytically accessible predictive\ndistribution model by performing progressive moment matching for the first time\nfor approximate weight marginalization. The eventual model introduces a\nprohibitively large number of hyperparameters for stable training. We overcome\nthis drawback by deriving a vacuous PAC bound that comprises the marginal\nlikelihood of the predictor and a complexity penalty. We observe on regression,\nclassification, and out-of-domain detection benchmarks that our method improves\nmodel fit and uncertainty quantification.\n",
			"Comment: Presented at AABI 2020"
		],
		"date": [
			"2019-06-03",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1906.00816",
		"pdf_url": "http://arxiv.org/pdf/1906.00816.pdf"
	},
	"92": {
		"title": "Unbiased estimators for the variance of MMD estimators",
		"creator": "Sutherland, Danica J.",
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  The maximum mean discrepancy (MMD) is a kernel-based distance between\nprobability distributions useful in many applications (Gretton et al. 2012),\nbearing a simple estimator with pleasing computational and statistical\nproperties. Being able to efficiently estimate the variance of this estimator\nis very helpful to various problems in two-sample testing. Towards this end,\nBounliphone et al. (2016) used the theory of U-statistics to derive estimators\nfor the variance of an MMD estimator, and differences between two such\nestimators. Their estimator, however, drops lower-order terms, and is\nunnecessarily biased. We show in this note - extending and correcting work of\nSutherland et al. (2017) - that we can find a truly unbiased estimator for the\nactual variance of both the squared MMD estimator and the difference of two\ncorrelated squared MMD estimators, at essentially no additional computational\ncost.\n",
			"Comment: Fixes and extends the appendices of arXiv:1611.04488 and\n  arXiv:1511.04581"
		],
		"date": [
			"2019-06-05",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1906.02104",
		"pdf_url": "http://arxiv.org/pdf/1906.02104.pdf"
	},
	"93": {
		"title": "Combinatorial Optimization based Feature Selection Method: A study on\n  Network Intrusion Detection",
		"creator": [
			"Nazir, Anjum",
			"Khan, Rizwan Ahmed"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Networking and Internet Architecture"
		],
		"description": [
			"  Advancements in computer networks and communication technologies like\nsoftware defined networks (SDN), Internet of things (IoT), microservices\narchitecture, cloud computing and network function virtualization (NFV) have\nopened new fronts and challenges for security experts to combat against modern\ncyberattacks. Relying on perimeter defense and signature-based network security\nsolutions like Intrusion Detection and Prevention Systems (IDS/IPS) have failed\nto deliver adequate level of security against new attack vectors such as\nadvance persistent threats, zero days, ransomware, botnets and other forms of\ntargeted attacks. Recent developments in machine learning and cognitive\ncomputing have shown great potential to detect unknown and new intrusion events\nwhere legacy misuse and anomaly based intrusion detection systems usually fail.\nIn this research study we applied state of the art machine learning algorithms\non UNSW-NB15 dataset for potential applicability to detect new attacks. We also\nproposed a novel wrapper based feature selection technique TS-RF using\nmetaheuristic Tabu Search (TS) algorithm and Random Forest (RF) ensemble\nclassifier. Results obtained by applying proposed feature selection technique\ni.e. TS-RF on UNSW-NB15 dataset show improvement in overall intrusion detection\naccuracy while it reduces computation complexity as it removes more than 60%\nfeatures.\n",
			"Comment: Data is ambiguous and multi-dimensional and it is not possible to\n  update this article at the moment"
		],
		"date": [
			"2019-06-11",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1906.04494",
		"pdf_url": "http://arxiv.org/pdf/1906.04494.pdf"
	},
	"94": {
		"title": "Meta-Learning via Learned Loss",
		"creator": [
			"Bechtle, Sarah",
			"Molchanov, Artem",
			"Chebotar, Yevgen",
			"Grefenstette, Edward",
			"Righetti, Ludovic",
			"Sukhatme, Gaurav",
			"Meier, Franziska"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Robotics",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Typically, loss functions, regularization mechanisms and other important\naspects of training parametric models are chosen heuristically from a limited\nset of options. In this paper, we take the first step towards automating this\nprocess, with the view of producing models which train faster and more\nrobustly. Concretely, we present a meta-learning method for learning parametric\nloss functions that can generalize across different tasks and model\narchitectures. We develop a pipeline for meta-training such loss functions,\ntargeted at maximizing the performance of the model trained under them. The\nloss landscape produced by our learned losses significantly improves upon the\noriginal task-specific losses in both supervised and reinforcement learning\ntasks. Furthermore, we show that our meta-learning framework is flexible enough\nto incorporate additional information at meta-train time. This information\nshapes the learned loss function such that the environment does not need to\nprovide this information during meta-test time. We make our code available at\nhttps://sites.google.com/view/mlthree.\n",
			"Comment: Project website with code and video at\n  https://sites.google.com/view/mlthree"
		],
		"date": [
			"2019-06-12",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1906.05374",
		"pdf_url": "http://arxiv.org/pdf/1906.05374.pdf"
	},
	"95": {
		"title": "Deep Network Approximation Characterized by Number of Neurons",
		"creator": [
			"Shen, Zuowei",
			"Yang, Haizhao",
			"Zhang, Shijun"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"Computer Science - Machine Learning"
		],
		"description": "  This paper quantitatively characterizes the approximation power of deep\nfeed-forward neural networks (FNNs) in terms of the number of neurons. It is\nshown by construction that ReLU FNNs with width $\\mathcal{O}\\big(\\max\\{d\\lfloor\nN^{1/d}\\rfloor,\\, N+1\\}\\big)$ and depth $\\mathcal{O}(L)$ can approximate an\narbitrary H\\\"older continuous function of order $\\alpha\\in (0,1]$ on $[0,1]^d$\nwith a nearly tight approximation rate $\\mathcal{O}\\big(\\sqrt{d}\nN^{-2\\alpha/d}L^{-2\\alpha/d}\\big)$ measured in $L^p$-norm for any $N,L\\in\n\\mathbb{N}^+$ and $p\\in[1,\\infty]$. More generally for an arbitrary continuous\nfunction $f$ on $[0,1]^d$ with a modulus of continuity $\\omega_f(\\cdot)$, the\nconstructive approximation rate is $\\mathcal{O}\\big(\\sqrt{d}\\,\\omega_f(\nN^{-2/d}L^{-2/d})\\big)$. We also extend our analysis to $f$ on irregular\ndomains or those localized in an $\\varepsilon$-neighborhood of a\n$d_{\\mathcal{M}}$-dimensional smooth manifold $\\mathcal{M}\\subseteq [0,1]^d$\nwith $d_{\\mathcal{M}}\\ll d$. Especially, in the case of an essentially\nlow-dimensional domain, we show an approximation rate\n$\\mathcal{O}\\big(\\omega_f(\\tfrac{\\varepsilon}{1-\\delta}\\sqrt{\\tfrac{d}{d_\\delta}}+\\varepsilon)+\\sqrt{d}\\,\\omega_f(\\tfrac{\\sqrt{d}}{(1-\\delta)\\sqrt{d_\\delta}}N^{-2/d_\\delta}L^{-2/d_\\delta})\\big)$\nfor ReLU FNNs to approximate $f$ in the $\\varepsilon$-neighborhood, where\n$d_\\delta=\\mathcal{O}\\big(d_{\\mathcal{M}}\\tfrac{\\ln (d/\\delta)}{\\delta^2}\\big)$\nfor any $\\delta\\in(0,1)$ as a relative error for a projection to approximate an\nisometry when projecting $\\mathcal{M}$ to a $d_{\\delta}$-dimensional domain.\n",
		"date": [
			"2019-06-13",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1906.05497",
			"Communications in Computational Physics, Volume 28, Issue 5,\n  November 2020, Pages 1768-1811",
			"doi:10.4208/cicp.OA-2020-0149"
		],
		"pdf_url": "http://arxiv.org/pdf/1906.05497.pdf"
	},
	"96": {
		"title": "The $\\infty$-groupoid generated by an arbitrary topological\n  $\\lambda$-model",
		"creator": [
			"Martínez-Rivillas, Daniel O.",
			"de Queiroz, Ruy J. G. B."
		],
		"subject": [
			"Computer Science - Logic in Computer Science",
			"Mathematics - Algebraic Topology",
			"Mathematics - Category Theory",
			"68Q05",
			"F.4.1"
		],
		"description": "  The lambda calculus is a universal programming language. It can represent the\ncomputable functions, and such offers a formal counterpart to the point of view\nof functions as rules. Terms represent functions and this allows for the\napplication of a term/function to any other term/function, including itself.\nThe calculus can be seen as a formal theory with certain pre-established axioms\nand inference rules, which can be interpreted by models. Dana Scott proposed\nthe first non-trivial model of the extensional lambda calculus, known as $\nD_\\infty$, to represent the $\\lambda$-terms as the typical functions of set\ntheory, where it is not allowed to apply a function to itself. Here we propose\na construction of an $\\infty$-groupoid from any lambda model endowed with a\ntopology. We apply this construction for the particular case $D_\\infty$, and we\nsee that the Scott topology does not provide enough information about the\nrelationship between higher homotopies. This motivates a new line of research\nfocused on the exploration of $\\lambda$-models with the structure of a\nnon-trivial $\\infty$-groupoid to generalize the proofs of term conversion\n(e.g., $\\beta$-equality, $\\eta$-equality) to higher-proofs in\n$\\lambda$-calculus.\n",
		"date": [
			"2019-06-13",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1906.05729",
		"pdf_url": "http://arxiv.org/pdf/1906.05729.pdf"
	},
	"97": {
		"title": "Reward Prediction Error as an Exploration Objective in Deep RL",
		"creator": [
			"Simmons-Edler, Riley",
			"Eisner, Ben",
			"Yang, Daniel",
			"Bisulco, Anthony",
			"Mitchell, Eric",
			"Seung, Sebastian",
			"Lee, Daniel"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  A major challenge in reinforcement learning is exploration, when local\ndithering methods such as epsilon-greedy sampling are insufficient to solve a\ngiven task. Many recent methods have proposed to intrinsically motivate an\nagent to seek novel states, driving the agent to discover improved reward.\nHowever, while state-novelty exploration methods are suitable for tasks where\nnovel observations correlate well with improved reward, they may not explore\nmore efficiently than epsilon-greedy approaches in environments where the two\nare not well-correlated. In this paper, we distinguish between exploration\ntasks in which seeking novel states aids in finding new reward, and those where\nit does not, such as goal-conditioned tasks and escaping local reward maxima.\nWe propose a new exploration objective, maximizing the reward prediction error\n(RPE) of a value function trained to predict extrinsic reward. We then propose\na deep reinforcement learning method, QXplore, which exploits the temporal\ndifference error of a Q-function to solve hard exploration tasks in\nhigh-dimensional MDPs. We demonstrate the exploration behavior of QXplore on\nseveral OpenAI Gym MuJoCo tasks and Atari games and observe that QXplore is\ncomparable to or better than a baseline state-novelty method in all cases,\noutperforming the baseline on tasks where state novelty is not well-correlated\nwith improved reward.\n",
			"Comment: Published at IJCAI 2020, camera-ready version"
		],
		"date": [
			"2019-06-19",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1906.08189",
		"pdf_url": "http://arxiv.org/pdf/1906.08189.pdf"
	},
	"98": {
		"title": "Probabilistic model predictive safety certification for learning-based\n  control",
		"creator": [
			"Wabersich, Kim P.",
			"Hewing, Lukas",
			"Carron, Andrea",
			"Zeilinger, Melanie N."
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": "  Reinforcement learning (RL) methods have demonstrated their efficiency in\nsimulation environments. However, many applications for which RL offers great\npotential, such as autonomous driving, are also safety critical and require a\ncertified closed-loop behavior in order to meet safety specifications in the\npresence of physical constraints. This paper introduces a concept, called\nprobabilistic model predictive safety certification (PMPSC), which can be\ncombined with any RL algorithm and provides provable safety certificates in\nterms of state and input chance constraints for potentially large-scale\nsystems. The certificate is realized through a stochastic tube that safely\nconnects the current system state with a terminal set of states, that is known\nto be safe. A novel formulation in terms of a convex receding horizon problem\nallows a recursively feasible real-time computation of such probabilistic\ntubes, despite the presence of possibly unbounded disturbances. A design\nprocedure for PMPSC relying on bayesian inference and recent advances in\nprobabilistic set invariance is presented. Using a numerical car simulation,\nthe method and its design procedure are illustrated by enhancing a simple RL\nalgorithm with safety certificates.\n",
		"date": [
			"2019-06-25",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1906.10417",
		"pdf_url": "http://arxiv.org/pdf/1906.10417.pdf"
	},
	"99": {
		"title": "Complexity of Highly Parallel Non-Smooth Convex Optimization",
		"creator": [
			"Bubeck, Sébastien",
			"Jiang, Qijia",
			"Lee, Yin Tat",
			"Li, Yuanzhi",
			"Sidford, Aaron"
		],
		"subject": [
			"Mathematics - Optimization and Control",
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Machine Learning"
		],
		"description": "  A landmark result of non-smooth convex optimization is that gradient descent\nis an optimal algorithm whenever the number of computed gradients is smaller\nthan the dimension $d$. In this paper we study the extension of this result to\nthe parallel optimization setting. Namely we consider optimization algorithms\ninteracting with a highly parallel gradient oracle, that is one that can answer\n$\\mathrm{poly}(d)$ gradient queries in parallel. We show that in this case\ngradient descent is optimal only up to $\\tilde{O}(\\sqrt{d})$ rounds of\ninteractions with the oracle. The lower bound improves upon a decades old\nconstruction by Nemirovski which proves optimality only up to $d^{1/3}$ rounds\n(as recently observed by Balkanski and Singer), and the suboptimality of\ngradient descent after $\\sqrt{d}$ rounds was already observed by Duchi,\nBartlett and Wainwright. In the latter regime we propose a new method with\nimproved complexity, which we conjecture to be optimal. The analysis of this\nnew method is based upon a generalized version of the recent results on optimal\nacceleration for highly smooth convex optimization.\n",
		"date": [
			"2019-06-25",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1906.10655",
		"pdf_url": "http://arxiv.org/pdf/1906.10655.pdf"
	},
	"100": {
		"title": "Solving Statistical Mechanics on Sparse Graphs with Feedback Set\n  Variational Autoregressive Networks",
		"creator": [
			"Pan, Feng",
			"Zhou, Pengfei",
			"Zhou, Hai-Jun",
			"Zhang, Pan"
		],
		"subject": [
			"Condensed Matter - Statistical Mechanics",
			"Condensed Matter - Disordered Systems and Neural Networks",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  We propose a method for solving statistical mechanics problems defined on\nsparse graphs. It extracts a small Feedback Vertex Set (FVS) from the sparse\ngraph, converting the sparse system to a much smaller system with many-body and\ndense interactions with an effective energy on every configuration of the FVS,\nthen learns a variational distribution parameterized using neural networks to\napproximate the original Boltzmann distribution. The method is able to estimate\nfree energy, compute observables, and generate unbiased samples via direct\nsampling without auto-correlation. Extensive experiments show that our approach\nis more accurate than existing approaches for sparse spin glasses. On random\ngraphs and real-world networks, our approach significantly outperforms the\nstandard methods for sparse systems such as the belief-propagation algorithm;\non structured sparse systems such as two-dimensional lattices our approach is\nsignificantly faster and more accurate than recently proposed variational\nautoregressive networks using convolution neural networks.\n",
			"Comment: 13 pages, 5 figures"
		],
		"date": [
			"2019-06-26",
			"2020-05-22"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1906.10935",
			"Phys. Rev. E 103, 012103 (2021)",
			"doi:10.1103/PhysRevE.103.012103"
		],
		"pdf_url": "http://arxiv.org/pdf/1906.10935.pdf"
	},
	"101": {
		"title": "Robust Transmission Network Expansion Planning Problem Considering\n  Storage Units",
		"creator": [
			"García-Cerezo, Álvaro",
			"Baringo, Luis",
			"García-Bertrand, Raquel"
		],
		"subject": [
			"Mathematics - Optimization and Control",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": [
			"  This paper addresses the transmission network expansion planning problem\nconsidering storage units under uncertain demand and generation capacity. A\ntwo-stage adaptive robust optimization framework is adopted whereby short- and\nlong-term uncertainties are accounted for. This work differs from previously\nreported solutions in an important aspect, namely, we include binary recourse\nvariables to avoid the simultaneous charging and discharging of storage units\nonce uncertainty is revealed. Two-stage robust optimization with discrete\nrecourse problems is a challenging task, so we propose using a nested\ncolumn-and-constraint generation algorithm to solve the resulting problem. This\nalgorithm guarantees convergence to the global optimum in a finite number of\niterations. The performance of the proposed algorithm is illustrated using the\nGarver's test system.\n",
			"Comment: 6 pages, 2 figures, conference"
		],
		"date": "2019-07-10",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1907.04775",
			"doi:10.1109/SEST.2019.8848999"
		],
		"pdf_url": "http://arxiv.org/pdf/1907.04775.pdf"
	},
	"102": {
		"title": "Imitation-Projected Programmatic Reinforcement Learning",
		"creator": [
			"Verma, Abhinav",
			"Le, Hoang M.",
			"Yue, Yisong",
			"Chaudhuri, Swarat"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Programming Languages",
			"Statistics - Machine Learning"
		],
		"description": [
			"  We study the problem of programmatic reinforcement learning, in which\npolicies are represented as short programs in a symbolic language. Programmatic\npolicies can be more interpretable, generalizable, and amenable to formal\nverification than neural policies; however, designing rigorous learning\napproaches for such policies remains a challenge. Our approach to this\nchallenge -- a meta-algorithm called PROPEL -- is based on three insights.\nFirst, we view our learning task as optimization in policy space, modulo the\nconstraint that the desired policy has a programmatic representation, and solve\nthis optimization problem using a form of mirror descent that takes a gradient\nstep into the unconstrained policy space and then projects back onto the\nconstrained space. Second, we view the unconstrained policy space as mixing\nneural and programmatic representations, which enables employing\nstate-of-the-art deep policy gradient approaches. Third, we cast the projection\nstep as program synthesis via imitation learning, and exploit contemporary\ncombinatorial methods for this task. We present theoretical convergence results\nfor PROPEL and empirically evaluate the approach in three continuous control\ndomains. The experiments show that PROPEL can significantly outperform\nstate-of-the-art approaches for learning programmatic policies.\n",
			"Comment: Published in Advances in Neural Information Processing Systems\n  (NeurIPS) 2019"
		],
		"date": [
			"2019-07-11",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1907.05431",
		"pdf_url": "http://arxiv.org/pdf/1907.05431.pdf"
	},
	"103": {
		"title": "Representative Days for Expansion Decisions in Power Systems",
		"creator": [
			"García-Cerezo, Álvaro",
			"Baringo, Luis"
		],
		"subject": [
			"Mathematics - Optimization and Control",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": [
			"  Short-term uncertainty should be properly modeled when the expansion planning\nproblem in a power system is analyzed. Since the use of all available\nhistorical data may lead to intractability, clustering algorithms should be\napplied in order to reduce computer workload without renouncing accuracy\nrepresentation of historical data. In this paper, we propose a modified version\nof the traditional K-means method that seeks to attain the representation of\nmaximum and minimum values of input data, namely, the electric load and the\nrenewable production in several locations of an electric energy system. The\ncrucial role of depicting extreme values of these parameters lies in the fact\nthat they can have a great impact on the expansion and operation decisions\ntaken. The proposed method is based on the traditional K-means algorithm that\nrepresents the correlation between electric load and wind-power production.\nChronology of historical data, which influences the performance of some\ntechnologies, is characterized though representative days, each one composed of\n24 operating conditions. A realistic case study based on the generation and\ntransmission expansion planning of the IEEE 24-bus Reliability Test System is\nanalyzed applying representative days and comparing the results obtained using\nthe traditional K-means technique and the proposed method.\n",
			"Comment: 36 pages, 16 figures"
		],
		"date": [
			"2019-07-16",
			"2019-09-24"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1907.06972",
			"Energies, vol. 13, no. 2, p. 335, Jan. 2020",
			"doi:10.3390/en13020335"
		],
		"pdf_url": "http://arxiv.org/pdf/1907.06972.pdf"
	},
	"104": {
		"title": "Data-Driven Wide-Area Control Design of Power System Using the Passivity\n  Shortage Framework",
		"creator": [
			"Xu, Ying",
			"Qu, Zhihua",
			"Harvey, Roland",
			"Namerikawa, Toru"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  A novel wide-area control design is presented to mitigate inter-area power\nfrequency oscillations. A large-scale power system is decomposed into a network\nof passivity-short subsystems whose nonlinear interconnections have a\nstate-dependent affine form, and by utilizing the passivity shortage framework\na two-level design procedure is developed. At the lower level, any generator\ncontrol can be viewed as one that makes the generator passivity-short and $L_2$\nstable, and the stability impact of the lower-level control on the overall\nsystem can be characterized in terms of two parameters. While the system is\nnonlinear, the impact parameters can be optimized by solving a data-driven\nmatrix inequality (DMI), and the high-level wide-area control is then designed\nby solving another Lyapunov matrix inequality in terms of the design\nparameters. The proposed methodology makes the design modular, and the\nresulting control is adaptive with respect to operating conditions of the power\nsystem. A test system is used to illustrate the proposed design, including DMI\nand the wide-area control, and simulation results demonstrate effectiveness in\ndamping out inter-area oscillations.\n",
			"Comment: 12 pages, 9 figures"
		],
		"date": "2019-07-18",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1907.08289",
			"doi:10.1109/TPWRS.2020.3009630"
		],
		"pdf_url": "http://arxiv.org/pdf/1907.08289.pdf"
	},
	"105": {
		"title": "Does Facebook Use Sensitive Data for Advertising Purposes? Worldwide\n  Analysis and GDPR Impact",
		"creator": [
			"Cuevas, Ángel",
			"Cabañas, José González",
			"Arrate, Aritz",
			"Cuevas, Rubén"
		],
		"subject": [
			"Computer Science - Social and Information Networks",
			"Computer Science - Computers and Society"
		],
		"description": [
			"  The recent European General Data Protection Regulation (GDPR) and other data\nprotection regulations restrict the processing of some categories of personal\ndata (health, political orientation, sexual preferences, religious beliefs,\nethnic origin, etc.) due to the privacy risks associated to such information.\nThe GDPR refers to these categories as sensitive personal data. This paper\nquantifies the portion of Facebook (FB) users, across 197 countries, who are\nlabeled with advertising interests linked to potentially sensitive personal\ndata. Our study reveals that Facebook labels 67% of users with potential\nsensitive interests. This corresponds to 22% of the population in the referred\n197 countries. Moreover, our work shows that the GDPR enforcement had a\nnegligible impact in this context since the portion of FB users labeled with\nsensitive interests in the European Union remains almost the same 5 months\nbefore and 9 months after the GDPR was enacted. The paper also illustrates\npotential risks associated to the use of sensitive interests. For instance, we\nquantify the portion of FB users labelled with the interest \"Homosexuality\" in\ncountries where being gay may be punished with the death penalty. The last\ncontribution is the implementation of a web browser extension that allows FB\nusers removing in a simple way the potentially sensitive interests FB has\nassigned them.\n",
			"Comment: 6 pages, 3 figures, 3 tables. arXiv admin note: text overlap with\n  arXiv:1802.05030"
		],
		"date": "2019-07-23",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1907.10672",
			"Communications of the ACM 64 (1) (2021) 62-69",
			"doi:10.1145/3426361"
		],
		"pdf_url": "http://arxiv.org/pdf/1907.10672.pdf"
	},
	"106": {
		"title": "Min-max Entropy for Weakly Supervised Pointwise Localization",
		"creator": [
			"Belharbi, Soufiane",
			"Rony, Jérôme",
			"Dolz, Jose",
			"Ayed, Ismail Ben",
			"McCaffrey, Luke",
			"Granger, Eric"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Pointwise localization allows more precise localization and accurate\ninterpretability, compared to bounding box, in applications where objects are\nhighly unstructured such as in medical domain. In this work, we focus on weakly\nsupervised localization (WSL) where a model is trained to classify an image and\nlocalize regions of interest at pixel-level using only global image annotation.\nTypical convolutional attentions maps are prune to high false positive regions.\nTo alleviate this issue, we propose a new deep learning method for WSL,\ncomposed of a localizer and a classifier, where the localizer is constrained to\ndetermine relevant and irrelevant regions using conditional entropy (CE) with\nthe aim to reduce false positive regions. Experimental results on a public\nmedical dataset and two natural datasets, using Dice index, show that, compared\nto state of the art WSL methods, our proposal can provide significant\nimprovements in terms of image-level classification and pixel-level\nlocalization (low false positive) with robustness to overfitting. A public\nreproducible PyTorch implementation is provided in:\nhttps://github.com/sbelharbi/wsol-min-max-entropy-interpretability .\n",
			"Comment: 27 pages, 15 figures"
		],
		"date": [
			"2019-07-24",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1907.12934",
		"pdf_url": "http://arxiv.org/pdf/1907.12934.pdf"
	},
	"107": {
		"title": "Distributed Resource Allocation over Time-varying Balanced Digraphs with\n  Discrete-time Communication",
		"creator": [
			"Su, Lanlan",
			"Li, Mengmou",
			"Gupta, Vijay",
			"Chesi, Graziano"
		],
		"subject": [
			"Computer Science - Multiagent Systems",
			"Electrical Engineering and Systems Science - Systems and Control",
			"Mathematics - Optimization and Control"
		],
		"description": [
			"  This work is concerned with the problem of distributed resource allocation in\ncontinuous-time setting but with discrete-time communication over infinitely\njointly connected and balanced digraphs. We provide a passivity-based\nperspective for the continuous-time algorithm, based on which an intermittent\ncommunication scheme is developed. Particularly, a periodic communication\nscheme is first derived through analyzing the passivity degradation over output\nsampling of the distributed dynamics at each node. Then, an asynchronous\ndistributed event-triggered scheme is further developed. The sampled-based\nevent-triggered communication scheme is exempt from Zeno behavior as the\nminimum inter-event time is lower bounded by the sampling period. The\nparameters in the proposed algorithm rely only on local information of each\nindividual nodes, which can be designed in a truly distributed fashion\n",
			"Comment: 12 pages, 7 figures"
		],
		"date": [
			"2019-07-30",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1907.13003",
		"pdf_url": "http://arxiv.org/pdf/1907.13003.pdf"
	},
	"108": {
		"title": "Persistent Intersection Homology for the Analysis of Discrete Data",
		"creator": [
			"Rieck, Bastian",
			"Banagl, Markus",
			"Sadlo, Filip",
			"Leitte, Heike"
		],
		"subject": [
			"Mathematics - Algebraic Topology",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Topological data analysis is becoming increasingly relevant to support the\nanalysis of unstructured data sets. A common assumption in data analysis is\nthat the data set is a sample---not necessarily a uniform one---of some\nhigh-dimensional manifold. In such cases, persistent homology can be\nsuccessfully employed to extract features, remove noise, and compare data sets.\nThe underlying problems in some application domains, however, turn out to\nrepresent multiple manifolds with different dimensions. Algebraic topology\ntypically analyzes such problems using intersection homology, an extension of\nhomology that is capable of handling configurations with singularities. In this\npaper, we describe how the persistent variant of intersection homology can be\nused to assist data analysis in visualization. We point out potential pitfalls\nin approximating data sets with singularities and give strategies for resolving\nthem.\n",
			"Comment: Topology-based Methods in Visualization 2017"
		],
		"date": "2019-07-31",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1907.13485",
			"doi:10.1007/978-3-030-43036-8_3"
		],
		"pdf_url": "http://arxiv.org/pdf/1907.13485.pdf"
	},
	"109": {
		"title": "Topological Machine Learning with Persistence Indicator Functions",
		"creator": [
			"Rieck, Bastian",
			"Sadlo, Filip",
			"Leitte, Heike"
		],
		"subject": [
			"Mathematics - Algebraic Topology",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Techniques from computational topology, in particular persistent homology,\nare becoming increasingly relevant for data analysis. Their stable metrics\npermit the use of many distance-based data analysis methods, such as\nmultidimensional scaling, while providing a firm theoretical ground. Many\nmodern machine learning algorithms, however, are based on kernels. This paper\npresents persistence indicator functions (PIFs), which summarize persistence\ndiagrams, i.e., feature descriptors in topological data analysis. PIFs can be\ncalculated and compared in linear time and have many beneficial properties,\nsuch as the availability of a kernel-based similarity measure. We demonstrate\ntheir usage in common data analysis scenarios, such as confidence set\nestimation and classification of complex structured data.\n",
			"Comment: Topology-based Methods in Visualization 2017"
		],
		"date": "2019-07-31",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1907.13496",
			"doi:10.1007/978-3-030-43036-8_6"
		],
		"pdf_url": "http://arxiv.org/pdf/1907.13496.pdf"
	},
	"110": {
		"title": "Computational approaches to non-convex, sparsity-inducing multi-penalty\n  regularization",
		"creator": [
			"Kereta, Zeljko",
			"Maly, Johannes",
			"Naumova, Valeriya"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  In this work we consider numerical efficiency and convergence rates for\nsolvers of non-convex multi-penalty formulations when reconstructing sparse\nsignals from noisy linear measurements. We extend an existing approach, based\non reduction to an augmented single-penalty formulation, to the non-convex\nsetting and discuss its computational intractability in large-scale\napplications. To circumvent this limitation, we propose an alternative\nsingle-penalty reduction based on infimal convolution that shares the benefits\nof the augmented approach but is computationally less dependent on the problem\nsize. We provide linear convergence rates for both approaches, and their\ndependence on design parameters. Numerical experiments substantiate our\ntheoretical findings.\n",
			"Comment: 20 pages, 2 figures"
		],
		"date": [
			"2019-08-07",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1908.02503",
		"pdf_url": "http://arxiv.org/pdf/1908.02503.pdf"
	},
	"111": {
		"title": "EigenRank by Committee: A Data Subset Selection and Failure Prediction\n  paradigm for Robust Deep Learning based Medical Image Segmentation",
		"creator": [
			"Gaonkar, Bilwaj",
			"Beckett, Joel",
			"Attiah, Mark",
			"Ahn, Christine",
			"Edwards, Matthew",
			"Wilson, Bayard",
			"Laiwalla, Azim",
			"Salehi, Banafsheh",
			"Yoo, Bryan",
			"Bui, Alex",
			"Macyszyn, Luke"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning",
			"68T45 (Primary) 68T05, 68T20 (Secondary)",
			"I.5.4",
			"I.4.6"
		],
		"description": "  Translation of fully automated deep learning based medical image segmentation\ntechnologies to clinical workflows face two main algorithmic challenges. The\nfirst, is the collection and archival of large quantities of manually annotated\nground truth data for both training and validation. The second is the relative\ninability of the majority of deep learning based segmentation techniques to\nalert physicians to a likely segmentation failure. Here we propose a novel\nalgorithm, named `Eigenrank' which addresses both of these challenges.\nEigenrank can select for manual labeling, a subset of medical images from a\nlarge database, such that a U-Net trained on this subset is superior to one\ntrained on a randomly selected subset of the same size. Eigenrank can also be\nused to pick out, cases in a large database, where deep learning segmentation\nwill fail. We present our algorithm, followed by results and a discussion of\nhow Eigenrank exploits the Von Neumann information to perform both data subset\nselection and failure prediction for medical image segmentation using deep\nlearning.\n",
		"date": [
			"2019-08-17",
			"2021-01-18"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1908.06337",
			"Medical Image Analysis, Volume 67, 2021, Medical Image Analysis,\n  Volume 67,2021,101834,ISSN 1361-8415,",
			"doi:10.1016/j.media.2020.101834"
		],
		"pdf_url": "http://arxiv.org/pdf/1908.06337.pdf"
	},
	"112": {
		"title": "How to gamble with non-stationary $\\mathcal{X}$-armed bandits and have\n  no regrets",
		"creator": "Avanesov, Valeriy",
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning",
			"Mathematics - Statistics Theory"
		],
		"description": [
			"  In $\\mathcal{X}$-armed bandit problem an agent sequentially interacts with\nenvironment which yields a reward based on the vector input the agent provides.\nThe agent's goal is to maximise the sum of these rewards across some number of\ntime steps. The problem and its variations have been a subject of numerous\nstudies, suggesting sub-linear and some times optimal strategies. The given\npaper introduces a novel variation of the problem. We consider an environment,\nwhich can abruptly change its behaviour an unknown number of times. To that end\nwe propose a novel strategy and prove it attains sub-linear cumulative regret.\nMoreover, in case of highly smooth relation between an action and the\ncorresponding reward, the method is nearly optimal. The theoretical result are\nsupported by experimental study.\n",
			"Comment: The algorithm is optimized, the theoretical result is more detailed\n  now"
		],
		"date": [
			"2019-08-20",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1908.07636",
		"pdf_url": "http://arxiv.org/pdf/1908.07636.pdf"
	},
	"113": {
		"title": "Numerical reconstruction of radiative sources in an absorbing and\n  non-diffusing scattering medium in two dimensions",
		"creator": [
			"Fujiwara, Hiroshi",
			"Sadiq, Kamran",
			"Tamasan, Alexandru"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"65N21, 30E20"
		],
		"description": "  We consider the two dimensional quantitative imaging problem of recovering a\nradiative source inside an absorbing and scattering medium from knowledge of\nthe outgoing radiation measured at the boundary. The medium has an anisotropic\nscattering property that is neither negligible nor large enough for the\ndiffusion approximation to hold. We present the numerical realization of the\nauthors' recently proposed reconstruction method. For scattering kernels of\nfinite Fourier content in the angular variable, the solution is exact. The\nfeasibility of the proposed algorithms is demonstrated in several numerical\nexperiments, including simulated scenarios for parameters meaningful in optical\nmolecular imaging.\n",
		"date": "2019-08-24",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1908.09133",
			"doi:10.1137/19M1282921"
		],
		"pdf_url": "http://arxiv.org/pdf/1908.09133.pdf"
	},
	"114": {
		"title": "Ellipsis Resolution as Question Answering: An Evaluation",
		"creator": [
			"Aralikatte, Rahul",
			"Lamm, Matthew",
			"Hardt, Daniel",
			"Søgaard, Anders"
		],
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  Most, if not all forms of ellipsis (e.g., so does Mary) are similar to\nreading comprehension questions (what does Mary do), in that in order to\nresolve them, we need to identify an appropriate text span in the preceding\ndiscourse. Following this observation, we present an alternative approach for\nEnglish ellipsis resolution relying on architectures developed for question\nanswering (QA). We present both single-task models, and joint models trained on\nauxiliary QA and coreference resolution datasets, clearly outperforming the\ncurrent state of the art for Sluice Ellipsis (from 70.00 to 86.01 F1) and Verb\nPhrase Ellipsis (from 72.89 to 78.66 F1).\n",
			"Comment: To appear in EACL 2021"
		],
		"date": [
			"2019-08-29",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1908.11141",
		"pdf_url": "http://arxiv.org/pdf/1908.11141.pdf"
	},
	"115": {
		"title": "Learning without feedback: Fixed random learning signals allow for\n  feedforward training of deep neural networks",
		"creator": [
			"Frenkel, Charlotte",
			"Lefebvre, Martin",
			"Bol, David"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning",
			"Computer Science - Neural and Evolutionary Computing"
		],
		"description": [
			"  While the backpropagation of error algorithm enables deep neural network\ntraining, it implies (i) bidirectional synaptic weight transport and (ii)\nupdate locking until the forward and backward passes are completed. Not only do\nthese constraints preclude biological plausibility, but they also hinder the\ndevelopment of low-cost adaptive smart sensors at the edge, as they severely\nconstrain memory accesses and entail buffering overhead. In this work, we show\nthat the one-hot-encoded labels provided in supervised classification problems,\ndenoted as targets, can be viewed as a proxy for the error sign. Therefore,\ntheir fixed random projections enable a layerwise feedforward training of the\nhidden layers, thus solving the weight transport and update locking problems\nwhile relaxing the computational and memory requirements. Based on these\nobservations, we propose the direct random target projection (DRTP) algorithm\nand demonstrate that it provides a tradeoff between accuracy and computational\ncost that is suitable for adaptive edge computing devices.\n",
			"Comment: This document is the paper as accepted for publication in the\n  Frontiers in Neuroscience journal, the fully-edited paper is available at\n  https://www.frontiersin.org/articles/10.3389/fnins.2021.629892"
		],
		"date": [
			"2019-09-03",
			"2021-01-16"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1909.01311",
			"doi:10.3389/fnins.2021.629892"
		],
		"pdf_url": "http://arxiv.org/pdf/1909.01311.pdf"
	},
	"116": {
		"title": "Sequential Convolutional Recurrent Neural Networks for Fast Automatic\n  Modulation Classification",
		"creator": [
			"Liao, Kaisheng",
			"Zhao, Yaodong",
			"Gu, Jie",
			"Zhang, Yaping",
			"Zhong, Yi"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Signal Processing",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  A novel and efficient end-to-end learning model for automatic modulation\nclassification is proposed for wireless spectrum monitoring applications, which\nautomatically learns from the time domain in-phase and quadrature data without\nrequiring the design of hand-crafted expert features. With the intuition of\nconvolutional layers with pooling serving as the role of front-end feature\ndistillation and dimensionality reduction, sequential convolutional recurrent\nneural networks are developed to take complementary advantage of parallel\ncomputing capability of convolutional neural networks and temporal sensitivity\nof recurrent neural networks. Experimental results demonstrate that the\nproposed architecture delivers overall superior performance in signal to noise\nratio range above -10~dB, and achieves significantly improved classification\naccuracy from 80\\% to 92.1\\% at high signal to noise ratio range, while\ndrastically reduces the average training and prediction time by approximately\n74% and 67%, respectively. Response patterns learned by the proposed\narchitecture are visualized to better understand the physics of the model.\nFurthermore, a comparative study is performed to investigate the impacts of\nvarious sequential convolutional recurrent neural network structure settings on\nclassification performance. A representative sequential convolutional recurrent\nneural network architecture with the two-layer convolutional neural network and\nsubsequent two-layer long short-term memory neural network is developed to\nsuggest the option for fast automatic modulation classification.\n",
			"Comment: update the content for some details and clarity"
		],
		"date": [
			"2019-09-09",
			"2021-01-19"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1909.03050",
			"doi:10.1109/ACCESS.2021.3053427"
		],
		"pdf_url": "http://arxiv.org/pdf/1909.03050.pdf"
	},
	"117": {
		"title": "In Defense of LSTMs for Addressing Multiple Instance Learning Problems",
		"creator": [
			"Wang, Kaili",
			"Oramas, Jose",
			"Tuytelaars, Tinne"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  LSTMs have a proven track record in analyzing sequential data. But what about\nunordered instance bags, as found under a Multiple Instance Learning (MIL)\nsetting? While not often used for this, we show LSTMs excell under this setting\ntoo. In addition, we show thatLSTMs are capable of indirectly capturing\ninstance-level information us-ing only bag-level annotations. Thus, they can be\nused to learn instance-level models in a weakly supervised manner. Our\nempirical evaluation on both simplified (MNIST) and realistic (Lookbook and\nHistopathology) datasets shows that LSTMs are competitive with or even surpass\nstate-of-the-art methods specially designed for handling specific MIL problems.\nMoreover, we show that their performance on instance-level prediction is close\nto that of fully-supervised methods.\n",
			"Comment: accepted in ACCV 2020 (oral)"
		],
		"date": [
			"2019-09-11",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1909.05690",
		"pdf_url": "http://arxiv.org/pdf/1909.05690.pdf"
	},
	"118": {
		"title": "Where are the Keys? -- Learning Object-Centric Navigation Policies on\n  Semantic Maps with Graph Convolutional Networks",
		"creator": "Sünderhauf, Niko",
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Robotics"
		],
		"description": "  Emerging object-based SLAM algorithms can build a graph representation of an\nenvironment comprising nodes for robot poses and object landmarks. However,\nwhile this map will contain static objects such as furniture or appliances,\nmany moveable objects (e.g. the car keys, the glasses, or a magazine), are not\nsuitable as landmarks and will not be part of the map due to their non-static\nnature. We show that Graph Convolutional Networks can learn navigation policies\nto find such unmapped objects by learning to exploit the hidden probabilistic\nmodel that governs where these objects appear in the environment. The learned\npolicies can generalise to object classes unseen during training by using word\nvectors that express semantic similarity as representations for object nodes in\nthe graph. Furthermore, we show that the policies generalise to unseen\nenvironments with only minimal loss of performance. We demonstrate that\npre-training the policy network with a proxy task can significantly speed up\nlearning, improving sample efficiency.\n",
		"date": [
			"2019-09-16",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1909.07376",
		"pdf_url": "http://arxiv.org/pdf/1909.07376.pdf"
	},
	"119": {
		"title": "Utilizing Dependence among Variables in Evolutionary Algorithms for\n  Mixed-Integer Programming: A Case Study on Multi-Objective Constrained\n  Portfolio Optimization",
		"creator": [
			"Chen, Yi",
			"Zhou, Aimin",
			"Das, Swagatam"
		],
		"subject": [
			"Computer Science - Computational Engineering, Finance, and Science",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  Several real-world applications could be modeled as Mixed-Integer Non-Linear\nProgramming (MINLP) problems, and some prominent examples include portfolio\noptimization, remote sensing technology, and so on. Most of the models for\nthese applications are non-convex and always involve some conflicting\nobjectives. The mathematical and heuristic methods have their advantages in\nsolving this category of problems. In this work, we turn to Multi-Objective\nEvolutionary Algorithms (MOEAs) for finding elegant solutions for such\nproblems. In this framework, we investigate a multi-objective constrained\nportfolio optimization problem, which can be cast as a classical financial\nproblem and can also be naturally modeled as an MINLP problem. Consequently, we\npoint out one challenge, faced by a direct coding scheme for MOEAs, to this\nproblem. It is that the dependence among variables, like the selection and\nweights for one same asset, will likely make the search difficult. We thus,\npropose a Compressed Coding Scheme (CCS), compressing the two dependent\nvariables into one variable to utilize the dependence and thereby meeting this\nchallenge. Subsequently, we carry out a detailed empirical study on two sets of\ninstances. The first part consists of 5 instances from OR-Library, which is\nsolvable for the general mathematical optimizer, like CPLEX, while the\nremaining 15 instances from NGINX are addressed only by MOEAs. The two\nbenchmarks, involving the number of assets from 31 to 2235, consistently\nindicate that CCS is not only efficient but also robust for dealing with the\nconstrained multi-objective portfolio optimization.\n",
		"date": [
			"2019-09-18",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1909.08748",
		"pdf_url": "http://arxiv.org/pdf/1909.08748.pdf"
	},
	"120": {
		"title": "Bayesian Optimization for Iterative Learning",
		"creator": [
			"Nguyen, Vu",
			"Schulze, Sebastian",
			"Osborne, Michael A"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  The performance of deep (reinforcement) learning systems crucially depends on\nthe choice of hyperparameters. Their tuning is notoriously expensive, typically\nrequiring an iterative training process to run for numerous steps to\nconvergence. Traditional tuning algorithms only consider the final performance\nof hyperparameters acquired after many expensive iterations and ignore\nintermediate information from earlier training steps. In this paper, we present\na Bayesian optimization (BO) approach which exploits the iterative structure of\nlearning algorithms for efficient hyperparameter tuning. We propose to learn an\nevaluation function compressing learning progress at any stage of the training\nprocess into a single numeric score according to both training success and\nstability. Our BO framework is then balancing the benefit of assessing a\nhyperparameter setting over additional training steps against their computation\ncost. We further increase model efficiency by selectively including scores from\ndifferent training steps for any evaluated hyperparameter set. We demonstrate\nthe efficiency of our algorithm by tuning hyperparameters for the training of\ndeep reinforcement learning agents and convolutional neural networks. Our\nalgorithm outperforms all existing baselines in identifying optimal\nhyperparameters in minimal time.\n",
			"Comment: Camera ready NeurIPS 2020"
		],
		"date": [
			"2019-09-20",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1909.09593",
		"pdf_url": "http://arxiv.org/pdf/1909.09593.pdf"
	},
	"121": {
		"title": "IoT Inspector: Crowdsourcing Labeled Network Traffic from Smart Home\n  Devices at Scale",
		"creator": [
			"Huang, Danny Yuxing",
			"Apthorpe, Noah",
			"Acar, Gunes",
			"Li, Frank",
			"Feamster, Nick"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": "  The proliferation of smart home devices has created new opportunities for\nempirical research in ubiquitous computing, ranging from security and privacy\nto personal health. Yet, data from smart home deployments are hard to come by,\nand existing empirical studies of smart home devices typically involve only a\nsmall number of devices in lab settings. To contribute to data-driven smart\nhome research, we crowdsource the largest known dataset of labeled network\ntraffic from smart home devices from within real-world home networks. To do so,\nwe developed and released IoT Inspector, an open-source tool that allows users\nto observe the traffic from smart home devices on their own home networks.\nSince April 2019, 4,322 users have installed IoT Inspector, allowing us to\ncollect labeled network traffic from 44,956 smart home devices across 13\ncategories and 53 vendors. We demonstrate how this data enables new research\ninto smart homes through two case studies focused on security and privacy.\nFirst, we find that many device vendors use outdated TLS versions and advertise\nweak ciphers. Second, we discover about 350 distinct third-party advertiser and\ntracking domains on smart TVs. We also highlight other research areas, such as\nnetwork management and healthcare, that can take advantage of IoT Inspector's\ndataset. To facilitate future reproducible research in smart homes, we will\nrelease the IoT Inspector data to the public.\n",
		"date": "2019-09-21",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1909.09848",
			"Proceedings of the ACM on Interactive, Mobile, Wearable and\n  Ubiquitous Technologies. Volume 4, Issue 2, Article 46. June 2020",
			"doi:10.1145/3397333"
		],
		"pdf_url": "http://arxiv.org/pdf/1909.09848.pdf"
	},
	"122": {
		"title": "Learning to Seek: Autonomous Source Seeking with Deep Reinforcement\n  Learning Onboard a Nano Drone Microcontroller",
		"creator": [
			"Duisterhof, Bardienus P.",
			"Krishnan, Srivatsan",
			"Cruz, Jonathan J.",
			"Banbury, Colby R.",
			"Fu, William",
			"Faust, Aleksandra",
			"de Croon, Guido C. H. E.",
			"Reddi, Vijay Janapa"
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": "  We present fully autonomous source seeking onboard a highly constrained nano\nquadcopter, by contributing application-specific system and observation feature\ndesign to enable inference of a deep-RL policy onboard a nano quadcopter. Our\ndeep-RL algorithm finds a high-performance solution to a challenging problem,\neven in presence of high noise levels and generalizes across real and\nsimulation environments with different obstacle configurations. We verify our\napproach with simulation and in-field testing on a Bitcraze CrazyFlie using\nonly the cheap and ubiquitous Cortex-M4 microcontroller unit. The results show\nthat by end-to-end application-specific system design, our contribution\nconsumes almost three times less additional power, as compared to competing\nlearning-based navigation approach onboard a nano quadcopter. Thanks to our\nobservation space, which we carefully design within the resource constraints,\nour solution achieves a 94% success rate in cluttered and randomized test\nenvironments, as compared to the previously achieved 80%. We also compare our\nstrategy to a simple finite state machine (FSM), geared towards efficient\nexploration, and demonstrate that our policy is more robust and resilient at\nobstacle avoidance as well as up to 70% more efficient in source seeking. To\nthis end, we contribute a cheap and lightweight end-to-end tiny robot learning\n(tinyRL) solution, running onboard a nano quadcopter, that proves to be robust\nand efficient in a challenging task using limited sensory input.\n",
		"date": [
			"2019-09-24",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1909.11236",
		"pdf_url": "http://arxiv.org/pdf/1909.11236.pdf"
	},
	"123": {
		"title": "Interpreting Knowledge Graph Relation Representation from Word\n  Embeddings",
		"creator": [
			"Allen, Carl",
			"Balažević, Ivana",
			"Hospedales, Timothy"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  Many models learn representations of knowledge graph data by exploiting its\nlow-rank latent structure, encoding known relations between entities and\nenabling unknown facts to be inferred. To predict whether a relation holds\nbetween entities, embeddings are typically compared in the latent space\nfollowing a relation-specific mapping. Whilst their predictive performance has\nsteadily improved, how such models capture the underlying latent structure of\nsemantic information remains unexplained. Building on recent theoretical\nunderstanding of word embeddings, we categorise knowledge graph relations into\nthree types and for each derive explicit requirements of their representations.\nWe show that empirical properties of relation representations and the relative\nperformance of leading knowledge graph representation methods are justified by\nour analysis.\n",
		"date": [
			"2019-09-25",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1909.11611",
		"pdf_url": "http://arxiv.org/pdf/1909.11611.pdf"
	},
	"124": {
		"title": "Learned Point Cloud Geometry Compression",
		"creator": [
			"Wang, Jianqiang",
			"Zhu, Hao",
			"Ma, Zhan",
			"Chen, Tong",
			"Liu, Haojie",
			"Shen, Qiu"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": [
			"  This paper presents a novel end-to-end Learned Point Cloud Geometry\nCompression (a.k.a., Learned-PCGC) framework, to efficiently compress the point\ncloud geometry (PCG) using deep neural networks (DNN) based variational\nautoencoders (VAE). In our approach, PCG is first voxelized, scaled and\npartitioned into non-overlapped 3D cubes, which is then fed into stacked 3D\nconvolutions for compact latent feature and hyperprior generation. Hyperpriors\nare used to improve the conditional probability modeling of latent features. A\nweighted binary cross-entropy (WBCE) loss is applied in training while an\nadaptive thresholding is used in inference to remove unnecessary voxels and\nreduce the distortion. Objectively, our method exceeds the geometry-based point\ncloud compression (G-PCC) algorithm standardized by well-known Moving Picture\nExperts Group (MPEG) with a significant performance margin, e.g., at least 60%\nBD-Rate (Bjontegaard Delta Rate) gains, using common test datasets.\nSubjectively, our method has presented better visual quality with smoother\nsurface reconstruction and appealing details, in comparison to all existing\nMPEG standard compliant PCC methods. Our method requires about 2.5MB parameters\nin total, which is a fairly small size for practical implementation, even on\nembedded platform. Additional ablation studies analyze a variety of aspects\n(e.g., cube size, kernels, etc) to explore the application potentials of our\nlearned-PCGC.\n",
			"Comment: 13 pages"
		],
		"date": "2019-09-26",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1909.12037",
			"doi:10.1109/TCSVT.2021.3051377"
		],
		"pdf_url": "http://arxiv.org/pdf/1909.12037.pdf"
	},
	"125": {
		"title": "Comment on \"$\\Phi$ memristor: Real memristor found\" by F. Z. Wang, L.\n  Li, L. Shi, H. Wu, and L. O. Chua [J. Appl. Phys. 125, 054504 (2019)]",
		"creator": [
			"Pershin, Y. V.",
			"Di Ventra, M."
		],
		"subject": [
			"Computer Science - Emerging Technologies",
			"Condensed Matter - Mesoscale and Nanoscale Physics"
		],
		"description": [
			"  Wang et al. claim [J. Appl. Phys. 125, 054504 (2019)] that a current-carrying\nwire interacting with a magnetic core represents a memristor. Here, we\ndemonstrate that this claim is false. We first show that such memristor\n\"discovery\" is based on incorrect physics, which does not even capture basic\nproperties of magnetic core materials, such as their magnetic hysteresis.\nMoreover, the predictions of Wang et al.'s model contradict the experimental\ncurves presented in their paper. Additionally, the theoretical pinched\nhysteresis loops presented by Wang et al. can not be reproduced if their model\nis used, and there are serious flaws in their \"negative memristor\" emulator\ndesign. Finally, a simple gedanken experiment shows that the proposed\n$\\Phi$-memristor would fail the memristor test we recently suggested in J.\nPhys. D: Appl. Phys. 52, 01LT01 (2019). The device \"discovered\" by Wang et al.\nis just an inductor with memory.\n",
			"Comment: Following this comment, the article [F. Z. Wang, L. Li, L. Shi, H.\n  Wu, and L. O. Chua, J. Appl. Phys. 125, 054504 (2019)] was retracted from JAP\n  on technical grounds. The retraction notice can be found at\n  https://doi.org/10.1063/5.0040852"
		],
		"date": [
			"2019-09-26",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1909.12464",
		"pdf_url": "http://arxiv.org/pdf/1909.12464.pdf"
	},
	"126": {
		"title": "Imitation Learning Based on Bilateral Control for Human-Robot\n  Cooperation",
		"creator": [
			"Sasagawa, Ayumu",
			"Fujimoto, Kazuki",
			"Sakaino, Sho",
			"Tsuji, Toshiaki"
		],
		"subject": "Computer Science - Robotics",
		"description": [
			"  Robots are required to autonomously respond to changing situations. Imitation\nlearning is a promising candidate for achieving generalization performance, and\nextensive results have been demonstrated in object manipulation. However,\ncooperative work between humans and robots is still a challenging issue because\nrobots must control dynamic interactions among themselves, humans, and objects.\nFurthermore, it is difficult to follow subtle perturbations that may occur\namong coworkers. In this study, we find that cooperative work can be\naccomplished by imitation learning using bilateral control. Thanks to bilateral\ncontrol, which can extract response values and command values independently,\nhuman skills to control dynamic interactions can be extracted. Then, the task\nof serving food is considered. The experimental results clearly demonstrate the\nimportance of force control, and the dynamic interactions can be controlled by\nthe inferred action force.\n",
			"Comment: Copyright 2020 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"
		],
		"date": [
			"2019-09-27",
			"2021-01-19"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1909.13018",
			"doi:10.1109/LRA.2020.3011353"
		],
		"pdf_url": "http://arxiv.org/pdf/1909.13018.pdf"
	},
	"127": {
		"title": "Lane Attention: Predicting Vehicles' Moving Trajectories by Learning\n  Their Attention over Lanes",
		"creator": [
			"Pan, Jiacheng",
			"Sun, Hongyi",
			"Xu, Kecheng",
			"Jiang, Yifei",
			"Xiao, Xiangquan",
			"Hu, Jiangtao",
			"Miao, Jinghao"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Robotics",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Accurately forecasting the future movements of surrounding vehicles is\nessential for safe and efficient operations of autonomous driving cars. This\ntask is difficult because a vehicle's moving trajectory is greatly determined\nby its driver's intention, which is often hard to estimate. By leveraging\nattention mechanisms along with long short-term memory (LSTM) networks, this\nwork learns the relation between a driver's intention and the vehicle's\nchanging positions relative to road infrastructures, and uses it to guide the\nprediction. Different from other state-of-the-art solutions, our work treats\nthe on-road lanes as non-Euclidean structures, unfolds the vehicle's moving\nhistory to form a spatio-temporal graph, and uses methods from Graph Neural\nNetworks to solve the problem. Not only is our approach a pioneering attempt in\nusing non-Euclidean methods to process static environmental features around a\npredicted object, our model also outperforms other state-of-the-art models in\nseveral metrics. The practicability and interpretability analysis of the model\nshows great potential for large-scale deployment in various autonomous driving\nsystems in addition to our own.\n",
			"Comment: IROS 2020"
		],
		"date": [
			"2019-09-29",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1909.13377",
		"pdf_url": "http://arxiv.org/pdf/1909.13377.pdf"
	},
	"128": {
		"title": "Using GANs for Sharing Networked Time Series Data: Challenges, Initial\n  Promise, and Open Questions",
		"creator": [
			"Lin, Zinan",
			"Jain, Alankar",
			"Wang, Chen",
			"Fanti, Giulia",
			"Sekar, Vyas"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Networking and Internet Architecture",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Limited data access is a longstanding barrier to data-driven research and\ndevelopment in the networked systems community. In this work, we explore if and\nhow generative adversarial networks (GANs) can be used to incentivize data\nsharing by enabling a generic framework for sharing synthetic datasets with\nminimal expert knowledge. As a specific target, our focus in this paper is on\ntime series datasets with metadata (e.g., packet loss rate measurements with\ncorresponding ISPs). We identify key challenges of existing GAN approaches for\nsuch workloads with respect to fidelity (e.g., long-term dependencies, complex\nmultidimensional relationships, mode collapse) and privacy (i.e., existing\nguarantees are poorly understood and can sacrifice fidelity). To improve\nfidelity, we design a custom workflow called DoppelGANger (DG) and demonstrate\nthat across diverse real-world datasets (e.g., bandwidth measurements, cluster\nrequests, web sessions) and use cases (e.g., structural characterization,\npredictive modeling, algorithm comparison), DG achieves up to 43% better\nfidelity than baseline models. Although we do not resolve the privacy problem\nin this work, we identify fundamental challenges with both classical notions of\nprivacy and recent advances to improve the privacy properties of GANs, and\nsuggest a potential roadmap for addressing these challenges. By shedding light\non the promise and challenges, we hope our work can rekindle the conversation\non workflows for data sharing.\n",
			"Comment: Published in IMC 2020. 20 pages, 26 figures"
		],
		"date": [
			"2019-09-29",
			"2021-01-16"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1909.13403",
			"doi:10.1145/3419394.3423643"
		],
		"pdf_url": "http://arxiv.org/pdf/1909.13403.pdf"
	},
	"129": {
		"title": "Stochastic gradient descent for hybrid quantum-classical optimization",
		"creator": [
			"Sweke, Ryan",
			"Wilde, Frederik",
			"Meyer, Johannes",
			"Schuld, Maria",
			"Faehrmann, Paul K.",
			"Meynard-Piganeau, Barthélémy",
			"Eisert, Jens"
		],
		"subject": [
			"Quantum Physics",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Within the context of hybrid quantum-classical optimization, gradient descent\nbased optimizers typically require the evaluation of expectation values with\nrespect to the outcome of parameterized quantum circuits. In this work, we\nexplore the consequences of the prior observation that estimation of these\nquantities on quantum hardware results in a form of stochastic gradient descent\noptimization. We formalize this notion, which allows us to show that in many\nrelevant cases, including VQE, QAOA and certain quantum classifiers, estimating\nexpectation values with $k$ measurement outcomes results in optimization\nalgorithms whose convergence properties can be rigorously well understood, for\nany value of $k$. In fact, even using single measurement outcomes for the\nestimation of expectation values is sufficient. Moreover, in many settings the\nrequired gradients can be expressed as linear combinations of expectation\nvalues -- originating, e.g., from a sum over local terms of a Hamiltonian, a\nparameter shift rule, or a sum over data-set instances -- and we show that in\nthese cases $k$-shot expectation value estimation can be combined with sampling\nover terms of the linear combination, to obtain \"doubly stochastic\" gradient\ndescent optimizers. For all algorithms we prove convergence guarantees,\nproviding a framework for the derivation of rigorous optimization results in\nthe context of near-term quantum devices. Additionally, we explore numerically\nthese methods on benchmark VQE, QAOA and quantum-enhanced machine learning\ntasks and show that treating the stochastic settings as hyper-parameters allows\nfor state-of-the-art results with significantly fewer circuit executions and\nmeasurements.\n",
			"Comment: Significantly revised version - accepted in Quantum. Includes\n  reference and discussion of earlier related work by Harrow and Napp\n  (arXiv:1901.05374)"
		],
		"date": [
			"2019-10-02",
			"2021-01-20"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1910.01155",
			"Quantum 4, 314 (2020)",
			"doi:10.22331/q-2020-08-31-314"
		],
		"pdf_url": "http://arxiv.org/pdf/1910.01155.pdf"
	},
	"130": {
		"title": "Blockchains vs. Distributed Databases: Dichotomy and Fusion",
		"creator": [
			"Ruan, Pingcheng",
			"Dinh, Tien Tuan Anh",
			"Loghin, Dumitrel",
			"Zhang, Meihui",
			"Chen, Gang",
			"Lin, Qian",
			"Ooi, Beng Chin"
		],
		"subject": [
			"Computer Science - Databases",
			"Computer Science - Performance"
		],
		"description": "  Blockchain has come a long way: a system that was initially proposed\nspecifically for cryptocurrencies is now being adapted and adopted as a\ngeneral-purpose transactional system. As blockchain evolves into another data\nmanagement system, the natural question is how it compares against distributed\ndatabase systems. Existing works on this comparison focus on high-level\nproperties, such as security and throughput. They stop short of showing how the\nunderlying design choices contribute to the overall differences. Our work fills\nthis important gap and provides a principled framework for analyzing the\nemerging trend of blockchain-database fusion.\n  We perform a twin study of blockchains and distributed database systems as\ntwo types of transactional systems. We propose a taxonomy that illustrates the\ndichotomy across four dimensions, namely replication, concurrency, storage, and\nsharding. Within each dimension, we discuss how the design choices are driven\nby two goals: security for blockchains, and performance for distributed\ndatabases. To expose the impact of different design choices on the overall\nperformance, we conduct an in-depth performance analysis of two blockchains,\nnamely Quorum and Hyperledger Fabric, and two distributed databases, namely\nTiDB, and etcd. Lastly, we propose a framework for back-of-the-envelope\nperformance forecast of blockchain-database hybrids.\n",
		"date": [
			"2019-10-03",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1910.01310",
		"pdf_url": "http://arxiv.org/pdf/1910.01310.pdf"
	},
	"131": {
		"title": "An Empirical Study of C++ Vulnerabilities in Crowd-Sourced Code Examples",
		"creator": [
			"Verdi, Morteza",
			"Sami, Ashkan",
			"Akhondali, Jafar",
			"Khomh, Foutse",
			"Uddin, Gias",
			"Motlagh, Alireza Karami"
		],
		"subject": "Computer Science - Software Engineering",
		"description": [
			"  Software developers share programming solutions in Q&A sites like Stack\nOverflow. The reuse of crowd-sourced code snippets can facilitate rapid\nprototyping. However, recent research shows that the shared code snippets may\nbe of low quality and can even contain vulnerabilities. This paper aims to\nunderstand the nature and the prevalence of security vulnerabilities in\ncrowd-sourced code examples. To achieve this goal, we investigate security\nvulnerabilities in the C++ code snippets shared on Stack Overflow over a period\nof 10 years. In collaborative sessions involving multiple human coders, we\nmanually assessed each code snippet for security vulnerabilities following CWE\n(Common Weakness Enumeration) guidelines. From the 72,483 reviewed code\nsnippets used in at least one project hosted on GitHub, we found a total of 69\nvulnerable code snippets categorized into 29 types. Many of the investigated\ncode snippets are still not corrected on Stack Overflow. The 69 vulnerable code\nsnippets found in Stack Overflow were reused in a total of 2859 GitHub\nprojects. To help improve the quality of code snippets shared on Stack\nOverflow, we developed a browser extension that allow Stack Overflow users to\ncheck for vulnerabilities in code snippets when they upload them on the\nplatform.\n",
			"Comment: 14 pages"
		],
		"date": [
			"2019-10-03",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1910.01321",
		"pdf_url": "http://arxiv.org/pdf/1910.01321.pdf"
	},
	"132": {
		"title": "Towards a Definitive Compressibility Measure for Repetitive Sequences",
		"creator": [
			"Kociumaka, Tomasz",
			"Navarro, Gonzalo",
			"Prezza, Nicola"
		],
		"subject": "Computer Science - Data Structures and Algorithms",
		"description": "  Unlike in statistical compression, where Shannon's entropy is a definitive\nlower bound, no such clear measure exists for the compressibility of repetitive\nsequences. Since statistical entropy does not capture repetitiveness, ad-hoc\nmeasures like the size $z$ of the Lempel--Ziv parse are frequently used to\nestimate it. The size $b \\le z$ of the smallest bidirectional macro scheme\ncaptures better what can be achieved via copy-paste processes, though it is\nNP-complete to compute and it is not monotonic upon symbol appends. Recently, a\nmore principled measure, the size $\\gamma$ of the smallest string\n\\emph{attractor}, was introduced. The measure $\\gamma \\le b$ lower bounds all\nthe previous relevant ones, yet length-$n$ strings can be represented and\nefficiently indexed within space $O(\\gamma\\log\\frac{n}{\\gamma})$, which also\nupper bounds most measures. While $\\gamma$ is certainly a better measure of\nrepetitiveness than $b$, it is also NP-complete to compute and not monotonic,\nand it is unknown if one can always represent a string in $o(\\gamma\\log n)$\nspace.\n  In this paper, we study an even smaller measure, $\\delta \\le \\gamma$, which\ncan be computed in linear time, is monotonic, and allows encoding every string\nin $O(\\delta\\log\\frac{n}{\\delta})$ space because $z =\nO(\\delta\\log\\frac{n}{\\delta})$. We show that $\\delta$ better captures the\ncompressibility of repetitive strings. Concretely, we show that (1) $\\delta$\ncan be strictly smaller than $\\gamma$, by up to a logarithmic factor; (2) there\nare string families needing $\\Omega(\\delta\\log\\frac{n}{\\delta})$ space to be\nencoded, so this space is optimal for every $n$ and $\\delta$; (3) one can build\nrun-length context-free grammars of size $O(\\delta\\log\\frac{n}{\\delta})$,\nwhereas the smallest (non-run-length) grammar can be up to $\\Theta(\\log\nn/\\log\\log n)$ times larger; and (4) within $O(\\delta\\log\\frac{n}{\\delta})$\nspace we can not only...\n",
		"date": [
			"2019-10-04",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1910.02151",
		"pdf_url": "http://arxiv.org/pdf/1910.02151.pdf"
	},
	"133": {
		"title": "Template-based Minor Embedding for Adiabatic Quantum Optimization",
		"creator": [
			"Serra, Thiago",
			"Huang, Teng",
			"Raghunathan, Arvind",
			"Bergman, David"
		],
		"subject": [
			"Computer Science - Data Structures and Algorithms",
			"Mathematics - Optimization and Control"
		],
		"description": [
			"  Quantum Annealing (QA) can be used to quickly obtain near-optimal solutions\nfor Quadratic Unconstrained Binary Optimization (QUBO) problems. In QA\nhardware, each decision variable of a QUBO should be mapped to one or more\nadjacent qubits in such a way that pairs of variables defining a quadratic term\nin the objective function are mapped to some pair of adjacent qubits. However,\nqubits have limited connectivity in existing QA hardware. This has spurred work\non preprocessing algorithms for embedding the graph representing problem\nvariables with quadratic terms into the hardware graph representing qubits\nadjacencies, such as the Chimera graph in hardware produced by D-Wave Systems.\nIn this paper, we use integer linear programming to search for an embedding of\nthe problem graph into certain classes of minors of the Chimera graph, which we\ncall template embeddings. One of these classes corresponds to complete\nbipartite graphs, for which we show the limitation of the existing approach\nbased on minimum Odd Cycle Transversals (OCTs). One of the formulations\npresented is exact, and thus can be used to certify the absence of a minor\nembedding using that template. On an extensive test set consisting of random\ngraphs from five different classes of varying size and sparsity, we can embed\nmore graphs than a state-of-the-art OCT-based approach, our approach scales\nbetter with the hardware size, and the runtime is generally orders of magnitude\nsmaller.\n",
			"Comment: INFORMS Journal on Computing (to appear)"
		],
		"date": [
			"2019-10-04",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1910.02179",
		"pdf_url": "http://arxiv.org/pdf/1910.02179.pdf"
	},
	"134": {
		"title": "Level set image segmentation with velocity term learned from data with\n  applications to lung nodule segmentation",
		"creator": [
			"Hancock, Matthew C",
			"Magnan, Jerry F"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  Purpose: Lung nodule segmentation, i.e., the algorithmic delineation of the\nlung nodule surface, is a fundamental component of computational nodule\nanalysis pipelines. We propose a new method for segmentation that is a machine\nlearning based extension of current approaches, using labeled image examples to\nimprove its accuracy.\n  Approach: We introduce an extension of the standard level set image\nsegmentation method where the velocity function is learned from data via\nmachine learning regression methods, rather than a priori designed. Instead,\nthe method employs a set of features to learn a velocity function that guides\nthe level set evolution from initialization.\n  Results: We apply the method to image volumes of lung nodules from CT scans\nin the publicly available LIDC dataset, obtaining an average intersection over\nunion score of 0.7185($\\pm$0.1114), which is competitive with other methods. We\nanalyze segmentation performance by anatomical and appearance-based categories\nof the nodules, finding that the method performs better for isolated nodules\nwith well-defined margins. We find that the segmentation performance for\nnodules in more complex surroundings and having more complex CT appearance is\nimproved with the addition of combined global-local features.\n  Conclusions: The level set machine learning segmentation approach proposed\nherein is competitive with current methods. It provides accurate lung nodule\nsegmentation results in a variety of anatomical contexts.\n",
		"date": [
			"2019-10-07",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1910.03191",
		"pdf_url": "http://arxiv.org/pdf/1910.03191.pdf"
	},
	"135": {
		"title": "Mollified finite element approximants of arbitrary order and smoothness",
		"creator": [
			"Febrianto, Eky",
			"Ortiz, Michael",
			"Cirak, Fehmi"
		],
		"subject": "Mathematics - Numerical Analysis",
		"description": "  The approximation properties of the finite element method can often be\nsubstantially improved by choosing smooth high-order basis functions. It is\nextremely difficult to devise such basis functions for partitions consisting of\narbitrarily shaped polytopes. We propose the mollified basis functions of\narbitrary order and smoothness for partitions consisting of convex polytopes.\nOn each polytope an independent local polynomial approximant of arbitrary order\nis assumed. The basis functions are defined as the convolutions of the local\napproximants with a mollifier. The mollifier is chosen to be smooth, to have a\ncompact support and a unit volume. The approximation properties of the obtained\nbasis functions are governed by the local polynomial approximation order and\nmollifier smoothness. The convolution integrals are evaluated numerically first\nby computing the boolean intersection between the mollifier and the polytope\nand then applying the divergence theorem to reduce the dimension of the\nintegrals. The support of a basis function is given as the Minkowski sum of the\nrespective polytope and the mollifier. The breakpoints of the basis functions,\ni.e. locations with non-infinite smoothness, are not necessarily aligned with\npolytope boundaries. Furthermore, the basis functions are not boundary\ninterpolating so that we apply boundary conditions with the non-symmetric\nNitsche method as in immersed/embedded finite elements. The presented numerical\nexamples confirm the optimal convergence of the proposed approximation scheme\nfor Poisson and elasticity problems.\n",
		"date": [
			"2019-10-09",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1910.04002",
			"doi:10.1016/j.cma.2020.113513"
		],
		"pdf_url": "http://arxiv.org/pdf/1910.04002.pdf"
	},
	"136": {
		"title": "Understanding Limitation of Two Symmetrized Orders by Worst-case\n  Complexity",
		"creator": [
			"Xiao, Peijun",
			"Xiao, Zhisheng",
			"Sun, Ruoyu"
		],
		"subject": [
			"Mathematics - Optimization and Control",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Update order is one of the major design choices of block decomposition\nalgorithms. There are at least two classes of deterministic update orders:\nnonsymmetric (e.g. cyclic order) and symmetric (e.g. Gaussian back substitution\nor symmetric Gauss-Seidel). Recently, Coordinate Descent (CD) with cyclic order\nwas shown to be $O(n^2)$ times slower than randomized versions in the\nworst-case. A natural question arises: can the symmetrized orders achieve\nfaster convergence rates than the cyclic order, or even getting close to the\nrandomized versions? In this paper, we give a negative answer to this question.\nWe show that both Gaussian back substitution (GBS) and symmetric Gauss-Seidel\n(sGS) suffer from the same slow convergence issue as the cyclic order in the\nworst case. In particular, we prove that for unconstrained problems, both\nGBS-CD and sGS-CD can be $O(n^2)$ times slower than R-CD. Despite unconstrained\nproblems, we also empirically study linearly constrained problems with\nquadratic objective: we empirically demonstrate that the convergence speed of\nGBS-ADMM and sGS-ADMM can be roughly $O(n^2)$ times slower than randomly\npermuted ADMM.\n",
			"Comment: 31 pages, 9 tables"
		],
		"date": [
			"2019-10-10",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1910.04366",
		"pdf_url": "http://arxiv.org/pdf/1910.04366.pdf"
	},
	"137": {
		"title": "Organization of machine learning based product development as per ISO\n  26262 and ISO/PAS 21448",
		"creator": [
			"Radlak, Krystian",
			"Szczepankiewicz, Michał",
			"Jones, Tim",
			"Serwa, Piotr"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  Machine learning (ML) algorithms generate a continuous stream of success\nstories from various domains and enable many novel applications in\nsafety-critical systems. With the advent of autonomous driving, ML algorithms\nare being used in the automotive domain, where the applicable functional safety\nstandard is ISO 26262. However, requirements and recommendations provided by\nISO 26262 do not cover specific properties of machine learning algorithms.\nTherefore, specific aspects of ML (e.g., dataset requirements, performance\nevaluation metrics, lack of interpretability) must be addressed within some\nwork products, which collect documentation resulting from one or more\nassociated requirements and recommendations of ISO 26262. In this paper, we\npropose how key technical aspects and supporting processes related to\ndevelopment of ML-based systems can be organized according to ISO 26262 phases,\nsub-phases, and work products. We follow the same approach as in the ISO/PAS\n21448 standard, which complements ISO 26262, in order to account for edge cases\nthat can lead to hazards not directly caused by system failure.%, but resulting\nfrom functional insufficiencies of the intended functionality or by reasonably\nforeseeable misuse by persons.\n",
			"Comment: 10 pages, 2 figures"
		],
		"date": [
			"2019-10-07",
			"2021-01-06"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1910.05112",
			"doi:10.1109/PRDC50213.2020.00022"
		],
		"pdf_url": "http://arxiv.org/pdf/1910.05112.pdf"
	},
	"138": {
		"title": "IdBench: Evaluating Semantic Representations of Identifier Names in\n  Source Code",
		"creator": [
			"Wainakh, Yaza",
			"Rauf, Moiz",
			"Pradel, Michael"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Programming Languages",
			"Computer Science - Software Engineering",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Identifier names convey useful information about the intended semantics of\ncode. Name-based program analyses use this information, e.g., to detect bugs,\nto predict types, and to improve the readability of code. At the core of\nname-based analyses are semantic representations of identifiers, e.g., in the\nform of learned embeddings. The high-level goal of such a representation is to\nencode whether two identifiers, e.g., len and size, are semantically similar.\nUnfortunately, it is currently unclear to what extent semantic representations\nmatch the semantic relatedness and similarity perceived by developers. This\npaper presents IdBench, the first benchmark for evaluating semantic\nrepresentations against a ground truth created from thousands of ratings by 500\nsoftware developers. We use IdBench to study state-of-the-art embedding\ntechniques proposed for natural language, an embedding technique specifically\ndesigned for source code, and lexical string distance functions. Our results\nshow that the effectiveness of semantic representations varies significantly\nand that the best available embeddings successfully represent semantic\nrelatedness. On the downside, no existing technique provides a satisfactory\nrepresentation of semantic similarities, among other reasons because\nidentifiers with opposing meanings are incorrectly considered to be similar,\nwhich may lead to fatal mistakes, e.g., in a refactoring tool. Studying the\nstrengths and weaknesses of the different techniques shows that they complement\neach other. As a first step toward exploiting this complementarity, we present\nan ensemble model that combines existing techniques and that clearly\noutperforms the best available semantic representation.\n",
			"Comment: Accepted as full research paper at International Conference on\n  Software Engineering (ICSE) 2021"
		],
		"date": [
			"2019-10-11",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1910.05177",
		"pdf_url": "http://arxiv.org/pdf/1910.05177.pdf"
	},
	"139": {
		"title": "Analyzing the Forgetting Problem in the Pretrain-Finetuning of Dialogue\n  Response Models",
		"creator": [
			"He, Tianxing",
			"Liu, Jun",
			"Cho, Kyunghyun",
			"Ott, Myle",
			"Liu, Bing",
			"Glass, James",
			"Peng, Fuchun"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": "  In this work, we study how the finetuning stage in the pretrain-finetune\nframework changes the behavior of a pretrained neural language generator. We\nfocus on the transformer encoder-decoder model for the open-domain dialogue\nresponse generation task. Our major finding is that after standard finetuning,\nthe model forgets some of the important language generation skills acquired\nduring large-scale pretraining. We demonstrate the forgetting phenomenon\nthrough a set of detailed behavior analysis from the perspectives of knowledge\ntransfer, context sensitivity, and function space projection. As a preliminary\nattempt to alleviate the forgetting problem, we propose an intuitive finetuning\nstrategy named \"mix-review\". We find that mix-review effectively regularizes\nthe finetuning process, and the forgetting problem is alleviated to some\nextent. Finally, we discuss interesting behavior of the resulting dialogue\nmodel and its implications.\n",
		"date": [
			"2019-10-15",
			"2021-01-16"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1910.07117",
			"EACL 2021"
		],
		"pdf_url": "http://arxiv.org/pdf/1910.07117.pdf"
	},
	"140": {
		"title": "Community Detection in Multiplex Networks",
		"creator": [
			"Magnani, Matteo",
			"Hanteer, Obaida",
			"Interdonato, Roberto",
			"Rossi, Luca",
			"Tagarelli, Andrea"
		],
		"subject": [
			"Computer Science - Social and Information Networks",
			"Physics - Data Analysis, Statistics and Probability"
		],
		"description": [
			"  A multiplex network models different modes of interaction among same-type\nentities. In this article we provide a taxonomy of community detection\nalgorithms in multiplex networks. We characterize the different algorithms\nbased on various properties and we discuss the type of communities detected by\neach method. We then provide an extensive experimental evaluation of the\nreviewed methods to answer three main questions: to what extent the evaluated\nmethods are able to detect ground-truth communities, to what extent different\nmethods produce similar community structures and to what extent the evaluated\nmethods are scalable. One goal of this survey is to help scholars and\npractitioners to choose the right methods for the data and the task at hand,\nwhile also emphasizing when such choice is problematic.\n",
			"Comment: 55 pages. Accepted for publication on ACM Computing Surveys in a\n  shorter version"
		],
		"date": [
			"2019-10-16",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1910.07646",
		"pdf_url": "http://arxiv.org/pdf/1910.07646.pdf"
	},
	"141": {
		"title": "Sparsification as a Remedy for Staleness in Distributed Asynchronous SGD",
		"creator": [
			"Candela, Rosa",
			"Franzese, Giulio",
			"Filippone, Maurizio",
			"Michiardi, Pietro"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  Large scale machine learning is increasingly relying on distributed\noptimization, whereby several machines contribute to the training process of a\nstatistical model. In this work we study the performance of asynchronous,\ndistributed settings, when applying sparsification, a technique used to reduce\ncommunication overheads. In particular, for the first time in an asynchronous,\nnon-convex setting, we theoretically prove that, in presence of staleness,\nsparsification does not harm SGD performance: the ergodic convergence rate\nmatches the known result of standard SGD, that is $\\mathcal{O} \\left(\n1/\\sqrt{T} \\right)$. We also carry out an empirical study to complement our\ntheory, and confirm that the effects of sparsification on the convergence rate\nare negligible, when compared to 'vanilla' SGD, even in the challenging\nscenario of an asynchronous, distributed system.\n",
		"date": [
			"2019-10-21",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1910.09466",
		"pdf_url": "http://arxiv.org/pdf/1910.09466.pdf"
	},
	"142": {
		"title": "Low-Delay High-Rate Operation of 802.11ac WLAN Downlink: Nonlinear\n  Controller Analysis & Design",
		"creator": [
			"Gringoli, Francesco",
			"Leith, Douglas J."
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": "  In this paper we consider a next generation edge architecture where traffic\nis routed via a proxy located close to the network edge (e.g. within a\ncloudlet). This creates freedom to implement new transport layer behaviour over\nthe wireless path between proxy and clients. We use this freedom to develop a\nnovel traffic shaping controller for the downlink in 802.11ac WLANs that\nadjusts the send rate to each WLAN client so as to maintain a target number of\npackets aggregated in each transmitted frame. In this way robust low-delay\noperation at high data rates becomes genuinely feasible across a wide range of\nnetwork conditions. Key to achieving robust operation is the design of an\nappropriate feedback controller, and it is this which is our focus. We develop\na novel nonlinear control design inspired by the solution to an associated\nproportional fair optimisation problem. The controller compensates for system\nnonlinearities and so can be used for the full envelope of operation. The\nrobust stability of the closed-loop system is analysed and the selection of\ncontrol design parameters discussed. We develop an implementation of the\nnonlinear control design and use this to present a performance evaluation using\nboth simulations and experimental measurements.\n",
		"date": [
			"2019-10-21",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1910.09651",
		"pdf_url": "http://arxiv.org/pdf/1910.09651.pdf"
	},
	"143": {
		"title": "Automatic Reminiscence Therapy for Dementia",
		"creator": [
			"Caros, Mariona",
			"Garolera, Maite",
			"Radeva, Petia",
			"Giro-i-Nieto, Xavier"
		],
		"subject": [
			"Computer Science - Multimedia",
			"Computer Science - Computation and Language",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  With people living longer than ever, the number of cases with dementia such\nas Alzheimer's disease increases steadily. It affects more than 46 million\npeople worldwide, and it is estimated that in 2050 more than 100 million will\nbe affected. While there are not effective treatments for these terminal\ndiseases, therapies such as reminiscence, that stimulate memories from the past\nare recommended. Currently, reminiscence therapy takes place in care homes and\nis guided by a therapist or a carer. In this work, we present an AI-based\nsolution to automatize the reminiscence therapy, which consists in a dialogue\nsystem that uses photos as input to generate questions. We run a usability case\nstudy with patients diagnosed of mild cognitive impairment that shows they\nfound the system very entertaining and challenging. Overall, this paper\npresents how reminiscence therapy can be automatized by using machine learning,\nand deployed to smartphones and laptops, making the therapy more accessible to\nevery person affected by dementia.\n",
			"Comment: MSc thesis at TelecomBCN, Universitat Politecnica de Catalunya 2019"
		],
		"date": [
			"2019-10-25",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1910.11949",
		"pdf_url": "http://arxiv.org/pdf/1910.11949.pdf"
	},
	"144": {
		"title": "Deep Multi-Magnification Networks for Multi-Class Breast Cancer Image\n  Segmentation",
		"creator": [
			"Ho, David Joon",
			"Yarlagadda, Dig V. K.",
			"D'Alfonso, Timothy M.",
			"Hanna, Matthew G.",
			"Grabenstetter, Anne",
			"Ntiamoah, Peter",
			"Brogi, Edi",
			"Tan, Lee K.",
			"Fuchs, Thomas J."
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  Pathologic analysis of surgical excision specimens for breast carcinoma is\nimportant to evaluate the completeness of surgical excision and has\nimplications for future treatment. This analysis is performed manually by\npathologists reviewing histologic slides prepared from formalin-fixed tissue.\nIn this paper, we present Deep Multi-Magnification Network trained by partial\nannotation for automated multi-class tissue segmentation by a set of patches\nfrom multiple magnifications in digitized whole slide images. Our proposed\narchitecture with multi-encoder, multi-decoder, and multi-concatenation\noutperforms other single and multi-magnification-based architectures by\nachieving the highest mean intersection-over-union, and can be used to\nfacilitate pathologists' assessments of breast cancer.\n",
			"Comment: Accepted at Computerized Medical Imaging and Graphics"
		],
		"date": [
			"2019-10-28",
			"2021-01-04"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1910.13042",
			"doi:10.1016/j.compmedimag.2021.101866"
		],
		"pdf_url": "http://arxiv.org/pdf/1910.13042.pdf"
	},
	"145": {
		"title": "Scalable Evaluation and Improvement of Document Set Expansion via Neural\n  Positive-Unlabeled Learning",
		"creator": [
			"Jacovi, Alon",
			"Niu, Gang",
			"Goldberg, Yoav",
			"Sugiyama, Masashi"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  We consider the situation in which a user has collected a small set of\ndocuments on a cohesive topic, and they want to retrieve additional documents\non this topic from a large collection. Information Retrieval (IR) solutions\ntreat the document set as a query, and look for similar documents in the\ncollection. We propose to extend the IR approach by treating the problem as an\ninstance of positive-unlabeled (PU) learning -- i.e., learning binary\nclassifiers from only positive and unlabeled data, where the positive data\ncorresponds to the query documents, and the unlabeled data is the results\nreturned by the IR engine. Utilizing PU learning for text with big neural\nnetworks is a largely unexplored field. We discuss various challenges in\napplying PU learning to the setting, including an unknown class prior,\nextremely imbalanced data and large-scale accurate evaluation of models, and we\npropose solutions and empirically validate them. We demonstrate the\neffectiveness of the method using a series of experiments of retrieving PubMed\nabstracts adhering to fine-grained topics. We demonstrate improvements over the\nbase IR solution and other baselines.\n",
			"Comment: Accepted as a long paper to EACL 2021"
		],
		"date": [
			"2019-10-29",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1910.13339",
		"pdf_url": "http://arxiv.org/pdf/1910.13339.pdf"
	},
	"146": {
		"title": "On weak convergence of Monge-Ampere measures for discrete convex mesh\n  functions",
		"creator": "Awanou, Gerard",
		"subject": "Mathematics - Numerical Analysis",
		"description": [
			"  To a mesh function we associate the natural analogue of the Monge-Ampere\nmeasure. The latter is shown to be equivalent to the Monge-Ampere measure of\nthe convex envelope. We prove that the uniform convergence to a bounded convex\nfunction of mesh functions implies the uniform convergence on compact subsets\nof their convex envelopes and hence the weak convergence of the associated\nMonge-Ampere measures. We also give conditions for mesh functions to have a\nsubsequence which converges uniformly to a convex function. Our result can be\nused to give alternate proofs of the convergence of some discretizations for\nthe second boundary value problem for the Monge-Ampere equation and was used\nfor a recently proposed discretization of the latter. For mesh functions which\nare uniformly bounded and satisfy a convexity condition at the discrete level,\nwe show that there is a subsequence which converges uniformly on compact\nsubsets to a convex function. The convex envelopes of the mesh functions of the\nsubsequence also converge uniformly on compact subsets. If in addition they\nagree with a continuous convex function on the boundary, the limit function is\nshown to satisfy the boundary condition strongly.\n",
			"Comment: arXiv admin note: text overlap with arXiv:1408.1729"
		],
		"date": [
			"2019-10-29",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1910.13870",
		"pdf_url": "http://arxiv.org/pdf/1910.13870.pdf"
	},
	"147": {
		"title": "Convergence of a damped Newton's method for discrete Monge-Ampere\n  functions with a prescribed asymptotic cone",
		"creator": "Awanou, Gerard",
		"subject": "Mathematics - Numerical Analysis",
		"description": [
			"  We prove the convergence of a damped Newton's method for the nonlinear system\nresulting from a discretization of the second boundary value problem for the\nMonge-Ampere equation. The boundary condition is enforced through the use of\nthe notion of asymptotic cone. The differential operator is discretized based\non a partial discrete analogue of the subdifferential.\n",
			"Comment: one figure"
		],
		"date": [
			"2019-11-01",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1911.00260",
		"pdf_url": "http://arxiv.org/pdf/1911.00260.pdf"
	},
	"148": {
		"title": "A Hybrid Approach To Hierarchical Density-based Cluster Selection",
		"creator": [
			"Malzer, Claudia",
			"Baum, Marcus"
		],
		"subject": "Computer Science - Databases",
		"description": [
			"  HDBSCAN is a density-based clustering algorithm that constructs a cluster\nhierarchy tree and then uses a specific stability measure to extract flat\nclusters from the tree. We show how the application of an additional threshold\nvalue can result in a combination of DBSCAN* and HDBSCAN clusters, and\ndemonstrate potential benefits of this hybrid approach when clustering data of\nvariable densities. In particular, our approach is useful in scenarios where we\nrequire a low minimum cluster size but want to avoid an abundance of\nmicro-clusters in high-density regions. The method can directly be applied to\nHDBSCAN's tree of cluster candidates and does not require any modifications to\nthe hierarchy itself. It can easily be integrated as an addition to existing\nHDBSCAN implementations.\n",
			"Comment: 6 pages. Conference: 2020 IEEE International Conference on\n  Multisensor Fusion and Integration for Intelligent Systems (MFI)"
		],
		"date": [
			"2019-11-06",
			"2021-01-21"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1911.02282",
			"2020 IEEE International Conference on Multisensor Fusion and\n  Integration for Intelligent Systems (MFI), Karlsruhe, Germany, 2020, pp.\n  223-228",
			"doi:10.1109/MFI49285.2020.9235263"
		],
		"pdf_url": "http://arxiv.org/pdf/1911.02282.pdf"
	},
	"149": {
		"title": "Option Compatible Reward Inverse Reinforcement Learning",
		"creator": [
			"Hwang, Rakhoon",
			"Lee, Hanjin",
			"Hwang, Hyung Ju"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Reinforcement learning in complex environments is a challenging problem. In\nparticular, the success of reinforcement learning algorithms depends on a\nwell-designed reward function. Inverse reinforcement learning (IRL) solves the\nproblem of recovering reward functions from expert demonstrations. In this\npaper, we solve a hierarchical inverse reinforcement learning problem within\nthe options framework, which allows us to utilize intrinsic motivation of the\nexpert demonstrations. A gradient method for parametrized options is used to\ndeduce a defining equation for the Q-feature space, which leads to a reward\nfeature space. Using a second-order optimality condition for option parameters,\nan optimal reward function is selected. Experimental results in both discrete\nand continuous domains confirm that our recovered rewards provide a solution to\nthe IRL problem using temporal abstraction, which in turn are effective in\naccelerating transfer learning tasks. We also show that our method is robust to\nnoises contained in expert demonstrations.\n",
			"Comment: This paper is under consideration at Pattern Recognition Letters"
		],
		"date": [
			"2019-11-06",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1911.02723",
		"pdf_url": "http://arxiv.org/pdf/1911.02723.pdf"
	},
	"150": {
		"title": "Knowledge Distillation for Incremental Learning in Semantic Segmentation",
		"creator": [
			"Michieli, Umberto",
			"Zanuttigh, Pietro"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": [
			"  Deep learning architectures have shown remarkable results in scene\nunderstanding problems, however they exhibit a critical drop of performances\nwhen they are required to learn incrementally new tasks without forgetting old\nones. This catastrophic forgetting phenomenon impacts on the deployment of\nartificial intelligence in real world scenarios where systems need to learn new\nand different representations over time. Current approaches for incremental\nlearning deal only with image classification and object detection tasks, while\nin this work we formally introduce incremental learning for semantic\nsegmentation. We tackle the problem applying various knowledge distillation\ntechniques on the previous model. In this way, we retain the information about\nlearned classes, whilst updating the current model to learn the new ones. We\ndeveloped four main methodologies of knowledge distillation working on both\noutput layers and internal feature representations. We do not store any image\nbelonging to previous training stages and only the last model is used to\npreserve high accuracy on previously learned classes. Extensive experimental\nresults on the Pascal VOC2012 and MSRC-v2 datasets show the effectiveness of\nthe proposed approaches in several incremental learning scenarios.\n",
			"Comment: Computer Vision and Image Understanding (CVIU), 2021. arXiv admin\n  note: text overlap with arXiv:1907.13372"
		],
		"date": [
			"2019-11-08",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1911.03462",
		"pdf_url": "http://arxiv.org/pdf/1911.03462.pdf"
	},
	"151": {
		"title": "Curriculum Self-Paced Learning for Cross-Domain Object Detection",
		"creator": [
			"Soviany, Petru",
			"Ionescu, Radu Tudor",
			"Rota, Paolo",
			"Sebe, Nicu"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Training (source) domain bias affects state-of-the-art object detectors, such\nas Faster R-CNN, when applied to new (target) domains. To alleviate this\nproblem, researchers proposed various domain adaptation methods to improve\nobject detection results in the cross-domain setting, e.g. by translating\nimages with ground-truth labels from the source domain to the target domain\nusing Cycle-GAN. On top of combining Cycle-GAN transformations and self-paced\nlearning in a smart and efficient way, in this paper, we propose a novel\nself-paced algorithm that learns from easy to hard. Our method is simple and\neffective, without any overhead during inference. It uses only pseudo-labels\nfor samples taken from the target domain, i.e. the domain adaptation is\nunsupervised. We conduct experiments on four cross-domain benchmarks, showing\nbetter results than the state of the art. We also perform an ablation study\ndemonstrating the utility of each component in our framework. Additionally, we\nstudy the applicability of our framework to other object detectors.\nFurthermore, we compare our difficulty measure with other measures from the\nrelated literature, proving that it yields superior results and that it\ncorrelates well with the performance metric.\n",
			"Comment: Accepted for publication in Computer Vision and Image Understanding"
		],
		"date": [
			"2019-11-15",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1911.06849",
		"pdf_url": "http://arxiv.org/pdf/1911.06849.pdf"
	},
	"152": {
		"title": "Any-Precision Deep Neural Networks",
		"creator": [
			"Yu, Haichao",
			"Li, Haoxiang",
			"Shi, Honghui",
			"Huang, Thomas S.",
			"Hua, Gang"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Statistics - Machine Learning"
		],
		"description": [
			"  We present any-precision deep neural networks (DNNs), which are trained with\na new method that allows the learned DNNs to be flexible in numerical precision\nduring inference. The same model in runtime can be flexibly and directly set to\ndifferent bit-widths, by truncating the least significant bits, to support\ndynamic speed and accuracy trade-off. When all layers are set to low-bits, we\nshow that the model achieved accuracy comparable to dedicated models trained at\nthe same precision. This nice property facilitates flexible deployment of deep\nlearning models in real-world applications, where in practice trade-offs\nbetween model accuracy and runtime efficiency are often sought. Previous\nliterature presents solutions to train models at each individual fixed\nefficiency/accuracy trade-off point. But how to produce a model flexible in\nruntime precision is largely unexplored. When the demand of efficiency/accuracy\ntrade-off varies from time to time or even dynamically changes in runtime, it\nis infeasible to re-train models accordingly, and the storage budget may forbid\nkeeping multiple models. Our proposed framework achieves this flexibility\nwithout performance degradation. More importantly, we demonstrate that this\nachievement is agnostic to model architectures and applicable to multiple\nvision tasks. Our code is released at\nhttps://github.com/SHI-Labs/Any-Precision-DNNs.\n",
			"Comment: AAAI 2021"
		],
		"date": [
			"2019-11-17",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1911.07346",
		"pdf_url": "http://arxiv.org/pdf/1911.07346.pdf"
	},
	"153": {
		"title": "Weak convergence rates for an explicit full-discretization of stochastic\n  Allen-Cahn equation with additive noise",
		"creator": [
			"Cai, Meng",
			"Gan, Siqing",
			"Wang, Xiaojie"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"Mathematics - Probability",
			"60H35, 60H15, 65C30"
		],
		"description": [
			"  We discretize the stochastic Allen-Cahn equation with additive noise by means\nof a spectral Galerkin method in space and a tamed version of the exponential\nEuler method in time. The resulting error bounds are analyzed for the\nspatio-temporal full discretization in both strong and weak senses. Different\nfrom existing works, we develop a new and direct approach for the weak error\nanalysis, which does not rely on the use of the associated Kolmogorov equation\nor It\\^{o}'s formula and is therefore non-Markovian in nature. Such an approach\nthus has a potential to be applied to non-Markovian equations such as\nstochastic Volterra equations or other types of fractional SPDEs, which suffer\nfrom the lack of Kolmogorov equations. It turns out that the obtained weak\nconvergence rates are, in both spatial and temporal direction, essentially\ntwice as high as the strong convergence rates. Also, it is revealed how the\nweak convergence rates depend on the regularity of the noise. Numerical\nexperiments are finally reported to confirm the theoretical conclusion.\n",
			"Comment: 28 pages"
		],
		"date": [
			"2019-11-21",
			"2021-01-19"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1911.09543",
			"J. Sci. Comput. (2021)",
			"doi:10.1007/s10915-020-01378-8"
		],
		"pdf_url": "http://arxiv.org/pdf/1911.09543.pdf"
	},
	"154": {
		"title": "Simple yet Effective Way for Improving the Performance of GAN",
		"creator": [
			"Shin, Yong-Goo",
			"Yeo, Yoon-Jae",
			"Ko, Sung-Jea"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Statistics - Machine Learning"
		],
		"description": [
			"  In adversarial learning, discriminator often fails to guide the generator\nsuccessfully since it distinguishes between real and generated images using\nsilly or non-robust features. To alleviate this problem, this brief presents a\nsimple but effective way that improves the performance of generative\nadversarial network (GAN) without imposing the training overhead or modifying\nthe network architectures of existing methods. The proposed method employs a\nnovel cascading rejection (CR) module for discriminator, which extracts\nmultiple non-overlapped features in an iterative manner using the vector\nrejection operation. Since the extracted diverse features prevent the\ndiscriminator from concentrating on non-meaningful features, the discriminator\ncan guide the generator effectively to produce the images that are more similar\nto the real images. In addition, since the proposed CR module requires only a\nfew simple vector operations, it can be readily applied to existing frameworks\nwith marginal training overheads. Quantitative evaluations on various datasets\nincluding CIFAR-10, CelebA, CelebA-HQ, LSUN, and tiny-ImageNet confirm that the\nproposed method significantly improves the performance of GAN and conditional\nGAN in terms of Frechet inception distance (FID) indicating the diversity and\nvisual appearance of the generated images.\n",
			"Comment: Accepted to IEEE transactions on neural networks and learning systems"
		],
		"date": [
			"2019-11-19",
			"2021-01-19"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1911.10979",
			"doi:10.1109/TNNLS.2020.3045000"
		],
		"pdf_url": "http://arxiv.org/pdf/1911.10979.pdf"
	},
	"155": {
		"title": "LL(1) Parsing with Derivatives and Zippers",
		"creator": [
			"Edelmann, Romain",
			"Hamza, Jad",
			"Kunčak, Viktor"
		],
		"subject": [
			"Computer Science - Formal Languages and Automata Theory",
			"Computer Science - Data Structures and Algorithms"
		],
		"description": [
			"  In this paper, we present an efficient, functional, and formally verified\nparsing algorithm for LL(1) context-free expressions based on the concept of\nderivatives of formal languages. Parsing with derivatives is an elegant parsing\ntechnique, which, in the general case, suffers from cubic worst-case time\ncomplexity and slow performance in practice. We specialise the parsing with\nderivatives algorithm to LL(1) context-free expressions, where alternatives can\nbe chosen given a single token of lookahead. We formalise the notion of LL(1)\nexpressions and show how to efficiently check the LL(1) property. Next, we\npresent a novel linear-time parsing with derivatives algorithm for LL(1)\nexpressions operating on a zipper-inspired data structure. We prove the\nalgorithm correct in Coq and present an implementation as a parser combinators\nframework in Scala, with enumeration and pretty printing capabilities.\n",
			"Comment: Appeared at PLDI'20 under the title \"Zippy LL(1) Parsing with\n  Derivatives\""
		],
		"date": [
			"2019-11-28",
			"2021-01-21"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1911.12737",
			"doi:10.1145/3385412.3385992"
		],
		"pdf_url": "http://arxiv.org/pdf/1911.12737.pdf"
	},
	"156": {
		"title": "Efficient Calibration of Embedded MPC",
		"creator": [
			"Forgione, Marco",
			"Piga, Dario",
			"Bemporad, Alberto"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Mathematics - Optimization and Control"
		],
		"description": [
			"  Model Predictive Control (MPC) is a powerful and flexible design tool of\nhigh-performance controllers for physical systems in the presence of input and\noutput constraints. A challenge for the practitioner applying MPC is the need\nof tuning a large number of parameters such as prediction and control horizons,\nweight matrices of the MPC cost function, and observer gains, according to\ndifferent trade-offs. The MPC design task is even more involved when the\ncontrol law has to be deployed to an embedded hardware unit endowed with\nlimited computational resources. In this case, real-time system requirements\nlimit the complexity of the applicable MPC configuration, engendering\nadditional design tradeoffs and requiring to tune further parameters, such as\nthe sampling time and the tolerances used in the on-line numerical solver. To\ntake into account closed-loop performance and real-time requirements, in this\npaper we tackle the embedded MPC design problem using a global, data-driven,\noptimization approach We showcase the potential of this approach by tuning an\nMPC controller on two hardware platforms characterized by largely different\ncomputational capabilities.\n",
			"Comment: Source code generating the results of the paper available at\n  https://github.com/forgi86/efficient-calibration-embedded-MPC"
		],
		"date": [
			"2019-11-29",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1911.13021",
		"pdf_url": "http://arxiv.org/pdf/1911.13021.pdf"
	},
	"157": {
		"title": "Deep Neural Network Fingerprinting by Conferrable Adversarial Examples",
		"creator": [
			"Lukas, Nils",
			"Zhang, Yuxuan",
			"Kerschbaum, Florian"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Cryptography and Security",
			"Statistics - Machine Learning"
		],
		"description": "  In Machine Learning as a Service, a provider trains a deep neural network and\ngives many users access. The hosted (source) model is susceptible to model\nstealing attacks, where an adversary derives a surrogate model from API access\nto the source model. For post hoc detection of such attacks, the provider needs\na robust method to determine whether a suspect model is a surrogate of their\nmodel. We propose a fingerprinting method for deep neural network classifiers\nthat extracts a set of inputs from the source model so that only surrogates\nagree with the source model on the classification of such inputs. These inputs\nare a subclass of transferable adversarial examples which we call conferrable\nadversarial examples that exclusively transfer with a target label from a\nsource model to its surrogates. We propose a new method to generate these\nconferrable adversarial examples. We present an extensive study on the\nirremovability of our fingerprint against fine-tuning, weight pruning,\nretraining, retraining with different architectures, three model extraction\nattacks from related work, transfer learning, adversarial training, and two new\nadaptive attacks. Our fingerprint is robust against distillation, related model\nextraction attacks, and even transfer learning when the attacker has no access\nto the model provider's dataset. Our fingerprint is the first method that\nreaches a ROC AUC of 1.0 in verifying surrogates, compared to a ROC AUC of 0.63\nby previous fingerprints.\n",
		"date": [
			"2019-12-02",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1912.00888",
		"pdf_url": "http://arxiv.org/pdf/1912.00888.pdf"
	},
	"158": {
		"title": "PolyTransform: Deep Polygon Transformer for Instance Segmentation",
		"creator": [
			"Liang, Justin",
			"Homayounfar, Namdar",
			"Ma, Wei-Chiu",
			"Xiong, Yuwen",
			"Hu, Rui",
			"Urtasun, Raquel"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  In this paper, we propose PolyTransform, a novel instance segmentation\nalgorithm that produces precise, geometry-preserving masks by combining the\nstrengths of prevailing segmentation approaches and modern polygon-based\nmethods. In particular, we first exploit a segmentation network to generate\ninstance masks. We then convert the masks into a set of polygons that are then\nfed to a deforming network that transforms the polygons such that they better\nfit the object boundaries. Our experiments on the challenging Cityscapes\ndataset show that our PolyTransform significantly improves the performance of\nthe backbone instance segmentation network and ranks 1st on the Cityscapes\ntest-set leaderboard. We also show impressive gains in the interactive\nannotation setting. We release the code at\nhttps://github.com/uber-research/PolyTransform.\n",
		"date": [
			"2019-12-05",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1912.02801",
		"pdf_url": "http://arxiv.org/pdf/1912.02801.pdf"
	},
	"159": {
		"title": "Efficient multivariate approximation on the cube",
		"creator": [
			"Nasdala, Robert",
			"Potts, Daniel"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"65T, 42B05"
		],
		"description": [
			"  We combine a periodization strategy for weighted $L_{2}$-integrands with\nefficient approximation methods in order to approximate multivariate\nnon-periodic functions on the high-dimensional cube\n$\\left[-\\frac{1}{2},\\frac{1}{2}\\right]^{d}$. Our concept allows to determine\nconditions on the $d$-variate torus-to-cube transformations\n${\\psi:\\left[-\\frac{1}{2},\\frac{1}{2}\\right]^{d}\\to\\left[-\\frac{1}{2},\\frac{1}{2}\\right]^{d}}$\nsuch that a non-periodic function is transformed into a smooth function in the\nSobolev space $\\mathcal H^{m}(\\mathbb{T}^{d})$ when applying $\\psi$. We adapt\nsome $L_{\\infty}(\\mathbb{T}^{d})$- and $L_{2}(\\mathbb{T}^{d})$-approximation\nerror estimates for single rank-$1$ lattice approximation methods and adjust\nalgorithms for the fast evaluation and fast reconstruction of multivariate\ntrigonometric polynomials on the torus in order to apply these methods to the\nnon-periodic setting. We illustrate the theoretical findings by means of\nnumerical tests in up to $d=5$ dimensions.\n",
			"Comment: arXiv admin note: substantial text overlap with arXiv:1805.09106"
		],
		"date": [
			"2019-12-06",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1912.03090",
		"pdf_url": "http://arxiv.org/pdf/1912.03090.pdf"
	},
	"160": {
		"title": "Attentive Representation Learning with Adversarial Training for Short\n  Text Clustering",
		"creator": [
			"Zhang, Wei",
			"Dong, Chao",
			"Yin, Jianhua",
			"Wang, Jianyong"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computation and Language",
			"Computer Science - Information Retrieval"
		],
		"description": [
			"  Short text clustering has far-reaching effects on semantic analysis, showing\nits importance for multiple applications such as corpus summarization and\ninformation retrieval. However, it inevitably encounters the severe sparsity of\nshort text representations, making the previous clustering approaches still far\nfrom satisfactory. In this paper, we present a novel attentive representation\nlearning model for shot text clustering, wherein cluster-level attention is\nproposed to capture the correlations between text representations and cluster\nrepresentations. Relying on this, the representation learning and clustering\nfor short texts are seamlessly integrated into a unified model. To further\nensure robust model training for short texts, we apply adversarial training to\nthe unsupervised clustering setting, by injecting perturbations into the\ncluster representations. The model parameters and perturbations are optimized\nalternately through a minimax game. Extensive experiments on four real-world\nshort text datasets demonstrate the superiority of the proposed model over\nseveral strong competitors, verifying that robust adversarial training yields\nsubstantial performance gains.\n",
			"Comment: 14pages, to appear in IEEE TKDE"
		],
		"date": [
			"2019-12-08",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1912.03720",
		"pdf_url": "http://arxiv.org/pdf/1912.03720.pdf"
	},
	"161": {
		"title": "ShadingNet: Image Intrinsics by Fine-Grained Shading Decomposition",
		"creator": [
			"Baslamisli, Anil S.",
			"Das, Partha",
			"Le, Hoang-An",
			"Karaoglu, Sezer",
			"Gevers, Theo"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  In general, intrinsic image decomposition algorithms interpret shading as one\nunified component including all photometric effects. As shading transitions are\ngenerally smoother than reflectance (albedo) changes, these methods may fail in\ndistinguishing strong photometric effects from reflectance variations.\nTherefore, in this paper, we propose to decompose the shading component into\ndirect (illumination) and indirect shading (ambient light and shadows)\nsubcomponents. The aim is to distinguish strong photometric effects from\nreflectance variations. An end-to-end deep convolutional neural network\n(ShadingNet) is proposed that operates in a fine-to-coarse manner with a\nspecialized fusion and refinement unit exploiting the fine-grained shading\nmodel. It is designed to learn specific reflectance cues separated from\nspecific photometric effects to analyze the disentanglement capability. A\nlarge-scale dataset of scene-level synthetic images of outdoor natural\nenvironments is provided with fine-grained intrinsic image ground-truths. Large\nscale experiments show that our approach using fine-grained shading\ndecompositions outperforms state-of-the-art algorithms utilizing unified\nshading on NED, MPI Sintel, GTA V, IIW, MIT Intrinsic Images, 3DRMS and SRD\ndatasets.\n",
			"Comment: Submitted to International Journal of Computer Vision (IJCV)"
		],
		"date": [
			"2019-12-09",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1912.04023",
		"pdf_url": "http://arxiv.org/pdf/1912.04023.pdf"
	},
	"162": {
		"title": "Existence, uniqueness, and approximation of solutions of jump-diffusion\n  SDEs with discontinuous drift",
		"creator": [
			"Przybyłowicz, Paweł",
			"Szölgyenyi, Michaela"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"Mathematics - Probability",
			"60H10, 65C30, 65C20, 65L20"
		],
		"description": "  In this paper we study jump-diffusion stochastic differential equations\n(SDEs) with a discontinuous drift coefficient and a possibly degenerate\ndiffusion coefficient. Such SDEs appear in applications such as optimal control\nproblems in energy markets. We prove existence and uniqueness of strong\nsolutions. In addition we study the strong convergence order of the\nEuler-Maruyama scheme and recover the optimal rate $1/2$.\n",
		"date": [
			"2019-12-09",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1912.04215",
		"pdf_url": "http://arxiv.org/pdf/1912.04215.pdf"
	},
	"163": {
		"title": "Image Classification with Deep Learning in the Presence of Noisy Labels:\n  A Survey",
		"creator": [
			"Algan, Görkem",
			"Ulusoy, Ilkay"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Statistics - Machine Learning"
		],
		"description": "  Image classification systems recently made a giant leap with the advancement\nof deep neural networks. However, these systems require an excessive amount of\nlabeled data to be adequately trained. Gathering a correctly annotated dataset\nis not always feasible due to several factors, such as the expensiveness of the\nlabeling process or difficulty of correctly classifying data, even for the\nexperts. Because of these practical challenges, label noise is a common problem\nin real-world datasets, and numerous methods to train deep neural networks with\nlabel noise are proposed in the literature. Although deep neural networks are\nknown to be relatively robust to label noise, their tendency to overfit data\nmakes them vulnerable to memorizing even random noise. Therefore, it is crucial\nto consider the existence of label noise and develop counter algorithms to fade\naway its adverse effects to train deep neural networks efficiently. Even though\nan extensive survey of machine learning techniques under label noise exists,\nthe literature lacks a comprehensive survey of methodologies centered\nexplicitly around deep learning in the presence of noisy labels. This paper\naims to present these algorithms while categorizing them into one of the two\nsubgroups: noise model based and noise model free methods. Algorithms in the\nfirst group aim to estimate the noise structure and use this information to\navoid the adverse effects of noisy labels. Differently, methods in the second\ngroup try to come up with inherently noise robust algorithms by using\napproaches like robust losses, regularizers or other learning paradigms.\n",
		"date": [
			"2019-12-11",
			"2021-01-11"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1912.05170",
			"doi:10.1016/j.knosys.2021.106771"
		],
		"pdf_url": "http://arxiv.org/pdf/1912.05170.pdf"
	},
	"164": {
		"title": "A Practical Solution for SAR Despeckling With Adversarial Learning\n  Generated Speckled-to-Speckled Images",
		"creator": [
			"Yuan, Ye",
			"Guan, Jian",
			"Feng, Pengming",
			"Wu, Yanxia"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": [
			"  In this letter, we aim to address a synthetic aperture radar (SAR)\ndespeckling problem with the necessity of neither clean (speckle-free) SAR\nimages nor independent speckled image pairs from the same scene, and a\npractical solution for SAR despeckling (PSD) is proposed. First, an adversarial\nlearning framework is designed to generate speckled-to-speckled (S2S) image\npairs from the same scene in the situation where only single speckled SAR\nimages are available. Then, the S2S SAR image pairs are employed to train a\nmodified despeckling Nested-UNet model using the Noise2Noise (N2N) strategy.\nMoreover, an iterative version of the PSD method (PSDi) is also presented.\nExperiments are conducted on both synthetic speckled and real SAR data to\ndemonstrate the superiority of the proposed methods compared with several\nstate-of-the-art methods. The results show that our methods can reach a good\ntradeoff between feature preservation and speckle suppression.\n",
			"Comment: 5 pages, 4 figures"
		],
		"date": [
			"2019-12-12",
			"2021-01-17"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1912.06295",
			"IEEE Geoscience and Remote Sensing Letters,(2020)1-5",
			"doi:10.1109/LGRS.2020.3034470"
		],
		"pdf_url": "http://arxiv.org/pdf/1912.06295.pdf"
	},
	"165": {
		"title": "Multi-Object Rearrangement with Monte Carlo Tree Search:A Case Study on\n  Planar Nonprehensile Sorting",
		"creator": [
			"Song, Haoran",
			"Haustein, Joshua A.",
			"Yuan, Weihao",
			"Hang, Kaiyu",
			"Wang, Michael Yu",
			"Kragic, Danica",
			"Stork, Johannes A."
		],
		"subject": "Computer Science - Robotics",
		"description": [
			"  In this work, we address a planar non-prehensile sorting task. Here, a robot\nneeds to push many densely packed objects belonging to different classes into a\nconfiguration where these classes are clearly separated from each other. To\nachieve this, we propose to employ Monte Carlo tree search equipped with a\ntask-specific heuristic function. We evaluate the algorithm on various\nsimulated and real-world sorting tasks. We observe that the algorithm is\ncapable to reliably sort large numbers of convex and non-convex objects, as\nwell as convex objects in the presence of immovable obstacles.\n",
			"Comment: IEEE/RSJ International Conference on Intelligent Robots and Systems\n  (IROS) 2020; Project page at http://haoran-song.github.io/mcts-sorting/"
		],
		"date": [
			"2019-12-15",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1912.07024",
		"pdf_url": "http://arxiv.org/pdf/1912.07024.pdf"
	},
	"166": {
		"title": "On-manifold Adversarial Data Augmentation Improves Uncertainty\n  Calibration",
		"creator": [
			"Patel, Kanil",
			"Beluch, William",
			"Zhang, Dan",
			"Pfeiffer, Michael",
			"Yang, Bin"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Uncertainty estimates help to identify ambiguous, novel, or anomalous inputs,\nbut the reliable quantification of uncertainty has proven to be challenging for\nmodern deep networks. In order to improve uncertainty estimation, we propose\nOn-Manifold Adversarial Data Augmentation or OMADA, which specifically attempts\nto generate the most challenging examples by following an on-manifold\nadversarial attack path in the latent space of an autoencoder-based generative\nmodel that closely approximates decision boundaries between two or more\nclasses. On a variety of datasets as well as on multiple diverse network\narchitectures, OMADA consistently yields more accurate and better calibrated\nclassifiers than baseline models, and outperforms competing approaches such as\nMixup, as well as achieving similar performance to (at times better than)\npost-processing calibration methods such as temperature scaling. Variants of\nOMADA can employ different sampling schemes for ambiguous on-manifold examples\nbased on the entropy of their estimated soft labels, which exhibit specific\nstrengths for generalization, calibration of predicted uncertainty, or\ndetection of out-of-distribution inputs.\n",
			"Comment: Accepted for oral at International Conference on Pattern Recognition,\n  ICPR 2020. Nominated (top 4) for Best Industry Related Paper Award (BIRPA)"
		],
		"date": [
			"2019-12-16",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1912.07458",
		"pdf_url": "http://arxiv.org/pdf/1912.07458.pdf"
	},
	"167": {
		"title": "MG-WFBP: Merging Gradients Wisely for Efficient Communication in\n  Distributed Deep Learning",
		"creator": [
			"Shi, Shaohuai",
			"Chu, Xiaowen",
			"Li, Bo"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Distributed synchronous stochastic gradient descent has been widely used to\ntrain deep neural networks (DNNs) on computer clusters. With the increase of\ncomputational power, network communications generally limit the system\nscalability. Wait-free backpropagation (WFBP) is a popular solution to overlap\ncommunications with computations during the training process. In this paper, we\nobserve that many DNNs have a large number of layers with only a small amount\nof data to be communicated at each layer in distributed training, which could\nmake WFBP inefficient. Based on the fact that merging some short communication\ntasks into a single one can reduce the overall communication time, we formulate\nan optimization problem to minimize the training time in pipelining\ncommunications and computations. We derive an optimal solution that can be\nsolved efficiently without affecting the training performance. We then apply\nthe solution to propose a distributed training algorithm named merged-gradient\nWFBP (MG-WFBP) and implement it in two platforms Caffe and PyTorch. Extensive\nexperiments in three GPU clusters are conducted to verify the effectiveness of\nMG-WFBP. We further exploit trace-based simulations of 4 to 2048 GPUs to\nexplore the potential scaling efficiency of MG-WFBP. Experimental results show\nthat MG-WFBP achieves much better scaling performance than existing methods.\n",
			"Comment: Accepted by IEEE TPDS. 15 pages. arXiv admin note: substantial text\n  overlap with arXiv:1811.11141"
		],
		"date": [
			"2019-12-17",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1912.09268",
		"pdf_url": "http://arxiv.org/pdf/1912.09268.pdf"
	},
	"168": {
		"title": "Exploring the Capacity of an Orderless Box Discretization Network for\n  Multi-orientation Scene Text Detection",
		"creator": [
			"Liu, Yuliang",
			"He, Tong",
			"Chen, Hao",
			"Wang, Xinyu",
			"Luo, Canjie",
			"Zhang, Shuaitao",
			"Shen, Chunhua",
			"Jin, Lianwen"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Multi-orientation scene text detection has recently gained significant\nresearch attention. Previous methods directly predict words or text lines,\ntypically by using quadrilateral shapes. However, many of these methods neglect\nthe significance of consistent labeling, which is important for maintaining a\nstable training process, especially when it comprises a large amount of data.\nHere we solve this problem by proposing a new method, Orderless Box\nDiscretization (OBD), which first discretizes the quadrilateral box into\nseveral key edges containing all potential horizontal and vertical positions.\nTo decode accurate vertex positions, a simple yet effective matching procedure\nis proposed for reconstructing the quadrilateral bounding boxes. Our method\nsolves the ambiguity issue, which has a significant impact on the learning\nprocess. Extensive ablation studies are conducted to validate the effectiveness\nof our proposed method quantitatively. More importantly, based on OBD, we\nprovide a detailed analysis of the impact of a collection of refinements, which\nmay inspire others to build state-of-the-art text detectors. Combining both OBD\nand these useful refinements, we achieve state-of-the-art performance on\nvarious benchmarks, including ICDAR 2015 and MLT. Our method also won the first\nplace in the text detection task at the recent ICDAR2019 Robust Reading\nChallenge for Reading Chinese Text on Signboards, further demonstrating its\nsuperior performance. The code is available at https://git.io/TextDet.\n",
		"date": [
			"2019-12-19",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1912.09629",
		"pdf_url": "http://arxiv.org/pdf/1912.09629.pdf"
	},
	"169": {
		"title": "A New Preconditioning Approach for an Interior Point-Proximal Method of\n  Multipliers for Linear and Convex Quadratic Programming",
		"creator": [
			"Bergamaschi, Luca",
			"Gondzio, Jacek",
			"Martínez, Ángeles",
			"Pearson, John W.",
			"Pougkakiotis, Spyridon"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"Mathematics - Optimization and Control"
		],
		"description": "  In this paper, we address the efficient numerical solution of linear and\nquadratic programming problems, often of large scale. With this aim, we devise\nan infeasible interior point method, blended with the proximal method of\nmultipliers, which in turn results in a primal-dual regularized interior point\nmethod. Application of this method gives rise to a sequence of increasingly\nill-conditioned linear systems which cannot always be solved by factorization\nmethods, due to memory and CPU time restrictions. We propose a novel\npreconditioning strategy which is based on a suitable sparsification of the\nnormal equations matrix in the linear case, and also constitutes the foundation\nof a block-diagonal preconditioner to accelerate MINRES for linear systems\narising from the solution of general quadratic programming problems. Numerical\nresults for a range of test problems demonstrate the robustness of the proposed\npreconditioning strategy, together with its ability to solve linear systems of\nvery large dimension.\n",
		"date": [
			"2019-12-20",
			"2020-12-11"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/1912.10064",
			"doi:10.1002/nla.2361"
		],
		"pdf_url": "http://arxiv.org/pdf/1912.10064.pdf"
	},
	"170": {
		"title": "Statistical analysis of Mapper for stochastic and multivariate filters",
		"creator": [
			"Carrière, Mathieu",
			"Michel, Bertrand"
		],
		"subject": [
			"Mathematics - Algebraic Topology",
			"Computer Science - Computational Geometry",
			"Statistics - Methodology",
			"Statistics - Machine Learning"
		],
		"description": "  Reeb spaces, as well as their discretized versions called Mappers, are common\ndescriptors used in Topological Data Analysis, with plenty of applications in\nvarious fields of science, such as computational biology and data\nvisualization, among others. The stability and quantification of the rate of\nconvergence of the Mapper to the Reeb space has been studied a lot in recent\nworks [BBMW19, CO17, CMO18, MW16], focusing on the case where a scalar-valued\nfilter is used for the computation of Mapper. On the other hand, much less is\nknown in the multivariate case, when the codomain of the filter is\n$\\mathbb{R}^p$, and in the general case, when it is a general metric space $(Z,\nd_Z)$, instead of $\\mathbb{R}$. The few results that are available in this\nsetting [DMW17, MW16] can only handle continuous topological spaces and cannot\nbe used as is for finite metric spaces representing data, such as point clouds\nand distance matrices. In this article, we introduce a slight modification of\nthe usual Mapper construction and we give risk bounds for estimating the Reeb\nspace using this estimator. Our approach applies in particular to the setting\nwhere the filter function used to compute Mapper is also estimated from data,\nsuch as the eigenfunctions of PCA. Our results are given with respect to the\nGromov-Hausdorff distance, computed with specific filter-based pseudometrics\nfor Mappers and Reeb spaces defined in [DMW17]. We finally provide applications\nof this setting in statistics and machine learning for different kinds of\ntarget filters, as well as numerical experiments that demonstrate the relevance\nof our approach\n",
		"date": [
			"2019-12-23",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1912.10742",
		"pdf_url": "http://arxiv.org/pdf/1912.10742.pdf"
	},
	"171": {
		"title": "Terahertz Multi-User Massive MIMO with Intelligent Reflecting Surface:\n  Beam Training and Hybrid Beamforming",
		"creator": [
			"Ning, Boyu",
			"Chen, Zhi",
			"Chen, Wenrong",
			"Du, Yiming",
			"Fang, Jun"
		],
		"subject": [
			"Computer Science - Information Theory",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": "  Terahertz (THz) communications open a new frontier for the wireless network\nthanks to their dramatically wider available bandwidth compared to the current\nmicro-wave and forthcoming millimeter-wave communications. However, due to the\nshort length of THz waves, they also suffer from severe path attenuation and\npoor diffraction. To compensate the THz-induced propagation loss, this paper\nproposes to combine two promising techniques, viz., massive multiple input\nmultiple output (MIMO) and intelligent reflecting surface (IRS), in THz\nmulti-user communications, considering their significant beamforming and\naperture gains. Nonetheless, channel estimation and low-cost beamforming turn\nout to be two main obstacles to realizing this combination, due to the\npassivity of IRS for sending/receiving pilot signals and the large-scale use of\nexpensive RF chains in massive MIMO. In view of these limitations, this paper\nfirst develops a cooperative beam training scheme to facilitate the channel\nestimation with IRS. In particular, we design two different hierarchical\ncodebooks for the proposed training procedure, which are able to balance\nbetween the robustness against noise and searching complexity. Based on the\ntraining results, we further propose two cost-efficient hybrid beamforming (HB)\ndesigns for both single-user and multi-user scenarios, respectively. Simulation\nresults demonstrate that the proposed joint beam training and HB scheme is able\nto achieve close performance to the optimal fully digital beamforming (FDB)\nwhich is implemented even under perfect channel state information (CSI).\n",
		"date": [
			"2019-12-25",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1912.11662",
		"pdf_url": "http://arxiv.org/pdf/1912.11662.pdf"
	},
	"172": {
		"title": "Copy Move Source-Target Disambiguation through Multi-Branch CNNs",
		"creator": [
			"Barni, Mauro",
			"Phan, Quoc-Tin",
			"Tondi, Benedetta"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Cryptography and Security"
		],
		"description": "  We propose a method to identify the source and target regions of a copy-move\nforgery so allow a correct localisation of the tampered area. First, we cast\nthe problem into a hypothesis testing framework whose goal is to decide which\nregion between the two nearly-duplicate regions detected by a generic copy-move\ndetector is the original one. Then we design a multi-branch CNN architecture\nthat solves the hypothesis testing problem by learning a set of features\ncapable to reveal the presence of interpolation artefacts and boundary\ninconsistencies in the copy-moved area. The proposed architecture, trained on a\nsynthetic dataset explicitly built for this purpose, achieves good results on\ncopy-move forgeries from both synthetic and realistic datasets. Based on our\ntests, the proposed disambiguation method can reliably reveal the target region\neven in realistic cases where an approximate version of the copy-move\nlocalization mask is provided by a state-of-the-art copy-move detection\nalgorithm.\n",
		"date": [
			"2019-12-29",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/1912.12640",
		"pdf_url": "http://arxiv.org/pdf/1912.12640.pdf"
	},
	"173": {
		"title": "Stacked DeBERT: All Attention in Incomplete Data for Text Classification",
		"creator": [
			"Sergio, Gwenaelle Cunha",
			"Lee, Minho"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  In this paper, we propose Stacked DeBERT, short for Stacked Denoising\nBidirectional Encoder Representations from Transformers. This novel model\nimproves robustness in incomplete data, when compared to existing systems, by\ndesigning a novel encoding scheme in BERT, a powerful language representation\nmodel solely based on attention mechanisms. Incomplete data in natural language\nprocessing refer to text with missing or incorrect words, and its presence can\nhinder the performance of current models that were not implemented to withstand\nsuch noises, but must still perform well even under duress. This is due to the\nfact that current approaches are built for and trained with clean and complete\ndata, and thus are not able to extract features that can adequately represent\nincomplete data. Our proposed approach consists of obtaining intermediate input\nrepresentations by applying an embedding layer to the input tokens followed by\nvanilla transformers. These intermediate features are given as input to novel\ndenoising transformers which are responsible for obtaining richer input\nrepresentations. The proposed approach takes advantage of stacks of multilayer\nperceptrons for the reconstruction of missing words' embeddings by extracting\nmore abstract and meaningful hidden feature vectors, and bidirectional\ntransformers for improved embedding representation. We consider two datasets\nfor training and evaluation: the Chatbot Natural Language Understanding\nEvaluation Corpus and Kaggle's Twitter Sentiment Corpus. Our model shows\nimproved F1-scores and better robustness in informal/incorrect texts present in\ntweets and in texts with Speech-to-Text error in the sentiment and intent\nclassification tasks.\n",
			"Comment: Published (https://doi.org/10.1016/j.neunet.2020.12.018), Code\n  (https://github.com/gcunhase/StackedDeBERT)"
		],
		"date": [
			"2019-12-31",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2001.00137",
			"Neural Networks 136 (2021) 87-96",
			"doi:10.1016/j.neunet.2020.12.018"
		],
		"pdf_url": "http://arxiv.org/pdf/2001.00137.pdf"
	},
	"174": {
		"title": "Monte Carlo Cubature Construction",
		"creator": "Hayakawa, Satoshi",
		"subject": [
			"Mathematics - Numerical Analysis",
			"Mathematics - Probability"
		],
		"description": [
			"  In numerical integration, cubature methods are effective, especially when the\nintegrands can be well-approximated by known test functions, such as\npolynomials. However, the construction of cubature formulas has not generally\nbeen known, and existing examples only represent the particular domains of\nintegrands, such as hypercubes and spheres. In this study, we show that\ncubature formulas can be constructed for probability measures provided that we\nhave an i.i.d. sampler from the measure and the mean values of given test\nfunctions. Moreover, the proposed method also works as a means of data\ncompression, even if sufficient prior information of the measure is not\navailable.\n",
			"Comment: 10 pages"
		],
		"date": [
			"2020-01-03",
			"2020-01-24"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2001.00843",
			"doi:10.1007/s13160-020-00451-x"
		],
		"pdf_url": "http://arxiv.org/pdf/2001.00843.pdf"
	},
	"175": {
		"title": "Simple explanation of Landauer's bound and its ineffectiveness for\n  multivalued logic",
		"creator": [
			"Kycia, Radosław A.",
			"Niemczynowcz, Agnieszka"
		],
		"subject": [
			"Condensed Matter - Statistical Mechanics",
			"Condensed Matter - Materials Science",
			"Computer Science - Information Theory",
			"Mathematical Physics"
		],
		"description": [
			"  We discuss, using recent results on the Landauer's bound in multivalued\nlogic, the difficulties and pitfalls of how to apply this principle. The\npresentation is based on Szilard's version of Maxwell's demon experiment and\nuse of equilibrium Thermodynamics. Different versions of\nthermodynamical/mechanical memory are presented - one-hot encoding version and\nthe implementation based on reversed Szilard's experiment. Relation of the\nLandauer's principle to Galois connection is explained in detail.\n",
			"Comment: 13 pages, 8 figures"
		],
		"date": [
			"2020-01-03",
			"2020-03-19"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2001.00942",
			"Technical Transactions, 117 1 (2020)",
			"doi:10.37705/TechTrans/e2020042"
		],
		"pdf_url": "http://arxiv.org/pdf/2001.00942.pdf"
	},
	"176": {
		"title": "Causal Mosaic: Cause-Effect Inference via Nonlinear ICA and Ensemble\n  Method",
		"creator": [
			"Wu, Pengzhou",
			"Fukumizu, Kenji"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  We address the problem of distinguishing cause from effect in bivariate\nsetting. Based on recent developments in nonlinear independent component\nanalysis (ICA), we train nonparametrically general nonlinear causal models that\nallow non-additive noise. Further, we build an ensemble framework, namely\nCausal Mosaic, which models a causal pair by a mixture of nonlinear models. We\ncompare this method with other recent methods on artificial and real world\nbenchmark datasets, and our method shows state-of-the-art performance.\n",
			"Comment: Accepted to AISTATS 2020. Camera-ready version in preparation"
		],
		"date": "2020-01-07",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2001.01894",
			"An updated version at AISTATS 2020:\n  http://proceedings.mlr.press/v108/wu20b/wu20b.pdf. Main changes: a correction\n  in Theorem 3 and additional explanations in Sec. 4"
		],
		"pdf_url": "http://arxiv.org/pdf/2001.01894.pdf"
	},
	"177": {
		"title": "How to Cut a Cake Fairly: A Generalization to Groups",
		"creator": [
			"Segal-Halevi, Erel",
			"Suksompong, Warut"
		],
		"subject": [
			"Economics - Theoretical Economics",
			"Computer Science - Computer Science and Game Theory",
			"Mathematics - Combinatorics"
		],
		"description": "  A fundamental result in cake cutting states that for any number of players\nwith arbitrary preferences over a cake, there exists a division of the cake\nsuch that every player receives a single contiguous piece and no player is left\nenvious. We generalize this result by showing that it is possible to partition\nthe players into groups of any desired sizes and divide the cake among the\ngroups, so that each group receives a single contiguous piece and no player\nfinds the piece of another group better than that of the player's own group.\n",
		"date": [
			"2020-01-10",
			"2020-04-02"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2001.03327",
			"American Mathematical Monthly, 128(1): 79-83 (2021)",
			"doi:10.1080/00029890.2021.1835338"
		],
		"pdf_url": "http://arxiv.org/pdf/2001.03327.pdf"
	},
	"178": {
		"title": "PIR Codes with Short Block Length",
		"creator": [
			"Kurz, Sascha",
			"Yaakobi, Eitan"
		],
		"subject": [
			"Computer Science - Information Theory",
			"Mathematics - Combinatorics",
			"68P30",
			"E.4"
		],
		"description": [
			"  In this work private information retrieval (PIR) codes are studied. In a\n$k$-PIR code, $s$ information bits are encoded in such a way that every\ninformation bit has $k$ mutually disjoint recovery sets. The main problem under\nthis paradigm is to minimize the number of encoded bits given the values of $s$\nand $k$, where this value is denoted by $P(s,k)$. The main focus of this work\nis to analyze $P(s,k)$ for a large range of parameters of $s$ and $k$. In\nparticular, we improve upon several of the existing results on this value.\n",
			"Comment: 10 pages, 1 table"
		],
		"date": "2020-01-10",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2001.03433",
			"doi:10.1007/s10623-020-00828-6"
		],
		"pdf_url": "http://arxiv.org/pdf/2001.03433.pdf"
	},
	"179": {
		"title": "Attitude Determination and Estimation using Vector Observations: Review,\n  Challenges and Comparative Results",
		"creator": "Hashim, Hashim A",
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": "  This paper concerns the problem of attitude determination and estimation. The\nearly applications considered algebraic methods of attitude determination.\nAttitude determination algorithms were supplanted by the Gaussian attitude\nestimation filters (which continue to be widely used in commercial\napplications). However, the sensitivity of the Gaussian attitude filter to the\nmeasurement noise prompted the introduction of the nonlinear attitude filters\nwhich account for the nonlinear nature of the attitude dynamics problem and\nallow for a simpler filter derivation. This paper presents a survey of several\ntypes of attitude determination and estimation algorithms. Each category is\ndetailed and illustrated with literature examples in both continuous and\ndiscrete form. A comparison between these algorithms is demonstrated in terms\nof transient and steady-state error through simulation results. The comparison\nis supplemented by statistical analysis of the error-related mean, infinity\nnorm, and standard deviation of each algorithm in the steady-state. Keywords:\nComparative Study, Attitude, Determination, Estimation, Filter, Adaptive\nFilter, Gaussian Filter, Nonlinear Filter, Overview, Review, Rodrigues Vector,\nSpecial Orthogonal Group, Unit-quaternion, Angle-axis, Determinstic,\nStochastic, Continuous, Discrete, Multiplicative extended kalman filter, KF,\nEKF, MEKF, white noise, colored noise.\n",
		"date": [
			"2020-01-11",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2001.03787",
		"pdf_url": "http://arxiv.org/pdf/2001.03787.pdf"
	},
	"180": {
		"title": "Scalable distributed and decentralized $\\mathscr{H}_2$ controller\n  synthesis for interconnected linear discrete-time systems",
		"creator": [
			"Steentjes, Tom R. V.",
			"Lazar, Mircea",
			"Hof, Paul M. J. Van den"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  The current limitation in the synthesis of distributed $\\mathscr{H}_2$\ncontrollers for linear interconnected systems is scalability due to non-convex\nor unstructured synthesis conditions. In this paper we develop convex and\nstructured conditions for the existence of a distributed $\\mathscr{H}_2$\ncontroller for discrete-time interconnected systems with an interconnection\nstructure that corresponds to an arbitrary graph. Neutral interconnections and\na storage function with a block-diagonal structure are utilized to attain\ncoupling conditions that are of a considerably lower computational complexity\ncompared to the corresponding centralized $\\mathscr{H}_2$ controller synthesis\nproblem. Additionally, the developed conditions are adapted for the\ncorresponding decentralized $\\mathscr{H}_2$ controller synthesis problem with\nfixed supply functions for the interconnections. The effectiveness and\nscalability of the developed distributed $\\mathscr{H}_2$ controller synthesis\nmethod is demonstrated for small- to large-scale oscillator networks on a cycle\ngraph.\n",
			"Comment: Changes in this version include: overview of dissipativity-based\n  results for interconnected systems is removed, result on the existence of a\n  decentralized controller is included and a simulation example for the\n  illustration of scalability replaces the previous simulation example"
		],
		"date": [
			"2020-01-14",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2001.04875",
		"pdf_url": "http://arxiv.org/pdf/2001.04875.pdf"
	},
	"181": {
		"title": "Simple and Effective Prevention of Mode Collapse in Deep One-Class\n  Classification",
		"creator": [
			"Chong, Penny",
			"Ruff, Lukas",
			"Kloft, Marius",
			"Binder, Alexander"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Anomaly detection algorithms find extensive use in various fields. This area\nof research has recently made great advances thanks to deep learning. A recent\nmethod, the deep Support Vector Data Description (deep SVDD), which is inspired\nby the classic kernel-based Support Vector Data Description (SVDD), is capable\nof simultaneously learning a feature representation of the data and a\ndata-enclosing hypersphere. The method has shown promising results in both\nunsupervised and semi-supervised settings. However, deep SVDD suffers from\nhypersphere collapse -- also known as mode collapse, if the architecture of the\nmodel does not comply with certain architectural constraints, e.g. the removal\nof bias terms. These constraints limit the adaptability of the model and in\nsome cases, may affect the model performance due to learning sub-optimal\nfeatures. In this work, we consider two regularizers to prevent hypersphere\ncollapse in deep SVDD. The first regularizer is based on injecting random noise\nvia the standard cross-entropy loss. The second regularizer penalizes the\nminibatch variance when it becomes too small. Moreover, we introduce an\nadaptive weighting scheme to control the amount of penalization between the\nSVDD loss and the respective regularizer. Our proposed regularized variants of\ndeep SVDD show encouraging results and outperform a prominent state-of-the-art\nmethod on a setup where the anomalies have no apparent geometrical structure.\n",
			"Comment: Accepted in 2020 International Joint Conference on Neural Networks\n  (IJCNN)"
		],
		"date": [
			"2020-01-23",
			"2021-01-19"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2001.08873",
			"doi:10.1109/IJCNN48605.2020.9207209"
		],
		"pdf_url": "http://arxiv.org/pdf/2001.08873.pdf"
	},
	"182": {
		"title": "Gesticulator: A framework for semantically-aware speech-driven gesture\n  generation",
		"creator": [
			"Kucherenko, Taras",
			"Jonell, Patrik",
			"van Waveren, Sanne",
			"Henter, Gustav Eje",
			"Alexanderson, Simon",
			"Leite, Iolanda",
			"Kjellström, Hedvig"
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Audio and Speech Processing",
			"I.2.7",
			"I.2.6",
			"I.3.7"
		],
		"description": [
			"  During speech, people spontaneously gesticulate, which plays a key role in\nconveying information. Similarly, realistic co-speech gestures are crucial to\nenable natural and smooth interactions with social agents. Current end-to-end\nco-speech gesture generation systems use a single modality for representing\nspeech: either audio or text. These systems are therefore confined to producing\neither acoustically-linked beat gestures or semantically-linked gesticulation\n(e.g., raising a hand when saying \"high\"): they cannot appropriately learn to\ngenerate both gesture types. We present a model designed to produce arbitrary\nbeat and semantic gestures together. Our deep-learning based model takes both\nacoustic and semantic representations of speech as input, and generates\ngestures as a sequence of joint angle rotations as output. The resulting\ngestures can be applied to both virtual agents and humanoid robots. Subjective\nand objective evaluations confirm the success of our approach. The code and\nvideo are available at the project page\nhttps://svito-zar.github.io/gesticulator .\n",
			"Comment: ICMI 2020 Best Paper Award. Code is available. 9 pages, 6 figures"
		],
		"date": [
			"2020-01-25",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2001.09326",
			"Proceedings of the 2020 International Conference on Multimodal\n  Interaction (ICMI '20)",
			"doi:10.1145/3382507.3418815"
		],
		"pdf_url": "http://arxiv.org/pdf/2001.09326.pdf"
	},
	"183": {
		"title": "Sub-Gaussian Matrices on Sets: Optimal Tail Dependence and Applications",
		"creator": [
			"Jeong, Halyun",
			"Li, Xiaowei",
			"Plan, Yaniv",
			"Yılmaz, Özgür"
		],
		"subject": [
			"Computer Science - Information Theory",
			"Mathematics - Statistics Theory",
			"Statistics - Machine Learning"
		],
		"description": "  Random linear mappings are widely used in modern signal processing,\ncompressed sensing and machine learning. These mappings may be used to embed\nthe data into a significantly lower dimension while at the same time preserving\nuseful information. This is done by approximately preserving the distances\nbetween data points, which are assumed to belong to $\\mathbb{R}^n$. Thus, the\nperformance of these mappings is usually captured by how close they are to an\nisometry on the data. Gaussian linear mappings have been the object of much\nstudy, while the sub-Gaussian settings is not yet fully understood. In the\nlatter case, the performance depends on the sub-Gaussian norm of the rows. In\nmany applications, e.g., compressed sensing, this norm may be large, or even\ngrowing with dimension, and thus it is important to characterize this\ndependence.\n  We study when a sub-Gaussian matrix can become a near isometry on a set, show\nthat previous best known dependence on the sub-Gaussian norm was sub-optimal,\nand present the optimal dependence. Our result not only answers a remaining\nquestion posed by Liaw, Mehrabian, Plan and Vershynin in 2017, but also\ngeneralizes their work. We also develop a new Bernstein type inequality for\nsub-exponential random variables, and a new Hanson-Wright inequality for\nquadratic forms of sub-Gaussian random variables, in both cases improving the\nbounds in the sub-Gaussian regime under moment constraints. Finally, we\nillustrate popular applications such as Johnson-Lindenstrauss embeddings, null\nspace property for 0-1 matrices, randomized sketches and blind demodulation,\nwhose theoretical guarantees can be improved by our results (in the\nsub-Gaussian case).\n",
		"date": [
			"2020-01-28",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2001.10631",
		"pdf_url": "http://arxiv.org/pdf/2001.10631.pdf"
	},
	"184": {
		"title": "Generalized Visual Information Analysis via Tensorial Algebra",
		"creator": [
			"Liao, Liang",
			"Maybank, Stephen John"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"Mathematics - Commutative Algebra",
			"Mathematics - Rings and Algebras"
		],
		"description": [
			"  Higher order data is modeled using matrices whose entries are numerical\narrays of a fixed size. These arrays, called t-scalars, form a commutative ring\nunder the convolution product. Matrices with elements in the ring of t-scalars\nare referred to as t-matrices. The t-matrices can be scaled, added and\nmultiplied in the usual way. There are t-matrix generalizations of positive\nmatrices, orthogonal matrices and Hermitian symmetric matrices. With the\nt-matrix model, it is possible to generalize many well-known matrix algorithms.\nIn particular, the t-matrices are used to generalize the SVD (Singular Value\nDecomposition), HOSVD (High Order SVD), PCA (Principal Component Analysis),\n2DPCA (Two Dimensional PCA) and GCA (Grassmannian Component Analysis). The\ngeneralized t-matrix algorithms, namely TSVD, THOSVD,TPCA, T2DPCA and TGCA, are\napplied to low-rank approximation, reconstruction,and supervised classification\nof images. Experiments show that the t-matrix algorithms compare favorably with\nstandard matrix algorithms.\n",
			"Comment: 42 pages, 17 figures"
		],
		"date": [
			"2020-01-31",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2001.11708",
		"pdf_url": "http://arxiv.org/pdf/2001.11708.pdf"
	},
	"185": {
		"title": "An Autonomous Intrusion Detection System Using an Ensemble of Advanced\n  Learners",
		"creator": [
			"Andalib, Amir",
			"Vakili, Vahid Tabataba"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  An intrusion detection system (IDS) is a vital security component of modern\ncomputer networks. With the increasing amount of sensitive services that use\ncomputer network-based infrastructures, IDSs need to be more intelligent and\nautonomous. Aside from autonomy, another important feature for an IDS is its\nability to detect zero-day attacks. To address these issues, in this paper, we\npropose an IDS which reduces the amount of manual interaction and needed expert\nknowledge and is able to yield acceptable performance under zero-day attacks.\nOur approach is to use three learning techniques in parallel: gated recurrent\nunit (GRU), convolutional neural network as deep techniques and random forest\nas an ensemble technique. These systems are trained in parallel and the results\nare combined under two logics: majority vote and \"OR\" logic. We use the NSL-KDD\ndataset to verify the proficiency of our proposed system. Simulation results\nshow that the system has the potential to operate with a very low technician\ninteraction under the zero-day attacks. We achieved 87:28% accuracy on the\nNSL-KDD's \"KDDTest+\" dataset and 76:61% accuracy on the challenging\n\"KDDTest-21\" with lower training time and lower needed computational resources.\n",
			"Comment: 5 pages"
		],
		"date": [
			"2020-01-31",
			"2020-12-29"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2001.11936",
			"2020 28th Iranian Conference on Electrical Engineering (ICEE)",
			"doi:10.1109/ICEE50131.2020.9260808"
		],
		"pdf_url": "http://arxiv.org/pdf/2001.11936.pdf"
	},
	"186": {
		"title": "Brainstorming Generative Adversarial Networks (BGANs): Towards\n  Multi-Agent Generative Models with Distributed Private Datasets",
		"creator": [
			"Ferdowsi, Aidin",
			"Saad, Walid"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Statistics - Machine Learning"
		],
		"description": [
			"  To achieve a high learning accuracy, generative adversarial networks (GANs)\nmust be fed by large datasets that adequately represent the data space.\nHowever, in many scenarios, the available datasets may be limited and\ndistributed across multiple agents, each of which is seeking to learn the\ndistribution of the data on its own. In such scenarios, the local datasets are\ninherently private and agents often do not wish to share them. In this paper,\nto address this multi-agent GAN problem, a novel brainstorming GAN (BGAN)\narchitecture is proposed using which multiple agents can generate real-like\ndata samples while operating in a fully distributed manner and preserving their\ndata privacy. BGAN allows the agents to gain information from other agents\nwithout sharing their real datasets but by \"brainstorming\" via the sharing of\ntheir generated data samples. In contrast to existing distributed GAN\nsolutions, the proposed BGAN architecture is designed to be fully distributed,\nand it does not need any centralized controller. Moreover, BGANs are shown to\nbe scalable and not dependent on the hyperparameters of the agents' deep neural\nnetworks (DNNs) thus enabling the agents to have different DNN architectures.\nTheoretically, the interactions between BGAN agents are analyzed as a game\nwhose unique Nash equilibrium is derived. Experimental results show that BGAN\ncan generate real-like data samples with higher quality and lower\nJensen-Shannon divergence (JSD) and Fr\\'echet Inception distance (FID) compared\nto other distributed GAN architectures.\n",
			"Comment: 13 pages, 16 figures, 3 tables"
		],
		"date": [
			"2020-02-01",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2002.00306",
		"pdf_url": "http://arxiv.org/pdf/2002.00306.pdf"
	},
	"187": {
		"title": "An Efficient Architecture for Predicting the Case of Characters using\n  Sequence Models",
		"creator": [
			"Ramena, Gopi",
			"Nagaraju, Divija",
			"Moharana, Sukumar",
			"Mohanty, Debi Prasanna",
			"Purre, Naresh"
		],
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  The dearth of clean textual data often acts as a bottleneck in several\nnatural language processing applications. The data available often lacks proper\ncase (uppercase or lowercase) information. This often comes up when text is\nobtained from social media, messaging applications and other online platforms.\nThis paper attempts to solve this problem by restoring the correct case of\ncharacters, commonly known as Truecasing. Doing so improves the accuracy of\nseveral processing tasks further down in the NLP pipeline. Our proposed\narchitecture uses a combination of convolutional neural networks (CNN),\nbi-directional long short-term memory networks (LSTM) and conditional random\nfields (CRF), which work at a character level without any explicit feature\nengineering. In this study we compare our approach to previous statistical and\ndeep learning based approaches. Our method shows an increment of 0.83 in F1\nscore over the current state of the art. Since truecasing acts as a\npreprocessing step in several applications, every increment in the F1 score\nleads to a significant improvement in the language processing tasks.\n",
			"Comment: to be published in IEEE ICSC 2020 proceedings"
		],
		"date": "2020-01-30",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2002.00738",
			"doi:10.1109/ICSC.2020.00035"
		],
		"pdf_url": "http://arxiv.org/pdf/2002.00738.pdf"
	},
	"188": {
		"title": "PLLay: Efficient Topological Layer based on Persistence Landscapes",
		"creator": [
			"Kim, Kwangho",
			"Kim, Jisu",
			"Zaheer, Manzil",
			"Kim, Joon Sik",
			"Chazal, Frederic",
			"Wasserman, Larry"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computational Geometry",
			"Statistics - Machine Learning"
		],
		"description": [
			"  We propose PLLay, a novel topological layer for general deep learning models\nbased on persistence landscapes, in which we can efficiently exploit the\nunderlying topological features of the input data structure. In this work, we\nshow differentiability with respect to layer inputs, for a general persistent\nhomology with arbitrary filtration. Thus, our proposed layer can be placed\nanywhere in the network and feed critical information on the topological\nfeatures of input data into subsequent layers to improve the learnability of\nthe networks toward a given task. A task-optimal structure of PLLay is learned\nduring training via backpropagation, without requiring any input featurization\nor data preprocessing. We provide a novel adaptation for the DTM function-based\nfiltration, and show that the proposed layer is robust against noise and\noutliers through a stability analysis. We demonstrate the effectiveness of our\napproach by classification experiments on various datasets.\n",
			"Comment: 29 pages, 7 figures"
		],
		"date": [
			"2020-02-07",
			"2021-01-17"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2002.02778",
			"34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada"
		],
		"pdf_url": "http://arxiv.org/pdf/2002.02778.pdf"
	},
	"189": {
		"title": "Random Features Strengthen Graph Neural Networks",
		"creator": [
			"Sato, Ryoma",
			"Yamada, Makoto",
			"Kashima, Hisashi"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Graph neural networks (GNNs) are powerful machine learning models for various\ngraph learning tasks. Recently, the limitations of the expressive power of\nvarious GNN models have been revealed. For example, GNNs cannot distinguish\nsome non-isomorphic graphs and they cannot learn efficient graph algorithms. In\nthis paper, we demonstrate that GNNs become powerful just by adding a random\nfeature to each node. We prove that the random features enable GNNs to learn\nalmost optimal polynomial-time approximation algorithms for the minimum\ndominating set problem and maximum matching problem in terms of approximation\nratios. The main advantage of our method is that it can be combined with\noff-the-shelf GNN models with slight modifications. Through experiments, we\nshow that the addition of random features enables GNNs to solve various\nproblems that normal GNNs, including the graph convolutional networks (GCNs)\nand graph isomorphism networks (GINs), cannot solve.\n",
			"Comment: Accepted to SDM 2021"
		],
		"date": [
			"2020-02-08",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2002.03155",
		"pdf_url": "http://arxiv.org/pdf/2002.03155.pdf"
	},
	"190": {
		"title": "A Diffusion Theory For Deep Learning Dynamics: Stochastic Gradient\n  Descent Exponentially Favors Flat Minima",
		"creator": [
			"Xie, Zeke",
			"Sato, Issei",
			"Sugiyama, Masashi"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Stochastic Gradient Descent (SGD) and its variants are mainstream methods for\ntraining deep networks in practice. SGD is known to find a flat minimum that\noften generalizes well. However, it is mathematically unclear how deep learning\ncan select a flat minimum among so many minima. To answer the question\nquantitatively, we develop a density diffusion theory (DDT) to reveal how\nminima selection quantitatively depends on the minima sharpness and the\nhyperparameters. To the best of our knowledge, we are the first to\ntheoretically and empirically prove that, benefited from the Hessian-dependent\ncovariance of stochastic gradient noise, SGD favors flat minima exponentially\nmore than sharp minima, while Gradient Descent (GD) with injected white noise\nfavors flat minima only polynomially more than sharp minima. We also reveal\nthat either a small learning rate or large-batch training requires\nexponentially many iterations to escape from minima in terms of the ratio of\nthe batch size and learning rate. Thus, large-batch training cannot search flat\nminima efficiently in a realistic computational time.\n",
			"Comment: ICLR 2021; 28 pages; 19 figures"
		],
		"date": [
			"2020-02-09",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2002.03495",
		"pdf_url": "http://arxiv.org/pdf/2002.03495.pdf"
	},
	"191": {
		"title": "Maximizing Products of Linear Forms, and The Permanent of Positive\n  Semidefinite Matrices",
		"creator": [
			"Yuan, Chenyang",
			"Parrilo, Pablo A."
		],
		"subject": [
			"Mathematics - Optimization and Control",
			"Computer Science - Data Structures and Algorithms",
			"Mathematics - Combinatorics"
		],
		"description": [
			"  We study the convex relaxation of a polynomial optimization problem,\nmaximizing a product of linear forms over the complex sphere. We show that this\nconvex program is also a relaxation of the permanent of Hermitian positive\nsemidefinite (HPSD) matrices. By analyzing a constructive randomized rounding\nalgorithm, we obtain an improved multiplicative approximation factor to the\npermanent of HPSD matrices, as well as computationally efficient certificates\nfor this approximation. We also propose an analog of van der Waerden's\nconjecture for HPSD matrices, where the polynomial optimization problem is\ninterpreted as a relaxation of the permanent.\n",
			"Comment: 12 pages, 2 figures"
		],
		"date": [
			"2020-02-10",
			"2021-01-13"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2002.04149",
			"Math. Program. (2021)",
			"doi:10.1007/s10107-021-01616-3"
		],
		"pdf_url": "http://arxiv.org/pdf/2002.04149.pdf"
	},
	"192": {
		"title": "Feature Importance Estimation with Self-Attention Networks",
		"creator": [
			"Škrlj, Blaž",
			"Džeroski, Sašo",
			"Lavrač, Nada",
			"Petkovič, Matej"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Black-box neural network models are widely used in industry and science, yet\nare hard to understand and interpret. Recently, the attention mechanism was\nintroduced, offering insights into the inner workings of neural language\nmodels. This paper explores the use of attention-based neural networks\nmechanism for estimating feature importance, as means for explaining the models\nlearned from propositional (tabular) data. Feature importance estimates,\nassessed by the proposed Self-Attention Network (SAN) architecture, are\ncompared with the established ReliefF, Mutual Information and Random\nForest-based estimates, which are widely used in practice for model\ninterpretation. For the first time we conduct scale-free comparisons of feature\nimportance estimates across algorithms on ten real and synthetic data sets to\nstudy the similarities and differences of the resulting feature importance\nestimates, showing that SANs identify similar high-ranked features as the other\nmethods. We demonstrate that SANs identify feature interactions which in some\ncases yield better predictive performance than the baselines, suggesting that\nattention extends beyond interactions of just a few key features and detects\nlarger feature subsets relevant for the considered learning task.\n",
			"Comment: Accepted for publication in ECAI 2020"
		],
		"date": "2020-02-11",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2002.04464",
			"doi:10.3233/FAIA200256"
		],
		"pdf_url": "http://arxiv.org/pdf/2002.04464.pdf"
	},
	"193": {
		"title": "Numerical solution of a class of third-kind Volterra integral equations\n  using Jacobi wavelets",
		"creator": [
			"Nemati, Somayeh",
			"Lima, Pedro M.",
			"Torres, Delfim F. M."
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"34D05, 45E10, 65T60"
		],
		"description": [
			"  We propose a spectral collocation method, based on the generalized Jacobi\nwavelets along with the Gauss-Jacobi quadrature formula, for solving a class of\nthird-kind Volterra integral equations. To do this, the interval of integration\nis first transformed into the interval [-1,1], by considering a suitable change\nof variable. Then, by introducing special Jacobi parameters, the integral part\nis approximated using the Gauss-Jacobi quadrature rule. An approximation of the\nunknown function is considered in terms of Jacobi wavelets functions with\nunknown coefficients, which must be determined. By substituting this\napproximation into the equation, and collocating the resulting equation at a\nset of collocation points, a system of linear algebraic equations is obtained.\nThen, we suggest a method to determine the number of basis functions necessary\nto attain a certain precision. Finally, some examples are included to\nillustrate the applicability, efficiency, and accuracy of the new scheme.\n",
			"Comment: This is a preprint of a paper whose final and definite form is with\n  'Numer. Algorithms', Print ISSN 1017-1398, Electronic ISSN 1572-9265,\n  available at [https://www.springer.com/journal/11075]. Submitted 12-Oct-2019;\n  Revised 17-Dec-2019; Accepted 11-Feb-2020"
		],
		"date": "2020-02-11",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2002.04736",
			"Numer. Algorithms 86 (2021), no. 2, 675--691",
			"doi:10.1007/s11075-020-00906-9"
		],
		"pdf_url": "http://arxiv.org/pdf/2002.04736.pdf"
	},
	"194": {
		"title": "Intra-Camera Supervised Person Re-Identification",
		"creator": [
			"Zhu, Xiangping",
			"Zhu, Xiatian",
			"Li, Minxian",
			"Morerio, Pietro",
			"Murino, Vittorio",
			"Gong, Shaogang"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Existing person re-identification (re-id) methods mostly exploit a large set\nof cross-camera identity labelled training data. This requires a tedious data\ncollection and annotation process, leading to poor scalability in practical\nre-id applications. On the other hand unsupervised re-id methods do not need\nidentity label information, but they usually suffer from much inferior and\ninsufficient model performance. To overcome these fundamental limitations, we\npropose a novel person re-identification paradigm based on an idea of\nindependent per-camera identity annotation. This eliminates the most\ntime-consuming and tedious inter-camera identity labelling process,\nsignificantly reducing the amount of human annotation efforts. Consequently, it\ngives rise to a more scalable and more feasible setting, which we call\nIntra-Camera Supervised (ICS) person re-id, for which we formulate a Multi-tAsk\nmulTi-labEl (MATE) deep learning method. Specifically, MATE is designed for\nself-discovering the cross-camera identity correspondence in a per-camera\nmulti-task inference framework. Extensive experiments demonstrate the\ncost-effectiveness superiority of our method over the alternative approaches on\nthree large person re-id datasets. For example, MATE yields 88.7% rank-1 score\non Market-1501 in the proposed ICS person re-id setting, significantly\noutperforming unsupervised learning models and closely approaching conventional\nfully supervised learning competitors.\n",
			"Comment: Accepted to IJCV"
		],
		"date": [
			"2020-02-12",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2002.05046",
		"pdf_url": "http://arxiv.org/pdf/2002.05046.pdf"
	},
	"195": {
		"title": "Classical limit for the varying-mass Schr\\\"odinger equation with random\n  inhomogeneities",
		"creator": [
			"Chen, Shi",
			"Li, Qin",
			"Yang, Xu"
		],
		"subject": "Mathematics - Numerical Analysis",
		"description": "  The varying-mass Schr\\\"odinger equation (VMSE) has been successfully applied\nto model electronic properties of semiconductor hetero-structures, for example,\nquantum dots and quantum wells. In this paper, we consider VMSE with small\nrandom heterogeneities, and derive a radiative transfer equation as its\nasymptotic limit. The main tool is to systematically apply the Wigner transform\nin the classical regime when the rescaled Planck constant $\\epsilon\\ll 1$, and\nexpand the Wigner equation to proper orders of $\\epsilon$. As a proof of\nconcept, we numerically compute both VMSE and its limiting radiative transfer\nequation, and show that their solutions agree well in the classical regime.\n",
		"date": [
			"2020-02-12",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2002.05277",
		"pdf_url": "http://arxiv.org/pdf/2002.05277.pdf"
	},
	"196": {
		"title": "Stabilizing Differentiable Architecture Search via Perturbation-based\n  Regularization",
		"creator": [
			"Chen, Xiangning",
			"Hsieh, Cho-Jui"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Differentiable architecture search (DARTS) is a prevailing NAS solution to\nidentify architectures. Based on the continuous relaxation of the architecture\nspace, DARTS learns a differentiable architecture weight and largely reduces\nthe search cost. However, its stability has been challenged for yielding\ndeteriorating architectures as the search proceeds. We find that the\nprecipitous validation loss landscape, which leads to a dramatic performance\ndrop when distilling the final architecture, is an essential factor that causes\ninstability. Based on this observation, we propose a perturbation-based\nregularization - SmoothDARTS (SDARTS), to smooth the loss landscape and improve\nthe generalizability of DARTS-based methods. In particular, our new\nformulations stabilize DARTS-based methods by either random smoothing or\nadversarial attack. The search trajectory on NAS-Bench-1Shot1 demonstrates the\neffectiveness of our approach and due to the improved stability, we achieve\nperformance gain across various search spaces on 4 datasets. Furthermore, we\nmathematically show that SDARTS implicitly regularizes the Hessian norm of the\nvalidation loss, which accounts for a smoother loss landscape and improved\nperformance.\n",
			"Comment: ICML 2020, code is available at\n  https://github.com/xiangning-chen/SmoothDARTS"
		],
		"date": [
			"2020-02-12",
			"2021-01-12"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2002.05283",
		"pdf_url": "http://arxiv.org/pdf/2002.05283.pdf"
	},
	"197": {
		"title": "A Set of Distinct Facial Traits Learned by Machines Is Not Predictive of\n  Appearance Bias in the Wild",
		"creator": [
			"Steed, Ryan",
			"Caliskan, Aylin"
		],
		"subject": [
			"Computer Science - Computers and Society",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Research in social psychology has shown that people's biased, subjective\njudgments about another's personality based solely on their appearance are not\npredictive of their actual personality traits. But researchers and companies\noften utilize computer vision models to predict similarly subjective\npersonality attributes such as \"employability.\" We seek to determine whether\nstate-of-the-art, black box face processing technology can learn human-like\nappearance biases. With features extracted with FaceNet, a widely used face\nrecognition framework, we train a transfer learning model on human subjects'\nfirst impressions of personality traits in other faces as measured by social\npsychologists. We find that features extracted with FaceNet can be used to\npredict human appearance bias scores for deliberately manipulated faces but not\nfor randomly generated faces scored by humans. Additionally, in contrast to\nwork with human biases in social psychology, the model does not find a\nsignificant signal correlating politicians' vote shares with perceived\ncompetence bias. With Local Interpretable Model-Agnostic Explanations (LIME),\nwe provide several explanations for this discrepancy. Our results suggest that\nsome signals of appearance bias documented in social psychology are not\nembedded by the machine learning techniques we investigate. We shed light on\nthe ways in which appearance bias could be embedded in face processing\ntechnology and cast further doubt on the practice of predicting subjective\ntraits based on appearances.\n",
			"Comment: 11 pages, 7 figures. Revision for AI Ethics"
		],
		"date": [
			"2020-02-13",
			"2021-01-13"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2002.05636",
			"AI Ethics (2021)",
			"doi:10.1007/s43681-020-00035-y"
		],
		"pdf_url": "http://arxiv.org/pdf/2002.05636.pdf"
	},
	"198": {
		"title": "Multivariate Probabilistic Time Series Forecasting via Conditioned\n  Normalizing Flows",
		"creator": [
			"Rasul, Kashif",
			"Sheikh, Abdul-Saboor",
			"Schuster, Ingmar",
			"Bergmann, Urs",
			"Vollgraf, Roland"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  Time series forecasting is often fundamental to scientific and engineering\nproblems and enables decision making. With ever increasing data set sizes, a\ntrivial solution to scale up predictions is to assume independence between\ninteracting time series. However, modeling statistical dependencies can improve\naccuracy and enable analysis of interaction effects. Deep learning methods are\nwell suited for this problem, but multivariate models often assume a simple\nparametric distribution and do not scale to high dimensions. In this work we\nmodel the multivariate temporal dynamics of time series via an autoregressive\ndeep learning model, where the data distribution is represented by a\nconditioned normalizing flow. This combination retains the power of\nautoregressive models, such as good performance in extrapolation into the\nfuture, with the flexibility of flows as a general purpose high-dimensional\ndistribution model, while remaining computationally tractable. We show that it\nimproves over the state-of-the-art for standard metrics on many real-world data\nsets with several thousand interacting time-series.\n",
		"date": [
			"2020-02-14",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2002.06103",
		"pdf_url": "http://arxiv.org/pdf/2002.06103.pdf"
	},
	"199": {
		"title": "Polarization-adjusted Convolutional (PAC) Codes: Sequential Decoding vs\n  List Decoding",
		"creator": [
			"Rowshan, Mohammad",
			"Burg, Andreas",
			"Viterbo, Emanuele"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  In the Shannon lecture at the 2019 International Symposium on Information\nTheory (ISIT), Ar{\\i}kan proposed to employ a one-to-one convolutional\ntransform as a pre-coding step before the polar transform. The resulting codes\nof this concatenation are called polarization-adjusted convolutional (PAC)\ncodes. In this scheme, a pair of polar mapper and demapper as pre- and\npostprocessing devices are deployed around a memoryless channel, which provides\npolarized information to an outer decoder leading to improved error correction\nperformance of the outer code. In this paper, the list decoding and sequential\ndecoding (including Fano decoding and stack decoding) are first adapted for use\nto decode PAC codes. Then, to reduce the complexity of sequential decoding of\nPAC/polar codes, we propose (i) an adaptive heuristic metric, (ii) tree search\nconstraints for backtracking to avoid exploration of unlikely sub-paths, and\n(iii) tree search strategies consistent with the pattern of error occurrence in\npolar codes. These contribute to the reduction of the average decoding time\ncomplexity from 50% to 80%, trading with 0.05 to 0.3 dB degradation in error\ncorrection performance within FER=10^-3 range, respectively, relative to not\napplying the corresponding search strategies. Additionally, as an important\ningredient in Fano decoding of PAC/polar codes, an efficient computation method\nfor the intermediate LLRs and partial sums is provided. This method is\neffective in backtracking and avoids storing the intermediate information or\nrestarting the decoding process. Eventually, all three decoding algorithms are\ncompared in terms of performance, complexity, and resource requirements.\n",
			"Comment: To appear in IEEE Transactions on Vehicular Technology"
		],
		"date": [
			"2020-02-17",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2002.06805",
		"pdf_url": "http://arxiv.org/pdf/2002.06805.pdf"
	},
	"200": {
		"title": "Serial Speakers: a Dataset of TV Series",
		"creator": [
			"Bost, Xavier",
			"Labatut, Vincent",
			"Linares, Georges"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Multimedia"
		],
		"description": "  For over a decade, TV series have been drawing increasing interest, both from\nthe audience and from various academic fields. But while most viewers are\nhooked on the continuous plots of TV serials, the few annotated datasets\navailable to researchers focus on standalone episodes of classical TV series.\nWe aim at filling this gap by providing the multimedia/speech processing\ncommunities with Serial Speakers, an annotated dataset of 161 episodes from\nthree popular American TV serials: Breaking Bad, Game of Thrones and House of\nCards. Serial Speakers is suitable both for investigating multimedia retrieval\nin realistic use case scenarios, and for addressing lower level speech related\ntasks in especially challenging conditions. We publicly release annotations for\nevery speech turn (boundaries, speaker) and scene boundary, along with\nannotations for shot boundaries, recurring shots, and interacting speakers in a\nsubset of episodes. Because of copyright restrictions, the textual content of\nthe speech turns is encrypted in the public version of the dataset, but we\nprovide the users with a simple online tool to recover the plain text from\ntheir own subtitle files.\n",
		"date": "2020-02-17",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2002.06923",
			"12th International Conference on Language Resources and Evaluation\n  (LREC 2020), p.4256-4264, May 2020, Marseille, France"
		],
		"pdf_url": "http://arxiv.org/pdf/2002.06923.pdf"
	},
	"201": {
		"title": "Tourism Demand Forecasting: An Ensemble Deep Learning Approach",
		"creator": [
			"Sun, Shaolong",
			"Li, Yanzhao",
			"Guo, Ju-e",
			"Wang, Shouyang"
		],
		"subject": [
			"Statistics - Applications",
			"Computer Science - Machine Learning",
			"Economics - Econometrics"
		],
		"description": "  The availability of tourism-related big data increases the potential to\nimprove the accuracy of tourism demand forecasting, but presents significant\nchallenges for forecasting, including curse of dimensionality and high model\ncomplexity. A novel bagging-based multivariate ensemble deep learning approach\nintegrating stacked autoencoders and kernel-based extreme learning machines\n(B-SAKE) is proposed to address these challenges in this study. By using\nhistorical tourist arrival data, economic variable data and search intensity\nindex (SII) data, we forecast tourist arrivals in Beijing from four countries.\nThe consistent results of multiple schemes suggest that our proposed B-SAKE\napproach outperforms benchmark models in terms of level accuracy, directional\naccuracy and even statistical significance. Both bagging and stacked\nautoencoder can effectively alleviate the challenges brought by tourism big\ndata and improve the forecasting performance of the models. The ensemble deep\nlearning model we propose contributes to tourism forecasting literature and\nbenefits relevant government officials and tourism practitioners.\n",
		"date": [
			"2020-02-18",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2002.07964",
		"pdf_url": "http://arxiv.org/pdf/2002.07964.pdf"
	},
	"202": {
		"title": "Fluid flow through anisotropic and deformable double porosity media with\n  ultra-low matrix permeability: A continuum framework",
		"creator": [
			"Zhang, Qi",
			"Yan, Xia",
			"Shao, Jianli"
		],
		"subject": [
			"Physics - Geophysics",
			"Mathematics - Numerical Analysis"
		],
		"description": [
			"  Fractured porous media or double porosity media are common in nature. At the\nsame time, accurate modeling remains a significant challenge due to bi-modal\npore size distribution, anisotropy, multi-field coupling, and various flow\npatterns. This study aims to formulate a comprehensive coupled continuum\nframework that could adequately consider these critical characteristics. In our\nframework, fluid flow in the micro-fracture network is modeled with the\ngeneralized Darcy's law, in which the equivalent fracture permeability is\nupscaled from the detailed geological characterizations. The liquid in the much\nless permeable matrix follows a low-velocity non-Darcy flow characterized by\nthreshold values and non-linearity. The fluid mass transfer is assumed to be a\nfunction of the shape factor, pressure difference, and (variable) interface\npermeability. The solid deformation relies on a thermodynamically consistent\neffective stress derived from the energy balance equation, and it is modeled\nfollowing anisotropic poroelastic theory. The discussion revolves around\ngeneric double porosity media. Model applications reveal the capability of our\nframework to capture the crucial roles of coupling, poroelastic coefficients,\nanisotropy, and ultra-low matrix permeability in dictating the pressure and\ndisplacement fields.\n",
			"Comment: Paper finally published in Journal of Petroleum Science and\n  Engineering (2021)"
		],
		"date": [
			"2020-02-17",
			"2021-01-13"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2002.08180",
			"doi:10.1016/j.petrol.2021.108349"
		],
		"pdf_url": "http://arxiv.org/pdf/2002.08180.pdf"
	},
	"203": {
		"title": "Distance-Based Regularisation of Deep Networks for Fine-Tuning",
		"creator": [
			"Gouk, Henry",
			"Hospedales, Timothy M.",
			"Pontil, Massimiliano"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": "  We investigate approaches to regularisation during fine-tuning of deep neural\nnetworks. First we provide a neural network generalisation bound based on\nRademacher complexity that uses the distance the weights have moved from their\ninitial values. This bound has no direct dependence on the number of weights\nand compares favourably to other bounds when applied to convolutional networks.\nOur bound is highly relevant for fine-tuning, because providing a network with\na good initialisation based on transfer learning means that learning can modify\nthe weights less, and hence achieve tighter generalisation. Inspired by this,\nwe develop a simple yet effective fine-tuning algorithm that constrains the\nhypothesis class to a small sphere centred on the initial pre-trained weights,\nthus obtaining provably better generalisation performance than conventional\ntransfer learning. Empirical evaluation shows that our algorithm works well,\ncorroborating our theoretical results. It outperforms both state of the art\nfine-tuning competitors, and penalty-based alternatives that we show do not\ndirectly constrain the radius of the search space.\n",
		"date": [
			"2020-02-19",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2002.08253",
		"pdf_url": "http://arxiv.org/pdf/2002.08253.pdf"
	},
	"204": {
		"title": "Comparing Different Deep Learning Architectures for Classification of\n  Chest Radiographs",
		"creator": [
			"Bressem, Keno K.",
			"Adams, Lisa",
			"Erxleben, Christoph",
			"Hamm, Bernd",
			"Niehues, Stefan",
			"Vahldiek, Janis"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": [
			"  Chest radiographs are among the most frequently acquired images in radiology\nand are often the subject of computer vision research. However, most of the\nmodels used to classify chest radiographs are derived from openly available\ndeep neural networks, trained on large image-datasets. These datasets routinely\ndiffer from chest radiographs in that they are mostly color images and contain\nseveral possible image classes, while radiographs are greyscale images and\noften only contain fewer image classes. Therefore, very deep neural networks,\nwhich can represent more complex relationships in image-features, might not be\nrequired for the comparatively simpler task of classifying grayscale chest\nradiographs. We compared fifteen different architectures of artificial neural\nnetworks regarding training-time and performance on the openly available\nCheXpert dataset to identify the most suitable models for deep learning tasks\non chest radiographs. We could show, that smaller networks such as ResNet-34,\nAlexNet or VGG-16 have the potential to classify chest radiographs as precisely\nas deeper neural networks such as DenseNet-201 or ResNet-151, while being less\ncomputationally demanding.\n",
			"Comment: 15 pages, 6 figures, 3 tables"
		],
		"date": "2020-02-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2002.08991",
			"doi:10.1038/s41598-020-70479-z"
		],
		"pdf_url": "http://arxiv.org/pdf/2002.08991.pdf"
	},
	"205": {
		"title": "Post-training Quantization with Multiple Points: Mixed Precision without\n  Mixed Precision",
		"creator": [
			"Liu, Xingchao",
			"Ye, Mao",
			"Zhou, Dengyong",
			"Liu, Qiang"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Statistics - Machine Learning"
		],
		"description": [
			"  We consider the post-training quantization problem, which discretizes the\nweights of pre-trained deep neural networks without re-training the model. We\npropose multipoint quantization, a quantization method that approximates a\nfull-precision weight vector using a linear combination of multiple vectors of\nlow-bit numbers; this is in contrast to typical quantization methods that\napproximate each weight using a single low precision number. Computationally,\nwe construct the multipoint quantization with an efficient greedy selection\nprocedure, and adaptively decides the number of low precision points on each\nquantized weight vector based on the error of its output. This allows us to\nachieve higher precision levels for important weights that greatly influence\nthe outputs, yielding an 'effect of mixed precision' but without physical mixed\nprecision implementations (which requires specialized hardware accelerators).\nEmpirically, our method can be implemented by common operands, bringing almost\nno memory and computation overhead. We show that our method outperforms a range\nof state-of-the-art methods on ImageNet classification and it can be\ngeneralized to more challenging tasks like PASCAL VOC object detection.\n",
			"Comment: Accepted by AAAI2021"
		],
		"date": [
			"2020-02-20",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2002.09049",
		"pdf_url": "http://arxiv.org/pdf/2002.09049.pdf"
	},
	"206": {
		"title": "Autonomous Discovery of Unknown Reaction Pathways from Data by Chemical\n  Reaction Neural Network",
		"creator": [
			"Ji, Weiqi",
			"Deng, Sili"
		],
		"subject": [
			"Quantitative Biology - Molecular Networks",
			"Computer Science - Machine Learning",
			"Physics - Chemical Physics",
			"Statistics - Machine Learning"
		],
		"description": "  Chemical reactions occur in energy, environmental, biological, and many other\nnatural systems, and the inference of the reaction networks is essential to\nunderstand and design the chemical processes in engineering and life sciences.\nYet, revealing the reaction pathways for complex systems and processes is still\nchallenging due to the lack of knowledge of the involved species and reactions.\nHere, we present a neural network approach that autonomously discovers reaction\npathways from the time-resolved species concentration data. The proposed\nChemical Reaction Neural Network (CRNN), by design, satisfies the fundamental\nphysics laws, including the Law of Mass Action and the Arrhenius Law.\nConsequently, the CRNN is physically interpretable such that the reaction\npathways can be interpreted, and the kinetic parameters can be quantified\nsimultaneously from the weights of the neural network. The inference of the\nchemical pathways is accomplished by training the CRNN with species\nconcentration data via stochastic gradient descent. We demonstrate the\nsuccessful implementations and the robustness of the approach in elucidating\nthe chemical reaction pathways of several chemical engineering and biochemical\nsystems. The autonomous inference by the CRNN approach precludes the need for\nexpert knowledge in proposing candidate networks and addresses the curse of\ndimensionality in complex systems. The physical interpretability also makes the\nCRNN capable of not only fitting the data for a given system but also\ndeveloping knowledge of unknown pathways that could be generalized to similar\nchemical systems.\n",
		"date": [
			"2020-02-20",
			"2021-01-08"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2002.09062",
			"The Journal of Physical Chemistry A, 2021",
			"doi:10.1021/acs.jpca.0c09316"
		],
		"pdf_url": "http://arxiv.org/pdf/2002.09062.pdf"
	},
	"207": {
		"title": "Learning Deep Kernels for Non-Parametric Two-Sample Tests",
		"creator": [
			"Liu, Feng",
			"Xu, Wenkai",
			"Lu, Jie",
			"Zhang, Guangquan",
			"Gretton, Arthur",
			"Sutherland, Danica J."
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning",
			"Statistics - Methodology"
		],
		"description": "  We propose a class of kernel-based two-sample tests, which aim to determine\nwhether two sets of samples are drawn from the same distribution. Our tests are\nconstructed from kernels parameterized by deep neural nets, trained to maximize\ntest power. These tests adapt to variations in distribution smoothness and\nshape over space, and are especially suited to high dimensions and complex\ndata. By contrast, the simpler kernels used in prior kernel testing work are\nspatially homogeneous, and adaptive only in lengthscale. We explain how this\nscheme includes popular classifier-based two-sample tests as a special case,\nbut improves on them in general. We provide the first proof of consistency for\nthe proposed adaptation method, which applies both to kernels on deep features\nand to simpler radial basis kernels or multiple kernel learning. In\nexperiments, we establish the superior performance of our deep kernels in\nhypothesis testing on benchmark and real-world data. The code of our\ndeep-kernel-based two sample tests is available at\nhttps://github.com/fengliu90/DK-for-TST.\n",
		"date": [
			"2020-02-20",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2002.09116",
			"Proceedings of the 37th International Conference on Machine\n  Learning (ICML 2020), PMLR 119:6316-6326"
		],
		"pdf_url": "http://arxiv.org/pdf/2002.09116.pdf"
	},
	"208": {
		"title": "Fully Convolutional Neural Networks for Raw Eye Tracking Data\n  Segmentation, Generation, and Reconstruction",
		"creator": [
			"Fuhl, Wolfgang",
			"Rong, Yao",
			"Kasneci, Enkelejda"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  In this paper, we use fully convolutional neural networks for the semantic\nsegmentation of eye tracking data. We also use these networks for\nreconstruction, and in conjunction with a variational auto-encoder to generate\neye movement data. The first improvement of our approach is that no input\nwindow is necessary, due to the use of fully convolutional networks and\ntherefore any input size can be processed directly. The second improvement is\nthat the used and generated data is raw eye tracking data (position X, Y and\ntime) without preprocessing. This is achieved by pre-initializing the filters\nin the first layer and by building the input tensor along the z axis. We\nevaluated our approach on three publicly available datasets and compare the\nresults to the state of the art.\n",
		"date": [
			"2020-02-17",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2002.10905",
		"pdf_url": "http://arxiv.org/pdf/2002.10905.pdf"
	},
	"209": {
		"title": "Relaxed Scheduling for Scalable Belief Propagation",
		"creator": [
			"Aksenov, Vitaly",
			"Alistarh, Dan",
			"Korhonen, Janne H."
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  The ability to leverage large-scale hardware parallelism has been one of the\nkey enablers of the accelerated recent progress in machine learning.\nConsequently, there has been considerable effort invested into developing\nefficient parallel variants of classic machine learning algorithms. However,\ndespite the wealth of knowledge on parallelization, some classic machine\nlearning algorithms often prove hard to parallelize efficiently while\nmaintaining convergence.\n  In this paper, we focus on efficient parallel algorithms for the key machine\nlearning task of inference on graphical models, in particular on the\nfundamental belief propagation algorithm. We address the challenge of\nefficiently parallelizing this classic paradigm by showing how to leverage\nscalable relaxed schedulers in this context. We present an extensive empirical\nstudy, showing that our approach outperforms previous parallel belief\npropagation implementations both in terms of scalability and in terms of\nwall-clock convergence time, on a range of practical applications.\n",
		"date": [
			"2020-02-25",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2002.11505",
		"pdf_url": "http://arxiv.org/pdf/2002.11505.pdf"
	},
	"210": {
		"title": "Comprehensive Framework of RDMA-enabled Concurrency Control Protocols",
		"creator": [
			"Wang, Chao",
			"Huang, Kezhao",
			"Qian, Xuehai"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Databases"
		],
		"description": "  In this paper, we develop RCC, the first unified and comprehensive\nRDMA-enabled distributed transaction processing framework supporting six\nserializable concurrency control protocols: not only the classical protocols\nNOWAIT, WAITDIE, and OCC, but also more advanced MVCC and SUNDIAL, and even\nCALVIN, the deterministic concurrency control protocol. Our goal is to\nunbiasedly compare the protocols in a common execution environment with the\nconcurrency control protocol being the only changeable component. We focus on\nthe correct and efficient implementation using key techniques, such as\nco-routines, outstanding requests, and doorbell batching, with two-sided and\none-sided communication primitives. Based on RCC, we get the deep insights that\ncannot be obtained by any existing systems. Most importantly, we obtain the\nexecution stage latency breakdowns with one-sided and two-sided primitive for\neach protocol, which are analyzed to develop more efficient hybrid\nimplementations. Our results show that three hybrid designs are indeed better\nthan both one-sided and two-sided implementations by up to 17.8%. We believe\nthat RCC is a significant advance over the state-of-the-art; it can both\nprovide performance insights and be used as the common infrastructure for fast\nprototyping new implementations.\n",
		"date": [
			"2020-02-28",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2002.12664",
		"pdf_url": "http://arxiv.org/pdf/2002.12664.pdf"
	},
	"211": {
		"title": "Advances in centerline estimation for autonomous lateral control",
		"creator": [
			"Cudrano, Paolo",
			"Mentasti, Simone",
			"Matteucci, Matteo",
			"Bersani, Mattia",
			"Arrigoni, Stefano",
			"Cheli, Federico"
		],
		"subject": "Computer Science - Robotics",
		"description": [
			"  The ability of autonomous vehicles to maintain an accurate trajectory within\ntheir road lane is crucial for safe operation. This requires detecting the road\nlines and estimating the car relative pose within its lane. Lateral lines are\nusually retrieved from camera images. Still, most of the works on line\ndetection are limited to image mask retrieval and do not provide a usable\nrepresentation in world coordinates. What we propose in this paper is a\ncomplete perception pipeline based on monocular vision and able to retrieve all\nthe information required by a vehicle lateral control system: road lines\nequation, centerline, vehicle heading and lateral displacement. We evaluate our\nsystem by acquiring data with accurate geometric ground truth. To act as a\nbenchmark for further research, we make this new dataset publicly available at\nhttp://airlab.deib.polimi.it/datasets/.\n",
			"Comment: Presented at 2020 IEEE Intelligent Vehicles Symposium (IV), 8 pages,\n  8 figures"
		],
		"date": [
			"2020-02-28",
			"2021-01-15"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2002.12685",
			"In 2020 IEEE Intelligent Vehicles Symposium (IV), pp. 1415-1422.\n  IEEE, 2020",
			"doi:10.1109/IV47402.2020.9304729"
		],
		"pdf_url": "http://arxiv.org/pdf/2002.12685.pdf"
	},
	"212": {
		"title": "Dynamic Queue-Jump Lane for Emergency Vehicles under Partially Connected\n  Settings: A Multi-Agent Deep Reinforcement Learning Approach",
		"creator": [
			"Su, Haoran",
			"Shi, Kejian",
			"Chow, Joseph. Y. J.",
			"Jin, Li"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": [
			"  Emergency vehicle (EMV) service is a key function of cities and is\nexceedingly challenging due to urban traffic congestion. The main reason behind\nEMV service delay is the lack of communication and cooperation between vehicles\nblocking EMVs. In this paper, we study the improvement of EMV service under V2X\nconnectivity. We consider the establishment of dynamic queue jump lanes (DQJLs)\nbased on real-time coordination of connected vehicles in the presence of\nnon-connected human-driven vehicles. We develop a novel Markov decision process\nformulation for the DQJL coordination strategies, which explicitly accounts for\nthe uncertainty of drivers' yielding pattern to approaching EMVs. Based on\npairs of neural networks representing actors and critics for agent vehicles, we\ndevelop a multi-agent actor-critic deep reinforcement learning algorithm that\nhandles a varying number of vehicles and a random proportion of connected\nvehicles in the traffic. Approaching the optimal coordination strategies via\nindirect and direct reinforcement learning, we present two schemata to address\nmulti-agent reinforcement learning on this connected vehicle application. Both\napproaches are validated, on a micro-simulation testbed SUMO, to establish a\nDQJL fast and safely. Validation results reveal that, with DQJL coordination\nstrategies, it saves up to 30% time for EMVs to pass a link-level intelligent\nurban roadway than the baseline scenario.\n",
			"Comment: 42 pages, 13 figures, 7 tables"
		],
		"date": [
			"2020-03-02",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.01025",
		"pdf_url": "http://arxiv.org/pdf/2003.01025.pdf"
	},
	"213": {
		"title": "Adversarial Network Traffic: Towards Evaluating the Robustness of Deep\n  Learning-Based Network Traffic Classification",
		"creator": [
			"Sadeghzadeh, Amir Mahdi",
			"Shiravi, Saeed",
			"Jalili, Rasool"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": [
			"  Network traffic classification is used in various applications such as\nnetwork traffic management, policy enforcement, and intrusion detection\nsystems. Although most applications encrypt their network traffic and some of\nthem dynamically change their port numbers, Machine Learning (ML) and\nespecially Deep Learning (DL)-based classifiers have shown impressive\nperformance in network traffic classification. In this paper, we evaluate the\nrobustness of DL-based network traffic classifiers against Adversarial Network\nTraffic (ANT). ANT causes DL-based network traffic classifiers to predict\nincorrectly using Universal Adversarial Perturbation (UAP) generating methods.\nSince there is no need to buffer network traffic before sending ANT, it is\ngenerated live. We partition the input space of the DL-based network traffic\nclassification into three categories: packet classification, flow content\nclassification, and flow time series classification. To generate ANT, we\npropose three new attacks injecting UAP into network traffic. AdvPad attack\ninjects a UAP into the content of packets to evaluate the robustness of packet\nclassifiers. AdvPay attack injects a UAP into the payload of a dummy packet to\nevaluate the robustness of flow content classifiers. AdvBurst attack injects a\nspecific number of dummy packets with crafted statistical features based on a\nUAP into a selected burst of a flow to evaluate the robustness of flow time\nseries classifiers. The results indicate injecting a little UAP into network\ntraffic, highly decreases the performance of DL-based network traffic\nclassifiers in all categories.\n",
			"Comment: 14 pages, 3 figures, and 7 tables. Accepted in IEEE Transactions on\n  Network and Service Management (TNSM). Supplementary Material:\n  https://github.com/amsadeghzadeh/AdversarialNetworkTraffic"
		],
		"date": [
			"2020-03-02",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.01261",
		"pdf_url": "http://arxiv.org/pdf/2003.01261.pdf"
	},
	"214": {
		"title": "Scalable Distributed Approximation of Internal Measures for Clustering\n  Evaluation",
		"creator": [
			"Altieri, Federico",
			"Pietracaprina, Andrea",
			"Pucci, Geppino",
			"Vandin, Fabio"
		],
		"subject": [
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Machine Learning",
			"I.5.3",
			"I.5.4",
			"I.5.5"
		],
		"description": [
			"  The most widely used internal measure for clustering evaluation is the\nsilhouette coefficient, whose naive computation requires a quadratic number of\ndistance calculations, which is clearly unfeasible for massive datasets.\nSurprisingly, there are no known general methods to efficiently approximate the\nsilhouette coefficient of a clustering with rigorously provable high accuracy.\nIn this paper, we present the first scalable algorithm to compute such a\nrigorous approximation for the evaluation of clusterings based on any metric\ndistances. Our algorithm hinges on a Probability Proportional to Size (PPS)\nsampling scheme, and, for any fixed $\\varepsilon, \\delta \\in (0,1)$, it\napproximates the silhouette coefficient within a mere additive error\n$O(\\varepsilon)$ with probability $1-\\delta$, using a very small number of\ndistance calculations. We also prove that the algorithm can be adapted to\nobtain rigorous approximations of other internal measures of clustering\nquality, such as cohesion and separation. Importantly, we provide a distributed\nimplementation of the algorithm using the MapReduce model, which runs in\nconstant rounds and requires only sublinear local space at each worker, which\nmakes our estimation approach applicable to big data scenarios. We perform an\nextensive experimental evaluation of our silhouette approximation algorithm,\ncomparing its performance to a number of baseline heuristics on real and\nsynthetic datasets. The experiments provide evidence that, unlike other\nheuristics, our estimation strategy not only provides tight theoretical\nguarantees but is also able to return highly accurate estimations while running\nin a fraction of the time required by the exact computation, and that its\ndistributed implementation is highly scalable, thus enabling the computation of\ninternal measures for very large datasets for which the exact computation is\nprohibitive.\n",
			"Comment: 16 pages, 4 tables, 1 figure"
		],
		"date": [
			"2020-03-03",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.01430",
		"pdf_url": "http://arxiv.org/pdf/2003.01430.pdf"
	},
	"215": {
		"title": "Satellite Relative Motion Modeling and Estimation via Nodal Elements",
		"creator": [
			"Leomanni, Mirko",
			"Garulli, Andrea",
			"Giannitrapani, Antonio",
			"Quartullo, Renato"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": "  In this paper, a new parametrization of the relative motion between two\nsatellites orbiting a central body is presented. The parametrization is based\non the nodal elements: a set of angles describing the orbit geometry with\nrespect to the relative line of nodes. These are combined with classical\norbital elements to yield a nonsingular relative motion description. The exact\nnonlinear, perturbed dynamic model resulting from the new parametrization is\nestablished. The proposed parameter set captures the fundamental Keplerian\ninvariants, while retaining a simple relationship with local orbital\ncoordinates. An angles-only relative navigation filter and a collision\navoidance scheme are devised by exploiting these features. The navigation\nsolution is validated on a case study of an asteroid flyby mission. It is shown\nthat a collision can be detected early on in the estimation process, which\nallows one to issue a timely evasive maneuver.\n",
		"date": "2020-03-04",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2003.02140",
			"Journal of Guidance, Control and Dynamics, Vol. 43, No. 10, 2020",
			"doi:10.2514/1.G005186"
		],
		"pdf_url": "http://arxiv.org/pdf/2003.02140.pdf"
	},
	"216": {
		"title": "COMPLEX-IT: A Case-Based Modeling and Scenario Simulation Platform for\n  Social Inquiry",
		"creator": [
			"Schimpf, Corey",
			"Castellani, Brian"
		],
		"subject": [
			"Computer Science - Mathematical Software",
			"Computer Science - Computers and Society"
		],
		"description": "  COMPLEX-IT is a case-based, mixed-methods platform for social inquiry into\ncomplex data/systems, designed to increase non-expert access to the tools of\ncomputational social science (i.e., cluster analysis, artificial intelligence,\ndata visualization, data forecasting, and scenario simulation). In particular,\nCOMPLEX-IT aids social inquiry though a heavy emphasis on learning about the\ncomplex data/system under study, which it does by (a) identifying and\nforecasting major and minor clusters/trends; (b) visualizing their complex\ncausality; and (c) simulating scenarios for potential interventions. COMPLEX-IT\nis accessible through the web or can be run locally and is powered by R and the\nShiny web framework.\n",
		"date": "2020-03-06",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2003.03099",
			"Journal of Open Research Software (2020) 8:25",
			"doi:10.5334/jors.298"
		],
		"pdf_url": "http://arxiv.org/pdf/2003.03099.pdf"
	},
	"217": {
		"title": "Tighter Bound Estimation of Sensitivity Analysis for Incremental and\n  Decremental Data Modification",
		"creator": [
			"Zhou, Kaichen",
			"Song, Shiji",
			"Huang, Gao",
			"Cheng, Wu",
			"Zhou, Quan"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  In large-scale classification problems, the data set always be faced with\nfrequent updates when a part of the data is added to or removed from the\noriginal data set. In this case, conventional incremental learning, which\nupdates an existing classifier by explicitly modeling the data modification, is\nmore efficient than retraining a new classifier from scratch. However,\nsometimes, we are more interested in determining whether we should update the\nclassifier or performing some sensitivity analysis tasks. To deal with these\nsuch tasks, we propose an algorithm to make rational inferences about the\nupdated linear classifier without exactly updating the classifier.\nSpecifically, the proposed algorithm can be used to estimate the upper and\nlower bounds of the updated classifier's coefficient matrix with a low\ncomputational complexity related to the size of the updated dataset. Both\ntheoretical analysis and experiment results show that the proposed approach is\nsuperior to existing methods in terms of tightness of coefficients' bounds and\ncomputational complexity.\n",
		"date": [
			"2020-03-06",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.03351",
		"pdf_url": "http://arxiv.org/pdf/2003.03351.pdf"
	},
	"218": {
		"title": "Step on the Gas? A Better Approach for Recommending the Ethereum Gas\n  Price",
		"creator": [
			"Werner, Sam M.",
			"Pritz, Paul J.",
			"Perez, Daniel"
		],
		"subject": "Computer Science - Distributed, Parallel, and Cluster Computing",
		"description": "  In the Ethereum network, miners are incentivized to include transactions in a\nblock depending on the gas price specified by the sender. The sender of a\ntransaction therefore faces a trade-off between timely inclusion and cost of\nhis transaction. Existing recommendation mechanisms aggregate recent gas price\ndata on a per-block basis to suggest a gas price. We perform an empirical\nanalysis of historic block data to motivate the use of a predictive model for\ngas price recommendation. Subsequently, we propose a novel mechanism that\ncombines a deep-learning based price forecasting model as well as an algorithm\nparameterized by a user-specific urgency value to recommend gas prices. In a\ncomprehensive evaluation on real-world data, we show that our approach results\non average in costs savings of more than 50% while only incurring an inclusion\ndelay of 1.3 blocks, when compared to the gas price recommendation mechanism of\nthe most widely used Ethereum client.\n",
		"date": [
			"2020-03-06",
			"2021-01-20"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2003.03479",
			"in proceedings of The 2nd International Conference on Mathematical\n  Research for Blockchain Economy (MARBLE 2020)"
		],
		"pdf_url": "http://arxiv.org/pdf/2003.03479.pdf"
	},
	"219": {
		"title": "Automatic Recognition of the General-Purpose Communicative Functions\n  defined by the ISO 24617-2 Standard for Dialog Act Annotation",
		"creator": [
			"Ribeiro, Eugénio",
			"Ribeiro, Ricardo",
			"de Matos, David Martins"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"H.1.2",
			"H.3.1",
			"I.2.7"
		],
		"description": [
			"  ISO 24617-2, the standard for dialog act annotation, defines a hierarchically\norganized set of general-purpose communicative functions. The automatic\nrecognition of these functions, although practically unexplored, is relevant\nfor a dialog system, since they provide cues regarding the intention behind the\nsegments and how they should be interpreted. We explore the recognition of\ngeneral-purpose communicative functions in the DialogBank, which is a reference\nset of dialogs annotated according to this standard. To do so, we propose\nadaptations of existing approaches to flat dialog act recognition that allow\nthem to deal with the hierarchical classification problem. More specifically,\nwe propose the use of a hierarchical network with cascading outputs and maximum\na posteriori path estimation to predict the communicative function at each\nlevel of the hierarchy, preserve the dependencies between the functions in the\npath, and decide at which level to stop. Furthermore, since the amount of\ndialogs in the DialogBank is reduced, we rely on transfer learning processes to\nreduce overfitting and improve performance. The results of our experiments show\nthat the hierarchical approach outperforms a flat one and that each of its\ncomponents plays an important role towards the recognition of general-purpose\ncommunicative functions.\n",
			"Comment: 30 pages, 4 figures, 9 tables"
		],
		"date": [
			"2020-03-07",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.03556",
		"pdf_url": "http://arxiv.org/pdf/2003.03556.pdf"
	},
	"220": {
		"title": "A scheme for automatic differentiation of complex loss functions",
		"creator": [
			"Guo, Chu",
			"Poletti, Dario"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  For a real function, automatic differentiation is such a standard algorithm\nused to efficiently compute its gradient, that it is integrated in various\nneural network frameworks. However, despite the recent advances in using\ncomplex functions in machine learning and the well-established usefulness of\nautomatic differentiation, the support of automatic differentiation for complex\nfunctions is not as well-established and widespread as for real functions. In\nthis work we propose an efficient and seamless scheme to implement automatic\ndifferentiation for complex functions, which is a compatible generalization of\nthe current scheme for real functions. This scheme can significantly simplify\nthe implementation of neural networks which use complex numbers.\n",
			"Comment: 6 pages, 1 figure, 1 table"
		],
		"date": "2020-03-01",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2003.04295",
			"Phys. Rev. E 103, 013309 (2021)",
			"doi:10.1103/PhysRevE.103.013309"
		],
		"pdf_url": "http://arxiv.org/pdf/2003.04295.pdf"
	},
	"221": {
		"title": "Unpaired Image-to-Image Translation using Adversarial Consistency Loss",
		"creator": [
			"Zhao, Yihao",
			"Wu, Ruihai",
			"Dong, Hao"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Unpaired image-to-image translation is a class of vision problems whose goal\nis to find the mapping between different image domains using unpaired training\ndata. Cycle-consistency loss is a widely used constraint for such problems.\nHowever, due to the strict pixel-level constraint, it cannot perform geometric\nchanges, remove large objects, or ignore irrelevant texture. In this paper, we\npropose a novel adversarial-consistency loss for image-to-image translation.\nThis loss does not require the translated image to be translated back to be a\nspecific source image but can encourage the translated images to retain\nimportant features of the source images and overcome the drawbacks of\ncycle-consistency loss noted above. Our method achieves state-of-the-art\nresults on three challenging tasks: glasses removal, male-to-female\ntranslation, and selfie-to-anime translation.\n",
		"date": [
			"2020-03-10",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.04858",
		"pdf_url": "http://arxiv.org/pdf/2003.04858.pdf"
	},
	"222": {
		"title": "Deep Vectorization of Technical Drawings",
		"creator": [
			"Egiazarian, Vage",
			"Voynov, Oleg",
			"Artemov, Alexey",
			"Volkhonskiy, Denis",
			"Safin, Aleksandr",
			"Taktasheva, Maria",
			"Zorin, Denis",
			"Burnaev, Evgeny"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Graphics"
		],
		"description": "  We present a new method for vectorization of technical line drawings, such as\nfloor plans, architectural drawings, and 2D CAD images. Our method includes (1)\na deep learning-based cleaning stage to eliminate the background and\nimperfections in the image and fill in missing parts, (2) a transformer-based\nnetwork to estimate vector primitives, and (3) optimization procedure to obtain\nthe final primitive configurations. We train the networks on synthetic data,\nrenderings of vector line drawings, and manually vectorized scans of line\ndrawings. Our method quantitatively and qualitatively outperforms a number of\nexisting techniques on a collection of representative technical drawings.\n",
		"date": [
			"2020-03-11",
			"2020-07-30"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2003.05471",
			"doi:10.1007/978-3-030-58601-0_35"
		],
		"pdf_url": "http://arxiv.org/pdf/2003.05471.pdf"
	},
	"223": {
		"title": "DeepURL: Deep Pose Estimation Framework for Underwater Relative\n  Localization",
		"creator": [
			"Joshi, Bharat",
			"Modasshir, Md",
			"Manderson, Travis",
			"Damron, Hunter",
			"Xanthidis, Marios",
			"Li, Alberto Quattrini",
			"Rekleitis, Ioannis",
			"Dudek, Gregory"
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  In this paper, we propose a real-time deep learning approach for determining\nthe 6D relative pose of Autonomous Underwater Vehicles (AUV) from a single\nimage. A team of autonomous robots localizing themselves in a\ncommunication-constrained underwater environment is essential for many\napplications such as underwater exploration, mapping, multi-robot convoying,\nand other multi-robot tasks. Due to the profound difficulty of collecting\nground truth images with accurate 6D poses underwater, this work utilizes\nrendered images from the Unreal Game Engine simulation for training. An\nimage-to-image translation network is employed to bridge the gap between the\nrendered and the real images producing synthetic images for training. The\nproposed method predicts the 6D pose of an AUV from a single image as 2D image\nkeypoints representing 8 corners of the 3D model of the AUV, and then the 6D\npose in the camera coordinates is determined using RANSAC-based PnP.\nExperimental results in real-world underwater environments (swimming pool and\nocean) with different cameras demonstrate the robustness and accuracy of the\nproposed technique in terms of translation error and orientation error over the\nstate-of-the-art methods. The code is publicly available.\n",
		"date": [
			"2020-03-11",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.05523",
		"pdf_url": "http://arxiv.org/pdf/2003.05523.pdf"
	},
	"224": {
		"title": "Cooperative output feedback tracking control of stochastic linear\n  heterogeneous multi-agent systems",
		"creator": [
			"Li, Dianqiang",
			"Li, Tao"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": "  We study cooperative output feedback tracking control of stochastic linear\nheterogeneous leader-following multi-agent systems. Each agent has a\ncontinuous-time linear heterogeneous dynamics with incompletely measurable\nstate, and there are additive and multiplicative noises along with information\nexchange among agents. We propose a set of admissible distributed observation\nstrategies for estimating the leader's and the followers' states, and a set of\nadmissible cooperative output feedback control strategies based on the\ncertainty equivalence principle. By output regulation theory and stochastic\nanalysis, we show that for observable leader's dynamics and stabilizable and\ndetectable followers' dynamics, if the intensity coefficient of multiplicative\nnoises multiplied by the sum of real parts of the leader' s unstable modes is\nless than 1/4 of the minimum non-zero eigenvalue of graph Laplacian, then there\nexist admissible distributed observation and cooperative control strategies to\nensure mean square bounded output tracking, provided the associated output\nregulation equations are solvable. Finally, the effectiveness of our control\nstrategies is demonstrated by a numerical simulation.\n",
		"date": [
			"2020-03-11",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.05601",
		"pdf_url": "http://arxiv.org/pdf/2003.05601.pdf"
	},
	"225": {
		"title": "SARDO: An Automated Search-and-Rescue Drone-based Solution for Victims\n  Localization",
		"creator": [
			"Albanese, Antonio",
			"Sciancalepore, Vincenzo",
			"Costa-Pérez, Xavier"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": "  Natural disasters affect millions of people every year. Finding missing\npersons in the shortest possible time is of crucial importance to reduce the\ndeath toll. This task is especially challenging when victims are sparsely\ndistributed in large and/or difficult-to-reach areas and cellular networks are\ndown. In this paper we present SARDO, a drone-based search and rescue solution\nthat exploits the high penetration rate of mobile phones in the society to\nlocalize missing people. SARDO is an autonomous, all-in-one drone-based mobile\nnetwork solution that does not require infrastructure support or mobile phones\nmodifications. It builds on novel concepts such as pseudo-trilateration\ncombined with machine-learning techniques to efficiently locate mobile phones\nin a given area. Our results, with a prototype implementation in a field-trial,\nshow that SARDO rapidly determines the location of mobile phones (~3 min/UE) in\na given area with an accuracy of few tens of meters and at a low battery\nconsumption cost (~5%). State-of-the-art localization solutions for disaster\nscenarios rely either on mobile infrastructure support or exploit onboard\ncameras for human/computer vision, IR, thermal-based localization. To the best\nof our knowledge, SARDO is the first drone-based cellular search-and-rescue\nsolution able to accurately localize missing victims through mobile phones.\n",
		"date": "2020-03-12",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2003.05819",
			"IEEE Transactions on Mobile Computing ( Early Access ), 2021",
			"doi:10.1109/TMC.2021.3051273"
		],
		"pdf_url": "http://arxiv.org/pdf/2003.05819.pdf"
	},
	"226": {
		"title": "Online Fast Adaptation and Knowledge Accumulation: a New Approach to\n  Continual Learning",
		"creator": [
			"Caccia, Massimo",
			"Rodriguez, Pau",
			"Ostapenko, Oleksiy",
			"Normandin, Fabrice",
			"Lin, Min",
			"Caccia, Lucas",
			"Laradji, Issam",
			"Rish, Irina",
			"Lacoste, Alexandre",
			"Vazquez, David",
			"Charlin, Laurent"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": "  Continual learning studies agents that learn from streams of tasks without\nforgetting previous ones while adapting to new ones. Two recent\ncontinual-learning scenarios have opened new avenues of research. In\nmeta-continual learning, the model is pre-trained to minimize catastrophic\nforgetting of previous tasks. In continual-meta learning, the aim is to train\nagents for faster remembering of previous tasks through adaptation. In their\noriginal formulations, both methods have limitations. We stand on their\nshoulders to propose a more general scenario, OSAKA, where an agent must\nquickly solve new (out-of-distribution) tasks, while also requiring fast\nremembering. We show that current continual learning, meta-learning,\nmeta-continual learning, and continual-meta learning techniques fail in this\nnew scenario. We propose Continual-MAML, an online extension of the popular\nMAML algorithm as a strong baseline for this scenario. We empirically show that\nContinual-MAML is better suited to the new scenario than the aforementioned\nmethodologies, as well as standard continual learning and meta-learning\napproaches.\n",
		"date": [
			"2020-03-12",
			"2021-01-20"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2003.05856",
			"NeurIPS 2020"
		],
		"pdf_url": "http://arxiv.org/pdf/2003.05856.pdf"
	},
	"227": {
		"title": "WAC: A Corpus of Wikipedia Conversations for Online Abuse Detection",
		"creator": [
			"Cecillon, Noé",
			"Labatut, Vincent",
			"Dufour, Richard",
			"Linares, Georges"
		],
		"subject": "Computer Science - Computation and Language",
		"description": "  With the spread of online social networks, it is more and more difficult to\nmonitor all the user-generated content. Automating the moderation process of\nthe inappropriate exchange content on Internet has thus become a priority task.\nMethods have been proposed for this purpose, but it can be challenging to find\na suitable dataset to train and develop them. This issue is especially true for\napproaches based on information derived from the structure and the dynamic of\nthe conversation. In this work, we propose an original framework, based on the\nWikipedia Comment corpus, with comment-level abuse annotations of different\ntypes. The major contribution concerns the reconstruction of conversations, by\ncomparison to existing corpora, which focus only on isolated messages (i.e.\ntaken out of their conversational context). This large corpus of more than 380k\nannotated messages opens perspectives for online abuse detection and especially\nfor context-based approaches. We also propose, in addition to this corpus, a\ncomplete benchmarking platform to stimulate and fairly compare scientific works\naround the problem of content abuse detection, trying to avoid the recurring\nproblem of result replication. Finally, we apply two classification methods to\nour dataset to demonstrate its potential.\n",
		"date": "2020-03-13",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2003.06190",
			"12th Language Resources and Evaluation Conference (LREC 2020),\n  p.1375-1383 , May 2020, Marseille, France"
		],
		"pdf_url": "http://arxiv.org/pdf/2003.06190.pdf"
	},
	"228": {
		"title": "Hyper-reduction for parametrized transport dominated problems via\n  online-adaptive reduced meshes",
		"creator": [
			"Sarna, Neeraj",
			"Grundel, Sara"
		],
		"subject": "Mathematics - Numerical Analysis",
		"description": "  We propose an efficient residual minimization technique for the nonlinear\nmodel-order reduction of parameterized hyperbolic partial differential\nequations. Our nonlinear approximation space is a span of snapshots evaluated\non a shifted spatial domain, and we compute our reduced approximation via\nresidual minimization. To speed-up the residual minimization, we compute and\nminimize the residual on a (preferably small) subset of the mesh, the so-called\nreduced mesh. Due to the nonlinearity of our approximation space we show that,\nsimilar to the solution, the residual also exhibits transport-type behaviour.\nTo account for this behaviour, we introduce online-adaptivity in the reduced\nmesh by \"moving\" it along the spatial domain with parameter dependent shifts.\nWe also present an extension of our method to spatial transforms different from\nshifting. Numerical experiments showcase the effectiveness of our method and\nthe inaccuracies resulting from a non-adaptive reduced mesh.\n",
		"date": [
			"2020-03-13",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.06362",
		"pdf_url": "http://arxiv.org/pdf/2003.06362.pdf"
	},
	"229": {
		"title": "VMLoc: Variational Fusion For Learning-Based Multimodal Camera\n  Localization",
		"creator": [
			"Zhou, Kaichen",
			"Chen, Changhao",
			"Wang, Bing",
			"Saputra, Muhamad Risqi U.",
			"Trigoni, Niki",
			"Markham, Andrew"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": "  Recent learning-based approaches have achieved impressive results in the\nfield of single-shot camera localization. However, how best to fuse multiple\nmodalities (e.g., image and depth) and to deal with degraded or missing input\nare less well studied. In particular, we note that previous approaches towards\ndeep fusion do not perform significantly better than models employing a single\nmodality. We conjecture that this is because of the naive approaches to feature\nspace fusion through summation or concatenation which do not take into account\nthe different strengths of each modality. To address this, we propose an\nend-to-end framework, termed VMLoc, to fuse different sensor inputs into a\ncommon latent space through a variational Product-of-Experts (PoE) followed by\nattention-based fusion. Unlike previous multimodal variational works directly\nadapting the objective function of vanilla variational auto-encoder, we show\nhow camera localization can be accurately estimated through an unbiased\nobjective function based on importance weighting. Our model is extensively\nevaluated on RGB-D datasets and the results prove the efficacy of our model.\nThe source code is available at https://github.com/Zalex97/VMLoc.\n",
		"date": [
			"2020-03-12",
			"2021-01-13"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2003.07289",
			"The Thirty-Fifth AAAI Conference on Artificial Intelligence\n  (AAAI-2021)"
		],
		"pdf_url": "http://arxiv.org/pdf/2003.07289.pdf"
	},
	"230": {
		"title": "Scaling Strongly Consistent Replication",
		"creator": [
			"Charapko, Aleksey",
			"Ailijiang, Ailidani",
			"Demirbas, Murat"
		],
		"subject": "Computer Science - Distributed, Parallel, and Cluster Computing",
		"description": "  Strong consistency replication helps keep application logic simple and\nprovides significant benefits for correctness and manageability. Unfortunately,\nthe adoption of strongly-consistent replication protocols has been curbed due\nto their limited scalability and performance. To alleviate the leader\nbottleneck in strongly-consistent replication protocols, we introduce Pig, an\nin-protocol communication aggregation and piggybacking technique. Pig employs\nrandomly selected nodes from follower subgroups to relay the leader's message\nto the rest of the followers in the subgroup, and to perform in-network\naggregation of acknowledgments back from these followers. By randomly\nalternating the relay nodes across replication operations, Pig shields the\nrelay nodes as well as the leader from becoming hotspots and improves\nthroughput scalability.\n  We showcase Pig in the context of classical Paxos protocols employed for\nstrongly consistent replication by many cloud computing services and databases.\nWe implement and evaluate PigPaxos, in comparison to Paxos and EPaxos protocols\nunder various workloads over clusters of size 5 to 25 nodes. We show that the\naggregation at the relay has little latency overhead, and PigPaxos can provide\nmore than 3 folds improved throughput over Paxos and EPaxos with little latency\ndeterioration. We support our experimental observations with the analytical\nmodeling of the bottlenecks and show that the rotating of the relay nodes\nprovides the most benefit for reducing the bottlenecks and that the throughput\nis maximized when employing only 1 randomly rotating relay node.\n",
		"date": [
			"2020-03-17",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.07760",
		"pdf_url": "http://arxiv.org/pdf/2003.07760.pdf"
	},
	"231": {
		"title": "The Future of Digital Health with Federated Learning",
		"creator": [
			"Rieke, Nicola",
			"Hancox, Jonny",
			"Li, Wenqi",
			"Milletari, Fausto",
			"Roth, Holger",
			"Albarqouni, Shadi",
			"Bakas, Spyridon",
			"Galtier, Mathieu N.",
			"Landman, Bennett",
			"Maier-Hein, Klaus",
			"Ourselin, Sebastien",
			"Sheller, Micah",
			"Summers, Ronald M.",
			"Trask, Andrew",
			"Xu, Daguang",
			"Baust, Maximilian",
			"Cardoso, M. Jorge"
		],
		"subject": [
			"Computer Science - Computers and Society",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Data-driven Machine Learning has emerged as a promising approach for building\naccurate and robust statistical models from medical data, which is collected in\nhuge volumes by modern healthcare systems. Existing medical data is not fully\nexploited by ML primarily because it sits in data silos and privacy concerns\nrestrict access to this data. However, without access to sufficient data, ML\nwill be prevented from reaching its full potential and, ultimately, from making\nthe transition from research to clinical practice. This paper considers key\nfactors contributing to this issue, explores how Federated Learning (FL) may\nprovide a solution for the future of digital health and highlights the\nchallenges and considerations that need to be addressed.\n",
			"Comment: This is a pre-print version of\n  https://www.nature.com/articles/s41746-020-00323-1"
		],
		"date": [
			"2020-03-18",
			"2021-01-15"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2003.08119",
			"npj Digital Medicine volume 3, Article number: 119 (2020)",
			"doi:10.1038/s41746-020-00323-1"
		],
		"pdf_url": "http://arxiv.org/pdf/2003.08119.pdf"
	},
	"232": {
		"title": "Pose Augmentation: Class-agnostic Object Pose Transformation for Object\n  Recognition",
		"creator": [
			"Ge, Yunhao",
			"Zhao, Jiaping",
			"Itti, Laurent"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Object pose increases intraclass object variance which makes object\nrecognition from 2D images harder. To render a classifier robust to pose\nvariations, most deep neural networks try to eliminate the influence of pose by\nusing large datasets with many poses for each class. Here, we propose a\ndifferent approach: a class-agnostic object pose transformation network\n(OPT-Net) can transform an image along 3D yaw and pitch axes to synthesize\nadditional poses continuously. Synthesized images lead to better training of an\nobject classifier. We design a novel eliminate-add structure to explicitly\ndisentangle pose from object identity: first eliminate pose information of the\ninput image and then add target pose information (regularized as continuous\nvariables) to synthesize any target pose. We trained OPT-Net on images of toy\nvehicles shot on a turntable from the iLab-20M dataset. After training on\nunbalanced discrete poses (5 classes with 6 poses per object instance, plus 5\nclasses with only 2 poses), we show that OPT-Net can synthesize balanced\ncontinuous new poses along yaw and pitch axes with high quality. Training a\nResNet-18 classifier with original plus synthesized poses improves mAP accuracy\nby 9% overtraining on original poses only. Further, the pre-trained OPT-Net can\ngeneralize to new object classes, which we demonstrate on both iLab-20M and\nRGB-D. We also show that the learned features can generalize to ImageNet.\n",
			"Comment: ECCV 2020, with supplementary materials"
		],
		"date": [
			"2020-03-18",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.08526",
		"pdf_url": "http://arxiv.org/pdf/2003.08526.pdf"
	},
	"233": {
		"title": "Gaussian Curvature Filter on 3D Meshes",
		"creator": [
			"Tang, Wenming",
			"Gong, Yuanhao",
			"Liu, Kanglin",
			"Liu, Jun",
			"Pan, Wei",
			"Liu, Bozhi",
			"Qiu, Guoping"
		],
		"subject": "Computer Science - Graphics",
		"description": [
			"  Minimizing the Gaussian curvature of meshes can play a fundamental role in 3D\nmesh processing. However, there is a lack of computationally efficient and\nrobust Gaussian curvature optimization method. In this paper, we present a\nsimple yet effective method that can efficiently reduce Gaussian curvature for\n3D meshes. We first present the mathematical foundation of our method. Then, we\nintroduce a simple and robust implicit Gaussian curvature optimization method\nnamed Gaussian Curvature Filter (GCF). GCF implicitly minimizes Gaussian\ncurvature without the need to explicitly calculate the Gaussian curvature\nitself. GCF is highly efficient and this method can be used in a large range of\napplications that involve Gaussian curvature. We conduct extensive experiments\nto demonstrate that GCF significantly outperforms state-of-the-art methods in\nminimizing Gaussian curvature, and geometric feature preserving soothing on 3D\nmeshes. GCF program is available at https://github.com/tangwenming/GCF-filter.\n",
			"Comment: 15 pages"
		],
		"date": [
			"2020-03-20",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.09178",
		"pdf_url": "http://arxiv.org/pdf/2003.09178.pdf"
	},
	"234": {
		"title": "Review of data analysis in vision inspection of power lines with an\n  in-depth discussion of deep learning technology",
		"creator": [
			"Liu, Xinyu",
			"Miao, Xiren",
			"Jiang, Hao",
			"Chen, Jing"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": "  The widespread popularity of unmanned aerial vehicles enables an immense\namount of power lines inspection data to be collected. How to employ massive\ninspection data especially the visible images to maintain the reliability,\nsafety, and sustainability of power transmission is a pressing issue. To date,\nsubstantial works have been conducted on the analysis of power lines inspection\ndata. With the aim of providing a comprehensive overview for researchers who\nare interested in developing a deep-learning-based analysis system for power\nlines inspection data, this paper conducts a thorough review of the current\nliterature and identifies the challenges for future research. Following the\ntypical procedure of inspection data analysis, we categorize current works in\nthis area into component detection and fault diagnosis. For each aspect, the\ntechniques and methodologies adopted in the literature are summarized. Some\nvaluable information is also included such as data description and method\nperformance. Further, an in-depth discussion of existing deep-learning-related\nanalysis methods in power lines inspection is proposed. Finally, we conclude\nthe paper with several research trends for the future of this area, such as\ndata quality problems, small object detection, embedded application, and\nevaluation baseline.\n",
		"date": "2020-03-22",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2003.09802",
			"doi:10.1016/j.arcontrol.2020.09.002"
		],
		"pdf_url": "http://arxiv.org/pdf/2003.09802.pdf"
	},
	"235": {
		"title": "Open Source Software Development Challenges: A Systematic Literature\n  Review on GitHub",
		"creator": [
			"Şeker, Abdulkadir",
			"Diri, Banu",
			"Arslan, Halil",
			"Amasyalı, Mehmet Fatih"
		],
		"subject": [
			"Computer Science - Software Engineering",
			"Computer Science - Social and Information Networks"
		],
		"description": [
			"  Git is used as the distributed version control system for many open-source\nsoftware projects. One Git-based service, GitHub, is the most common code\nhosting and repository service for open-source software projects. For\nresearchers that study software engineering, the content that is hosted on\nthese platforms provides much valuable data. There are some alternatives to get\nGitHub data such as GitHub Archive, GitHub API or GHTorrent. Among these\noptions, GHTorrent is the most widely known and used GitHub dataset in the\nliterature. Although there are some review studies about software engineering\nchallenges across the GitHub platform, no review of GHTorrent dataset-specific\nresearch is available. In this study, the 172 studies that use GHTorrent as a\ndata source were categorized within the scope of open source software\ndevelopment challenges and a systematic literature review was carried out.\nMoreover, the pros and cons of the dataset have been indicated and the focused\nissues of the literature on and the open challenges have been noted.\n",
			"Comment: This is old version, It include typo errors based on latex, I cant\n  remove it"
		],
		"date": [
			"2020-03-24",
			"2020-07-27"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2003.10750",
			"International Journal of Open Source Software and Processes\n  (IJOSSP),2020, 11(4), p 1-26",
			"doi:10.4018/IJOSSP.2020100101"
		],
		"pdf_url": "http://arxiv.org/pdf/2003.10750.pdf"
	},
	"236": {
		"title": "PiP: Planning-informed Trajectory Prediction for Autonomous Driving",
		"creator": [
			"Song, Haoran",
			"Ding, Wenchao",
			"Chen, Yuxuan",
			"Shen, Shaojie",
			"Wang, Michael Yu",
			"Chen, Qifeng"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Robotics"
		],
		"description": [
			"  It is critical to predict the motion of surrounding vehicles for self-driving\nplanning, especially in a socially compliant and flexible way. However, future\nprediction is challenging due to the interaction and uncertainty in driving\nbehaviors. We propose planning-informed trajectory prediction (PiP) to tackle\nthe prediction problem in the multi-agent setting. Our approach is\ndifferentiated from the traditional manner of prediction, which is only based\non historical information and decoupled with planning. By informing the\nprediction process with the planning of ego vehicle, our method achieves the\nstate-of-the-art performance of multi-agent forecasting on highway datasets.\nMoreover, our approach enables a novel pipeline which couples the prediction\nand planning, by conditioning PiP on multiple candidate trajectories of the ego\nvehicle, which is highly beneficial for autonomous driving in interactive\nscenarios.\n",
			"Comment: European Conference on Computer Vision (ECCV) 2020; Project page at\n  http://haoran-song.github.io/planning-informed-prediction"
		],
		"date": [
			"2020-03-25",
			"2021-01-18"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2003.11476",
			"doi:10.1007/978-3-030-58589-1_36"
		],
		"pdf_url": "http://arxiv.org/pdf/2003.11476.pdf"
	},
	"237": {
		"title": "A Topological Characterization of Modulo-$p$ Arguments and Implications\n  for Necklace Splitting",
		"creator": [
			"Filos-Ratsikas, Aris",
			"Hollender, Alexandros",
			"Sotiraki, Katerina",
			"Zampetakis, Manolis"
		],
		"subject": [
			"Computer Science - Computational Complexity",
			"Computer Science - Computational Geometry",
			"Computer Science - Discrete Mathematics"
		],
		"description": [
			"  The classes PPA-$p$ have attracted attention lately, because they are the\nmain candidates for capturing the complexity of Necklace Splitting with $p$\nthieves, for prime $p$. However, these classes were not known to have complete\nproblems of a topological nature, which impedes any progress towards settling\nthe complexity of the Necklace Splitting problem. On the contrary, topological\nproblems have been pivotal in obtaining completeness results for PPAD and PPA,\nsuch as the PPAD-completeness of finding a Nash equilibrium [Daskalakis et al.,\n2009, Chen et al., 2009b] and the PPA-completeness of Necklace Splitting with 2\nthieves [Filos-Ratsikas and Goldberg, 2019].\n  In this paper, we provide the first topological characterization of the\nclasses PPA-$p$. First, we show that the computational problem associated with\na simple generalization of Tucker's Lemma, termed $p$-polygon-Tucker, as well\nas the associated Borsuk-Ulam-type theorem, $p$-polygon-Borsuk-Ulam, are\nPPA-$p$-complete. Then, we show that the computational version of the\nwell-known BSS Theorem [Barany et al., 1981], as well as the associated\nBSS-Tucker problem are PPA-$p$-complete. Finally, using a different\ngeneralization of Tucker's Lemma (termed $\\mathbb{Z}_p$-star-Tucker), which we\nprove to be PPA-$p$-complete, we prove that $p$-thief Necklace Splitting is in\nPPA-$p$. This latter result gives a new combinatorial proof for the Necklace\nSplitting theorem, the only proof of this nature other than that of Meunier\n[2014].\n  All of our containment results are obtained through a new combinatorial proof\nfor $\\mathbb{Z}_p$-versions of Tucker's lemma that is a natural generalization\nof the standard combinatorial proof of Tucker's lemma by Freund and Todd\n[1981]. We believe that this new proof technique is of independent interest.\n",
			"Comment: v2: improved presentation based on reviewer comments and suggestions"
		],
		"date": [
			"2020-03-26",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.11974",
		"pdf_url": "http://arxiv.org/pdf/2003.11974.pdf"
	},
	"238": {
		"title": "An immersed interface-lattice Boltzmann method for fluid-structure\n  interaction",
		"creator": [
			"Qin, Jianhua",
			"Kolahdouz, Ebrahim M.",
			"Griffith, Boyce E."
		],
		"subject": [
			"Physics - Computational Physics",
			"Mathematics - Numerical Analysis",
			"Physics - Fluid Dynamics"
		],
		"description": "  An immersed interface-lattice Boltzmann method (II-LBM) is developed for\nmodelling fluid-structure systems. The key element of this approach is the\ndetermination of the jump conditions that are satisfied by the distribution\nfunctions within the framework of the lattice Boltzmann method when forces are\nimposed along a surface immersed in an incompressible fluid. In this initial\nII-LBM, the discontinuity related to the normal portion of the interfacial\nforce is sharply resolved by imposing the relevant jump conditions using an\napproach that is analogous to imposing the corresponding pressure jump\ncondition in the incompressible Navier-Stokes equations. We show that the jump\nconditions for the distribution functions are the same in both\nsingle-relaxation-time and multi-relaxation-time LBM formulations. Tangential\nforces are treated using the immersed boundary-lattice Boltzmann method\n(IB-LBM). The performance of the II-LBM method is compared to both the direct\nforcing IB-LBM for rigid-body fluid-structure interaction, and the classical\nIB-LBM for elastic interfaces. Higher order accuracy is observed with the\nII-LBM as compared to the IB-LBM for selected benchmark problems. Because the\njump conditions of the distribution function also satisfy the continuity of the\nvelocity field across the interface, the error in the velocity field is much\nsmaller for the II-LBM than the IB-LBM. The II-LBM is also demonstrated to\nprovide superior volume conservation when simulating flexible boundaries.\n",
		"date": "2020-03-26",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2003.12186",
			"Journal of Computational Physics, Volume 428, 1 March 2021, 109807",
			"doi:10.1016/j.jcp.2020.109807"
		],
		"pdf_url": "http://arxiv.org/pdf/2003.12186.pdf"
	},
	"239": {
		"title": "Progressive Graph Convolutional Networks for Semi-Supervised Node\n  Classification",
		"creator": [
			"Heidari, Negar",
			"Iosifidis, Alexandros"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Graph convolutional networks have been successful in addressing graph-based\ntasks such as semi-supervised node classification. Existing methods use a\nnetwork structure defined by the user based on experimentation with fixed\nnumber of layers and neurons per layer and employ a layer-wise propagation rule\nto obtain the node embeddings. Designing an automatic process to define a\nproblem-dependant architecture for graph convolutional networks can greatly\nhelp to reduce the need for manual design of the structure of the model in the\ntraining process. In this paper, we propose a method to automatically build\ncompact and task-specific graph convolutional networks. Experimental results on\nwidely used publicly available datasets show that the proposed method\noutperforms related methods based on convolutional graph networks in terms of\nclassification performance and network compactness.\n",
			"Comment: 11 pages, 4 figures, 4 tables, 1 algorithm"
		],
		"date": [
			"2020-03-27",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.12277",
		"pdf_url": "http://arxiv.org/pdf/2003.12277.pdf"
	},
	"240": {
		"title": "Convolutional Spiking Neural Networks for Spatio-Temporal Feature\n  Extraction",
		"creator": [
			"Samadzadeh, Ali",
			"Far, Fatemeh Sadat Tabatabaei",
			"Javadi, Ali",
			"Nickabadi, Ahmad",
			"Chehreghani, Morteza Haghir"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Spiking neural networks (SNNs) can be used in low-power and embedded systems\n(such as emerging neuromorphic chips) due to their event-based nature. Also,\nthey have the advantage of low computation cost in contrast to conventional\nartificial neural networks (ANNs), while preserving ANN's properties. However,\ntemporal coding in layers of convolutional spiking neural networks and other\ntypes of SNNs has yet to be studied. In this paper, we provide insight into\nspatio-temporal feature extraction of convolutional SNNs in experiments\ndesigned to exploit this property. The shallow convolutional SNN outperforms\nstate-of-the-art spatio-temporal feature extractor methods such as C3D,\nConvLstm, and similar networks. Furthermore, we present a new deep spiking\narchitecture to tackle real-world problems (in particular classification tasks)\nwhich achieved superior performance compared to other SNN methods on NMNIST\n(99.6%), DVS-CIFAR10 (69.2%) and DVS-Gesture (96.7%) and ANN methods on UCF-101\n(42.1%) and HMDB-51 (21.5%) datasets. It is also worth noting that the training\nprocess is implemented based on variation of spatio-temporal backpropagation\nexplained in the paper.\n",
			"Comment: 10 pages, 7 figures, 2 tables"
		],
		"date": [
			"2020-03-27",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.12346",
		"pdf_url": "http://arxiv.org/pdf/2003.12346.pdf"
	},
	"241": {
		"title": "An Empirical Analysis of Privacy in the Lightning Network",
		"creator": [
			"Kappos, George",
			"Yousaf, Haaroon",
			"Piotrowska, Ania",
			"Kanjalkar, Sanket",
			"Delgado-Segura, Sergi",
			"Miller, Andrew",
			"Meiklejohn, Sarah"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": [
			"  Payment channel networks, and the Lightning Network in particular, seem to\noffer a solution to the lack of scalability and privacy offered by Bitcoin and\nother blockchain-based cryptocurrencies. Previous research has focused on the\nscalability, availability, and crypto-economics of the Lightning Network, but\nrelatively little attention has been paid to exploring the level of privacy it\nachieves in practice. This paper presents a thorough analysis of the privacy\noffered by the Lightning Network, by presenting several attacks that exploit\npublicly available information about the network in order to learn information\nthat is designed to be kept secret, such as how many coins a node has available\nor who the sender and recipient are in a payment routed through the network.\n",
			"Comment: 26 pages, 5 figures"
		],
		"date": [
			"2020-03-27",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.12470",
		"pdf_url": "http://arxiv.org/pdf/2003.12470.pdf"
	},
	"242": {
		"title": "Semantic Implicit Neural Scene Representations With Semi-Supervised\n  Training",
		"creator": [
			"Kohli, Amit",
			"Sitzmann, Vincent",
			"Wetzstein, Gordon"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"I.2.10",
			"I.4.5",
			"I.4.6",
			"I.4.8",
			"I.4.10"
		],
		"description": [
			"  The recent success of implicit neural scene representations has presented a\nviable new method for how we capture and store 3D scenes. Unlike conventional\n3D representations, such as point clouds, which explicitly store scene\nproperties in discrete, localized units, these implicit representations encode\na scene in the weights of a neural network which can be queried at any\ncoordinate to produce these same scene properties. Thus far, implicit\nrepresentations have primarily been optimized to estimate only the appearance\nand/or 3D geometry information in a scene. We take the next step and\ndemonstrate that an existing implicit representation (SRNs) is actually\nmulti-modal; it can be further leveraged to perform per-point semantic\nsegmentation while retaining its ability to represent appearance and geometry.\nTo achieve this multi-modal behavior, we utilize a semi-supervised learning\nstrategy atop the existing pre-trained scene representation. Our method is\nsimple, general, and only requires a few tens of labeled 2D segmentation masks\nin order to achieve dense 3D semantic segmentation. We explore two novel\napplications for this semantically aware implicit neural scene representation:\n3D novel view and semantic label synthesis given only a single input RGB image\nor 2D label mask, as well as 3D interpolation of appearance and semantics.\n",
			"Comment: 3DV 2020 Camera Ready\n  https://www.computationalimaging.org/publications/"
		],
		"date": [
			"2020-03-27",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.12673",
		"pdf_url": "http://arxiv.org/pdf/2003.12673.pdf"
	},
	"243": {
		"title": "In-Hand Object-Dynamics Inference using Tactile Fingertips",
		"creator": [
			"Sundaralingam, Balakumar",
			"Hermans, Tucker"
		],
		"subject": "Computer Science - Robotics",
		"description": [
			"  Having the ability to estimate an object's properties through interaction\nwill enable robots to manipulate novel objects. Object's dynamics, specifically\nthe friction and inertial parameters have only been estimated in a lab\nenvironment with precise and often external sensing. Could we infer an object's\ndynamics in the wild with only the robot's sensors? In this paper, we explore\nthe estimation of dynamics of a grasped object in motion, with tactile force\nsensing at multiple fingertips. Our estimation approach does not rely on torque\nsensing to estimate the dynamics. To estimate friction, we develop a control\nscheme to actively interact with the object until slip is detected. To robustly\nperform the inertial estimation, we setup a factor graph that fuses all our\nsensor measurements on physically consistent manifolds and perform inference.\nWe show that tactile fingertips enable in-hand dynamics estimation of low mass\nobjects.\n",
			"Comment: Accepted at IEEE Transactions on Robotics (T-RO). Website:\n  https://sites.google.com/view/tactile-obj-dynamics"
		],
		"date": [
			"2020-03-29",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.13165",
		"pdf_url": "http://arxiv.org/pdf/2003.13165.pdf"
	},
	"244": {
		"title": "Deep Learning-Based Anomaly Detection in Cyber-Physical Systems:\n  Progress and Opportunities",
		"creator": [
			"Luo, Yuan",
			"Xiao, Ya",
			"Cheng, Long",
			"Peng, Guojun",
			"Yao, Danfeng Daphne"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": "  Anomaly detection is crucial to ensure the security of cyber-physical systems\n(CPS). However, due to the increasing complexity of CPSs and more sophisticated\nattacks, conventional anomaly detection methods, which face the growing volume\nof data and need domain-specific knowledge, cannot be directly applied to\naddress these challenges. To this end, deep learning-based anomaly detection\n(DLAD) methods have been proposed. In this paper, we review state-of-the-art\nDLAD methods in CPSs. We propose a taxonomy in terms of the type of anomalies,\nstrategies, implementation, and evaluation metrics to understand the essential\nproperties of current methods. Further, we utilize this taxonomy to identify\nand highlight new characteristics and designs in each CPS domain. Also, we\ndiscuss the limitations and open problems of these methods. Moreover, to give\nusers insights into choosing proper DLAD methods in practice, we experimentally\nexplore the characteristics of typical neural models, the workflow of DLAD\nmethods, and the running performance of DL models. Finally, we discuss the\ndeficiencies of DL approaches, our findings, and possible directions to improve\nDLAD methods and motivate future research.\n",
		"date": [
			"2020-03-30",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2003.13213",
		"pdf_url": "http://arxiv.org/pdf/2003.13213.pdf"
	},
	"245": {
		"title": "The Discrete Gaussian for Differential Privacy",
		"creator": [
			"Canonne, Clément L.",
			"Kamath, Gautam",
			"Steinke, Thomas"
		],
		"subject": [
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Cryptography and Security",
			"Statistics - Machine Learning"
		],
		"description": [
			"  A key tool for building differentially private systems is adding Gaussian\nnoise to the output of a function evaluated on a sensitive dataset.\nUnfortunately, using a continuous distribution presents several practical\nchallenges. First and foremost, finite computers cannot exactly represent\nsamples from continuous distributions, and previous work has demonstrated that\nseemingly innocuous numerical errors can entirely destroy privacy. Moreover,\nwhen the underlying data is itself discrete (e.g., population counts), adding\ncontinuous noise makes the result less interpretable.\n  With these shortcomings in mind, we introduce and analyze the discrete\nGaussian in the context of differential privacy. Specifically, we theoretically\nand experimentally show that adding discrete Gaussian noise provides\nessentially the same privacy and accuracy guarantees as the addition of\ncontinuous Gaussian noise. We also present an simple and efficient algorithm\nfor exact sampling from this distribution. This demonstrates its applicability\nfor privately answering counting queries, or more generally, low-sensitivity\ninteger-valued queries.\n",
			"Comment: Improved time analysis, and generalisation to the multivariate case"
		],
		"date": [
			"2020-03-31",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2004.00010",
		"pdf_url": "http://arxiv.org/pdf/2004.00010.pdf"
	},
	"246": {
		"title": "The Paradox of Information Access: On Modeling Social-Media-Induced\n  Polarization",
		"creator": [
			"Xu, Chao",
			"Li, Jinyang",
			"Abdelzaher, Tarek",
			"Ji, Heng",
			"Szymanski, Boleslaw K.",
			"Dellaverson, John"
		],
		"subject": "Computer Science - Social and Information Networks",
		"description": [
			"  The paper develops a stochastic model of drift in human beliefs that shows\nthat today's sheer volume of accessible information, combined with consumers'\nconfirmation bias and natural preference to more outlying content, necessarily\nlead to increased polarization. The model explains the paradox of growing\nideological fragmentation in the age of increased sharing. As social media,\nsearch engines, and other real-time information sharing outlets purport to\nfacilitate access to information, a need for content filtering arises due to\nthe ensuing information overload. In general, consumers select information that\nmatches their individual views and values. The bias inherent in such selection\nis echoed by today's information curation services that maximize user\nengagement by filtering new content in accordance with observed consumer\npreferences. Consequently, individuals get exposed to increasingly narrower\nbands of the ideology spectrum, thus fragmenting society into increasingly\nideologically isolated enclaves. We call this dynamic the paradox of\ninformation access. The model also suggests the disproportionate damage\nattainable with a small infusion of well-positioned misinformation. The paper\ndescribes the modeling methodology, and evaluates modeling results for\ndifferent population sizes and parameter settings.\n",
			"Comment: An updated version of this preprint was submitted to IEEE TCNS"
		],
		"date": [
			"2020-04-02",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2004.01106",
		"pdf_url": "http://arxiv.org/pdf/2004.01106.pdf"
	},
	"247": {
		"title": "Neuron Linear Transformation: Modeling the Domain Shift for Crowd\n  Counting",
		"creator": [
			"Wang, Qi",
			"Han, Tao",
			"Gao, Junyu",
			"Yuan, Yuan"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Cross-domain crowd counting (CDCC) is a hot topic due to its importance in\npublic safety. The purpose of CDCC is to alleviate the domain shift between the\nsource and target domain. Recently, typical methods attempt to extract\ndomain-invariant features via image translation and adversarial learning. When\nit comes to specific tasks, we find that the domain shifts are reflected on\nmodel parameters' differences. To describe the domain gap directly at the\nparameter-level, we propose a Neuron Linear Transformation (NLT) method,\nexploiting domain factor and bias weights to learn the domain shift.\nSpecifically, for a specific neuron of a source model, NLT exploits few labeled\ntarget data to learn domain shift parameters. Finally, the target neuron is\ngenerated via a linear transformation. Extensive experiments and analysis on\nsix real-world datasets validate that NLT achieves top performance compared\nwith other domain adaptation methods. An ablation study also shows that the NLT\nis robust and more effective than supervised and fine-tune training. Code is\navailable at: \\url{https://github.com/taohan10200/NLT}.\n",
			"Comment: accepted by IEEE T-NNLS"
		],
		"date": [
			"2020-04-05",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2004.02133",
			"doi:10.1109/TNNLS.2021.3051371"
		],
		"pdf_url": "http://arxiv.org/pdf/2004.02133.pdf"
	},
	"248": {
		"title": "Stable Boundary Conditions and Discretization for PN Equations",
		"creator": [
			"Bünger, Jonas",
			"Sarna, Neeraj",
			"Torrilhon, Manuel"
		],
		"subject": "Mathematics - Numerical Analysis",
		"description": [
			"  A solution to the linear Boltzmann equation satisfies an energy bound, which\nreflects a natural fact: The energy of particles in a finite volume is bounded\nin time by the energy of particles initially occupying the volume augmented by\nthe energy transported into the volume by particles entering the volume over\ntime. In this paper, we present boundary conditions (BCs) for the spherical\nharmonic (PN) approximation, which ensure that this fundamental energy bound is\nsatisfied by the PN approximation. Our BCs are compatible with the\ncharacteristic waves of PN equations and determine the incoming waves uniquely.\nBoth, energy bound and compatibility, are shown based on abstract formulations\nof PN equations and BCs to isolate the necessary structures and properties. The\nBCs are derived from a Marshak type formulation of BC and base on a\nnon-classical even/odd-classification of spherical harmonic functions and a\nstabilization step, which is similar to the truncation of the series expansion\nin the PN method. We show that summation by parts (SBP) finite differences on\nstaggered grids in space and the method of simultaneous approximation terms\n(SAT) allows to maintain the energy bound also on the semi-discrete level.\n",
			"Comment: 26 pages, 17 figures"
		],
		"date": [
			"2020-04-06",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2004.02497",
		"pdf_url": "http://arxiv.org/pdf/2004.02497.pdf"
	},
	"249": {
		"title": "Residual Shuffle-Exchange Networks for Fast Processing of Long Sequences",
		"creator": [
			"Draguns, Andis",
			"Ozoliņš, Emīls",
			"Šostaks, Agris",
			"Apinis, Matīss",
			"Freivalds, Kārlis"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Sound",
			"Electrical Engineering and Systems Science - Audio and Speech Processing"
		],
		"description": [
			"  Attention is a commonly used mechanism in sequence processing, but it is of\nO(n^2) complexity which prevents its application to long sequences. The\nrecently introduced neural Shuffle-Exchange network offers a\ncomputation-efficient alternative, enabling the modelling of long-range\ndependencies in O(n log n) time. The model, however, is quite complex,\ninvolving a sophisticated gating mechanism derived from the Gated Recurrent\nUnit. In this paper, we present a simple and lightweight variant of the\nShuffle-Exchange network, which is based on a residual network employing GELU\nand Layer Normalization. The proposed architecture not only scales to longer\nsequences but also converges faster and provides better accuracy. It surpasses\nthe Shuffle-Exchange network on the LAMBADA language modelling task and\nachieves state-of-the-art performance on the MusicNet dataset for music\ntranscription while being efficient in the number of parameters. We show how to\ncombine the improved Shuffle-Exchange network with convolutional layers,\nestablishing it as a useful building block in long sequence processing\napplications.\n",
			"Comment: 35th AAAI Conference on Artificial Intelligence (AAAI-21)"
		],
		"date": [
			"2020-04-06",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2004.04662",
		"pdf_url": "http://arxiv.org/pdf/2004.04662.pdf"
	},
	"250": {
		"title": "Prune2Edge: A Multi-Phase Pruning Pipelines to Deep Ensemble Learning in\n  IIoT",
		"creator": [
			"Alhalabi, Besher",
			"Gaber, Mohamed",
			"Basurra, Shadi"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Most recently, with the proliferation of IoT devices, computational nodes in\nmanufacturing systems IIoT(Industrial-Internet-of-things) and the lunch of 5G\nnetworks, there will be millions of connected devices generating a massive\namount of data. In such an environment, the controlling systems need to be\nintelligent enough to deal with a vast amount of data to detect defects in a\nreal-time process. Driven by such a need, artificial intelligence models such\nas deep learning have to be deployed into IIoT systems. However, learning and\nusing deep learning models are computationally expensive, so an IoT device with\nlimited computational power could not run such models. To tackle this issue,\nedge intelligence had emerged as a new paradigm towards running Artificial\nIntelligence models on edge devices. Although a considerable amount of studies\nhave been proposed in this area, the research is still in the early stages. In\nthis paper, we propose a novel edge-based multi-phase pruning pipelines to\nensemble learning on IIoT devices. In the first phase, we generate a diverse\nensemble of pruned models, then we apply integer quantisation, next we prune\nthe generated ensemble using a clustering-based technique. Finally, we choose\nthe best representative from each generated cluster to be deployed to a\ndistributed IoT environment. On CIFAR-100 and CIFAR-10, our proposed approach\nwas able to outperform the predictability levels of a baseline model (up to\n7%), more importantly, the generated learners have small sizes (up to 90%\nreduction in the model size) that minimise the required computational\ncapabilities to make an inference on the resource-constraint devices.\n",
			"Comment: a revised version is going to be submitted to a journal soon"
		],
		"date": [
			"2020-04-09",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2004.04710",
		"pdf_url": "http://arxiv.org/pdf/2004.04710.pdf"
	},
	"251": {
		"title": "Mehler's Formula, Branching Process, and Compositional Kernels of Deep\n  Neural Networks",
		"creator": [
			"Liang, Tengyuan",
			"Tran-Bach, Hai"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning",
			"Mathematics - Statistics Theory"
		],
		"description": "  We utilize a connection between compositional kernels and branching processes\nvia Mehler's formula to study deep neural networks. This new probabilistic\ninsight provides us a novel perspective on the mathematical role of activation\nfunctions in compositional neural networks. We study the unscaled and rescaled\nlimits of the compositional kernels and explore the different phases of the\nlimiting behavior, as the compositional depth increases. We investigate the\nmemorization capacity of the compositional kernels and neural networks by\ncharacterizing the interplay among compositional depth, sample size,\ndimensionality, and non-linearity of the activation. Explicit formulas on the\neigenvalues of the compositional kernel are provided, which quantify the\ncomplexity of the corresponding reproducing kernel Hilbert space. On the\nmethodological front, we propose a new random features algorithm, which\ncompresses the compositional layers by devising a new activation function.\n",
		"date": [
			"2020-04-09",
			"2020-09-28"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2004.04767",
			"Journal of the American Statistical Association (2020)",
			"doi:10.1080/01621459.2020.1853547"
		],
		"pdf_url": "http://arxiv.org/pdf/2004.04767.pdf"
	},
	"252": {
		"title": "Multiplicative automatic sequences",
		"creator": [
			"Konieczny, Jakub",
			"Lemańczyk, Mariusz",
			"Müllner, Clemens"
		],
		"subject": [
			"Mathematics - Number Theory",
			"Computer Science - Formal Languages and Automata Theory",
			"Mathematics - Combinatorics",
			"Mathematics - Dynamical Systems",
			"11B85, 37B10, 68R15"
		],
		"description": [
			"  We obtain a complete classification of complex-valued sequences which are\nboth multiplicative and automatic.\n",
			"Comment: 30 pages"
		],
		"date": [
			"2020-04-10",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2004.04920",
		"pdf_url": "http://arxiv.org/pdf/2004.04920.pdf"
	},
	"253": {
		"title": "Peak Age of Information Distribution for Edge Computing with Wireless\n  Links",
		"creator": [
			"Chiariotti, Federico",
			"Vikhrova, Olga",
			"Soret, Beatriz",
			"Popovski, Petar"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"60K25, 68M20",
			"C.2.2",
			"G.3"
		],
		"description": [
			"  Age of Information (AoI) is a critical metric for several Internet of Things\n(IoT) applications, where sensors keep track of the environment by sending\nupdates that need to be as fresh as possible. The development of edge computing\nsolutions has moved the monitoring process closer to the sensor, reducing the\ncommunication delays, but the processing time of the edge node needs to be\ntaken into account. Furthermore, a reliable system design in terms of freshness\nrequires the knowledge of the full distribution of the Peak AoI (PAoI), from\nwhich the probability of occurrence of rare, but extremely damaging events can\nbe obtained. In this work, we model the communication and computation delay of\nsuch a system as two First Come First Serve (FCFS) queues in tandem,\nanalytically deriving the full distribution of the PAoI for the M/M/1 - M/D/1\nand the M/M/1 - M/M/1 tandems, which can represent a wide variety of realistic\nscenarios.\n",
			"Comment: Preprint version of the paper accepted for publication in the\n  Transactions on Communications"
		],
		"date": [
			"2020-04-10",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2004.05088",
		"pdf_url": "http://arxiv.org/pdf/2004.05088.pdf"
	},
	"254": {
		"title": "Output-Lifted Learning Model Predictive Control",
		"creator": [
			"Nair, Siddharth H.",
			"Rosolia, Ugo",
			"Borrelli, Francesco"
		],
		"subject": [
			"Mathematics - Optimization and Control",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": "  We propose a computationally efficient Learning Model Predictive Control\n(LMPC) scheme for constrained optimal control of a class of nonlinear systems\nwhere the state and input can be reconstructed using lifted outputs. For the\nconsidered class of systems, we show how to use historical trajectory data\ncollected during iterative tasks to construct a convex value function\napproximation along with a convex safe set in a lifted space of virtual\noutputs. These constructions are iteratively updated with historical data and\nused to synthesize predictive control policies. We show that the proposed\nstrategy guarantees recursive constraint satisfaction, asymptotic stability and\nnon-decreasing closed-loop performance at each policy update. Finally,\nsimulation results demonstrate the effectiveness of the proposed strategy on a\npiecewise affine (PWA) system, kinematic unicycle and bilinear DC motor.\n",
		"date": [
			"2020-04-10",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2004.05173",
		"pdf_url": "http://arxiv.org/pdf/2004.05173.pdf"
	},
	"255": {
		"title": "Attend and Decode: 4D fMRI Task State Decoding Using Attention Models",
		"creator": [
			"Nguyen, Sam",
			"Ng, Brenda",
			"Kaplan, Alan D.",
			"Ray, Priyadip"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Functional magnetic resonance imaging (fMRI) is a neuroimaging modality that\ncaptures the blood oxygen level in a subject's brain while the subject either\nrests or performs a variety of functional tasks under different conditions.\nGiven fMRI data, the problem of inferring the task, known as task state\ndecoding, is challenging due to the high dimensionality (hundreds of million\nsampling points per datum) and complex spatio-temporal blood flow patterns\ninherent in the data. In this work, we propose to tackle the fMRI task state\ndecoding problem by casting it as a 4D spatio-temporal classification problem.\nWe present a novel architecture called Brain Attend and Decode (BAnD), that\nuses residual convolutional neural networks for spatial feature extraction and\nself-attention mechanisms for temporal modeling. We achieve significant\nperformance gain compared to previous works on a 7-task benchmark from the\nlarge-scale Human Connectome Project-Young Adult (HCP-YA) dataset. We also\ninvestigate the transferability of BAnD's extracted features on unseen HCP\ntasks, either by freezing the spatial feature extraction layers and retraining\nthe temporal model, or finetuning the entire model. The pre-trained features\nfrom BAnD are useful on similar tasks while finetuning them yields competitive\nresults on unseen tasks/conditions.\n",
		"date": [
			"2020-04-10",
			"2021-01-19"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2004.05234",
			"Proceedings of the Machine Learning for Health NeurIPS Workshop,\n  PMLR 136:267-279, 2020"
		],
		"pdf_url": "http://arxiv.org/pdf/2004.05234.pdf"
	},
	"256": {
		"title": "Telling BERT's full story: from Local Attention to Global Aggregation",
		"creator": [
			"Pascual, Damian",
			"Brunner, Gino",
			"Wattenhofer, Roger"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computation and Language"
		],
		"description": [
			"  We take a deep look into the behavior of self-attention heads in the\ntransformer architecture. In light of recent work discouraging the use of\nattention distributions for explaining a model's behavior, we show that\nattention distributions can nevertheless provide insights into the local\nbehavior of attention heads. This way, we propose a distinction between local\npatterns revealed by attention and global patterns that refer back to the\ninput, and analyze BERT from both angles. We use gradient attribution to\nanalyze how the output of an attention attention head depends on the input\ntokens, effectively extending the local attention-based analysis to account for\nthe mixing of information throughout the transformer layers. We find that there\nis a significant discrepancy between attention and attribution distributions,\ncaused by the mixing of context inside the model. We quantify this discrepancy\nand observe that interestingly, there are some patterns that persist across all\nlayers despite the mixing.\n",
			"Comment: Accepted at EACL 2021"
		],
		"date": [
			"2020-04-09",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2004.05916",
		"pdf_url": "http://arxiv.org/pdf/2004.05916.pdf"
	},
	"257": {
		"title": "Distilling Localization for Self-Supervised Representation Learning",
		"creator": [
			"Zhao, Nanxuan",
			"Wu, Zhirong",
			"Lau, Rynson W. H.",
			"Lin, Stephen"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Recent progress in contrastive learning has revolutionized unsupervised\nrepresentation learning. Concretely, multiple views (augmentations) from the\nsame image are encouraged to map to the similar embeddings, while views from\ndifferent images are pulled apart. In this paper, through visualizing and\ndiagnosing classification errors, we observe that current contrastive models\nare ineffective at localizing the foreground object, limiting their ability to\nextract discriminative high-level features. This is due to the fact that view\ngeneration process considers pixels in an image uniformly. To address this\nproblem, we propose a data-driven approach for learning invariance to\nbackgrounds. It first estimates foreground saliency in images and then creates\naugmentations by copy-and-pasting the foreground onto a variety of backgrounds.\nThe learning still follows the instance discrimination pretext task, so that\nthe representation is trained to disregard background content and focus on the\nforeground. We study a variety of saliency estimation methods, and find that\nmost methods lead to improvements for contrastive learning. With this approach\n(DiLo), significant performance is achieved for self-supervised learning on\nImageNet classification, and also for object detection on PASCAL VOC and\nMSCOCO.\n",
			"Comment: Accepted by AAAI2021"
		],
		"date": [
			"2020-04-14",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2004.06638",
		"pdf_url": "http://arxiv.org/pdf/2004.06638.pdf"
	},
	"258": {
		"title": "Bounds on the Secrecy Outage Probability for Dependent Fading Channels",
		"creator": [
			"Besser, Karl-Ludwig",
			"Jorswieck, Eduard A."
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  The amount of sensitive data, which is transmitted wirelessly will increase\nwith future technologies. This raises many questions about secure data\ntransmission. Besides cryptography, information-theoretic security gained\nincreasing attention over the recent years. Among others, it deals with the\nproblem of secure data transmission on the physical layer to a legitimate\nreceiver (Bob) in the presence of an eavesdropper (Eve). In this work, we\ninvestigate upper and lower bounds on the secrecy outage probability for\nslowly-fading wiretap channels with an arbitrary dependency structure between\nthe fading channels to Bob and Eve. Both cases of absence of channel-state\ninformation at the transmitter (CSI-T) and availability of CSI-T of only the\nmain channel to the legitimate receiver are considered. Furthermore, we derive\nexplicit expressions for the upper and lower bounds for Rayleigh fading and\ncompare them to the case of independent channels. The joint distribution of the\nlegitimate and eavesdropper channels has a tremendous impact on the achievable\nsecrecy outage probability. The bounds enable developing guaranteed secrecy\nschemes by only measuring the marginal channel distributions.\n",
			"Comment: Accepted for publication in IEEE Transactions on Communications"
		],
		"date": [
			"2020-04-14",
			"2020-09-21"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2004.06644",
			"IEEE Transactions on Communications, vol. 69, no. 1, pp. 443-456,\n  Jan. 2021",
			"doi:10.1109/TCOMM.2020.3026654"
		],
		"pdf_url": "http://arxiv.org/pdf/2004.06644.pdf"
	},
	"259": {
		"title": "OptiGAN: Generative Adversarial Networks for Goal Optimized Sequence\n  Generation",
		"creator": [
			"Hossam, Mahmoud",
			"Le, Trung",
			"Huynh, Viet",
			"Papasimeon, Michael",
			"Phung, Dinh"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning",
			"68T01, 68T50",
			"I.2.0",
			"I.2.7",
			"I.5.0"
		],
		"description": [
			"  One of the challenging problems in sequence generation tasks is the optimized\ngeneration of sequences with specific desired goals. Current sequential\ngenerative models mainly generate sequences to closely mimic the training data,\nwithout direct optimization of desired goals or properties specific to the\ntask. We introduce OptiGAN, a generative model that incorporates both\nGenerative Adversarial Networks (GAN) and Reinforcement Learning (RL) to\noptimize desired goal scores using policy gradients. We apply our model to text\nand real-valued sequence generation, where our model is able to achieve higher\ndesired scores out-performing GAN and RL baselines, while not sacrificing\noutput sample diversity.\n",
			"Comment: Preprint for accepted conference paper at International Joint\n  Conference on Neural Networks (IJCNN) 2020"
		],
		"date": [
			"2020-04-16",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2004.07534",
		"pdf_url": "http://arxiv.org/pdf/2004.07534.pdf"
	},
	"260": {
		"title": "Convergence of Eigenvector Continuation",
		"creator": [
			"Sarkar, Avik",
			"Lee, Dean"
		],
		"subject": [
			"Nuclear Theory",
			"Condensed Matter - Strongly Correlated Electrons",
			"High Energy Physics - Lattice",
			"High Energy Physics - Phenomenology",
			"Mathematics - Numerical Analysis"
		],
		"description": [
			"  Eigenvector continuation is a computational method that finds the extremal\neigenvalues and eigenvectors of a Hamiltonian matrix with one or more control\nparameters. It does this by projection onto a subspace of eigenvectors\ncorresponding to selected training values of the control parameters. The method\nhas proven to be very efficient and accurate for interpolating and\nextrapolating eigenvectors. However, almost nothing is known about how the\nmethod converges, and its rapid convergence properties have remained\nmysterious. In this letter we present the first study of the convergence of\neigenvector continuation. In order to perform the mathematical analysis, we\nintroduce a new variant of eigenvector continuation that we call vector\ncontinuation. We first prove that eigenvector continuation and vector\ncontinuation have identical convergence properties and then analyze the\nconvergence of vector continuation. Our analysis shows that, in general,\neigenvector continuation converges more rapidly than perturbation theory. The\nfaster convergence is achieved by eliminating a phenomenon that we call\ndifferential folding, the interference between non-orthogonal vectors appearing\nat different orders in perturbation theory. From our analysis we can predict\nhow eigenvector continuation converges both inside and outside the radius of\nconvergence of perturbation theory. While eigenvector continuation is a\nnon-perturbative method, we show that its rate of convergence can be deduced\nfrom power series expansions of the eigenvectors. Our results also yield new\ninsights into the nature of divergences in perturbation theory.\n",
			"Comment: 5 pages and 4 figures (main text), 4 pages and 8 figures\n  (supplemental), new analysis of the multi-parameter case, new application to\n  BCS-BEC crossover and the unitary limit"
		],
		"date": [
			"2020-04-16",
			"2020-11-30"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2004.07651",
			"Phys. Rev. Lett. 126, 032501 (2021)",
			"doi:10.1103/PhysRevLett.126.032501"
		],
		"pdf_url": "http://arxiv.org/pdf/2004.07651.pdf"
	},
	"261": {
		"title": "A Framework for Enhancing Deep Neural Networks Against Adversarial\n  Malware",
		"creator": [
			"Li, Deqiang",
			"Li, Qianmu",
			"Ye, Yanfang",
			"Xu, Shouhuai"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Machine Learning",
			"68-06"
		],
		"description": [
			"  Machine learning-based malware detection is known to be vulnerable to\nadversarial evasion attacks. The state-of-the-art is that there are no\neffective defenses against these attacks. As a response to the adversarial\nmalware classification challenge organized by the MIT Lincoln Lab and\nassociated with the AAAI-19 Workshop on Artificial Intelligence for Cyber\nSecurity (AICS'2019), we propose six guiding principles to enhance the\nrobustness of deep neural networks. Some of these principles have been\nscattered in the literature, but the others are introduced in this paper for\nthe first time. Under the guidance of these six principles, we propose a\ndefense framework to enhance the robustness of deep neural networks against\nadversarial malware evasion attacks. By conducting experiments with the Drebin\nAndroid malware dataset, we show that the framework can achieve a 98.49\\%\naccuracy (on average) against grey-box attacks, where the attacker knows some\ninformation about the defense and the defender knows some information about the\nattack, and an 89.14% accuracy (on average) against the more capable white-box\nattacks, where the attacker knows everything about the defense and the defender\nknows some information about the attack. The framework wins the AICS'2019\nchallenge by achieving a 76.02% accuracy, where neither the attacker (i.e., the\nchallenge organizer) knows the framework or defense nor we (the defender) know\nthe attacks. This gap highlights the importance of knowing about the attack.\n",
			"Comment: A fully-fledge version for the preliminary paper arXiv:1812.08108 |\n  D. Li, Q. Li, Y. Ye, and S. Xu, \"A Framework for Enhancing Deep Neural\n  Networks Against Adversarial Malware\", in IEEE Transactions on Network\n  Science and Engineering"
		],
		"date": [
			"2020-04-15",
			"2021-01-15"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2004.07919",
			"doi:10.1109/TNSE.2021.3051354"
		],
		"pdf_url": "http://arxiv.org/pdf/2004.07919.pdf"
	},
	"262": {
		"title": "A novel embedded min-max approach for feature selection in nonlinear\n  support vector machine classification",
		"creator": [
			"Jiménez-Cordero, Asunción",
			"Morales, Juan Miguel",
			"Pineda, Salvador"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Mathematics - Optimization and Control",
			"Statistics - Machine Learning"
		],
		"description": [
			"  In recent years, feature selection has become a challenging problem in\nseveral machine learning fields, such as classification problems. Support\nVector Machine (SVM) is a well-known technique applied in classification tasks.\nVarious methodologies have been proposed in the literature to select the most\nrelevant features in SVM. Unfortunately, all of them either deal with the\nfeature selection problem in the linear classification setting or propose\nad-hoc approaches that are difficult to implement in practice. In contrast, we\npropose an embedded feature selection method based on a min-max optimization\nproblem, where a trade-off between model complexity and classification accuracy\nis sought. By leveraging duality theory, we equivalently reformulate the\nmin-max problem and solve it without further ado using off-the-shelf software\nfor nonlinear optimization. The efficiency and usefulness of our approach are\ntested on several benchmark data sets in terms of accuracy, number of selected\nfeatures and interpretability.\n",
			"Comment: Published at European Journal of Operational Research"
		],
		"date": [
			"2020-04-21",
			"2021-01-15"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2004.09863",
			"doi:10.1016/j.ejor.2020.12.009"
		],
		"pdf_url": "http://arxiv.org/pdf/2004.09863.pdf"
	},
	"263": {
		"title": "On the Role of Hash-based Signatures in Quantum-Safe Internet of Things:\n  Current Solutions and Future Directions",
		"creator": [
			"Suhail, Sabah",
			"Hussain, Rasheed",
			"Khan, Abid",
			"Hong, Choong Seon"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": [
			"  The Internet of Things (IoT) is gaining ground as a pervasive presence around\nus by enabling miniaturized things with computation and communication\ncapabilities to collect, process, analyze, and interpret information.\nConsequently, trustworthy data act as fuel for applications that rely on the\ndata generated by these things, for critical decision-making processes, data\ndebugging, risk assessment, forensic analysis, and performance tuning.\nCurrently, secure and reliable data communication in IoT is based on public-key\ncryptosystems such as Elliptic Curve Cryptosystem (ECC). Nevertheless, reliance\non the security of de-facto cryptographic primitives is at risk of being broken\nby the impending quantum computers. Therefore, the transition from classical\nprimitives to quantum-safe primitives is indispensable to ensure the overall\nsecurity of data en route. In this paper, we investigate applications of one of\nthe post-quantum signatures called Hash-Based Signature (HBS) schemes for the\nsecurity of IoT devices in the quantum era. We give a succinct overview of the\nevolution of HBS schemes with emphasis on their construction parameters and\nassociated strengths and weaknesses. Then, we outline the striking features of\nHBS schemes and their significance for the IoT security in the quantum era. We\ninvestigate the optimal selection of HBS in the IoT networks with respect to\ntheir performance-constrained requirements, resource-constrained nature, and\ndesign optimization objectives. In addition to ongoing standardization efforts,\nwe also highlight current and future research and deployment challenges along\nwith possible solutions. Finally, we outline the essential measures and\nrecommendations that must be adopted by the IoT ecosystem while preparing for\nthe quantum world.\n",
			"Comment: 18 pages, 7 tables, 7 figures"
		],
		"date": "2020-04-22",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2004.10435",
			"IEEE Internet of Things Journal, Vol. 8, No. 1, 2021",
			"doi:10.1109/JIOT.2020.3013019"
		],
		"pdf_url": "http://arxiv.org/pdf/2004.10435.pdf"
	},
	"264": {
		"title": "Assurance 2.0: A Manifesto",
		"creator": [
			"Bloomfield, Robin",
			"Rushby, John"
		],
		"subject": [
			"Computer Science - Software Engineering",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": "  System assurance is confronted by significant challenges. Some of these are\nnew, for example, autonomous systems with major functions driven by machine\nlearning and AI, and ultra-rapid system development, while others are the\nfamiliar, persistent issues of the need for efficient, effective and timely\nassurance. Traditional assurance is seen as a brake on innovation and often\ncostly and time consuming. We therefore propose a modernized framework,\nAssurance 2.0, as an enabler that supports innovation and continuous\nincremental assurance. Perhaps unexpectedly, it does so by making assurance\nmore rigorous, with increased focus on the reasoning and evidence employed, and\nexplicit identification of defeaters and counterevidence.\n",
		"date": [
			"2020-04-22",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2004.10474",
		"pdf_url": "http://arxiv.org/pdf/2004.10474.pdf"
	},
	"265": {
		"title": "Applications of shapelet transform to time series classification of\n  earthquake, wind and wave data",
		"creator": [
			"Arul, Monica",
			"Kareem, Ahsan"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Signal Processing",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Autonomous detection of desired events from large databases using time series\nclassification is becoming increasingly important in civil engineering as a\nresult of continued long-term health monitoring of a large number of\nengineering structures encompassing buildings, bridges, towers, and offshore\nplatforms. In this context, this paper proposes the application of a relatively\nnew time series representation named \"Shapelet transform\", which is based on\nlocal similarity in the shape of the time series subsequences. In consideration\nof the individual attributes distinctive to time series signals in earthquake,\nwind and ocean engineering, the application of this transform yields a new\nshape-based feature representation. Combining this shape-based representation\nwith a standard machine learning algorithm, a truly \"white-box\" machine\nlearning model is proposed with understandable features and a transparent\nalgorithm. This model automates event detection without the intervention of\ndomain practitioners, yielding a practical event detection procedure. The\nefficacy of this proposed shapelet transform-based autonomous detection\nprocedure is demonstrated by examples, to identify known and unknown earthquake\nevents from continuously recorded ground-motion measurements, to detect pulses\nin the velocity time history of ground motions to distinguish between\nnear-field and far-field ground motions, to identify thunderstorms from\ncontinuous wind speed measurements, to detect large-amplitude wind-induced\nvibrations from the bridge monitoring data, and to identify plunging breaking\nwaves that have a significant impact on offshore structures.\n",
			"Comment: 24 pages, 14 figures. arXiv admin note: text overlap with\n  arXiv:1911.09086"
		],
		"date": "2020-04-22",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2004.11243",
			"Eng. Struct 228 (2021) 111564",
			"doi:10.1016/j.engstruct.2020.111564"
		],
		"pdf_url": "http://arxiv.org/pdf/2004.11243.pdf"
	},
	"266": {
		"title": "Leveraging Planar Regularities for Point Line Visual-Inertial Odometry",
		"creator": [
			"Li, Xin",
			"He, Yijia",
			"Lin, Jinlong",
			"Liu, Xiao"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Robotics"
		],
		"description": [
			"  With monocular Visual-Inertial Odometry (VIO) system, 3D point cloud and\ncamera motion can be estimated simultaneously. Because pure sparse 3D points\nprovide a structureless representation of the environment, generating 3D mesh\nfrom sparse points can further model the environment topology and produce dense\nmapping. To improve the accuracy of 3D mesh generation and localization, we\npropose a tightly-coupled monocular VIO system, PLP-VIO, which exploits point\nfeatures and line features as well as plane regularities. The co-planarity\nconstraints are used to leverage additional structure information for the more\naccurate estimation of 3D points and spatial lines in state estimator. To\ndetect plane and 3D mesh robustly, we combine both the line features with point\nfeatures in the detection method. The effectiveness of the proposed method is\nverified on both synthetic data and public datasets and is compared with other\nstate-of-the-art algorithms.\n",
			"Comment: Accepted to IROS 2020"
		],
		"date": [
			"2020-04-16",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2004.11969",
		"pdf_url": "http://arxiv.org/pdf/2004.11969.pdf"
	},
	"267": {
		"title": "Filter Grafting for Deep Neural Networks: Reason, Method, and\n  Cultivation",
		"creator": [
			"Cheng, Hao",
			"Meng, Fanxu",
			"Li, Ke",
			"Gao, Yuting",
			"Lu, Guangming",
			"Sun, Xing",
			"Ji, Rongrong"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Filter is the key component in modern convolutional neural networks (CNNs).\nHowever, since CNNs are usually over-parameterized, a pre-trained network\nalways contain some invalid (unimportant) filters. These filters have\nrelatively small $l_{1}$ norm and contribute little to the output\n(\\textbf{Reason}). While filter pruning removes these invalid filters for\nefficiency consideration, we tend to reactivate them to improve the\nrepresentation capability of CNNs. In this paper, we introduce filter grafting\n(\\textbf{Method}) to achieve this goal. The activation is processed by grafting\nexternal information (weights) into invalid filters. To better perform the\ngrafting, we develop a novel criterion to measure the information of filters\nand an adaptive weighting strategy to balance the grafted information among\nnetworks. After the grafting operation, the network has fewer invalid filters\ncompared with its initial state, enpowering the model with more representation\ncapacity. Meanwhile, since grafting is operated reciprocally on all networks\ninvolved, we find that grafting may lose the information of valid filters when\nimproving invalid filters. To gain a universal improvement on both valid and\ninvalid filters, we compensate grafting with distillation\n(\\textbf{Cultivation}) to overcome the drawback of grafting . Extensive\nexperiments are performed on the classification and recognition tasks to show\nthe superiority of our method. Code is available at\n\\textcolor{black}{\\emph{https://github.com/fxmeng/filter-grafting}}.\n",
			"Comment: arXiv admin note: substantial text overlap with arXiv:2001.05868"
		],
		"date": [
			"2020-04-26",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2004.12311",
		"pdf_url": "http://arxiv.org/pdf/2004.12311.pdf"
	},
	"268": {
		"title": "Provably-secure symmetric private information retrieval with quantum\n  cryptography",
		"creator": [
			"Kon, Wen Yu",
			"Lim, Charles Ci Wen"
		],
		"subject": [
			"Quantum Physics",
			"Computer Science - Cryptography and Security",
			"Computer Science - Information Retrieval"
		],
		"description": [
			"  Private information retrieval (PIR) is a database query protocol that\nprovides user privacy, in that the user can learn a particular entry of the\ndatabase of his interest but his query would be hidden from the data centre.\nSymmetric private information retrieval (SPIR) takes PIR further by\nadditionally offering database privacy, where the user cannot learn any\nadditional entries of the database. Unconditionally secure SPIR solutions with\nmultiple databases are known classically, but are unrealistic because they\nrequire long shared secret keys between the parties for secure communication\nand shared randomness in the protocol. Here, we propose using quantum key\ndistribution (QKD) instead for a practical implementation, which can realise\nboth the secure communication and shared randomness requirements. We prove that\nQKD maintains the security of the SPIR protocol and that it is also secure\nagainst any external eavesdropper. We also show how such a classical-quantum\nsystem could be implemented practically, using the example of a two-database\nSPIR protocol with keys generated by measurement device-independent QKD.\nThrough key rate calculations, we show that such an implementation is feasible\nat the metropolitan level with current QKD technology.\n",
			"Comment: 19 pages"
		],
		"date": [
			"2020-04-28",
			"2021-01-17"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2004.13921",
			"Entropy 23, 54 (2021)",
			"doi:10.3390/e23010054"
		],
		"pdf_url": "http://arxiv.org/pdf/2004.13921.pdf"
	},
	"269": {
		"title": "Coded Computing and Cooperative Transmission for Wireless Distributed\n  Matrix Multiplication",
		"creator": [
			"Li, Kuikui",
			"Tao, Meixia",
			"Zhang, Jingjing",
			"Simeone, Osvaldo"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  Consider a multi-cell mobile edge computing network, in which each user\nwishes to compute the product of a user-generated data matrix with a\nnetwork-stored matrix. This is done through task offloading by means of input\nuploading, distributed computing at edge nodes (ENs), and output downloading.\nTask offloading may suffer long delay since servers at some ENs may be\nstraggling due to random computation time, and wireless channels may experience\nsevere fading and interference. This paper aims to investigate the interplay\namong upload, computation, and download latencies during the offloading process\nin the high signal-to-noise ratio regime from an information-theoretic\nperspective. A policy based on cascaded coded computing and on coordinated and\ncooperative interference management in uplink and downlink is proposed and\nproved to be approximately optimal for a sufficiently large upload time. By\ninvesting more time in uplink transmission, the policy creates data redundancy\nat the ENs, which can reduce the computation time, by enabling the use of coded\ncomputing, as well as the download time via transmitter cooperation. Moreover,\nthe policy allows computation time to be traded for download time. Numerical\nexamples demonstrate that the proposed policy can improve over existing schemes\nby significantly reducing the end-to-end execution time.\n",
			"Comment: To appear in IEEE Transactions on Communications"
		],
		"date": [
			"2020-04-29",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2004.14170",
		"pdf_url": "http://arxiv.org/pdf/2004.14170.pdf"
	},
	"270": {
		"title": "Do Neural Ranking Models Intensify Gender Bias?",
		"creator": [
			"Rekabsaz, Navid",
			"Schedl, Markus"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Concerns regarding the footprint of societal biases in information retrieval\n(IR) systems have been raised in several previous studies. In this work, we\nexamine various recent IR models from the perspective of the degree of gender\nbias in their retrieval results. To this end, we first provide a bias\nmeasurement framework which includes two metrics to quantify the degree of the\nunbalanced presence of gender-related concepts in a given IR model's ranking\nlist. To examine IR models by means of the framework, we create a dataset of\nnon-gendered queries, selected by human annotators. Applying these queries to\nthe MS MARCO Passage retrieval collection, we then measure the gender bias of a\nBM25 model and several recent neural ranking models. The results show that\nwhile all models are strongly biased toward male, the neural models, and in\nparticular the ones based on contextualized embedding models, significantly\nintensify gender bias. Our experiments also show an overall increase in the\ngender bias of neural models when they exploit transfer learning, namely when\nthey use (already biased) pre-trained embeddings.\n",
			"Comment: In Proceedings of ACM SIGIR 2020"
		],
		"date": [
			"2020-05-01",
			"2020-06-15"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2005.00372",
			"doi:10.1145/3397271.3401280"
		],
		"pdf_url": "http://arxiv.org/pdf/2005.00372.pdf"
	},
	"271": {
		"title": "Neural Computing for Online Arabic Handwriting Character Recognition\n  using Hard Stroke Features Mining",
		"creator": "Rehman, Amjad",
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Computation and Language"
		],
		"description": [
			"  Online Arabic cursive character recognition is still a big challenge due to\nthe existing complexities including Arabic cursive script styles, writing\nspeed, writer mood and so forth. Due to these unavoidable constraints, the\naccuracy of online Arabic character's recognition is still low and retain space\nfor improvement. In this research, an enhanced method of detecting the desired\ncritical points from vertical and horizontal direction-length of handwriting\nstroke features of online Arabic script recognition is proposed. Each extracted\nstroke feature divides every isolated character into some meaningful pattern\nknown as tokens. A minimum feature set is extracted from these tokens for\nclassification of characters using a multilayer perceptron with a\nback-propagation learning algorithm and modified sigmoid function-based\nactivation function. In this work, two milestones are achieved; firstly, attain\na fixed number of tokens, secondly, minimize the number of the most repetitive\ntokens. For experiments, handwritten Arabic characters are selected from the\nOHASD benchmark dataset to test and evaluate the proposed method. The proposed\nmethod achieves an average accuracy of 98.6% comparable in state of art\ncharacter recognition techniques.\n",
			"Comment: 16 pages"
		],
		"date": [
			"2020-05-02",
			"2021-01-15"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2005.02171",
			"IJICIC 2021"
		],
		"pdf_url": "http://arxiv.org/pdf/2005.02171.pdf"
	},
	"272": {
		"title": "Visualizing Deep Learning-based Radio Modulation Classifier",
		"creator": [
			"Huang, Liang",
			"Zhang, You",
			"Pan, Weijian",
			"Chen, Jinyin",
			"Qian, Li Ping",
			"Wu, Yuan"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": "  Deep learning has recently been successfully applied in automatic modulation\nclassification by extracting and classifying radio features in an end-to-end\nway. However, deep learning-based radio modulation classifiers are lack of\ninterpretability, and there is little explanation or visibility into what kinds\nof radio features are extracted and chosen for classification. In this paper,\nwe visualize different deep learning-based radio modulation classifiers by\nintroducing a class activation vector. Specifically, both convolutional neural\nnetworks (CNN) based classifier and long short-term memory (LSTM) based\nclassifier are separately studied, and their extracted radio features are\nvisualized. Extensive numerical results show both the CNN-based classifier and\nLSTM-based classifier extract similar radio features relating to modulation\nreference points. In particular, for the LSTM-based classifier, its obtained\nradio features are similar to the knowledge of human experts. Our numerical\nresults indicate the radio features extracted by deep learning-based\nclassifiers greatly depend on the contents carried by radio signals, and a\nshort radio sample may lead to misclassification.\n",
		"date": [
			"2020-05-03",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2005.02175",
		"pdf_url": "http://arxiv.org/pdf/2005.02175.pdf"
	},
	"273": {
		"title": "Precoder Design and Statistical Power Allocation for MIMO-NOMA via\n  User-Assisted Simultaneous Diagonalization",
		"creator": [
			"Krishnamoorthy, Aravindh",
			"Ding, Zhiguo",
			"Schober, Robert"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  In this paper, we investigate the downlink precoder design for two-user\npower-domain multiple-input multiple-output (MIMO) non-orthogonal multiple\naccess (NOMA). We propose a novel user-assisted (UA) simultaneous\ndiagonalization (SD) based MIMO-NOMA scheme that achieves SD of the MIMO\nchannels of both users through a combination of precoder design and\nlow-complexity self-interference cancellation at the users, thereby\nconsiderably lowering the overall decoding complexity compared to joint\ndecoding. The achievable ergodic user rates of the proposed scheme are analyzed\nfor Rayleigh fading channels based on a finite-size random matrix theory\nframework, which is further exploited to develop a statistical power allocation\nalgorithm. Simulation and numerical results show that the proposed UA-SD\nMIMO-NOMA scheme significantly outperforms orthogonal multiple access and a\nbenchmark precoder design performing SD via generalized singular value\ndecomposition in terms of the achievable ergodic rate region for most user\nrates. The ergodic rate region is further enhanced by a hybrid scheme which\nperforms time sharing between the proposed UA-SD MIMO-NOMA scheme and\nsingle-user MIMO.\n",
			"Comment: Accepted by the IEEE Transactions on Communications, see DOI. 32\n  pages, 8 figures, for associated code, see\n  https://gitlab.com/aravindh.krishnamoorthy/mimo-noma"
		],
		"date": [
			"2020-05-05",
			"2020-11-13"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2005.02308",
			"IEEE Transactions on Communications, 2020",
			"doi:10.1109/TCOMM.2020.3036453"
		],
		"pdf_url": "http://arxiv.org/pdf/2005.02308.pdf"
	},
	"274": {
		"title": "QuickSync: A Quickly Synchronizing PoS-Based Blockchain Protocol",
		"creator": [
			"Siddiqui, Shoeb",
			"Gujar, Sujit"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Computer Science and Game Theory"
		],
		"description": "  To implement a blockchain, we need a blockchain protocol for all the nodes to\nfollow. To design a blockchain protocol, we need a block publisher selection\nmechanism and a chain selection rule. In Proof-of-Stake (PoS) based blockchain\nprotocols, block publisher selection mechanism selects the node to publish the\nnext block based on the relative stake held by the node. However, PoS\nprotocols, such as Ouroboros v1, may face vulnerability to fully adaptive\ncorruptions.\n  In this paper, we propose a novel PoS-based blockchain protocol, QuickSync,\nto achieve security against fully adaptive corruptions while improving on\nperformance. We propose a metric called block power, a value defined for each\nblock, derived from the output of the verifiable random function based on the\ndigital signature of the block publisher. With this metric, we compute chain\npower, the sum of block powers of all the blocks comprising the chain, for all\nthe valid chains. These metrics are a function of the block publisher's stake\nto enable the PoS aspect of the protocol. The chain selection rule selects the\nchain with the highest chain power as the one to extend. This chain selection\nrule hence determines the selected block publisher of the previous block. When\nwe use metrics to define the chain selection rule, it may lead to\nvulnerabilities against Sybil attacks. QuickSync uses a Sybil attack resistant\nfunction implemented using histogram matching. We prove that QuickSync\nsatisfies common prefix, chain growth, and chain quality properties and hence\nit is secure. We also show that it is resilient to different types of\nadversarial attack strategies. Our analysis demonstrates that QuickSync\nperforms better than Bitcoin by an order of magnitude on both transactions per\nsecond and time to finality, and better than Ouroboros v1 by a factor of three\non time to finality.\n",
		"date": [
			"2020-05-07",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2005.03564",
		"pdf_url": "http://arxiv.org/pdf/2005.03564.pdf"
	},
	"275": {
		"title": "Scalable First-Order Methods for Robust MDPs",
		"creator": [
			"Grand-Clément, Julien",
			"Kroer, Christian"
		],
		"subject": [
			"Mathematics - Optimization and Control",
			"Computer Science - Machine Learning"
		],
		"description": "  Robust Markov Decision Processes (MDPs) are a powerful framework for modeling\nsequential decision-making problems with model uncertainty. This paper proposes\nthe first first-order framework for solving robust MDPs. Our algorithm\ninterleaves primal-dual first-order updates with approximate Value Iteration\nupdates. By carefully controlling the tradeoff between the accuracy and cost of\nValue Iteration updates, we achieve an ergodic convergence rate of $O \\left(\nA^{2} S^{3}\\log(S)\\log(\\epsilon^{-1}) \\epsilon^{-1} \\right)$ for the best\nchoice of parameters on ellipsoidal and Kullback-Leibler $s$-rectangular\nuncertainty sets, where $S$ and $A$ is the number of states and actions,\nrespectively. Our dependence on the number of states and actions is\nsignificantly better (by a factor of $O(A^{1.5}S^{1.5})$) than that of pure\nValue Iteration algorithms. In numerical experiments on ellipsoidal uncertainty\nsets we show that our algorithm is significantly more scalable than\nstate-of-the-art approaches. Our framework is also the first one to solve\nrobust MDPs with $s$-rectangular KL uncertainty sets.\n",
		"date": [
			"2020-05-11",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2005.05434",
		"pdf_url": "http://arxiv.org/pdf/2005.05434.pdf"
	},
	"276": {
		"title": "Latent Fingerprint Registration via Matching Densely Sampled Points",
		"creator": [
			"Gu, Shan",
			"Feng, Jianjiang",
			"Lu, Jiwen",
			"Zhou, Jie"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Latent fingerprint matching is a very important but unsolved problem. As a\nkey step of fingerprint matching, fingerprint registration has a great impact\non the recognition performance. Existing latent fingerprint registration\napproaches are mainly based on establishing correspondences between minutiae,\nand hence will certainly fail when there are no sufficient number of extracted\nminutiae due to small fingerprint area or poor image quality. Minutiae\nextraction has become the bottleneck of latent fingerprint registration. In\nthis paper, we propose a non-minutia latent fingerprint registration method\nwhich estimates the spatial transformation between a pair of fingerprints\nthrough a dense fingerprint patch alignment and matching procedure. Given a\npair of fingerprints to match, we bypass the minutiae extraction step and take\nuniformly sampled points as key points. Then the proposed patch alignment and\nmatching algorithm compares all pairs of sampling points and produces their\nsimilarities along with alignment parameters. Finally, a set of consistent\ncorrespondences are found by spectral clustering. Extensive experiments on\nNIST27 database and MOLF database show that the proposed method achieves the\nstate-of-the-art registration performance, especially under challenging\nconditions.\n",
		"date": [
			"2020-05-12",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2005.05878",
		"pdf_url": "http://arxiv.org/pdf/2005.05878.pdf"
	},
	"277": {
		"title": "Input-Dynamic Distributed Algorithms for Communication Networks",
		"creator": [
			"Foerster, Klaus-Tycho",
			"Korhonen, Janne H.",
			"Paz, Ami",
			"Rybicki, Joel",
			"Schmid, Stefan"
		],
		"subject": "Computer Science - Distributed, Parallel, and Cluster Computing",
		"description": "  Consider a distributed task where the communication network is fixed but the\nlocal inputs given to the nodes of the distributed system may change over time.\nIn this work, we explore the following question: if some of the local inputs\nchange, can an existing solution be updated efficiently, in a dynamic and\ndistributed manner?\n  To address this question, we define the batch dynamic CONGEST model in which\nwe are given a bandwidth-limited communication network and a dynamic edge\nlabelling defines the problem input. The task is to maintain a solution to a\ngraph problem on the labeled graph under batch changes. We investigate, when a\nbatch of $\\alpha$ edge label changes arrive,\n  -- how much time as a function of $\\alpha$ we need to update an existing\nsolution, and\n  -- how much information the nodes have to keep in local memory between\nbatches in order to update the solution quickly.\n  Our work lays the foundations for the theory of input-dynamic distributed\nnetwork algorithms. We give a general picture of the complexity landscape in\nthis model, design both universal algorithms and algorithms for concrete\nproblems, and present a general framework for lower bounds. In particular, we\nderive non-trivial upper bounds for two selected, contrasting problems:\nmaintaining a minimum spanning tree and detecting cliques.\n",
		"date": [
			"2020-05-15",
			"2021-01-19"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2005.07637",
			"doi:10.1145/3447384"
		],
		"pdf_url": "http://arxiv.org/pdf/2005.07637.pdf"
	},
	"278": {
		"title": "Pre-print: Radio Identity Verification-based IoT Security Using RF-DNA\n  Fingerprints and SVM",
		"creator": [
			"Reising, Donald",
			"Cancelleri, Joseph",
			"Loveless, T. Daniel",
			"Kandah, Farah",
			"Skjellum, Anthony"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Signal Processing",
			"Computer Science - Cryptography and Security",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  It is estimated that the number of IoT devices will reach 75 billion in the\nnext five years. Most of those currently, and to be deployed, lack sufficient\nsecurity to protect themselves and their networks from attack by malicious IoT\ndevices that masquerade as authorized devices to circumvent digital\nauthentication approaches. This work presents a PHY layer IoT authentication\napproach capable of addressing this critical security need through the use of\nfeature reduced Radio Frequency-Distinct Native Attributes (RF-DNA)\nfingerprints and Support Vector Machines (SVM). This work successfully\ndemonstrates 100%: (i) authorized ID verification across three trials of six\nrandomly chosen radios at signal-to-noise ratios greater than or equal to 6 dB,\nand (ii) rejection of all rogue radio ID spoofing attacks at signal-to-noise\nratios greater than or equal to 3 dB using RF-DNA fingerprints whose features\nare selected using the Relief-F algorithm.\n",
			"Comment: 14 pages, 23 figures and sub-figures, Submitted to the IEEE Internet\n  of Things Journal on May 19, 2020"
		],
		"date": "2020-05-19",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2005.09503",
			"IEEE Internet of Things Journal 2021",
			"doi:10.1109/JIOT.2020.3045305"
		],
		"pdf_url": "http://arxiv.org/pdf/2005.09503.pdf"
	},
	"279": {
		"title": "List Decodable Mean Estimation in Nearly Linear Time",
		"creator": [
			"Cherapanamjeri, Yeshwanth",
			"Mohanty, Sidhanth",
			"Yau, Morris"
		],
		"subject": "Computer Science - Data Structures and Algorithms",
		"description": [
			"  Learning from data in the presence of outliers is a fundamental problem in\nstatistics. Until recently, no computationally efficient algorithms were known\nto compute the mean of a high dimensional distribution under natural\nassumptions in the presence of even a small fraction of outliers. In this\npaper, we consider robust statistics in the presence of overwhelming outliers\nwhere the majority of the dataset is introduced adversarially. With only an\n$\\alpha < 1/2$ fraction of \"inliers\" (clean data) the mean of a distribution is\nunidentifiable. However, in their influential work, [CSV17] introduces a\npolynomial time algorithm recovering the mean of distributions with bounded\ncovariance by outputting a succinct list of $O(1/\\alpha)$ candidate solutions,\none of which is guaranteed to be close to the true distributional mean; a\ndirect analog of 'List Decoding' in the theory of error correcting codes. In\nthis work, we develop an algorithm for list decodable mean estimation in the\nsame setting achieving up to constants the information theoretically optimal\nrecovery, optimal sample complexity, and in nearly linear time up to\npolylogarithmic factors in dimension. Our conceptual innovation is to design a\ndescent style algorithm on a nonconvex landscape, iteratively removing minima\nto generate a succinct list of solutions. Our runtime bottleneck is a\nsaddle-point optimization for which we design custom primal dual solvers for\ngeneralized packing and covering SDP's under Ky-Fan norms, which may be of\nindependent interest.\n",
			"Comment: Minor corrections in Appendix A.3 and Algorithm 2"
		],
		"date": [
			"2020-05-19",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2005.09796",
		"pdf_url": "http://arxiv.org/pdf/2005.09796.pdf"
	},
	"280": {
		"title": "Large-scale comparison of bibliographic data sources: Scopus, Web of\n  Science, Dimensions, Crossref, and Microsoft Academic",
		"creator": [
			"Visser, Martijn",
			"van Eck, Nees Jan",
			"Waltman, Ludo"
		],
		"subject": "Computer Science - Digital Libraries",
		"description": "  We present a large-scale comparison of five multidisciplinary bibliographic\ndata sources: Scopus, Web of Science, Dimensions, Crossref, and Microsoft\nAcademic. The comparison considers scientific documents from the period\n2008-2017 covered by these data sources. Scopus is compared in a pairwise\nmanner with each of the other data sources. We first analyze differences\nbetween the data sources in the coverage of documents, focusing for instance on\ndifferences over time, differences per document type, and differences per\ndiscipline. We then study differences in the completeness and accuracy of\ncitation links. Based on our analysis, we discuss strengths and weaknesses of\nthe different data sources. We emphasize the importance of combining a\ncomprehensive coverage of the scientific literature with a flexible set of\nfilters for making selections of the literature.\n",
		"date": [
			"2020-05-21",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2005.10732",
		"pdf_url": "http://arxiv.org/pdf/2005.10732.pdf"
	},
	"281": {
		"title": "Memory-Aware Denial-of-Service Attacks on Shared Cache in Multicore\n  Real-Time Systems",
		"creator": [
			"Bechtel, Michael",
			"Yun, Heechul"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Hardware Architecture"
		],
		"description": "  In this paper, we identify that memory performance plays a crucial role in\nthe feasibility and effectiveness for performing denial-of-service attacks on\nshared cache. Based on this insight, we introduce new cache DoS attacks, which\ncan be mounted from the user-space and can cause extreme worst-case execution\ntime (WCET) impacts to cross-core victims -- even if the shared cache is\npartitioned -- by taking advantage of the platform's memory address mapping\ninformation and HugePage support. We deploy these enhanced attacks on two\npopular embedded out-of-order multicore platforms using both synthetic and\nreal-world benchmarks. The proposed DoS attacks achieve up to 111X WCET\nincreases on the tested platforms.\n",
		"date": [
			"2020-05-21",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2005.10864",
		"pdf_url": "http://arxiv.org/pdf/2005.10864.pdf"
	},
	"282": {
		"title": "Revisiting Membership Inference Under Realistic Assumptions",
		"creator": [
			"Jayaraman, Bargav",
			"Wang, Lingxiao",
			"Knipmeyer, Katherine",
			"Gu, Quanquan",
			"Evans, David"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  We study membership inference in settings where some of the assumptions\ntypically used in previous research are relaxed. First, we consider skewed\npriors, to cover cases such as when only a small fraction of the candidate pool\ntargeted by the adversary are actually members and develop a PPV-based metric\nsuitable for this setting. This setting is more realistic than the balanced\nprior setting typically considered by researchers. Second, we consider\nadversaries that select inference thresholds according to their attack goals\nand develop a threshold selection procedure that improves inference attacks.\nSince previous inference attacks fail in imbalanced prior setting, we develop a\nnew inference attack based on the intuition that inputs corresponding to\ntraining set members will be near a local minimum in the loss function, and\nshow that an attack that combines this with thresholds on the per-instance loss\ncan achieve high PPV even in settings where other attacks appear to be\nineffective. Code for our experiments can be found here:\nhttps://github.com/bargavj/EvaluatingDPML.\n",
		"date": [
			"2020-05-21",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2005.10881",
		"pdf_url": "http://arxiv.org/pdf/2005.10881.pdf"
	},
	"283": {
		"title": "Intent Mining from past conversations for conversational agent",
		"creator": [
			"Chatterjee, Ajay",
			"Sengupta, Shubhashis"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Conversational systems are of primary interest in the AI community. Chatbots\nare increasingly being deployed to provide round-the-clock support and to\nincrease customer engagement. Many of the commercial bot building frameworks\nfollow a standard approach that requires one to build and train an intent model\nto recognize a user input. Intent models are trained in a supervised setting\nwith a collection of textual utterance and intent label pairs. Gathering a\nsubstantial and wide coverage of training data for different intent is a\nbottleneck in the bot building process. Moreover, the cost of labeling a\nhundred to thousands of conversations with intent is a time consuming and\nlaborious job. In this paper, we present an intent discovery framework that\ninvolves 4 primary steps: Extraction of textual utterances from a conversation\nusing a pre-trained domain agnostic Dialog Act Classifier (Data Extraction),\nautomatic clustering of similar user utterances (Clustering), manual annotation\nof clusters with an intent label (Labeling) and propagation of intent labels to\nthe utterances from the previous step, which are not mapped to any cluster\n(Label Propagation); to generate intent training data from raw conversations.\nWe have introduced a novel density-based clustering algorithm ITER-DBSCAN for\nunbalanced data clustering. Subject Matter Expert (Annotators with domain\nexpertise) manually looks into the clustered user utterances and provides an\nintent label for discovery. We conducted user studies to validate the\neffectiveness of the trained intent model generated in terms of coverage of\nintents, accuracy and time saving concerning manual annotation. Although the\nsystem is developed for building an intent model for the conversational system,\nthis framework can also be used for a short text clustering or as a labeling\nframework.\n",
			"Comment: 8 pages, 2 figures"
		],
		"date": [
			"2020-05-22",
			"2021-01-18"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2005.11014",
			"Proceedings of the 28th International Conference on Computational\n  Linguistics, 2020"
		],
		"pdf_url": "http://arxiv.org/pdf/2005.11014.pdf"
	},
	"284": {
		"title": "Evolution of Cooperative Hunting in Artificial Multi-layered Societies",
		"creator": [
			"Bao, Honglin",
			"Banzhaf, Wolfgang"
		],
		"subject": [
			"Computer Science - Computers and Society",
			"Computer Science - Neural and Evolutionary Computing",
			"Nonlinear Sciences - Adaptation and Self-Organizing Systems",
			"Physics - Physics and Society"
		],
		"description": [
			"  The complexity of cooperative behavior is a crucial issue in multiagent-based\nsocial simulation. In this paper, an agent-based model is proposed to study the\nevolution of cooperative hunting behaviors in an artificial society. In this\nmodel, the standard hunting game of stag is modified into a new situation with\nsocial hierarchy and penalty. The agent society is divided into multiple layers\nwith supervisors and subordinates. In each layer, the society is divided into\nmultiple clusters. A supervisor controls all subordinates in a cluster locally.\nSubordinates interact with rivals through reinforcement learning, and report\nlearning information to their corresponding supervisor. Supervisors process the\nreported information through repeated affiliation-based aggregation and by\ninformation exchange with other supervisors, then pass down the reprocessed\ninformation to subordinates as guidance. Subordinates, in turn, update learning\ninformation according to guidance, following the \"win stay, lose shift\"\nstrategy. Experiments are carried out to test the evolution of cooperation in\nthis closed-loop semi-supervised emergent system with different parameters. We\nalso study the variations and phase transitions in this game setting.\n",
			"Comment: Conflict of interest with our previous collaborators. Thus, we\n  retract the preprint. We retract all earlier versions of the paper as well,\n  but due to the arXiv policy, previous versions cannot be removed. We ask that\n  you ignore the abstract, earlier versions and do not refer to or distribute\n  them further, and we apologize for any inconvenience caused. Thanks"
		],
		"date": [
			"2020-05-23",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2005.11580",
		"pdf_url": "http://arxiv.org/pdf/2005.11580.pdf"
	},
	"285": {
		"title": "Sentiment Analysis: Automatically Detecting Valence, Emotions, and Other\n  Affectual States from Text",
		"creator": "Mohammad, Saif M.",
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  Recent advances in machine learning have led to computer systems that are\nhuman-like in behaviour. Sentiment analysis, the automatic determination of\nemotions in text, is allowing us to capitalize on substantial previously\nunattainable opportunities in commerce, public health, government policy,\nsocial sciences, and art. Further, analysis of emotions in text, from news to\nsocial media posts, is improving our understanding of not just how people\nconvey emotions through language but also how emotions shape our behaviour.\nThis article presents a sweeping overview of sentiment analysis research that\nincludes: the origins of the field, the rich landscape of tasks, challenges, a\nsurvey of the methods and resources used, and applications. We also discuss\ndiscuss how, without careful fore-thought, sentiment analysis has the potential\nfor harmful outcomes. We outline the latest lines of research in pursuit of\nfairness in sentiment analysis.\n",
			"Comment: This is the author's manuscript of what is slated to appear in the\n  Second Edition of Emotion Measurement, 2021"
		],
		"date": [
			"2020-05-24",
			"2021-01-13"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2005.11882",
			"Second Edition of Emotion Measurement, 2021"
		],
		"pdf_url": "http://arxiv.org/pdf/2005.11882.pdf"
	},
	"286": {
		"title": "On the Impossibility of Global Convergence in Multi-Loss Optimization",
		"creator": "Letcher, Alistair",
		"subject": [
			"Mathematics - Optimization and Control",
			"Computer Science - Computer Science and Game Theory",
			"Computer Science - Machine Learning",
			"Computer Science - Multiagent Systems"
		],
		"description": [
			"  Under mild regularity conditions, gradient-based methods converge globally to\na critical point in the single-loss setting. This is known to break down for\nvanilla gradient descent when moving to multi-loss optimization, but can we\nhope to build some algorithm with global guarantees? We negatively resolve this\nopen problem by proving that desirable convergence properties cannot\nsimultaneously hold for any algorithm. Our result has more to do with the\nexistence of games with no satisfactory outcomes, than with algorithms per se.\nMore explicitly we construct a two-player game with zero-sum interactions whose\nlosses are both coercive and analytic, but whose only simultaneous critical\npoint is a strict maximum. Any 'reasonable' algorithm, defined to avoid strict\nmaxima, will therefore fail to converge. This is fundamentally different from\nsingle losses, where coercivity implies existence of a global minimum.\nMoreover, we prove that a wide range of existing gradient-based methods almost\nsurely have bounded but non-convergent iterates in a constructed zero-sum game\nfor suitably small learning rates. It nonetheless remains an open question\nwhether such behavior can arise in high-dimensional games of interest to ML\npractitioners, such as GANs or multi-agent RL.\n",
			"Comment: 26 pages, 3 figures"
		],
		"date": [
			"2020-05-26",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2005.12649",
		"pdf_url": "http://arxiv.org/pdf/2005.12649.pdf"
	},
	"287": {
		"title": "Algebraic Methods for Tensor Data",
		"creator": [
			"Tokcan, Neriman",
			"Gryak, Jonathan",
			"Najarian, Kayvan",
			"Derksen, Harm"
		],
		"subject": [
			"Mathematics - Representation Theory",
			"Mathematics - Combinatorics",
			"Mathematics - Numerical Analysis",
			"14-XX, 15A72, 15A69, 62-07, 22E45, 20G05, 5-XX, 90-XX"
		],
		"description": "  We develop algebraic methods for computations with tensor data. We give 3\napplications: extracting features that are invariant under the orthogonal\nsymmetries in each of the modes, approximation of the tensor spectral norm, and\namplification of low rank tensor structure. We introduce colored Brauer\ndiagrams, which are used for algebraic computations and in analyzing their\ncomputational complexity. We present numerical experiments whose results show\nthat the performance of the alternating least square algorithm for the low rank\napproximation of tensors can be improved using tensor amplification.\n",
		"date": "2020-05-25",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2005.12988",
		"pdf_url": "http://arxiv.org/pdf/2005.12988.pdf"
	},
	"288": {
		"title": "Uncertainty-aware Three-phase Optimal Power Flow based on Data-driven\n  Convexification",
		"creator": "Li, Qifeng",
		"subject": [
			"Mathematics - Optimization and Control",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": [
			"  This paper presents a novel optimization framework of formulating the\nthree-phase optimal power flow that involves uncertainty. The proposed\nuncertainty-aware optimization (UaO) framework is: 1) a deterministic framework\nthat is less complex than the existing optimization frameworks involving\nuncertainty, and 2) convex such that it admits polynomial-time algorithms and\nmature distributed optimization methods. To construct this UaO framework, a\nmethodology of learning-aided uncertainty-aware modeling, with prediction\nerrors of stochastic variables as the measurement of uncertainty, and a theory\nof data-driven convexification are proposed. Theoretically, the UaO framework\nis applicable for modeling general optimization problems under uncertainty.\n",
			"Comment: Accepted for pubication in the IEEE Transactions on Power Systems"
		],
		"date": [
			"2020-05-26",
			"2021-01-19"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2005.13075",
			"doi:10.1109/TPWRS.2021.3050926"
		],
		"pdf_url": "http://arxiv.org/pdf/2005.13075.pdf"
	},
	"289": {
		"title": "How to Retrain Recommender System? A Sequential Meta-Learning Method",
		"creator": [
			"Zhang, Yang",
			"Feng, Fuli",
			"Wang, Chenxu",
			"He, Xiangnan",
			"Wang, Meng",
			"Li, Yan",
			"Zhang, Yongdong"
		],
		"subject": "Computer Science - Information Retrieval",
		"description": [
			"  Practical recommender systems need be periodically retrained to refresh the\nmodel with new interaction data. To pursue high model fidelity, it is usually\ndesirable to retrain the model on both historical and new data, since it can\naccount for both long-term and short-term user preference. However, a full\nmodel retraining could be very time-consuming and memory-costly, especially\nwhen the scale of historical data is large. In this work, we study the model\nretraining mechanism for recommender systems, a topic of high practical values\nbut has been relatively little explored in the research community.\n  Our first belief is that retraining the model on historical data is\nunnecessary, since the model has been trained on it before. Nevertheless,\nnormal training on new data only may easily cause overfitting and forgetting\nissues, since the new data is of a smaller scale and contains fewer information\non long-term user preference. To address this dilemma, we propose a new\ntraining method, aiming to abandon the historical data during retraining\nthrough learning to transfer the past training experience. Specifically, we\ndesign a neural network-based transfer component, which transforms the old\nmodel to a new model that is tailored for future recommendations. To learn the\ntransfer component well, we optimize the \"future performance\" -- i.e., the\nrecommendation accuracy evaluated in the next time period. Our Sequential\nMeta-Learning(SML) method offers a general training paradigm that is applicable\nto any differentiable model. We demonstrate SML on matrix factorization and\nconduct experiments on two real-world datasets. Empirical results show that SML\nnot only achieves significant speed-up, but also outperforms the full model\nretraining in recommendation accuracy, validating the effectiveness of our\nproposals. We release our codes at: https://github.com/zyang1580/SML.\n",
			"Comment: Appear in SIGIR 2020"
		],
		"date": "2020-05-27",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2005.13258",
			"doi:10.1145/3397271.3401167"
		],
		"pdf_url": "http://arxiv.org/pdf/2005.13258.pdf"
	},
	"290": {
		"title": "Optimal Anticodes, Diameter Perfect Codes, Chains and Weights",
		"creator": [
			"Panek, Luciano",
			"Panek, Nayene Michele Paião"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  Let $P$ be a partial order on $[n] = \\{1,2,\\ldots,n\\}$, $\\mathbb{F}_{q}^n$ be\nthe linear space of $n$-tuples over a finite field $\\mathbb{F}_{q}$ and $w$ be\na weight on $\\mathbb{F}_{q}$. In this paper, we consider metrics on\n$\\mathbb{F}_{q}^n$ induced by chain orders $P$ over $[n]$ and weights $w$ over\n$\\mathbb{F}_q$, and we determine the cardinality of all optimal anticodes and\ncompletely classify them. Moreover, we determine all diameter perfect codes for\na set of relevant instances on the aforementioned metric spaces.\n",
			"Comment: This work has been accepted for publication in the IEEE Transactions\n  on Information Theory. Copyright (c) 2021 IEEE. Personal use of this material\n  is permitted. However, permission to use this material for any other purposes\n  must be obtained from the IEEE by sending a request to\n  pubs-permissions@ieee.org"
		],
		"date": [
			"2020-05-27",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2005.13715",
		"pdf_url": "http://arxiv.org/pdf/2005.13715.pdf"
	},
	"291": {
		"title": "On Tilings of Asymmetric Limited-Magnitude Balls",
		"creator": [
			"Wei, Hengjia",
			"Schwartz, Moshe"
		],
		"subject": [
			"Mathematics - Combinatorics",
			"Computer Science - Information Theory"
		],
		"description": "  We study whether an asymmetric limited-magnitude ball may tile\n$\\mathbb{Z}^n$. This ball generalizes previously studied shapes: crosses,\nsemi-crosses, and quasi-crosses. Such tilings act as perfect error-correcting\ncodes in a channel which changes a transmitted integer vector in a bounded\nnumber of entries by limited-magnitude errors.\n  A construction of lattice tilings based on perfect codes in the Hamming\nmetric is given. Several non-existence results are proved, both for general\ntilings, and lattice tilings. A complete classification of lattice tilings for\ntwo certain cases is proved.\n",
		"date": [
			"2020-05-30",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.00198",
		"pdf_url": "http://arxiv.org/pdf/2006.00198.pdf"
	},
	"292": {
		"title": "Adaptive quadrature schemes for Bayesian inference via active learning",
		"creator": [
			"Llorente, F.",
			"Martino, L.",
			"Elvira, V.",
			"Delgado, D.",
			"López-Santiago, J."
		],
		"subject": [
			"Statistics - Computation",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Signal Processing",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Numerical integration and emulation are fundamental topics across scientific\nfields. We propose novel adaptive quadrature schemes based on an active\nlearning procedure. We consider an interpolative approach for building a\nsurrogate posterior density, combining it with Monte Carlo sampling methods and\nother quadrature rules. The nodes of the quadrature are sequentially chosen by\nmaximizing a suitable acquisition function, which takes into account the\ncurrent approximation of the posterior and the positions of the nodes. This\nmaximization does not require additional evaluations of the true posterior. We\nintroduce two specific schemes based on Gaussian and Nearest Neighbors (NN)\nbases. For the Gaussian case, we also provide a novel procedure for fitting the\nbandwidth parameter, in order to build a suitable emulator of a density\nfunction. With both techniques, we always obtain a positive estimation of the\nmarginal likelihood (a.k.a., Bayesian evidence). An equivalent importance\nsampling interpretation is also described, which allows the design of extended\nschemes. Several theoretical results are provided and discussed. Numerical\nresults show the advantage of the proposed approach, including a challenging\ninference problem in an astronomic dynamical model, with the goal of revealing\nthe number of planets orbiting a star.\n",
			"Comment: Keywords: Numerical integration; emulation; Monte Carlo methods;\n  Bayesian quadrature; experimental design; active learning"
		],
		"date": [
			"2020-05-31",
			"2021-01-19"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2006.00535",
			"IEEE Access 8 (2020) 208462-208483",
			"doi:10.1109/ACCESS.2020.3038333"
		],
		"pdf_url": "http://arxiv.org/pdf/2006.00535.pdf"
	},
	"293": {
		"title": "Locally Differentially Private (Contextual) Bandits Learning",
		"creator": [
			"Zheng, Kai",
			"Cai, Tianle",
			"Huang, Weiran",
			"Li, Zhenguo",
			"Wang, Liwei"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  We study locally differentially private (LDP) bandits learning in this paper.\nFirst, we propose simple black-box reduction frameworks that can solve a large\nfamily of context-free bandits learning problems with LDP guarantee. Based on\nour frameworks, we can improve previous best results for private bandits\nlearning with one-point feedback, such as private Bandits Convex Optimization,\nand obtain the first result for Bandits Convex Optimization (BCO) with\nmulti-point feedback under LDP. LDP guarantee and black-box nature make our\nframeworks more attractive in real applications compared with previous\nspecifically designed and relatively weaker differentially private (DP)\ncontext-free bandits algorithms. Further, we extend our $(\\varepsilon,\n\\delta)$-LDP algorithm to Generalized Linear Bandits, which enjoys a sub-linear\nregret $\\tilde{O}(T^{3/4}/\\varepsilon)$ and is conjectured to be nearly\noptimal. Note that given the existing $\\Omega(T)$ lower bound for DP contextual\nlinear bandits (Shariff & Sheffe, 2018), our result shows a fundamental\ndifference between LDP and DP contextual bandits learning.\n",
			"Comment: Accepted by NeurIPS 2020"
		],
		"date": [
			"2020-06-01",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.00701",
		"pdf_url": "http://arxiv.org/pdf/2006.00701.pdf"
	},
	"294": {
		"title": "Renewable Power Trades and Network Congestion Externalities",
		"creator": [
			"Aguiar, Nayara",
			"Chakraborty, Indraneel",
			"Gupta, Vijay"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Economics - General Economics",
			"Physics - Physics and Society"
		],
		"description": "  Integrating renewable energy production into the electricity grid is an\nimportant policy goal to address climate change. However, such an integration\nfaces economic and technological challenges. As power generation by renewable\nsources increases, power transmission patterns over the electric grid change.\nDue to physical laws, these new transmission patterns lead to non-intuitive\ngrid congestion externalities. We derive the conditions under which negative\nnetwork externalities due to power trades occur. Calibration using a stylized\nframework and data from Europe shows that each additional unit of power traded\nbetween northern and western Europe reduces transmission capacity for the\nsouthern and eastern regions by 27% per unit traded. Such externalities suggest\nthat new investments in the electric grid infrastructure cannot be made\npiecemeal. In our example, power infrastructure investment in northern and\nwestern Europe needs an accompanying investment in southern and eastern Europe\nas well. An economic challenge is regions facing externalities do not always\nhave the financial ability to invest in infrastructure. Power transit fares can\nhelp finance power infrastructure investment in regions facing network\ncongestion externalities. The resulting investment in the overall electricity\ngrid facilitates integration of renewable energy production.\n",
		"date": [
			"2020-05-28",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.00916",
		"pdf_url": "http://arxiv.org/pdf/2006.00916.pdf"
	},
	"295": {
		"title": "A Smooth Representation of Belief over SO(3) for Deep Rotation Learning\n  with Uncertainty",
		"creator": [
			"Peretroukhin, Valentin",
			"Giamou, Matthew",
			"Rosen, David M.",
			"Greene, W. Nicholas",
			"Roy, Nicholas",
			"Kelly, Jonathan"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Accurate rotation estimation is at the heart of robot perception tasks such\nas visual odometry and object pose estimation. Deep neural networks have\nprovided a new way to perform these tasks, and the choice of rotation\nrepresentation is an important part of network design. In this work, we present\na novel symmetric matrix representation of the 3D rotation group, SO(3), with\ntwo important properties that make it particularly suitable for learned models:\n(1) it satisfies a smoothness property that improves convergence and\ngeneralization when regressing large rotation targets, and (2) it encodes a\nsymmetric Bingham belief over the space of unit quaternions, permitting the\ntraining of uncertainty-aware models. We empirically validate the benefits of\nour formulation by training deep neural rotation regressors on two data\nmodalities. First, we use synthetic point-cloud data to show that our\nrepresentation leads to superior predictive accuracy over existing\nrepresentations for arbitrary rotation targets. Second, we use image data\ncollected onboard ground and aerial vehicles to demonstrate that our\nrepresentation is amenable to an effective out-of-distribution (OOD) rejection\ntechnique that significantly improves the robustness of rotation estimates to\nunseen environmental effects and corrupted input images, without requiring the\nuse of an explicit likelihood loss, stochastic sampling, or an auxiliary\nclassifier. This capability is key for safety-critical applications where\ndetecting novel inputs can prevent catastrophic failure of learned models.\n",
			"Comment: In Proceedings of Robotics: Science and Systems (RSS'20), Corvallis ,\n  Oregon, USA, Jul. 12-16, 2020"
		],
		"date": [
			"2020-06-01",
			"2021-01-17"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2006.01031",
			"doi:10.15607/RSS.2020.XVI.007"
		],
		"pdf_url": "http://arxiv.org/pdf/2006.01031.pdf"
	},
	"296": {
		"title": "Aligning Faithful Interpretations with their Social Attribution",
		"creator": [
			"Jacovi, Alon",
			"Goldberg, Yoav"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  We find that the requirement of model interpretations to be faithful is vague\nand incomplete. With interpretation by textual highlights as a case-study, we\npresent several failure cases. Borrowing concepts from social science, we\nidentify that the problem is a misalignment between the causal chain of\ndecisions (causal attribution) and the attribution of human behavior to the\ninterpretation (social attribution). We re-formulate faithfulness as an\naccurate attribution of causality to the model, and introduce the concept of\naligned faithfulness: faithful causal chains that are aligned with their\nexpected social behavior. The two steps of causal attribution and social\nattribution together complete the process of explaining behavior. With this\nformalization, we characterize various failures of misaligned faithful\nhighlight interpretations, and propose an alternative causal chain to remedy\nthe issues. Finally, we implement highlight explanations of the proposed causal\nformat using contrastive explanations.\n",
			"Comment: Accepted as a journal paper to TACL"
		],
		"date": [
			"2020-06-01",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.01067",
		"pdf_url": "http://arxiv.org/pdf/2006.01067.pdf"
	},
	"297": {
		"title": "Outlier-Resilient Web Service QoS Prediction",
		"creator": [
			"Ye, Fanghua",
			"Lin, Zhiwei",
			"Chen, Chuan",
			"Zheng, Zibin",
			"Huang, Hong"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Software Engineering"
		],
		"description": [
			"  The proliferation of Web services makes it difficult for users to select the\nmost appropriate one among numerous functionally identical or similar service\ncandidates. Quality-of-Service (QoS) describes the non-functional\ncharacteristics of Web services, and it has become the key differentiator for\nservice selection. However, users cannot invoke all Web services to obtain the\ncorresponding QoS values due to high time cost and huge resource overhead.\nThus, it is essential to predict unknown QoS values. Although various QoS\nprediction methods have been proposed, few of them have taken outliers into\nconsideration, which may dramatically degrade the prediction performance. To\novercome this limitation, we propose an outlier-resilient QoS prediction method\nin this paper. Our method utilizes Cauchy loss to measure the discrepancy\nbetween the observed QoS values and the predicted ones. Owing to the robustness\nof Cauchy loss, our method is resilient to outliers. We further extend our\nmethod to provide time-aware QoS prediction results by taking the temporal\ninformation into consideration. Finally, we conduct extensive experiments on\nboth static and dynamic datasets. The results demonstrate that our method is\nable to achieve better performance than state-of-the-art baseline methods.\n",
			"Comment: 12 pages, to appear at the Web Conference (WWW) 2021"
		],
		"date": [
			"2020-06-01",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.01287",
		"pdf_url": "http://arxiv.org/pdf/2006.01287.pdf"
	},
	"298": {
		"title": "Value of Point-of-load Voltage Control for Enhanced Frequency Response\n  in Future GB Power System",
		"creator": [
			"Guo, Jinrui",
			"Badesa, Luis",
			"Teng, Fei",
			"Chaudhuri, Balarko",
			"Hui, Shu Yuen Ron",
			"Strbac, Goran"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": [
			"  The need for Enhanced Frequency Response (EFR) is expected to increase\nsignificantly in future low-carbon Great Britain (GB) power system. One way to\nprovide EFR is to use power electronic compensators (PECs) for point-of-load\nvoltage control (PVC) to exploit the voltage dependence of loads. This paper\ninvestigates the techno-economic feasibility of such technology in future GB\npower system by quantifying the total EFR obtainable through deploying PVC in\nthe urban domestic sector, the investment cost of the installment and the\neconomic and environmental benefits of using PVC. The quantification is based\non a stochastic domestic demand model and generic medium and low-voltage\ndistribution networks for the urban areas of GB and a stochastic unit\ncommitment (SUC) model with constraints for secure post-fault frequency\nevolution is used for the value assessment. Two future energy scenarios in the\nbackdrop of 2030 with `smart' and `non-smart' control of electric vehicles and\nheat pumps, under different levels of penetration of battery energy storage\nsystem (BESS) are considered to assess the value of PEC, as well as the\nassociated payback period. It is demonstrated that PVC could effectively\ncomplement BESS towards EFR provision in future GB power system.\n",
			"Comment: IEEE Transactions on Smart Grid"
		],
		"date": "2020-06-05",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2006.03559",
			"IEEE Transactions on Smart Grid, vol. 11, no. 6, pp. 4938-4948,\n  Nov. 2020",
			"doi:10.1109/TSG.2020.3000728"
		],
		"pdf_url": "http://arxiv.org/pdf/2006.03559.pdf"
	},
	"299": {
		"title": "Reconstructing Haemodynamics Quantities of Interest from Doppler\n  Ultrasound Imaging",
		"creator": [
			"Galarce, Felipe",
			"Lombardi, Damiano",
			"Mula, Olga"
		],
		"subject": "Mathematics - Numerical Analysis",
		"description": [
			"  The present contribution deals with the estimation of haemodynamics\nQuantities of Interest by exploiting Ultrasound Doppler measurements. A fast\nmethod is proposed, based on the PBDW method. Several methodological\ncontributions are described: a sub-manifold partitioning is introduced to\nimprove the reduced-order approximation, two different ways to estimate the\npressure drop are compared, and an error estimation is derived. A test-case on\na realistic common carotid geometry is presented, showing that the proposed\napproach is promising in view of realistic applications.\n",
			"Comment: arXiv admin note: text overlap with arXiv:1904.13367"
		],
		"date": [
			"2020-06-07",
			"2021-01-19"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2006.04174",
			"doi:10.1002/cnm.3416"
		],
		"pdf_url": "http://arxiv.org/pdf/2006.04174.pdf"
	},
	"300": {
		"title": "Motion Prediction using Trajectory Sets and Self-Driving Domain\n  Knowledge",
		"creator": [
			"Boulton, Freddy A.",
			"Grigore, Elena Corina",
			"Wolff, Eric M."
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Robotics",
			"Statistics - Machine Learning",
			"68T07 (Primary) 68T40, 68T45 (Secondary)",
			"I.2.6",
			"I.2.9",
			"I.2.10",
			"I.5"
		],
		"description": "  Predicting the future motion of vehicles has been studied using various\ntechniques, including stochastic policies, generative models, and regression.\nRecent work has shown that classification over a trajectory set, which\napproximates possible motions, achieves state-of-the-art performance and avoids\nissues like mode collapse. However, map information and the physical\nrelationships between nearby trajectories is not fully exploited in this\nformulation. We build on classification-based approaches to motion prediction\nby adding an auxiliary loss that penalizes off-road predictions. This auxiliary\nloss can easily be pretrained using only map information (e.g., off-road area),\nwhich significantly improves performance on small datasets. We also investigate\nweighted cross-entropy losses to capture spatial-temporal relationships among\ntrajectories. Our final contribution is a detailed comparison of classification\nand ordinal regression on two public self-driving datasets.\n",
		"date": [
			"2020-06-08",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.04767",
		"pdf_url": "http://arxiv.org/pdf/2006.04767.pdf"
	},
	"301": {
		"title": "Detection of Makeup Presentation Attacks based on Deep Face\n  Representations",
		"creator": [
			"Rathgeb, Christian",
			"Drozdowski, Pawel",
			"Busch, Christoph"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Facial cosmetics have the ability to substantially alter the facial\nappearance, which can negatively affect the decisions of a face recognition. In\naddition, it was recently shown that the application of makeup can be abused to\nlaunch so-called makeup presentation attacks. In such attacks, the attacker\nmight apply heavy makeup in order to achieve the facial appearance of a target\nsubject for the purpose of impersonation. In this work, we assess the\nvulnerability of a COTS face recognition system to makeup presentation attacks\nemploying the publicly available Makeup Induced Face Spoofing (MIFS) database.\nIt is shown that makeup presentation attacks might seriously impact the\nsecurity of the face recognition system. Further, we propose an attack\ndetection scheme which distinguishes makeup presentation attacks from genuine\nauthentication attempts by analysing differences in deep face representations\nobtained from potential makeup presentation attacks and corresponding target\nface images. The proposed detection system employs a machine learning-based\nclassifier, which is trained with synthetically generated makeup presentation\nattacks utilizing a generative adversarial network for facial makeup transfer\nin conjunction with image warping. Experimental evaluations conducted using the\nMIFS database reveal a detection equal error rate of 0.7% for the task of\nseparating genuine authentication attempts from makeup presentation attacks.\n",
			"Comment: published at 25th International Conference on Pattern Recognition\n  (ICPR'2020)"
		],
		"date": [
			"2020-06-09",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.05074",
		"pdf_url": "http://arxiv.org/pdf/2006.05074.pdf"
	},
	"302": {
		"title": "The Tragedy of the AI Commons",
		"creator": [
			"LaCroix, Travis",
			"Mohseni, Aydin"
		],
		"subject": [
			"Computer Science - Computers and Society",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computer Science and Game Theory",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Policy and guideline proposals for ethical artificial-intelligence research\nhave proliferated in recent years. These are supposed to guide the\nsocially-responsible development of AI for the common good. However, there\ntypically exist incentives for non-cooperation (i.e., non-adherence to such\npolicies and guidelines); and, these proposals often lack effective mechanisms\nto enforce their own normative claims. The situation just described constitutes\na social dilemma; namely, a situation where no one has an individual incentive\nto cooperate, though mutual cooperation would lead to the best outcome for all\ninvolved. In this paper, we use stochastic evolutionary game dynamics to model\nthis social dilemma in the context of the ethical development of artificial\nintelligence. This formalism allows us to isolate variables that may be\nintervened upon, thus providing actionable suggestions for increased\ncooperation amongst numerous stakeholders in AI. Our results show how\nstochastic effects can help make cooperation viable in such a scenario. They\nsuggest that coordination for a common good should be attempted in smaller\ngroups in which the cost for cooperation is low, and the perceived risk of\nfailure is high. This provides insight into the conditions under which we\nshould expect such ethics proposals to be successful with regard to their\nscope, scale, and content.\n",
			"Comment: 40 Pages, 5 Figures"
		],
		"date": [
			"2020-06-09",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.05203",
		"pdf_url": "http://arxiv.org/pdf/2006.05203.pdf"
	},
	"303": {
		"title": "Exploring Automatic Diagnosis of COVID-19 from Crowdsourced Respiratory\n  Sound Data",
		"creator": [
			"Brown, Chloë",
			"Chauhan, Jagmohan",
			"Grammenos, Andreas",
			"Han, Jing",
			"Hasthanasombat, Apinan",
			"Spathis, Dimitris",
			"Xia, Tong",
			"Cicuta, Pietro",
			"Mascolo, Cecilia"
		],
		"subject": [
			"Computer Science - Sound",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Audio and Speech Processing"
		],
		"description": [
			"  Audio signals generated by the human body (e.g., sighs, breathing, heart,\ndigestion, vibration sounds) have routinely been used by clinicians as\nindicators to diagnose disease or assess disease progression. Until recently,\nsuch signals were usually collected through manual auscultation at scheduled\nvisits. Research has now started to use digital technology to gather bodily\nsounds (e.g., from digital stethoscopes) for cardiovascular or respiratory\nexamination, which could then be used for automatic analysis. Some initial work\nshows promise in detecting diagnostic signals of COVID-19 from voice and\ncoughs. In this paper we describe our data analysis over a large-scale\ncrowdsourced dataset of respiratory sounds collected to aid diagnosis of\nCOVID-19. We use coughs and breathing to understand how discernible COVID-19\nsounds are from those in asthma or healthy controls. Our results show that even\na simple binary machine learning classifier is able to classify correctly\nhealthy and COVID-19 sounds. We also show how we distinguish a user who tested\npositive for COVID-19 and has a cough from a healthy user with a cough, and\nusers who tested positive for COVID-19 and have a cough from users with asthma\nand a cough. Our models achieve an AUC of above 80% across all tasks. These\nresults are preliminary and only scratch the surface of the potential of this\ntype of data and audio-based machine learning. This work opens the door to\nfurther investigation of how automatically analysed respiratory patterns could\nbe used as pre-screening signals to aid COVID-19 diagnosis.\n",
			"Comment: 9 pages, 6 figures, 2 tables, Accepted for publication at KDD'20\n  (Health Day)"
		],
		"date": [
			"2020-06-10",
			"2021-01-18"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2006.05919",
			"doi:10.1145/3394486.3412865"
		],
		"pdf_url": "http://arxiv.org/pdf/2006.05919.pdf"
	},
	"304": {
		"title": "On Uniform Convergence and Low-Norm Interpolation Learning",
		"creator": [
			"Zhou, Lijia",
			"Sutherland, Danica J.",
			"Srebro, Nathan"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  We consider an underdetermined noisy linear regression model where the\nminimum-norm interpolating predictor is known to be consistent, and ask: can\nuniform convergence in a norm ball, or at least (following Nagarajan and\nKolter) the subset of a norm ball that the algorithm selects on a typical input\nset, explain this success? We show that uniformly bounding the difference\nbetween empirical and population errors cannot show any learning in the norm\nball, and cannot show consistency for any set, even one depending on the exact\nalgorithm and distribution. But we argue we can explain the consistency of the\nminimal-norm interpolator with a slightly weaker, yet standard, notion: uniform\nconvergence of zero-error predictors in a norm ball. We use this to bound the\ngeneralization error of low- (but not minimal-) norm interpolating predictors.\n",
			"Comment: v3: No content changes to this final version, as published at NeurIPS\n  2020:\n  https://proceedings.neurips.cc/paper/2020/hash/4cc5400e63624c44fadeda99f57588a6-Abstract.html"
		],
		"date": [
			"2020-06-10",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.05942",
		"pdf_url": "http://arxiv.org/pdf/2006.05942.pdf"
	},
	"305": {
		"title": "Accelerating linear solvers for Stokes problems with C++ metaprogramming",
		"creator": [
			"Demidov, Denis",
			"Mu, Lin",
			"Wang, Bin"
		],
		"subject": [
			"Computer Science - Mathematical Software",
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Data Structures and Algorithms",
			"Physics - Fluid Dynamics",
			"35-04, 65-04, 65Y05, 65Y10, 65Y15, 97N80"
		],
		"description": "  The efficient solution of large sparse saddle point systems is very important\nin computational fluid mechanics. The discontinuous Galerkin finite element\nmethods have become increasingly popular for incompressible flow problems but\ntheir application is limited due to high computational cost. We describe the\nC++ programming techniques that may help to accelerate linear solvers for such\nproblems. The approach is based on the policy-based design pattern and partial\ntemplate specialization, and is implemented in the open source AMGCL library.\nThe efficiency is demonstrated with the example of accelerating an iterative\nsolver of a discontinuous Galerkin finite element method for the Stokes\nproblem. The implementation allows selecting algorithmic components of the\nsolver by adjusting template parameters without any changes to the codebase. It\nis possible to switch the system matrix to use small statically sized blocks to\nstore the nonzero values, or use a mixed precision solution, which results in\nup to 4 times speedup, and reduces the memory footprint of the algorithm by\nabout 40\\%. We evaluate both monolithic and composite preconditioning\nstrategies for the 3 benchmark problems. The performance of the proposed\nsolution is compared with a multithreaded direct Pardiso solver and a parallel\niterative PETSc solver.\n",
		"date": [
			"2020-06-10",
			"2020-12-22"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2006.06052",
			"doi:10.1016/j.jocs.2020.101285"
		],
		"pdf_url": "http://arxiv.org/pdf/2006.06052.pdf"
	},
	"306": {
		"title": "Uplink and Downlink MIMO-NOMA with Simultaneous Triangularization",
		"creator": [
			"Krishnamoorthy, Aravindh",
			"Schober, Robert"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  In this paper, we consider the uplink and downlink precoder design for\ntwo-user power-domain multiple-input multiple-output (MIMO) non-orthogonal\nmultiple access (NOMA) systems. We propose novel uplink and downlink precoding\nand decoding schemes that lower the decoding complexity at the receiver by\ndecomposing the MIMO-NOMA channels of the users into multiple single-input\nsingle-output (SISO)-NOMA channels via simultaneous triangularization (ST) of\nthe MIMO channels of the users and a low-complexity self-interference\ncancellation at the receiver. The proposed ST MIMO-NOMA schemes avoid channel\ninversion at transmitter and receiver and take advantage of the null spaces of\nthe MIMO channels of the users, which is beneficial for the ergodic achievable\nrate performance. We characterize the maximum ergodic achievable rate regions\nof the proposed uplink and downlink ST MIMO-NOMA schemes, and compare them with\nrespective upper bounds, baseline MIMO-NOMA precoding schemes, and orthogonal\nmultiple access (OMA). Our results illustrate that the proposed schemes\nsignificantly outperform the considered baseline MIMO-NOMA precoding schemes\nand OMA, and have a small gap to the respective upper bounds for most channel\nconditions and user rates. Moreover, we show that a hybrid scheme, which\nperforms time sharing between the proposed uplink and downlink ST MIMO-NOMA and\nsingle-user MIMO, can improve performance even further.\n",
			"Comment: Accepted by the IEEE Transactions on Wireless Communications. This is\n  the journal version of the submission arXiv:2006.04581 with 33 pages, 10\n  figures, and 2 tables. For associated code see\n  https://gitlab.com/aravindh.krishnamoorthy/mimo-noma"
		],
		"date": [
			"2020-06-10",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2006.06471",
			"IEEE Transactions on Wireless Communications, 2021",
			"doi:10.1109/TWC.2021.3049594"
		],
		"pdf_url": "http://arxiv.org/pdf/2006.06471.pdf"
	},
	"307": {
		"title": "Interpretable, similarity-driven multi-view embeddings from\n  high-dimensional biomedical data",
		"creator": [
			"Avants, Brian B.",
			"Tustison, Nicholas J.",
			"Stone, James R."
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Similarity-driven multi-view linear reconstruction (SiMLR) is an algorithm\nthat exploits inter-modality relationships to transform large scientific\ndatasets into smaller, more well-powered and interpretable low-dimensional\nspaces. SiMLR contributes a novel objective function for identifying joint\nsignal, regularization based on sparse matrices representing prior\nwithin-modality relationships and an implementation that permits application to\njoint reduction of large data matrices, each of which may have millions of\nentries. We demonstrate that SiMLR outperforms closely related methods on\nsupervised learning problems in simulation data, a multi-omics cancer survival\nprediction dataset and multiple modality neuroimaging datasets. Taken together,\nthis collection of results shows that SiMLR may be applied with default\nparameters to joint signal estimation from disparate modalities and may yield\npractically useful results in a variety of application domains.\n",
			"Comment: accepted to Nature Computational Science"
		],
		"date": [
			"2020-06-11",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.06545",
		"pdf_url": "http://arxiv.org/pdf/2006.06545.pdf"
	},
	"308": {
		"title": "What makes instance discrimination good for transfer learning?",
		"creator": [
			"Zhao, Nanxuan",
			"Wu, Zhirong",
			"Lau, Rynson W. H.",
			"Lin, Stephen"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Contrastive visual pretraining based on the instance discrimination pretext\ntask has made significant progress. Notably, recent work on unsupervised\npretraining has shown to surpass the supervised counterpart for finetuning\ndownstream applications such as object detection and segmentation. It comes as\na surprise that image annotations would be better left unused for transfer\nlearning. In this work, we investigate the following problems: What makes\ninstance discrimination pretraining good for transfer learning? What knowledge\nis actually learned and transferred from these models? From this understanding\nof instance discrimination, how can we better exploit human annotation labels\nfor pretraining? Our findings are threefold. First, what truly matters for the\ntransfer is low-level and mid-level representations, not high-level\nrepresentations. Second, the intra-category invariance enforced by the\ntraditional supervised model weakens transferability by increasing task\nmisalignment. Finally, supervised pretraining can be strengthened by following\nan exemplar-based approach without explicit constraints among the instances\nwithin the same category.\n",
			"Comment: Accepted by ICLR 2021"
		],
		"date": [
			"2020-06-11",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.06606",
		"pdf_url": "http://arxiv.org/pdf/2006.06606.pdf"
	},
	"309": {
		"title": "EMOGI: Efficient Memory-access for Out-of-memory Graph-traversal In GPUs",
		"creator": [
			"Min, Seung Won",
			"Mailthody, Vikram Sharma",
			"Qureshi, Zaid",
			"Xiong, Jinjun",
			"Ebrahimi, Eiman",
			"Hwu, Wen-mei"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Databases"
		],
		"description": "  Modern analytics and recommendation systems are increasingly based on graph\ndata that capture the relations between entities being analyzed. Practical\ngraphs come in huge sizes, offer massive parallelism, and are stored in\nsparse-matrix formats such as CSR. To exploit the massive parallelism,\ndevelopers are increasingly interested in using GPUs for graph traversal.\nHowever, due to their sizes, graphs often do not fit into the GPU memory. Prior\nworks have either used input data pre-processing/partitioning or UVM to migrate\nchunks of data from the host memory to the GPU memory. However, the large,\nmulti-dimensional, and sparse nature of graph data presents a major challenge\nto these schemes and results in significant amplification of data movement and\nreduced effective data throughput. In this work, we propose EMOGI, an\nalternative approach to traverse graphs that do not fit in GPU memory using\ndirect cacheline-sized access to data stored in host memory. This paper\naddresses the open question of whether a sufficiently large number of\noverlapping cacheline-sized accesses can be sustained to 1) tolerate the long\nlatency to host memory, 2) fully utilize the available bandwidth, and 3)\nachieve favorable execution performance. We analyze the data access patterns of\nseveral graph traversal applications in GPU over PCIe using an FPGA to\nunderstand the cause of poor external bandwidth utilization. By carefully\ncoalescing and aligning external memory requests, we show that we can minimize\nthe number of PCIe transactions and nearly fully utilize the PCIe bandwidth\neven with direct cache-line accesses to the host memory. EMOGI achieves\n2.92$\\times$ speedup on average compared to the optimized UVM implementations\nin various graph traversal applications. We also show that EMOGI scales better\nthan a UVM-based solution when the system uses higher bandwidth interconnects\nsuch as PCIe 4.0.\n",
		"date": [
			"2020-06-11",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.06890",
		"pdf_url": "http://arxiv.org/pdf/2006.06890.pdf"
	},
	"310": {
		"title": "Multi Layer Neural Networks as Replacement for Pooling Operations",
		"creator": [
			"Fuhl, Wolfgang",
			"Kasneci, Enkelejda"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  Pooling operations, which can be calculated at low cost and serve as a linear\nor nonlinear transfer function for data reduction, are found in almost every\nmodern neural network. Countless modern approaches have already tackled\nreplacing the common maximum value selection and mean value operations, not to\nmention providing a function that allows different functions to be selected\nthrough changing parameters. Additional neural networks are used to estimate\nthe parameters of these pooling functions.Consequently, pooling layers may\nrequire supplementary parameters to increase the complexity of the whole model.\nIn this work, we show that one perceptron can already be used effectively as a\npooling operation without increasing the complexity of the model. This kind of\npooling allows for the integration of multi-layer neural networks directly into\na model as a pooling operation by restructuring the data and, as a result,\nlearnin complex pooling operations. We compare our approach to tensor\nconvolution with strides as a pooling operation and show that our approach is\nboth effective and reduces complexity. The restructuring of the data in\ncombination with multiple perceptrons allows for our approach to be used for\nupscaling, which can then be utilized for transposed convolutions in semantic\nsegmentation.\n",
		"date": [
			"2020-06-12",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.06969",
		"pdf_url": "http://arxiv.org/pdf/2006.06969.pdf"
	},
	"311": {
		"title": "Convergence of adaptive discontinuous Galerkin and $C^0$-interior\n  penalty finite element methods for Hamilton--Jacobi--Bellman and Isaacs\n  equations",
		"creator": [
			"Kawecki, Ellya L.",
			"Smears, Iain"
		],
		"subject": "Mathematics - Numerical Analysis",
		"description": "  We prove the convergence of adaptive discontinuous Galerkin and\n$C^0$-interior penalty methods for fully nonlinear second-order elliptic\nHamilton--Jacobi--Bellman and Isaacs equations with Cordes coefficients. We\nconsider a broad family of methods on adaptively refined conforming simplicial\nmeshes in two and three space dimensions, with fixed but arbitrary polynomial\ndegrees greater than or equal to two. A key ingredient of our approach is a\nnovel intrinsic characterization of the limit space that enables us to identify\nthe weak limits of bounded sequences of nonconforming finite element functions.\nWe provide a detailed theory for the limit space, and also some original\nauxiliary functions spaces, that is of independent interest to adaptive\nnonconforming methods for more general problems, including Poincar\\'e and trace\ninequalities, a proof of density of functions with nonvanishing jumps on only\nfinitely many faces of the limit skeleton, approximation results by finite\nelement functions and weak convergence results.\n",
		"date": [
			"2020-06-12",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.07215",
		"pdf_url": "http://arxiv.org/pdf/2006.07215.pdf"
	},
	"312": {
		"title": "D-square-B: Deep Distribution Bound for Natural-looking Adversarial\n  Attack",
		"creator": [
			"Xu, Qiuling",
			"Tao, Guanhong",
			"Zhang, Xiangyu"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  We propose a novel technique that can generate natural-looking adversarial\nexamples by bounding the variations induced for internal activation values in\nsome deep layer(s), through a distribution quantile bound and a polynomial\nbarrier loss function. By bounding model internals instead of individual\npixels, our attack admits perturbations closely coupled with the existing\nfeatures of the original input, allowing the generated examples to be\nnatural-looking while having diverse and often substantial pixel distances from\nthe original input. Enforcing per-neuron distribution quantile bounds allows\naddressing the non-uniformity of internal activation values. Our evaluation on\nImageNet and five different model architecture demonstrates that our attack is\nquite effective. Compared to the state-of-the-art pixel space attack, semantic\nattack, and feature space attack, our attack can achieve the same attack\nsuccess/confidence level while having much more natural-looking adversarial\nperturbations. These perturbations piggy-back on existing local features and do\nnot have any fixed pixel bounds.\n",
		"date": [
			"2020-06-12",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.07258",
		"pdf_url": "http://arxiv.org/pdf/2006.07258.pdf"
	},
	"313": {
		"title": "Group Fairness for Knapsack Problems",
		"creator": [
			"Patel, Deval",
			"Khan, Arindam",
			"Louis, Anand"
		],
		"subject": "Computer Science - Data Structures and Algorithms",
		"description": "  We study the knapsack problem with group fairness constraints. The input of\nthe problem consists of a knapsack of bounded capacity and a set of items, each\nitem belongs to a particular category and has and associated weight and value.\nThe goal of this problem is to select a subset of items such that all\ncategories are fairly represented, the total weight of the selected items does\nnot exceed the capacity of the knapsack,and the total value is maximized. We\nstudy the fairness parameters such as the bounds on the total value of items\nfrom each category, the total weight of items from each category, and the total\nnumber of items from each category. We give approximation algorithms for these\nproblems. These fairness notions could also be extended to the min-knapsack\nproblem. The fair knapsack problems encompass various important problems, such\nas participatory budgeting, fair budget allocation, advertising.\n",
		"date": [
			"2020-06-14",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.07832",
		"pdf_url": "http://arxiv.org/pdf/2006.07832.pdf"
	},
	"314": {
		"title": "AdamP: Slowing Down the Slowdown for Momentum Optimizers on\n  Scale-invariant Weights",
		"creator": [
			"Heo, Byeongho",
			"Chun, Sanghyuk",
			"Oh, Seong Joon",
			"Han, Dongyoon",
			"Yun, Sangdoo",
			"Kim, Gyuwan",
			"Uh, Youngjung",
			"Ha, Jung-Woo"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Normalization techniques are a boon for modern deep learning. They let\nweights converge more quickly with often better generalization performances. It\nhas been argued that the normalization-induced scale invariance among the\nweights provides an advantageous ground for gradient descent (GD) optimizers:\nthe effective step sizes are automatically reduced over time, stabilizing the\noverall training procedure. It is often overlooked, however, that the\nadditional introduction of momentum in GD optimizers results in a far more\nrapid reduction in effective step sizes for scale-invariant weights, a\nphenomenon that has not yet been studied and may have caused unwanted side\neffects in the current practice. This is a crucial issue because arguably the\nvast majority of modern deep neural networks consist of (1) momentum-based GD\n(e.g. SGD or Adam) and (2) scale-invariant parameters. In this paper, we verify\nthat the widely-adopted combination of the two ingredients lead to the\npremature decay of effective step sizes and sub-optimal model performances. We\npropose a simple and effective remedy, SGDP and AdamP: get rid of the radial\ncomponent, or the norm-increasing direction, at each optimizer step. Because of\nthe scale invariance, this modification only alters the effective step sizes\nwithout changing the effective update directions, thus enjoying the original\nconvergence properties of GD optimizers. Given the ubiquity of momentum GD and\nscale invariance in machine learning, we have evaluated our methods against the\nbaselines on 13 benchmarks. They range from vision tasks like classification\n(e.g. ImageNet), retrieval (e.g. CUB and SOP), and detection (e.g. COCO) to\nlanguage modelling (e.g. WikiText) and audio classification (e.g. DCASE) tasks.\nWe verify that our solution brings about uniform gains in those benchmarks.\nSource code is available at https://github.com/clovaai/AdamP.\n",
			"Comment: Accepted at ICLR 2021. First two authors contributed equally"
		],
		"date": [
			"2020-06-15",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.08217",
		"pdf_url": "http://arxiv.org/pdf/2006.08217.pdf"
	},
	"315": {
		"title": "Comparing Alternative Route Planning Techniques: A Comparative User\n  Study on Melbourne, Dhaka and Copenhagen Road Networks",
		"creator": [
			"Li, Lingxiao",
			"Cheema, Muhammad Aamir",
			"Lu, Hua",
			"Ali, Mohammed Eunus",
			"Toosi, Adel N."
		],
		"subject": [
			"Computer Science - Databases",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Many modern navigation systems and map-based services do not only provide the\nfastest route from a source location s to a target location t but also provide\na few alternative routes to the users as more options to choose from.\nConsequently, computing alternative paths has received significant research\nattention. However, it is unclear which of the existing approaches generates\nalternative routes of better quality because the quality of these alternatives\nis mostly subjective. Motivated by this, in this paper, we present a user study\nconducted on the road networks of Melbourne, Dhaka and Copenhagen that compares\nthe quality (as perceived by the users) of the alternative routes generated by\nfour of the most popular existing approaches including the routes provided by\nGoogle Maps. We also present a web-based demo system that can be accessed using\nany internet-enabled device and allows users to see the alternative routes\ngenerated by the four approaches for any pair of selected source and target. We\nreport the average ratings received by the four approaches and our statistical\nanalysis shows that there is no credible evidence that the four approaches\nreceive different ratings on average. We also discuss the limitations of this\nuser study and recommend the readers to interpret these results with caution\nbecause certain factors may have affected the participants' ratings.\n",
			"Comment: Extended the user study to also include the road networks of Dhaka\n  and Copenhagen (the previous version only had Melbourne road network)"
		],
		"date": [
			"2020-06-15",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.08475",
		"pdf_url": "http://arxiv.org/pdf/2006.08475.pdf"
	},
	"316": {
		"title": "Reinforcement Learning Control of Robotic Knee with Human in the Loop by\n  Flexible Policy Iteration",
		"creator": [
			"Gao, Xiang",
			"Si, Jennie",
			"Wen, Yue",
			"Li, Minhan",
			"He",
			"Huang"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Computer Science - Machine Learning"
		],
		"description": "  We are motivated by the real challenges presented in a human-robot system to\ndevelop new designs that are efficient at data level and with performance\nguarantees such as stability and optimality at systems level. Existing\napproximate/adaptive dynamic programming (ADP) results that consider system\nperformance theoretically are not readily providing practically useful learning\ncontrol algorithms for this problem; and reinforcement learning (RL) algorithms\nthat address the issue of data efficiency usually do not have performance\nguarantees for the controlled system. This study fills these important voids by\nintroducing innovative features to the policy iteration algorithm. We introduce\nflexible policy iteration (FPI), which can flexibly and organically integrate\nexperience replay and supplemental values from prior experience into the RL\ncontroller. We show system level performances including convergence of the\napproximate value function, (sub)optimality of the solution, and stability of\nthe system. We demonstrate the effectiveness of the FPI via realistic\nsimulations of the human-robot system. It is noted that the problem we face in\nthis study may be difficult to address by design methods based on classical\ncontrol theory as it is nearly impossible to obtain a customized mathematical\nmodel of a human-robot system either online or offline. The results we have\nobtained also indicate the great potential of RL control to solving realistic\nand challenging problems with high dimensional control inputs.\n",
		"date": [
			"2020-06-16",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.09008",
		"pdf_url": "http://arxiv.org/pdf/2006.09008.pdf"
	},
	"317": {
		"title": "Network Diffusions via Neural Mean-Field Dynamics",
		"creator": [
			"He, Shushan",
			"Zha, Hongyuan",
			"Ye, Xiaojing"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Social and Information Networks",
			"Statistics - Machine Learning"
		],
		"description": [
			"  We propose a novel learning framework based on neural mean-field dynamics for\ninference and estimation problems of diffusion on networks. Our new framework\nis derived from the Mori-Zwanzig formalism to obtain an exact evolution of the\nnode infection probabilities, which renders a delay differential equation with\nmemory integral approximated by learnable time convolution operators, resulting\nin a highly structured and interpretable RNN. Directly using cascade data, our\nframework can jointly learn the structure of the diffusion network and the\nevolution of infection probabilities, which are cornerstone to important\ndownstream applications such as influence maximization. Connections between\nparameter learning and optimal control are also established. Empirical study\nshows that our approach is versatile and robust to variations of the underlying\ndiffusion network models, and significantly outperform existing approaches in\naccuracy and efficiency on both synthetic and real-world data.\n",
			"Comment: Accepted by NIPS2020, 21 pages, 5 figures"
		],
		"date": [
			"2020-06-16",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.09449",
		"pdf_url": "http://arxiv.org/pdf/2006.09449.pdf"
	},
	"318": {
		"title": "Categorical Normalizing Flows via Continuous Transformations",
		"creator": [
			"Lippe, Phillip",
			"Gavves, Efstratios"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Despite their popularity, to date, the application of normalizing flows on\ncategorical data stays limited. The current practice of using dequantization to\nmap discrete data to a continuous space is inapplicable as categorical data has\nno intrinsic order. Instead, categorical data have complex and latent relations\nthat must be inferred, like the synonymy between words. In this paper, we\ninvestigate \\emph{Categorical Normalizing Flows}, that is normalizing flows for\ncategorical data. By casting the encoding of categorical data in continuous\nspace as a variational inference problem, we jointly optimize the continuous\nrepresentation and the model likelihood. Using a factorized decoder, we\nintroduce an inductive bias to model any interactions in the normalizing flow.\nAs a consequence, we do not only simplify the optimization compared to having a\njoint decoder, but also make it possible to scale up to a large number of\ncategories that is currently impossible with discrete normalizing flows. Based\non Categorical Normalizing Flows, we propose GraphCNF a permutation-invariant\ngenerative model on graphs. GraphCNF implements a three step approach modeling\nthe nodes, edges and adjacency matrix stepwise to increase efficiency. On\nmolecule generation, GraphCNF outperforms both one-shot and autoregressive\nflow-based state-of-the-art.\n",
			"Comment: Submitted to: International Conference on Learning Representations\n  (ICLR), 2021"
		],
		"date": [
			"2020-06-17",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.09790",
		"pdf_url": "http://arxiv.org/pdf/2006.09790.pdf"
	},
	"319": {
		"title": "Matrix Completion with Quantified Uncertainty through Low Rank Gaussian\n  Copula",
		"creator": [
			"Zhao, Yuxuan",
			"Udell, Madeleine"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Modern large scale datasets are often plagued with missing entries. For\ntabular data with missing values, a flurry of imputation algorithms solve for a\ncomplete matrix which minimizes some penalized reconstruction error. However,\nalmost none of them can estimate the uncertainty of its imputations. This paper\nproposes a probabilistic and scalable framework for missing value imputation\nwith quantified uncertainty. Our model, the Low Rank Gaussian Copula, augments\na standard probabilistic model, Probabilistic Principal Component Analysis,\nwith marginal transformations for each column that allow the model to better\nmatch the distribution of the data. It naturally handles Boolean, ordinal, and\nreal-valued observations and quantifies the uncertainty in each imputation. The\ntime required to fit the model scales linearly with the number of rows and the\nnumber of columns in the dataset. Empirical results show the method yields\nstate-of-the-art imputation accuracy across a wide range of data types,\nincluding those with high rank. Our uncertainty measure predicts imputation\nerror well: entries with lower uncertainty do have lower imputation error (on\naverage). Moreover, for real-valued data, the resulting confidence intervals\nare well-calibrated.\n",
			"Comment: Accepted by NeurIPS 2020"
		],
		"date": [
			"2020-06-18",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.10829",
		"pdf_url": "http://arxiv.org/pdf/2006.10829.pdf"
	},
	"320": {
		"title": "Evaluating Prediction-Time Batch Normalization for Robustness under\n  Covariate Shift",
		"creator": [
			"Nado, Zachary",
			"Padhy, Shreyas",
			"Sculley, D.",
			"D'Amour, Alexander",
			"Lakshminarayanan, Balaji",
			"Snoek, Jasper"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  Covariate shift has been shown to sharply degrade both predictive accuracy\nand the calibration of uncertainty estimates for deep learning models. This is\nworrying, because covariate shift is prevalent in a wide range of real world\ndeployment settings. However, in this paper, we note that frequently there\nexists the potential to access small unlabeled batches of the shifted data just\nbefore prediction time. This interesting observation enables a simple but\nsurprisingly effective method which we call prediction-time batch\nnormalization, which significantly improves model accuracy and calibration\nunder covariate shift. Using this one line code change, we achieve\nstate-of-the-art on recent covariate shift benchmarks and an mCE of 60.28\\% on\nthe challenging ImageNet-C dataset; to our knowledge, this is the best result\nfor any model that does not incorporate additional data augmentation or\nmodification of the training pipeline. We show that prediction-time batch\nnormalization provides complementary benefits to existing state-of-the-art\napproaches for improving robustness (e.g. deep ensembles) and combining the two\nfurther improves performance. Our findings are supported by detailed\nmeasurements of the effect of this strategy on model behavior across rigorous\nablations on various dataset modalities. However, the method has mixed results\nwhen used alongside pre-training, and does not seem to perform as well under\nmore natural types of dataset shift, and is therefore worthy of additional\nstudy. We include links to the data in our figures to improve reproducibility,\nincluding a Python notebooks that can be run to easily modify our analysis at\nhttps://colab.research.google.com/drive/11N0wDZnMQQuLrRwRoumDCrhSaIhkqjof.\n",
		"date": [
			"2020-06-19",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.10963",
		"pdf_url": "http://arxiv.org/pdf/2006.10963.pdf"
	},
	"321": {
		"title": "A First Look at Android Applications in Google Play related to Covid-19",
		"creator": [
			"Samhi, Jordan",
			"Allix, Kevin",
			"Bissyandé, Tegawendé F.",
			"Klein, Jacques"
		],
		"subject": [
			"Computer Science - Software Engineering",
			"Computer Science - Computers and Society"
		],
		"description": [
			"  Due to the convenience of access-on-demand to information and business\nsolutions, mobile apps have become an important asset in the digital world. In\nthe context of the Covid-19 pandemic, app developers have joined the response\neffort in various ways by releasing apps that target different user bases\n(e.g., all citizens or journalists), offer different services (e.g., location\ntracking or diagnostic-aid), provide generic or specialized information, etc.\nWhile many apps have raised some concerns by spreading misinformation or even\nmalware, the literature does not yet provide a clear landscape of the different\napps that were developed. In this study, we focus on the Android ecosystem and\ninvestigate Covid-related Android apps. In a best-effort scenario, we attempt\nto systematically identify all relevant apps and study their characteristics\nwith the objective to provide a First taxonomy of Covid-related apps,\nbroadening the relevance beyond the implementation of contact tracing. Overall,\nour study yields a number of empirical insights that contribute to enlarge the\nknowledge on Covid-related apps: (1) Developer communities contributed rapidly\nto the Covid-19, with dedicated apps released as early as January 2020; (2)\nCovid-related apps deliver digital tools to users (e.g., health diaries), serve\nto broadcast information to users (e.g., spread statistics), and collect data\nfrom users (e.g., for tracing); (3) Covid-related apps are less complex than\nstandard apps; (4) they generally do not seem to leak sensitive data; (5) in\nthe majority of cases, Covid-related apps are released by entities with past\nexperience on the market, mostly official government entities or public health\norganizations.\n",
			"Comment: Accepted in Empirical Software Engineering under reference:\n  EMSE-D-20-00211R1"
		],
		"date": [
			"2020-06-19",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.11002",
		"pdf_url": "http://arxiv.org/pdf/2006.11002.pdf"
	},
	"322": {
		"title": "Lookahead Adversarial Learning for Near Real-Time Semantic Segmentation",
		"creator": [
			"Jamali-Rad, Hadi",
			"Szabo, Attila"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Semantic segmentation is one of the most fundamental problems in computer\nvision with significant impact on a wide variety of applications. Adversarial\nlearning is shown to be an effective approach for improving semantic\nsegmentation quality by enforcing higher-level pixel correlations and\nstructural information. However, state-of-the-art semantic segmentation models\ncannot be easily plugged into an adversarial setting because they are not\ndesigned to accommodate convergence and stability issues in adversarial\nnetworks. We bridge this gap by building a conditional adversarial network with\na state-of-the-art segmentation model (DeepLabv3+) at its core. To battle the\nstability issues, we introduce a novel lookahead adversarial learning (LoAd)\napproach with an embedded label map aggregation module. We focus on semantic\nsegmentation models that run fast at inference for near real-time field\napplications. Through extensive experimentation, we demonstrate that the\nproposed solution can alleviate divergence issues in an adversarial semantic\nsegmentation setting and results in considerable performance improvements (+5%\nin some classes) on the baseline for three standard datasets.\n",
			"Comment: 25 pages"
		],
		"date": [
			"2020-06-19",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.11227",
		"pdf_url": "http://arxiv.org/pdf/2006.11227.pdf"
	},
	"323": {
		"title": "Langevin Dynamics for Adaptive Inverse Reinforcement Learning of\n  Stochastic Gradient Algorithms",
		"creator": [
			"Krishnamurthy, Vikram",
			"Yin, George"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Systems and Control",
			"Statistics - Machine Learning"
		],
		"description": "  Inverse reinforcement learning (IRL) aims to estimate the reward function of\noptimizing agents by observing their response (estimates or actions). This\npaper considers IRL when noisy estimates of the gradient of a reward function\ngenerated by multiple stochastic gradient agents are observed. We present a\ngeneralized Langevin dynamics algorithm to estimate the reward function\n$R(\\theta)$; specifically, the resulting Langevin algorithm asymptotically\ngenerates samples from the distribution proportional to $\\exp(R(\\theta))$. The\nproposed IRL algorithms use kernel-based passive learning schemes. We also\nconstruct multi-kernel passive Langevin algorithms for IRL which are suitable\nfor high dimensional data. The performance of the proposed IRL algorithms are\nillustrated on examples in adaptive Bayesian learning, logistic regression\n(high dimensional problem) and constrained Markov decision processes. We prove\nweak convergence of the proposed IRL algorithms using martingale averaging\nmethods. We also analyze the tracking performance of the IRL algorithms in\nnon-stationary environments where the utility function $R(\\theta)$ jump changes\nover time as a slow Markov chain.\n",
		"date": [
			"2020-06-20",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.11674",
		"pdf_url": "http://arxiv.org/pdf/2006.11674.pdf"
	},
	"324": {
		"title": "Safe Reinforcement Learning via Curriculum Induction",
		"creator": [
			"Turchetta, Matteo",
			"Kolobov, Andrey",
			"Shah, Shital",
			"Krause, Andreas",
			"Agarwal, Alekh"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Robotics"
		],
		"description": "  In safety-critical applications, autonomous agents may need to learn in an\nenvironment where mistakes can be very costly. In such settings, the agent\nneeds to behave safely not only after but also while learning. To achieve this,\nexisting safe reinforcement learning methods make an agent rely on priors that\nlet it avoid dangerous situations during exploration with high probability, but\nboth the probabilistic guarantees and the smoothness assumptions inherent in\nthe priors are not viable in many scenarios of interest such as autonomous\ndriving. This paper presents an alternative approach inspired by human\nteaching, where an agent learns under the supervision of an automatic\ninstructor that saves the agent from violating constraints during learning. In\nthis model, we introduce the monitor that neither needs to know how to do well\nat the task the agent is learning nor needs to know how the environment works.\nInstead, it has a library of reset controllers that it activates when the agent\nstarts behaving dangerously, preventing it from doing damage. Crucially, the\nchoices of which reset controller to apply in which situation affect the speed\nof agent learning. Based on observing agents' progress, the teacher itself\nlearns a policy for choosing the reset controllers, a curriculum, to optimize\nthe agent's final policy reward. Our experiments use this framework in two\nenvironments to induce curricula for safe and efficient learning.\n",
		"date": [
			"2020-06-22",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.12136",
		"pdf_url": "http://arxiv.org/pdf/2006.12136.pdf"
	},
	"325": {
		"title": "The Depth-to-Width Interplay in Self-Attention",
		"creator": [
			"Levine, Yoav",
			"Wies, Noam",
			"Sharir, Or",
			"Bata, Hofit",
			"Shashua, Amnon"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computation and Language",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Self-attention architectures, which are rapidly pushing the frontier in\nnatural language processing, demonstrate a surprising depth-inefficient\nbehavior: previous works indicate that increasing the internal representation\n(network width) is just as useful as increasing the number of self-attention\nlayers (network depth). We theoretically predict a width-dependent transition\nbetween depth-efficiency and depth-inefficiency in self-attention. We conduct\nsystematic empirical ablations on networks of depths 6 to 48 that clearly\nreveal the theoretically predicted behaviors, and provide explicit quantitative\nsuggestions regarding the optimal depth-to-width allocation for a given\nself-attention network size. The race towards beyond 1-Trillion parameter\nlanguage models renders informed guidelines for increasing self-attention depth\nand width in tandem an essential ingredient. Our guidelines elucidate the\ndepth-to-width trade-off in self-attention networks of sizes up to the scale of\nGPT3 (which we project to be too deep for its size), and beyond, marking an\nunprecedented width of 30K as optimal for a 1-Trillion parameter network.\n",
			"Comment: NeurIPS 2020"
		],
		"date": [
			"2020-06-22",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.12467",
		"pdf_url": "http://arxiv.org/pdf/2006.12467.pdf"
	},
	"326": {
		"title": "Fairness Through Robustness: Investigating Robustness Disparity in Deep\n  Learning",
		"creator": [
			"Nanda, Vedant",
			"Dooley, Samuel",
			"Singla, Sahil",
			"Feizi, Soheil",
			"Dickerson, John P."
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computers and Society"
		],
		"description": [
			"  Deep neural networks (DNNs) are increasingly used in real-world applications\n(e.g. facial recognition). This has resulted in concerns about the fairness of\ndecisions made by these models. Various notions and measures of fairness have\nbeen proposed to ensure that a decision-making system does not\ndisproportionately harm (or benefit) particular subgroups of the population. In\nthis paper, we argue that traditional notions of fairness that are only based\non models' outputs are not sufficient when the model is vulnerable to\nadversarial attacks. We argue that in some cases, it may be easier for an\nattacker to target a particular subgroup, resulting in a form of\n\\textit{robustness bias}. We show that measuring robustness bias is a\nchallenging task for DNNs and propose two methods to measure this form of bias.\nWe then conduct an empirical study on state-of-the-art neural networks on\ncommonly used real-world datasets such as CIFAR-10, CIFAR-100, Adience, and\nUTKFace and show that in almost all cases there are subgroups (in some cases\nbased on sensitive attributes like race, gender, etc) which are less robust and\nare thus at a disadvantage. We argue that this kind of bias arises due to both\nthe data distribution and the highly complex nature of the learned decision\nboundary in the case of DNNs, thus making mitigation of such biases a\nnon-trivial task. Our results show that robustness bias is an important\ncriterion to consider while auditing real-world systems that rely on DNNs for\ndecision making. Code to reproduce all our results can be found here:\n\\url{https://github.com/nvedant07/Fairness-Through-Robustness}\n",
			"Comment: Accepted at ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT) 2021"
		],
		"date": [
			"2020-06-17",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.12621",
		"pdf_url": "http://arxiv.org/pdf/2006.12621.pdf"
	},
	"327": {
		"title": "Differentiable Segmentation of Sequences",
		"creator": [
			"Scharwächter, Erik",
			"Lennartz, Jonathan",
			"Müller, Emmanuel"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Applications",
			"Statistics - Methodology",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Segmented models are widely used to describe non-stationary sequential data\nwith discrete change points. Their estimation usually requires solving a mixed\ndiscrete-continuous optimization problem, where the segmentation is the\ndiscrete part and all other model parameters are continuous. A number of\nestimation algorithms have been developed that are highly specialized for their\nspecific model assumptions. The dependence on non-standard algorithms makes it\nhard to integrate segmented models in state-of-the-art deep learning\narchitectures that critically depend on gradient-based optimization techniques.\nIn this work, we formulate a relaxed variant of segmented models that enables\njoint estimation of all model parameters, including the segmentation, with\ngradient descent. We build on recent advances in learning continuous warping\nfunctions and propose a novel family of warping functions based on the\ntwo-sided power (TSP) distribution. TSP-based warping functions are\ndifferentiable, have simple closed-form expressions, and can represent\nsegmentation functions exactly. Our formulation includes the important class of\nsegmented generalized linear models as a special case, which makes it highly\nversatile. We use our approach to model the spread of COVID-19 with Poisson\nregression, apply it on a change point detection task, and learn classification\nmodels with concept drift. The experiments show that our approach effectively\nlearns all these tasks with standard algorithms for gradient descent.\n",
			"Comment: source codes available at https://github.com/diozaka/diffseg"
		],
		"date": [
			"2020-06-23",
			"2021-01-18"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2006.13105",
			"International Conference on Learning Representations (ICLR) 2021"
		],
		"pdf_url": "http://arxiv.org/pdf/2006.13105.pdf"
	},
	"328": {
		"title": "Momentum Contrastive Learning for Few-Shot COVID-19 Diagnosis from Chest\n  CT Images",
		"creator": [
			"Chen, Xiaocong",
			"Yao, Lina",
			"Zhou, Tao",
			"Dong, Jinming",
			"Zhang, Yu"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  The current pandemic, caused by the outbreak of a novel coronavirus\n(COVID-19) in December 2019, has led to a global emergency that has\nsignificantly impacted economies, healthcare systems and personal wellbeing all\naround the world. Controlling the rapidly evolving disease requires highly\nsensitive and specific diagnostics. While real-time RT-PCR is the most commonly\nused, these can take up to 8 hours, and require significant effort from\nhealthcare professionals. As such, there is a critical need for a quick and\nautomatic diagnostic system. Diagnosis from chest CT images is a promising\ndirection. However, current studies are limited by the lack of sufficient\ntraining samples, as acquiring annotated CT images is time-consuming. To this\nend, we propose a new deep learning algorithm for the automated diagnosis of\nCOVID-19, which only requires a few samples for training. Specifically, we use\ncontrastive learning to train an encoder which can capture expressive feature\nrepresentations on large and publicly available lung datasets and adopt the\nprototypical network for classification. We validate the efficacy of the\nproposed model in comparison with other competing methods on two publicly\navailable and annotated COVID-19 CT datasets. Our results demonstrate the\nsuperior performance of our model for the accurate diagnosis of COVID-19 based\non chest CT images.\n",
		"date": "2020-06-16",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2006.13276",
			"doi:10.1016/j.patcog.2021.107826"
		],
		"pdf_url": "http://arxiv.org/pdf/2006.13276.pdf"
	},
	"329": {
		"title": "Affinity Fusion Graph-based Framework for Natural Image Segmentation",
		"creator": [
			"Zhang, Yang",
			"Liu, Moyun",
			"He, Jingwu",
			"Pan, Fei",
			"Guo, Yanwen"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  This paper proposes an affinity fusion graph framework to effectively connect\ndifferent graphs with highly discriminating power and nonlinearity for natural\nimage segmentation. The proposed framework combines adjacency-graphs and kernel\nspectral clustering based graphs (KSC-graphs) according to a new definition\nnamed affinity nodes of multi-scale superpixels. These affinity nodes are\nselected based on a better affiliation of superpixels, namely\nsubspace-preserving representation which is generated by sparse subspace\nclustering based on subspace pursuit. Then a KSC-graph is built via a novel\nkernel spectral clustering to explore the nonlinear relationships among these\naffinity nodes. Moreover, an adjacency-graph at each scale is constructed,\nwhich is further used to update the proposed KSC-graph at affinity nodes. The\nfusion graph is built across different scales, and it is partitioned to obtain\nfinal segmentation result. Experimental results on the Berkeley segmentation\ndataset and Microsoft Research Cambridge dataset show the superiority of our\nframework in comparison with the state-of-the-art methods. The code is\navailable at https://github.com/Yangzhangcst/AF-graph.\n",
			"Comment: 11 pages, 10 figures"
		],
		"date": [
			"2020-06-24",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.13542",
		"pdf_url": "http://arxiv.org/pdf/2006.13542.pdf"
	},
	"330": {
		"title": "Autonomous Interference Mapping for Industrial IoT Networks over\n  Unlicensed Bands",
		"creator": [
			"Grimaldi, Simone",
			"Mahmood, Aamir",
			"Hassan, Syed Ali",
			"Hancke, Gerhard Petrus",
			"Gidlund, Mikael"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Signal Processing",
			"Computer Science - Information Theory"
		],
		"description": [
			"  The limited coexistence capabilities of current Internet-of-things (IoT)\nwireless standards produce inefficient spectrum utilization and mutual\nperformance impairment. The entity of the issue escalates in industrial IoT\n(IIoT) applications, which instead have stringent quality-of-service\nrequirements and exhibit very-low error tolerance. The constant growth of\nwireless applications over unlicensed bands mandates then the adoption of\ndynamic spectrum access techniques, which can greatly benefit from interference\nmapping over multiple dimensions of the radio space. In this article, the\nauthors analyze the critical role of real-time interference detection and\nclassification mechanisms that rely on IIoT devices only, without the added\ncomplexity of specialized hardware. The trade-offs between classification\nperformance and feasibility are analyzed in connection with the implementation\non low-complexity IIoT devices. Moreover, the authors explain how to use such\nmechanisms for enabling IIoT networks to construct and maintain\nmultidimensional interference maps at run-time in an autonomous fashion.\nLastly, the authors give an overview of the opportunities and challenges of\nusing interference maps to enhance the performance of IIoT networks under\ninterference.\n",
			"Comment: 7 figures, 1 table, final version to appear in IEEE Industrial\n  Electronics Magazine"
		],
		"date": "2020-06-24",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2006.13643",
			"doi:10.1109/MIE.2020.3007568"
		],
		"pdf_url": "http://arxiv.org/pdf/2006.13643.pdf"
	},
	"331": {
		"title": "Strictly Batch Imitation Learning by Energy-based Distribution Matching",
		"creator": [
			"Jarrett, Daniel",
			"Bica, Ioana",
			"van der Schaar, Mihaela"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Consider learning a policy purely on the basis of demonstrated behavior --\nthat is, with no access to reinforcement signals, no knowledge of transition\ndynamics, and no further interaction with the environment. This *strictly batch\nimitation learning* problem arises wherever live experimentation is costly,\nsuch as in healthcare. One solution is simply to retrofit existing algorithms\nfor apprenticeship learning to work in the offline setting. But such an\napproach leans heavily on off-policy evaluation or offline model estimation,\nand can be indirect and inefficient. We argue that a good solution should be\nable to explicitly parameterize a policy (i.e. respecting action conditionals),\nimplicitly learn from rollout dynamics (i.e. leveraging state marginals), and\n-- crucially -- operate in an entirely offline fashion. To address this\nchallenge, we propose a novel technique by *energy-based distribution matching*\n(EDM): By identifying parameterizations of the (discriminative) model of a\npolicy with the (generative) energy function for state distributions, EDM\nyields a simple but effective solution that equivalently minimizes a divergence\nbetween the occupancy measure for the demonstrator and a model thereof for the\nimitator. Through experiments with application to control and healthcare\nsettings, we illustrate consistent performance gains over existing algorithms\nfor strictly batch imitation learning.\n",
			"Comment: In Proc. 34th International Conference on Neural Information\n  Processing Systems (NeurIPS 2020)"
		],
		"date": [
			"2020-06-24",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.14154",
		"pdf_url": "http://arxiv.org/pdf/2006.14154.pdf"
	},
	"332": {
		"title": "A metric on directed graphs and Markov chains based on hitting\n  probabilities",
		"creator": [
			"Boyd, Zachary M.",
			"Fraiman, Nicolas",
			"Marzuola, Jeremy L.",
			"Mucha, Peter J.",
			"Osting, Braxton",
			"Weare, Jonathan"
		],
		"subject": [
			"Computer Science - Social and Information Networks",
			"Computer Science - Machine Learning",
			"Mathematics - Numerical Analysis",
			"Mathematics - Probability",
			"Statistics - Machine Learning"
		],
		"description": [
			"  The shortest-path, commute time, and diffusion distances on undirected graphs\nhave been widely employed in applications such as dimensionality reduction,\nlink prediction, and trip planning. Increasingly, there is interest in using\nasymmetric structure of data derived from Markov chains and directed graphs,\nbut few metrics are specifically adapted to this task. We introduce a metric on\nthe state space of any ergodic, finite-state, time-homogeneous Markov chain\nand, in particular, on any Markov chain derived from a directed graph. Our\nconstruction is based on hitting probabilities, with nearness in the metric\nspace related to the transfer of random walkers from one node to another at\nstationarity. Notably, our metric is insensitive to shortest and average walk\ndistances, thus giving new information compared to existing metrics. We use\npossible degeneracies in the metric to develop an interesting structural theory\nof directed graphs and explore a related quotienting procedure. Our metric can\nbe computed in $O(n^3)$ time, where $n$ is the number of states, and in\nexamples we scale up to $n=10,000$ nodes and $\\approx 38M$ edges on a desktop\ncomputer. In several examples, we explore the nature of the metric, compare it\nto alternative methods, and demonstrate its utility for weak recovery of\ncommunity structure in dense graphs, visualization, structure recovering,\ndynamics exploration, and multiscale cluster detection.\n",
			"Comment: 26 pages, 9 figures, for associated code, visit\n  https://github.com/zboyd2/hitting_probabilities_metric, accepted at SIAM J.\n  Math. Data Sci"
		],
		"date": [
			"2020-06-25",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.14482",
		"pdf_url": "http://arxiv.org/pdf/2006.14482.pdf"
	},
	"333": {
		"title": "APX-Hardness and Approximation for the k-Burning Number Problem",
		"creator": [
			"Mondal, Debajyoti",
			"Parthiban, N.",
			"Kavitha, V.",
			"Rajasingh, Indra"
		],
		"subject": [
			"Computer Science - Computational Complexity",
			"Computer Science - Data Structures and Algorithms",
			"03D15, 68Q25"
		],
		"description": "  Consider an information diffusion process on a graph $G$ that starts with\n$k>0$ burnt vertices, and at each subsequent step, burns the neighbors of the\ncurrently burnt vertices, as well as $k$ other unburnt vertices. The\n\\emph{$k$-burning number} of $G$ is the minimum number of steps $b_k(G)$ such\nthat all the vertices can be burned within $b_k(G)$ steps. Note that the last\nstep may have smaller than $k$ unburnt vertices available, where all of them\nare burned. The $1$-burning number coincides with the well-known burning number\nproblem, which was proposed to model the spread of social contagion. The\ngeneralization to $k$-burning number allows us to examine different worst-case\ncontagion scenarios by varying the spread factor $k$.\n  In this paper we prove that computing $k$-burning number is APX-hard, for any\nfixed constant $k$. We then give an $O((n+m)\\log n)$-time 3-approximation\nalgorithm for computing $k$-burning number, for any $k\\ge 1$, where $n$ and $m$\nare the number of vertices and edges, respectively. Finally, we show that even\nif the burning sources are given as an input, computing a burning sequence\nitself is an NP-hard problem.\n",
		"date": [
			"2020-06-25",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.14733",
		"pdf_url": "http://arxiv.org/pdf/2006.14733.pdf"
	},
	"334": {
		"title": "Interpretable and Trustworthy Deepfake Detection via Dynamic Prototypes",
		"creator": [
			"Trinh, Loc",
			"Tsang, Michael",
			"Rambhatla, Sirisha",
			"Liu, Yan"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  In this paper we propose a novel human-centered approach for detecting\nforgery in face images, using dynamic prototypes as a form of visual\nexplanations. Currently, most state-of-the-art deepfake detections are based on\nblack-box models that process videos frame-by-frame for inference, and few\nclosely examine their temporal inconsistencies. However, the existence of such\ntemporal artifacts within deepfake videos is key in detecting and explaining\ndeepfakes to a supervising human. To this end, we propose Dynamic Prototype\nNetwork (DPNet) -- an interpretable and effective solution that utilizes\ndynamic representations (i.e., prototypes) to explain deepfake temporal\nartifacts. Extensive experimental results show that DPNet achieves competitive\npredictive performance, even on unseen testing datasets such as Google's\nDeepFakeDetection, DeeperForensics, and Celeb-DF, while providing easy\nreferential explanations of deepfake dynamics. On top of DPNet's prototypical\nframework, we further formulate temporal logic specifications based on these\ndynamics to check our model's compliance to desired temporal behaviors, hence\nproviding trustworthiness for such critical detection systems.\n",
			"Comment: To appear in the 2021 IEEE Winter Conference on Applications of\n  Computer Vision (WACV 21')"
		],
		"date": [
			"2020-06-27",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.15473",
		"pdf_url": "http://arxiv.org/pdf/2006.15473.pdf"
	},
	"335": {
		"title": "Graph Convolutional Network for Recommendation with Low-pass\n  Collaborative Filters",
		"creator": [
			"Yu, Wenhui",
			"Qin, Zheng"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Information Retrieval",
			"Statistics - Machine Learning"
		],
		"description": [
			"  \\textbf{G}raph \\textbf{C}onvolutional \\textbf{N}etwork (\\textbf{GCN}) is\nwidely used in graph data learning tasks such as recommendation. However, when\nfacing a large graph, the graph convolution is very computationally expensive\nthus is simplified in all existing GCNs, yet is seriously impaired due to the\noversimplification. To address this gap, we leverage the \\textit{original graph\nconvolution} in GCN and propose a \\textbf{L}ow-pass \\textbf{C}ollaborative\n\\textbf{F}ilter (\\textbf{LCF}) to make it applicable to the large graph. LCF is\ndesigned to remove the noise caused by exposure and quantization in the\nobserved data, and it also reduces the complexity of graph convolution in an\nunscathed way. Experiments show that LCF improves the effectiveness and\nefficiency of graph convolution and our GCN outperforms existing GCNs\nsignificantly. Codes are available on \\url{https://github.com/Wenhui-Yu/LCFN}.\n",
			"Comment: ICML 2020 paper"
		],
		"date": [
			"2020-06-28",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.15516",
		"pdf_url": "http://arxiv.org/pdf/2006.15516.pdf"
	},
	"336": {
		"title": "Stochastic impulse control of non-smooth dynamics with partial\n  observation and execution delay: application to an environmental restoration\n  problem",
		"creator": [
			"Yoshioka, Hidekazu",
			"Yaegashi, Yuta"
		],
		"subject": [
			"Mathematics - Optimization and Control",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": [
			"  Non-smooth dynamics driven by stochastic disturbance arise in a wide variety\nof engineering problems. Impulsive interventions are often employed to control\nstochastic systems; however, the modeling and analysis subject to execution\ndelay have been less explored. In addition, continuously receiving information\nof the dynamics is not always possible. In this paper, with an application to\nan environmental restoration problem, a continuous-time stochastic impulse\ncontrol problem subject to execution delay under discrete and random\nobservations is newly formulated and analyzed. The dynamics have a non-smooth\ncoefficient modulated by a Markov chain, and eventually attain an undesirable\nstate like a depletion due to the non-smoothness. The goal of the control\nproblem is to find the most cost-efficient policy that can prevent the dynamics\nfrom attaining the undesirable state. We demonstrate that finding the optimal\npolicy reduces to solving a non-standard system of degenerate elliptic\nequations, the optimality equation, which is rigorously and analytically\nverified in a simplified case. The associated Fokker-Planck equation for the\ncontrolled dynamics is derived and solved explicitly as well. The model is\nfinally applied to numerical computation of a recent river environmental\nrestoration problem. The optimality and Fokker-Planck equations are\nsuccessfully computed, and the optimal policy and the probability density\nfunctions are numerically obtained. The impacts of execution delay are\ndiscussed to deeper analyze the model.\n",
			"Comment: 8 figures and 4 tables"
		],
		"date": [
			"2020-06-29",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.16034",
		"pdf_url": "http://arxiv.org/pdf/2006.16034.pdf"
	},
	"337": {
		"title": "Natural Backdoor Attack on Text Data",
		"creator": "Sun, Lichao",
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Cryptography and Security",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Recently, advanced NLP models have seen a surge in the usage of various\napplications. This raises the security threats of the released models. In\naddition to the clean models' unintentional weaknesses, {\\em i.e.,} adversarial\nattacks, the poisoned models with malicious intentions are much more dangerous\nin real life. However, most existing works currently focus on the adversarial\nattacks on NLP models instead of positioning attacks, also named\n\\textit{backdoor attacks}. In this paper, we first propose the \\textit{natural\nbackdoor attacks} on NLP models. Moreover, we exploit the various attack\nstrategies to generate trigger on text data and investigate different types of\ntriggers based on modification scope, human recognition, and special cases.\nLast, we evaluate the backdoor attacks, and the results show the excellent\nperformance of with 100\\% backdoor attacks success rate and sacrificing of\n0.83\\% on the text classification task.\n",
			"Comment: under submission"
		],
		"date": [
			"2020-06-29",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.16176",
		"pdf_url": "http://arxiv.org/pdf/2006.16176.pdf"
	},
	"338": {
		"title": "New developer metrics: Are comments as crucial as code contributions?",
		"creator": [
			"Şeker, Abdulkadir",
			"Diri, Banu",
			"Arslan, Halil"
		],
		"subject": "Computer Science - Software Engineering",
		"description": [
			"  Open-source code development has become widespread in recent years. As a\nresult, open-source software platforms have also become popular, and millions\nof developers from diverse locations are able to contribute to the same\nprojects. On these platforms, various knowledge about them is obtained from\nuser activity. This information is used in the form of developer metrics to\nsolve a variety of challenges. In this study, we proposed new developer\nmetrics, including commenting and issue-related activity, that require less\ninformation. We concluded that commenting on any feature of a project can be\nequally as valuable as code contribution. In addition, besides the quantitative\nones, metrics based on only the existence of the activity have been shown to\noffer also considerable results. We saw that issues were crucial in identifying\nuser contributions. Even if a developer makes a contribution to only one issue\non a project, the relation between the developer and the project is tight. The\nhit scores are relatively lower because of the sparsity problem of our dataset;\neven so, we believe that we have presented improvable and remarkable new\ndeveloper metrics.\n",
			"Comment: 14 pages, 2 figures, This study submitted to Journal of Science China\n  Information Sciences"
		],
		"date": [
			"2020-06-29",
			"2020-07-27"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2006.16349",
			"Applied Sciences. 2021; 11(3):920",
			"doi:10.3390/app11030920"
		],
		"pdf_url": "http://arxiv.org/pdf/2006.16349.pdf"
	},
	"339": {
		"title": "Random Partitioning Forest for Point-Wise and Collective Anomaly\n  Detection -- Application to Intrusion Detection",
		"creator": "Marteau, Pierre-Francois",
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  In this paper, we propose DiFF-RF, an ensemble approach composed of random\npartitioning binary trees to detect point-wise and collective (as well as\ncontextual) anomalies. Thanks to a distance-based paradigm used at the leaves\nof the trees, this semi-supervised approach solves a drawback that has been\nidentified in the isolation forest (IF) algorithm. Moreover, taking into\naccount the frequencies of visits in the leaves of the random trees allows to\nsignificantly improve the performance of DiFF-RF when considering the presence\nof collective anomalies. DiFF-RF is fairly easy to train, and excellent\nperformance can be obtained by using a simple semi-supervised procedure to\nsetup the extra hyper-parameter that is introduced. We first evaluate DiFF-RF\non a synthetic data set to i) verify that the limitation of the IF algorithm is\novercome, ii) demonstrate how collective anomalies are actually detected and\niii) to analyze the effect of the meta-parameters it involves. We assess the\nDiFF-RF algorithm on a large set of datasets from the UCI repository, as well\nas two benchmarks related to intrusion detection applications. Our experiments\nshow that DiFF-RF almost systematically outperforms the IF algorithm, but also\nchallenges the one-class SVM baseline and a deep learning variational\nauto-encoder architecture. Furthermore, our experience shows that DiFF-RF can\nwork well in the presence of small-scale learning data, which is conversely\ndifficult for deep neural architectures. Finally, DiFF-RF is computationally\nefficient and can be easily parallelized on multi-core architectures.\n",
			"Comment: arXiv admin note: text overlap with arXiv:1705.03800"
		],
		"date": [
			"2020-06-29",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2006.16801",
			"IEEE Transactions on Information Forensics and Security, pp1-16,\n  2021",
			"doi:10.1109/TIFS.2021.3050605"
		],
		"pdf_url": "http://arxiv.org/pdf/2006.16801.pdf"
	},
	"340": {
		"title": "MDP Homomorphic Networks: Group Symmetries in Reinforcement Learning",
		"creator": [
			"van der Pol, Elise",
			"Worrall, Daniel E.",
			"van Hoof, Herke",
			"Oliehoek, Frans A.",
			"Welling, Max"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  This paper introduces MDP homomorphic networks for deep reinforcement\nlearning. MDP homomorphic networks are neural networks that are equivariant\nunder symmetries in the joint state-action space of an MDP. Current approaches\nto deep reinforcement learning do not usually exploit knowledge about such\nstructure. By building this prior knowledge into policy and value networks\nusing an equivariance constraint, we can reduce the size of the solution space.\nWe specifically focus on group-structured symmetries (invertible\ntransformations). Additionally, we introduce an easy method for constructing\nequivariant network layers numerically, so the system designer need not solve\nthe constraints by hand, as is typically done. We construct MDP homomorphic\nMLPs and CNNs that are equivariant under either a group of reflections or\nrotations. We show that such networks converge faster than unstructured\nbaselines on CartPole, a grid world and Pong.\n",
		"date": [
			"2020-06-30",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2006.16908",
		"pdf_url": "http://arxiv.org/pdf/2006.16908.pdf"
	},
	"341": {
		"title": "Maximizing Cohesion and Separation in Graph Representation Learning: A\n  Distance-aware Negative Sampling Approach",
		"creator": [
			"Maruf, M.",
			"Karpatne, Anuj"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Social and Information Networks",
			"Statistics - Machine Learning"
		],
		"description": [
			"  The objective of unsupervised graph representation learning (GRL) is to learn\na low-dimensional space of node embeddings that reflect the structure of a\ngiven unlabeled graph. Existing algorithms for this task rely on negative\nsampling objectives that maximize the similarity in node embeddings at nearby\nnodes (referred to as \"cohesion\") by maintaining positive and negative corpus\nof node pairs. While positive samples are drawn from node pairs that co-occur\nin short random walks, conventional approaches construct negative corpus by\nuniformly sampling random pairs, thus ignoring valuable information about\nstructural dissimilarity among distant node pairs (referred to as\n\"separation\"). In this paper, we present a novel Distance-aware Negative\nSampling (DNS) which maximizes the separation of distant node-pairs while\nmaximizing cohesion at nearby node-pairs by setting the negative sampling\nprobability proportional to the pair-wise shortest distances. Our approach can\nbe used in conjunction with any GRL algorithm and we demonstrate the efficacy\nof our approach over baseline negative sampling methods over downstream node\nclassification tasks on a number of benchmark datasets and GRL algorithms. All\nour codes and datasets are available at\nhttps://github.com/Distance-awareNS/DNS/.\n",
			"Comment: 14 pages, 9 figures, 3 tables, full length version with appendix;\n  Published in Proceedings of the 2021 SIAM International Conference on Data\n  Mining"
		],
		"date": [
			"2020-07-02",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.01423",
		"pdf_url": "http://arxiv.org/pdf/2007.01423.pdf"
	},
	"342": {
		"title": "DICE: Automatic Emulation of DMA Input Channels for Dynamic Firmware\n  Analysis",
		"creator": [
			"Mera, Alejandro",
			"Feng, Bo",
			"Lu, Long",
			"Kirda, Engin"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": "  Microcontroller-based embedded devices are at the core of Internet-of-Things\nand Cyber-Physical Systems. The security of these devices is of paramount\nimportance. Among the approaches to securing embedded devices, dynamic firmware\nanalysis gained great attention lately, thanks to its offline nature and low\nfalse-positive rates. However, regardless of the analysis and emulation\ntechniques used, existing dynamic firmware analyzers share a major limitation,\nnamely the inability to handle firmware using DMA. It severely limits the types\nof devices supported and firmware code coverage. We present DICE, a drop-in\nsolution for firmware analyzers to emulate DMA input channels and generate or\nmanipulate DMA inputs. DICE is designed to be hardware-independent, and\ncompatible with common MCU firmware and embedded architectures. DICE identifies\nDMA input channels as the firmware writes the source and destination DMA\ntransfer pointers into the DMA controller. Then DICE manipulates the input\ntransferred through DMA on behalf of the firmware analyzer. We integrated DICE\nto the firmware analyzer P2IM (Cortex-M architecture) and a PIC32 emulator\n(MIPS M4K/M-Class architecture). We evaluated it on 83 benchmarks and sample\nfirmware, representing 9 different DMA controllers from 5 different vendors.\nDICE detected 33 out of 37 DMA input channels, with 0 false positives. It\ncorrectly supplied DMA inputs to 21 out of 22 DMA buffers, which previous\nfirmware analyzers cannot achieve due to the lack of DMA emulation. DICE's\noverhead is fairly low, it adds 3.4% on average to P2IM execution time. We also\nfuzz-tested 7 real-world firmware using DICE and compared the results with the\noriginal P2IM. DICE uncovered tremendously more execution paths (as much as\n79X) and found 5 unique previously-unknown bugs that are unreachable without\nDMA emulation. All our source code and dataset are publicly available.\n",
		"date": [
			"2020-07-03",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2007.01502",
			"42nd IEEE Symposium on Security and Privacy, S&P 2021"
		],
		"pdf_url": "http://arxiv.org/pdf/2007.01502.pdf"
	},
	"343": {
		"title": "Finding Symmetry Breaking Order Parameters with Euclidean Neural\n  Networks",
		"creator": [
			"Smidt, Tess E.",
			"Geiger, Mario",
			"Miller, Benjamin Kurt"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Condensed Matter - Disordered Systems and Neural Networks",
			"Physics - Computational Physics"
		],
		"description": [
			"  Curie's principle states that \"when effects show certain asymmetry, this\nasymmetry must be found in the causes that gave rise to them\". We demonstrate\nthat symmetry equivariant neural networks uphold Curie's principle and can be\nused to articulate many symmetry-relevant scientific questions into simple\noptimization problems. We prove these properties mathematically and demonstrate\nthem numerically by training a Euclidean symmetry equivariant neural network to\nlearn symmetry-breaking input to deform a square into a rectangle and to\ngenerate octahedra tilting patterns in perovskites.\n",
			"Comment: 6 pages, 3 figures"
		],
		"date": [
			"2020-07-04",
			"2020-10-26"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2007.02005",
			"Phys. Rev. Research 3, 012002 (2021)",
			"doi:10.1103/PhysRevResearch.3.L012002"
		],
		"pdf_url": "http://arxiv.org/pdf/2007.02005.pdf"
	},
	"344": {
		"title": "An Optimal Energy-Saving Home Energy Management Supporting User Comfort\n  and Electricity Selling with Different Prices",
		"creator": [
			"Dinh, Huy Truong",
			"Kim, Daehee"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  In this study, we investigate the operation of an optimal home energy\nmanagement system (HEMS) with integrated renewable energy system (RES) and\nenergy storage system (ESS) supporting electricity selling functions. A\nmulti-objective mixed integer nonlinear programming model, including RES, ESS,\nhome appliances and the main grid, is proposed to optimize different and\nconflicting objectives which are energy cost, user comfort and PAR. The effect\nof different selling prices on the objectives is also considered in detail. We\nfurther develop a formula for the lower bound of energy cost to help residents\nor engineers quickly choose best parameters of RES and ESS for their homes\nduring the installation process. The performance of our system is verified\nthrough extensive simulations under three different scenarios of normal,\neconomic, and smart with different selling prices using real data, and\nsimulation results are compared in terms of daily energy cost, PAR, user's\nconvenience and consecutive waiting time to use appliances. Numerical results\nclearly show that the economic scenario achieves 51.6% reduction of daily\nenergy cost compared to the normal scenario while sacrificing the user's\nconvenience, PAR, and consecutive waiting time by 49%, 132%, and 1 hour,\nrespectively. On the other hand, the smart scenario shows only slight\ndegradation of user's convenience and PAR by 2% and 18%, respectively while\nachieving 46.4% reduction of daily energy cost and the same level of\nconsecutive waiting time. Furthermore, our simulation results show that a\ndecrease of selling prices has tiny impacts on PAR and user comfort even though\nthe daily energy cost increases.\n",
			"Comment: 15 pages, 14 figures, 7 tables"
		],
		"date": [
			"2020-07-06",
			"2021-01-11"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2007.03142",
			"IEEE Access, Volume 9, 11 January 2021",
			"doi:10.1109/ACCESS.2021.3050757"
		],
		"pdf_url": "http://arxiv.org/pdf/2007.03142.pdf"
	},
	"345": {
		"title": "See, Hear, Explore: Curiosity via Audio-Visual Association",
		"creator": [
			"Dean, Victoria",
			"Tulsiani, Shubham",
			"Gupta, Abhinav"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Statistics - Machine Learning"
		],
		"description": "  Exploration is one of the core challenges in reinforcement learning. A common\nformulation of curiosity-driven exploration uses the difference between the\nreal future and the future predicted by a learned model. However, predicting\nthe future is an inherently difficult task which can be ill-posed in the face\nof stochasticity. In this paper, we introduce an alternative form of curiosity\nthat rewards novel associations between different senses. Our approach exploits\nmultiple modalities to provide a stronger signal for more efficient\nexploration. Our method is inspired by the fact that, for humans, both sight\nand sound play a critical role in exploration. We present results on several\nAtari environments and Habitat (a photorealistic navigation simulator), showing\nthe benefits of using an audio-visual association model for intrinsically\nguiding learning agents in the absence of external rewards. For videos and\ncode, see https://vdean.github.io/audio-curiosity.html.\n",
		"date": [
			"2020-07-07",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.03669",
		"pdf_url": "http://arxiv.org/pdf/2007.03669.pdf"
	},
	"346": {
		"title": "Building Interpretable Interaction Trees for Deep NLP Models",
		"creator": [
			"Zhang, Die",
			"Zhou, Huilin",
			"Zhang, Hao",
			"Bao, Xiaoyi",
			"Huo, Da",
			"Chen, Ruizhao",
			"Cheng, Xu",
			"Wu, Mengyue",
			"Zhang, Quanshi"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning"
		],
		"description": "  This paper proposes a method to disentangle and quantify interactions among\nwords that are encoded inside a DNN for natural language processing. We\nconstruct a tree to encode salient interactions extracted by the DNN. Six\nmetrics are proposed to analyze properties of interactions between constituents\nin a sentence. The interaction is defined based on Shapley values of words,\nwhich are considered as an unbiased estimation of word contributions to the\nnetwork prediction. Our method is used to quantify word interactions encoded\ninside the BERT, ELMo, LSTM, CNN, and Transformer networks. Experimental\nresults have provided a new perspective to understand these DNNs, and have\ndemonstrated the effectiveness of our method.\n",
		"date": [
			"2020-06-29",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.04298",
		"pdf_url": "http://arxiv.org/pdf/2007.04298.pdf"
	},
	"347": {
		"title": "Contrastive Multiple Correspondence Analysis (cMCA): Using Contrastive\n  Learning to Identify Latent Subgroups in Political Parties",
		"creator": [
			"Fujiwara, Takanori",
			"Liu, Tzu-Ping"
		],
		"subject": [
			"Computer Science - Social and Information Networks",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Scaling methods have long been utilized to simplify and cluster\nhigh-dimensional data. However, the latent spaces derived from these methods\nare sometimes uninformative or unable to identify significant differences in\nthe data. To tackle this common issue, we adopt an emerging analysis approach\ncalled contrastive learning. We contribute to this emerging field by extending\nits ideas to multiple correspondence analysis (MCA) in order to enable an\nanalysis of data often encountered by social scientists -- namely binary,\nordinal, and nominal variables. We demonstrate the utility of contrastive MCA\n(cMCA) by analyzing three different surveys of voters in Europe, Japan, and the\nUnited States. Our results suggest that, first, cMCA can identify substantively\nimportant dimensions and divisions among (sub)groups that are overlooked by\ntraditional methods; second, for certain cases, cMCA can still derive latent\ntraits that generalize across and apply to multiple groups in the dataset;\nfinally, when data is high-dimensional and unstructured, cMCA provides\nobjective heuristics, above and beyond the standard results, enabling more\ncomplex subgroup analysis.\n",
			"Comment: Both authors contributed equally to the paper and listed\n  alphabetically. This manuscript is currently under review"
		],
		"date": [
			"2020-07-08",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.04540",
		"pdf_url": "http://arxiv.org/pdf/2007.04540.pdf"
	},
	"348": {
		"title": "Challenges of AI in Wireless Networks for IoT",
		"creator": [
			"Ahmad, Ijaz",
			"Shahabuddin, Shahriar",
			"Kumar, Tanesh",
			"Harjula, Erkki",
			"Meisel, Marcus",
			"Juntti, Markku",
			"Sauter, Thilo",
			"Ylianttila, Mika"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": "  The Internet of Things (IoT), hailed as the enabler of the next industrial\nrevolution, will require ubiquitous connectivity, context-aware and dynamic\nservice mobility, and extreme security through the wireless network\ninfrastructure. Artificial Intelligence (AI), thus, will play a major role in\nthe underlying network infrastructure. However, a number of challenges will\nsurface while using the concepts, tools and algorithms of AI in wireless\nnetworks used by IoT. In this article, the main challenges in using AI in the\nwireless network infrastructure that facilitate end-to-end IoT communication\nare highlighted with potential generalized solution and future research\ndirections.\n",
		"date": "2020-07-09",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2007.04705",
			"doi:10.1109/MIE.2020.2979272"
		],
		"pdf_url": "http://arxiv.org/pdf/2007.04705.pdf"
	},
	"349": {
		"title": "Animated GIF optimization by adaptive color local table management",
		"creator": [
			"Giudice, Oliver",
			"Allegra, Dario",
			"Guarnera, Francesco",
			"Stanco, Filippo",
			"Battiato, Sebastiano"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  After thirty years of the GIF file format, today is becoming more popular\nthan ever: being a great way of communication for friends and communities on\nInstant Messengers and Social Networks. While being so popular, the original\ncompression method to encode GIF images have not changed a bit. On the other\nhand popularity means that storage saving becomes an issue for hosting\nplatforms. In this paper a parametric optimization technique for animated GIFs\nwill be presented. The proposed technique is based on Local Color Table\nselection and color remapping in order to create optimized animated GIFs while\npreserving the original format. The technique achieves good results in terms of\nbyte reduction with limited or no loss of perceived color quality. Tests\ncarried out on 1000 GIF files demonstrate the effectiveness of the proposed\noptimization strategy.\n",
		"date": "2020-07-09",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2007.04717",
			"2020 IEEE International Conference on Image Processing (ICIP)",
			"doi:10.1109/ICIP40778.2020.9190967"
		],
		"pdf_url": "http://arxiv.org/pdf/2007.04717.pdf"
	},
	"350": {
		"title": "Gated Recurrent Context: Softmax-free Attention for Online\n  Encoder-Decoder Speech Recognition",
		"creator": [
			"Lee, Hyeonseung",
			"Kang, Woo Hyun",
			"Cheon, Sung Jun",
			"Kim, Hyeongju",
			"Kim, Nam Soo"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Audio and Speech Processing",
			"Computer Science - Sound"
		],
		"description": "  Recently, attention-based encoder-decoder (AED) models have shown\nstate-of-the-art performance in automatic speech recognition (ASR). As the\noriginal AED models with global attentions are not capable of online inference,\nvarious online attention schemes have been developed to reduce ASR latency for\nbetter user experience. However, a common limitation of the conventional\nsoftmax-based online attention approaches is that they introduce an additional\nhyperparameter related to the length of the attention window, requiring\nmultiple trials of model training for tuning the hyperparameter. In order to\ndeal with this problem, we propose a novel softmax-free attention method and\nits modified formulation for online attention, which does not need any\nadditional hyperparameter at the training phase. Through a number of ASR\nexperiments, we demonstrate the tradeoff between the latency and performance of\nthe proposed online attention technique can be controlled by merely adjusting a\nthreshold at the test phase. Furthermore, the proposed methods showed\ncompetitive performance to the conventional global and online attentions in\nterms of word-error-rates (WERs).\n",
		"date": [
			"2020-07-10",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2007.05214",
			"doi:10.1109/TASLP.2021.3049344"
		],
		"pdf_url": "http://arxiv.org/pdf/2007.05214.pdf"
	},
	"351": {
		"title": "Using Machine Learning to Detect Ghost Images in Automotive Radar",
		"creator": [
			"Kraus, Florian",
			"Scheiner, Nicolas",
			"Ritter, Werner",
			"Dietmayer, Klaus"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  Radar sensors are an important part of driver assistance systems and\nintelligent vehicles due to their robustness against all kinds of adverse\nconditions, e.g., fog, snow, rain, or even direct sunlight. This robustness is\nachieved by a substantially larger wavelength compared to light-based sensors\nsuch as cameras or lidars. As a side effect, many surfaces act like mirrors at\nthis wavelength, resulting in unwanted ghost detections. In this article, we\npresent a novel approach to detect these ghost objects by applying data-driven\nmachine learning algorithms. For this purpose, we use a large-scale automotive\ndata set with annotated ghost objects. We show that we can use a\nstate-of-the-art automotive radar classifier in order to detect ghost objects\nalongside real objects. Furthermore, we are able to reduce the amount of false\npositive detections caused by ghost images in some settings.\n",
		"date": "2020-07-10",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2007.05280",
			"IEEE 23rd International Conference on Intelligent Transportation\n  Systems (ITSC), Rhodes, Greece, 2020",
			"doi:10.1109/ITSC45102.2020.9294631"
		],
		"pdf_url": "http://arxiv.org/pdf/2007.05280.pdf"
	},
	"352": {
		"title": "Neural Knowledge Extraction From Cloud Service Incidents",
		"creator": [
			"Shetty, Manish",
			"Bansal, Chetan",
			"Kumar, Sumit",
			"Rao, Nikitha",
			"Nagappan, Nachiappan",
			"Zimmermann, Thomas"
		],
		"subject": [
			"Computer Science - Software Engineering",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  In the last decade, two paradigm shifts have reshaped the software industry -\nthe move from boxed products to services and the widespread adoption of cloud\ncomputing. This has had a huge impact on the software development life cycle\nand the DevOps processes. Particularly, incident management has become critical\nfor developing and operating large-scale services. Incidents are created to\nensure timely communication of service issues and, also, their resolution.\nPrior work on incident management has been heavily focused on the challenges\nwith incident triaging and de-duplication. In this work, we address the\nfundamental problem of structured knowledge extraction from service incidents.\nWe have built SoftNER, a framework for unsupervised knowledge extraction from\nservice incidents. We frame the knowledge extraction problem as a Named-entity\nRecognition task for extracting factual information. SoftNER leverages\nstructural patterns like key,value pairs and tables for bootstrapping the\ntraining data. Further, we build a novel multi-task learning based BiLSTM-CRF\nmodel which leverages not just the semantic context but also the data-types for\nnamed-entity extraction. We have deployed SoftNER at Microsoft, a major cloud\nservice provider and have evaluated it on more than 2 months of cloud\nincidents. We show that the unsupervised machine learning based approach has a\nhigh precision of 0.96. Our multi-task learning based deep learning model also\noutperforms the state of the art NER models. Lastly, using the knowledge\nextracted by SoftNER we are able to build significantly more accurate models\nfor important downstream tasks like incident triaging.\n",
			"Comment: To be published in the proceedings of ICSE 2021 - Software\n  Engineering in Practice Track"
		],
		"date": [
			"2020-07-10",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.05505",
		"pdf_url": "http://arxiv.org/pdf/2007.05505.pdf"
	},
	"353": {
		"title": "EMIXER: End-to-end Multimodal X-ray Generation via Self-supervision",
		"creator": [
			"Biswal, Siddharth",
			"Zhuang, Peiye",
			"Pyrros, Ayis",
			"Siddiqui, Nasir",
			"Koyejo, Sanmi",
			"Sun, Jimeng"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  Deep generative models have enabled the automated synthesis of high-quality\ndata for diverse applications. However, the most effective generative models\nare specialized to data from a single domain (e.g., images or text). Real-world\napplications such as healthcare require multi-modal data from multiple domains\n(e.g., both images and corresponding text), which are difficult to acquire due\nto limited availability and privacy concerns and are much harder to synthesize.\nTo tackle this joint synthesis challenge, we propose an End-to-end MultImodal\nX-ray genERative model (EMIXER) for jointly synthesizing x-ray images and\ncorresponding free-text reports, all conditional on diagnosis labels. EMIXER is\nan conditional generative adversarial model by 1) generating an image based on\na label, 2) encoding the image to a hidden embedding, 3) producing the\ncorresponding text via a hierarchical decoder from the image embedding, and 4)\na joint discriminator for assessing both the image and the corresponding text.\nEMIXER also enables self-supervision to leverage vast amount of unlabeled data.\nExtensive experiments with real X-ray reports data illustrate how data\naugmentation using synthesized multimodal samples can improve the performance\nof a variety of supervised tasks including COVID-19 X-ray classification with\nvery limited samples. The quality of generated images and reports are also\nconfirmed by radiologists. We quantitatively show that EMIXER generated\nsynthetic datasets can augment X-ray image classification, report generation\nmodels to achieve 5.94% and 6.9% improvement on models trained only on real\ndata samples. Taken together, our results highlight the promise of state of\ngenerative models to advance clinical machine learning.\n",
		"date": [
			"2020-07-10",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.05597",
		"pdf_url": "http://arxiv.org/pdf/2007.05597.pdf"
	},
	"354": {
		"title": "Transformations between deep neural networks",
		"creator": [
			"Bertalan, Tom",
			"Dietrich, Felix",
			"Kevrekidis, Ioannis G."
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  We propose to test, and when possible establish, an equivalence between two\ndifferent artificial neural networks by attempting to construct a data-driven\ntransformation between them, using manifold-learning techniques. In particular,\nwe employ diffusion maps with a Mahalanobis-like metric. If the construction\nsucceeds, the two networks can be thought of as belonging to the same\nequivalence class.\n  We first discuss transformation functions between only the outputs of the two\nnetworks; we then also consider transformations that take into account outputs\n(activations) of a number of internal neurons from each network. In general,\nWhitney's theorem dictates the number of measurements from one of the networks\nrequired to reconstruct each and every feature of the second network. The\nconstruction of the transformation function relies on a consistent, intrinsic\nrepresentation of the network input space.\n  We illustrate our algorithm by matching neural network pairs trained to learn\n(a) observations of scalar functions; (b) observations of two-dimensional\nvector fields; and (c) representations of images of a moving three-dimensional\nobject (a rotating horse). The construction of such equivalence classes across\ndifferent network instantiations clearly relates to transfer learning. We also\nexpect that it will be valuable in establishing equivalence between different\nMachine Learning-based models of the same phenomenon observed through different\ninstruments and by different research groups.\n",
			"Comment: 14 pages, 10 figures"
		],
		"date": [
			"2020-07-10",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.05646",
		"pdf_url": "http://arxiv.org/pdf/2007.05646.pdf"
	},
	"355": {
		"title": "Meta Soft Label Generation for Noisy Labels",
		"creator": [
			"Algan, Görkem",
			"Ulusoy, Ilkay"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  The existence of noisy labels in the dataset causes significant performance\ndegradation for deep neural networks (DNNs). To address this problem, we\npropose a Meta Soft Label Generation algorithm called MSLG, which can jointly\ngenerate soft labels using meta-learning techniques and learn DNN parameters in\nan end-to-end fashion. Our approach adapts the meta-learning paradigm to\nestimate optimal label distribution by checking gradient directions on both\nnoisy training data and noise-free meta-data. In order to iteratively update\nsoft labels, meta-gradient descent step is performed on estimated labels, which\nwould minimize the loss of noise-free meta samples. In each iteration, the base\nclassifier is trained on estimated meta labels. MSLG is model-agnostic and can\nbe added on top of any existing model at hand with ease. We performed extensive\nexperiments on CIFAR10, Clothing1M and Food101N datasets. Results show that our\napproach outperforms other state-of-the-art methods by a large margin.\n",
			"Comment: Accepted by ICPR 2020"
		],
		"date": [
			"2020-07-11",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.05836",
		"pdf_url": "http://arxiv.org/pdf/2007.05836.pdf"
	},
	"356": {
		"title": "VINNAS: Variational Inference-based Neural Network Architecture Search",
		"creator": [
			"Ferianc, Martin",
			"Fan, Hongxiang",
			"Rodrigues, Miguel"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Statistics - Machine Learning"
		],
		"description": [
			"  In recent years, neural architecture search (NAS) has received intensive\nscientific and industrial interest due to its capability of finding a neural\narchitecture with high accuracy for various artificial intelligence tasks such\nas image classification or object detection. In particular, gradient-based NAS\napproaches have become one of the more popular approaches thanks to their\ncomputational efficiency during the search. However, these methods often\nexperience a mode collapse, where the quality of the found architectures is\npoor due to the algorithm resorting to choosing a single operation type for the\nentire network, or stagnating at a local minima for various datasets or search\nspaces.\n  To address these defects, we present a differentiable variational\ninference-based NAS method for searching sparse convolutional neural networks.\nOur approach finds the optimal neural architecture by dropping out candidate\noperations in an over-parameterised supergraph using variational dropout with\nautomatic relevance determination prior, which makes the algorithm gradually\nremove unnecessary operations and connections without risking mode collapse.\nThe evaluation is conducted through searching two types of convolutional cells\nthat shape the neural network for classifying different image datasets. Our\nmethod finds diverse network cells, while showing state-of-the-art accuracy\nwith up to almost 2 times fewer non-zero parameters.\n",
			"Comment: 10 pages"
		],
		"date": [
			"2020-07-12",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.06103",
		"pdf_url": "http://arxiv.org/pdf/2007.06103.pdf"
	},
	"357": {
		"title": "Adaptive Periodic Averaging: A Practical Approach to Reducing\n  Communication in Distributed Learning",
		"creator": [
			"Jiang, Peng",
			"Agrawal, Gagan"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Statistics - Machine Learning"
		],
		"description": "  Stochastic Gradient Descent (SGD) is the key learning algorithm for many\nmachine learning tasks. Because of its computational costs, there is a growing\ninterest in accelerating SGD on HPC resources like GPU clusters. However, the\nperformance of parallel SGD is still bottlenecked by the high communication\ncosts even with a fast connection among the machines. A simple approach to\nalleviating this problem, used in many existing efforts, is to perform\ncommunication every few iterations, using a constant averaging period. In this\npaper, we show that the optimal averaging period in terms of convergence and\ncommunication cost is not a constant, but instead varies over the course of the\nexecution. Specifically, we observe that reducing the variance of model\nparameters among the computing nodes is critical to the convergence of periodic\nparameter averaging SGD. Given a fixed communication budget, we show that it is\nmore beneficial to synchronize more frequently in early iterations to reduce\nthe initial large variance and synchronize less frequently in the later phase\nof the training process. We propose a practical algorithm, named ADaptive\nPeriodic parameter averaging SGD (ADPSGD), to achieve a smaller overall\nvariance of model parameters, and thus better convergence compared with the\nConstant Periodic parameter averaging SGD (CPSGD). We evaluate our method with\nseveral image classification benchmarks and show that our ADPSGD indeed\nachieves smaller training losses and higher test accuracies with smaller\ncommunication compared with CPSGD. Compared with gradient-quantization SGD, we\nshow that our algorithm achieves faster convergence with only half of the\ncommunication. Compared with full-communication SGD, our ADPSGD achieves 1:14x\nto 1:27x speedups with a 100Gbps connection among computing nodes, and the\nspeedups increase to 1:46x ~ 1:95x with a 10Gbps connection.\n",
		"date": [
			"2020-07-12",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.06134",
		"pdf_url": "http://arxiv.org/pdf/2007.06134.pdf"
	},
	"358": {
		"title": "Benchmarking 16-element quantum search algorithms on superconducting\n  quantum processors",
		"creator": [
			"Gwinner, Jan",
			"Briański, Marcin",
			"Burkot, Wojciech",
			"Czerwiński, Łukasz",
			"Hlembotskyi, Vladyslav"
		],
		"subject": [
			"Quantum Physics",
			"Computer Science - Data Structures and Algorithms",
			"81P68"
		],
		"description": [
			"  We present experimental results on running 4-qubit unstructured search on IBM\nquantum processors. Our best attempt attained probability of success around\n24.5%. We try several algorithms and use the most recent developments in\nquantum search to reduce the number of entangling gates that are currently\nconsidered the main source of errors in quantum computations. Comparing\ntheoretical expectations of an algorithm performance with the actual data, we\nexplore the hardware limits, showing sharp, phase-transition-like degradation\nof performance on quantum processors. We conclude that it is extremely\nimportant to design hardware-aware algorithms and to include any other low\nlevel optimizations on NISQ devices.\n",
			"Comment: 12 pages, 13 figures"
		],
		"date": [
			"2020-07-13",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.06539",
		"pdf_url": "http://arxiv.org/pdf/2007.06539.pdf"
	},
	"359": {
		"title": "Lossless Compression of Structured Convolutional Models via Lifting",
		"creator": [
			"Sourek, Gustav",
			"Zelezny, Filip",
			"Kuzelka, Ondrej"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Lifting is an efficient technique to scale up graphical models generalized to\nrelational domains by exploiting the underlying symmetries. Concurrently,\nneural models are continuously expanding from grid-like tensor data into\nstructured representations, such as various attributed graphs and relational\ndatabases. To address the irregular structure of the data, the models typically\nextrapolate on the idea of convolution, effectively introducing parameter\nsharing in their, dynamically unfolded, computation graphs. The computation\ngraphs themselves then reflect the symmetries of the underlying data, similarly\nto the lifted graphical models. Inspired by lifting, we introduce a simple and\nefficient technique to detect the symmetries and compress the neural models\nwithout loss of any information. We demonstrate through experiments that such\ncompression can lead to significant speedups of structured convolutional\nmodels, such as various Graph Neural Networks, across various tasks, such as\nmolecule classification and knowledge-base completion.\n",
			"Comment: Accepted to ICLR 2021. TL;DR: Speeding up weight-sharing dynamic\n  neural computation graphs, such as GNNs, with lifted inference"
		],
		"date": [
			"2020-07-13",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.06567",
		"pdf_url": "http://arxiv.org/pdf/2007.06567.pdf"
	},
	"360": {
		"title": "Analyzing and Mitigating Data Stalls in DNN Training",
		"creator": [
			"Mohan, Jayashree",
			"Phanishayee, Amar",
			"Raniwala, Ashish",
			"Chidambaram, Vijay"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Machine Learning",
			"Computer Science - Operating Systems"
		],
		"description": "  Training Deep Neural Networks (DNNs) is resource-intensive and\ntime-consuming. While prior research has explored many different ways of\nreducing DNN training time, the impact of input data pipeline, i.e., fetching\nraw data items from storage and performing data pre-processing in memory, has\nbeen relatively unexplored. This paper makes the following contributions: (1)\nWe present the first comprehensive analysis of how the input data pipeline\naffects the training time of widely-used computer vision and audio Deep Neural\nNetworks (DNNs), that typically involve complex data preprocessing. We analyze\nnine different models across three tasks and four datasets while varying\nfactors such as the amount of memory, number of CPU threads, storage device,\nGPU generation etc on servers that are a part of a large production cluster at\nMicrosoft. We find that in many cases, DNN training time is dominated by data\nstall time: time spent waiting for data to be fetched and preprocessed. (2) We\nbuild a tool, DS-Analyzer to precisely measure data stalls using a differential\ntechnique, and perform predictive what-if analysis on data stalls. (3) Finally,\nbased on the insights from our analysis, we design and implement three simple\nbut effective techniques in a data-loading library, CoorDL, to mitigate data\nstalls. Our experiments on a range of DNN tasks, models, datasets, and hardware\nconfigs show that when PyTorch uses CoorDL instead of the state-of-the-art DALI\ndata loading library, DNN training time is reduced significantly (by as much as\n5x on a single server).\n",
		"date": [
			"2020-07-13",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.06775",
		"pdf_url": "http://arxiv.org/pdf/2007.06775.pdf"
	},
	"361": {
		"title": "On the Effective Capacity of IRS-assisted wireless communication",
		"creator": [
			"Aman, Waqas",
			"Rahman, M. Mahboob Ur",
			"Ansari, Shuja",
			"Nasir, Ali Arshad",
			"Qaraqe, Khalid",
			"Imran, M. Ali",
			"Abbasi, Qammer H."
		],
		"subject": [
			"Electrical Engineering and Systems Science - Signal Processing",
			"Computer Science - Information Theory"
		],
		"description": "  We consider futuristic, intelligent reflecting surfaces (IRS)-aided\ncommunication between a base station (BS) and a user equipment (UE) for two\ndistinct scenarios: a single-input, single-output (SISO) system whereby the BS\nhas a single antenna, and a multi-input, single-output (MISO) system whereby\nthe BS has multiple antennas. For the considered IRS-assisted downlink, we\ncompute the effective capacity (EC), which is a quantitative measure of the\nstatistical quality-of-service (QoS) offered by a communication system\nexperiencing random fading. For our analysis, we consider the two widely-known\nassumptions on channel state information (CSI) -- i.e., perfect CSI and no CSI,\nat the BS. Thereafter, we first derive the distribution of the signal-to-noise\nratio (SNR) for both SISO and MISO scenarios, and subsequently derive\nclosed-form expressions for the EC under perfect CSI and no CSI cases, for both\nSISO and MISO scenarios. Furthermore, for the SISO and MISO systems with no\nCSI, it turns out that the EC could be maximized further by searching for an\noptimal transmission rate $r^*$, which is computed by exploiting the iterative\ngradient-descent method. We provide extensive simulation results which\ninvestigate the impact of the various system parameters, e.g., QoS exponent,\npower budget, number of transmit antennas at the BS, number of reflective\nelements at the IRS etc., on the EC of the system.\n",
		"date": [
			"2020-07-14",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.06825",
		"pdf_url": "http://arxiv.org/pdf/2007.06825.pdf"
	},
	"362": {
		"title": "Explicit Regularisation in Gaussian Noise Injections",
		"creator": [
			"Camuto, Alexander",
			"Willetts, Matthew",
			"Şimşekli, Umut",
			"Roberts, Stephen",
			"Holmes, Chris"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": "  We study the regularisation induced in neural networks by Gaussian noise\ninjections (GNIs). Though such injections have been extensively studied when\napplied to data, there have been few studies on understanding the regularising\neffect they induce when applied to network activations. Here we derive the\nexplicit regulariser of GNIs, obtained by marginalising out the injected noise,\nand show that it penalises functions with high-frequency components in the\nFourier domain; particularly in layers closer to a neural network's output. We\nshow analytically and empirically that such regularisation produces calibrated\nclassifiers with large classification margins.\n",
		"date": [
			"2020-07-14",
			"2021-01-19"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2007.07368",
			"Advances in Neural Information Processing Systems 34 (2020)"
		],
		"pdf_url": "http://arxiv.org/pdf/2007.07368.pdf"
	},
	"363": {
		"title": "Multimodal Word Sense Disambiguation in Creative Practice",
		"creator": [
			"de Guevara, Manuel Ladron",
			"George, Christopher",
			"Gupta, Akshat",
			"Byrne, Daragh",
			"Krishnamurti, Ramesh"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Language is ambiguous; many terms and expressions can convey the same idea.\nThis is especially true in creative practice, where ideas and design intents\nare highly subjective. We present a dataset, Ambiguous Descriptions of Art\nImages (ADARI), of contemporary workpieces, which aims to provide a\nfoundational resource for subjective image description and multimodal word\ndisambiguation in the context of creative practice. The dataset contains a\ntotal of 240k images labeled with 260k descriptive sentences. It is\nadditionally organized into sub-domains of architecture, art, design, fashion,\nfurniture, product design and technology. In subjective image description,\nlabels are not deterministic: for example, the ambiguous label dynamic might\ncorrespond to hundreds of different images. To understand this complexity, we\nanalyze the ambiguity and relevance of text with respect to images using the\nstate-of-the-art pre-trained BERT model for sentence classification. We provide\na baseline for multi-label classification tasks and demonstrate the potential\nof multimodal approaches for understanding ambiguity in design intentions. We\nhope that ADARI dataset and baselines constitute a first step towards\nsubjective label classification.\n",
			"Comment: 9 pages, 5 figures, 2 tables"
		],
		"date": [
			"2020-07-15",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.07758",
		"pdf_url": "http://arxiv.org/pdf/2007.07758.pdf"
	},
	"364": {
		"title": "Channel Estimation for RIS-Aided mmWave MIMO Systems via Atomic Norm\n  Minimization",
		"creator": [
			"He, Jiguang",
			"Wymeersch, Henk",
			"Juntti, Markku"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Signal Processing",
			"Computer Science - Information Theory"
		],
		"description": [
			"  A reconfigurable intelligent surface (RIS) can shape the radio propagation\nenvironment by virtue of changing the impinging electromagnetic waves towards\nany desired directions, thus, breaking the general Snell's reflection law.\nHowever, the optimal control of the RIS requires perfect channel state\ninformation (CSI) of the individual channels that link the base station (BS)\nand the mobile station (MS) to each other via the RIS. Thereby super-resolution\nchannel (parameter) estimation needs to be efficiently conducted at the BS or\nMS with CSI feedback to the RIS controller. In this paper, we adopt a two-stage\nchannel estimation scheme for RIS-aided millimeter wave (mmWave) MIMO systems\nwithout a direct BS-MS channel, using atomic norm minimization to sequentially\nestimate the channel parameters, i.e., angular parameters, angle differences,\nand products of propagation path gains. We evaluate the mean square error of\nthe parameter estimates, the RIS gains, the average effective spectrum\nefficiency bound, and average squared distance between the designed beamforming\nand combining vectors and the optimal ones. The results demonstrate that the\nproposed scheme achieves super-resolution estimation compared to the existing\nbenchmark schemes, thus offering promising performance in the subsequent data\ntransmission phase.\n",
			"Comment: 30 pages, 10 figures, Submitted to IEEE TWC, under second round\n  review"
		],
		"date": [
			"2020-07-16",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.08158",
		"pdf_url": "http://arxiv.org/pdf/2007.08158.pdf"
	},
	"365": {
		"title": "BRP-NAS: Prediction-based NAS using GCNs",
		"creator": [
			"Dudziak, Łukasz",
			"Chau, Thomas",
			"Abdelfattah, Mohamed S.",
			"Lee, Royson",
			"Kim, Hyeji",
			"Lane, Nicholas D."
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Signal Processing",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Neural architecture search (NAS) enables researchers to automatically explore\nbroad design spaces in order to improve efficiency of neural networks. This\nefficiency is especially important in the case of on-device deployment, where\nimprovements in accuracy should be balanced out with computational demands of a\nmodel. In practice, performance metrics of model are computationally expensive\nto obtain. Previous work uses a proxy (e.g., number of operations) or a\nlayer-wise measurement of neural network layers to estimate end-to-end hardware\nperformance but the imprecise prediction diminishes the quality of NAS. To\naddress this problem, we propose BRP-NAS, an efficient hardware-aware NAS\nenabled by an accurate performance predictor-based on graph convolutional\nnetwork (GCN). What is more, we investigate prediction quality on different\nmetrics and show that sample efficiency of the predictor-based NAS can be\nimproved by considering binary relations of models and an iterative data\nselection strategy. We show that our proposed method outperforms all prior\nmethods on NAS-Bench-101 and NAS-Bench-201, and that our predictor can\nconsistently learn to extract useful features from the DARTS search space,\nimproving upon the second-order baseline. Finally, to raise awareness of the\nfact that accurate latency estimation is not a trivial task, we release\nLatBench -- a latency dataset of NAS-Bench-201 models running on a broad range\nof devices.\n",
			"Comment: Published at NeurIPS 2020"
		],
		"date": [
			"2020-07-16",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.08668",
		"pdf_url": "http://arxiv.org/pdf/2007.08668.pdf"
	},
	"366": {
		"title": "Dealing with Nuisance Parameters using Machine Learning in High Energy\n  Physics: a Review",
		"creator": [
			"Dorigo, Tommaso",
			"de Castro, Pablo"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning",
			"High Energy Physics - Experiment",
			"High Energy Physics - Phenomenology",
			"Physics - Data Analysis, Statistics and Probability"
		],
		"description": [
			"  In this work we discuss the impact of nuisance parameters on the\neffectiveness of machine learning in high-energy physics problems, and provide\na review of techniques that allow to include their effect and reduce their\nimpact in the search for optimal selection criteria and variable\ntransformations. The introduction of nuisance parameters complicates the\nsupervised learning task and its correspondence with the data analysis goal,\ndue to their contribution degrading the model performances in real data, and\nthe necessary addition of uncertainties in the resulting statistical inference.\nThe approaches discussed include nuisance-parameterized models, modified or\nadversary losses, semi-supervised learning approaches, and inference-aware\ntechniques.\n",
			"Comment: 43 pages, 5 figures. v1: original review manuscript. v2: text\n  improvement/fixes from review process"
		],
		"date": [
			"2020-07-17",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.09121",
		"pdf_url": "http://arxiv.org/pdf/2007.09121.pdf"
	},
	"367": {
		"title": "iNNk: A Multi-Player Game to Deceive a Neural Network",
		"creator": [
			"Villareale, Jennifer",
			"Acosta-Ruiz, Ana",
			"Arcaro, Samuel",
			"Fox, Thomas",
			"Freed, Evan",
			"Gray, Robert",
			"Löwe, Mathias",
			"Nuchprayoon, Panote",
			"Sladek, Aleksanteri",
			"Weigelt, Rush",
			"Li, Yifu",
			"Risi, Sebastian",
			"Zhu, Jichen"
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  This paper presents iNNK, a multiplayer drawing game where human players team\nup against an NN. The players need to successfully communicate a secret code\nword to each other through drawings, without being deciphered by the NN. With\nthis game, we aim to foster a playful environment where players can, in a small\nway, go from passive consumers of NN applications to creative thinkers and\ncritical challengers.\n",
		"date": [
			"2020-07-17",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.09177",
		"pdf_url": "http://arxiv.org/pdf/2007.09177.pdf"
	},
	"368": {
		"title": "Challenges in Developing Secure Mobile Health Applications, A Systematic\n  Review",
		"creator": [
			"Aljedaani, Bakheet",
			"Babar, M. Ali"
		],
		"subject": "Computer Science - Software Engineering",
		"description": [
			"  Mobile health (mHealth) applications (apps) have gained significant\npopularity over the last few years due to its tremendous benefits, such as\nlowering healthcare cost and increasing patient awareness. However, the\nsensitivity of healthcare data makes the security of mHealth apps a serious\nconcern. In this review, we aim to identify and analyse the reported challenges\nthat the developers of mHealth apps face concerning security. Additionally, our\nstudy aimed to develop a conceptual framework with the challenges faced by\nmHealth apps development organization for developing secure apps. The knowledge\nof such challenges can help to reduce the risk of developing insecure mHealth\napps. We followed the Systematic Literature Review method for this review. We\nselected studies that have been published between January 2008 and October\n2020. We selected 32 primary studies using predefined criteria and used\nthematic analysis method for analysing the extracted data. We identified nine\nchallenges that can affect the development of secure mHealth apps. Such as 1)\nlack of security guidelines and regulations for developing secure mHealth apps,\n2) developers lack of knowledge and expertise for secure mHealth app\ndevelopment, 3) lack of stakeholders involvement during mHealth app\ndevelopment, etc . Based on our analysis, we have presented a conceptual\nframework which highlights the correlation between the identified challenges.\nWe conclude that our findings can help them identify their weaknesses and\nimprove their security practices. Similarly, mHealth apps developers can\nidentify the challenges they face to develop mHealth apps that do not pose\nsecurity risks for users. Our review is a step towards providing insights into\nthe development of secure mHealth apps. Our proposed conceptual framework can\nact as a practice guideline for practitioners to enhance secure mHealth apps\ndevelopment.\n",
			"Comment: This paper has 5 figures and 1 table"
		],
		"date": [
			"2020-07-21",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.10876",
		"pdf_url": "http://arxiv.org/pdf/2007.10876.pdf"
	},
	"369": {
		"title": "EMaQ: Expected-Max Q-Learning Operator for Simple Yet Effective Offline\n  and Online RL",
		"creator": [
			"Ghasemipour, Seyed Kamyar Seyed",
			"Schuurmans, Dale",
			"Gu, Shixiang Shane"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  Off-policy reinforcement learning holds the promise of sample-efficient\nlearning of decision-making policies by leveraging past experience. However, in\nthe offline RL setting -- where a fixed collection of interactions are provided\nand no further interactions are allowed -- it has been shown that standard\noff-policy RL methods can significantly underperform. Recently proposed methods\noften aim to address this shortcoming by constraining learned policies to\nremain close to the given dataset of interactions. In this work, we closely\ninvestigate an important simplification of BCQ -- a prior approach for offline\nRL -- which removes a heuristic design choice and naturally restricts extracted\npolicies to remain exactly within the support of a given behavior policy.\nImportantly, in contrast to their original theoretical considerations, we\nderive this simplified algorithm through the introduction of a novel backup\noperator, Expected-Max Q-Learning (EMaQ), which is more closely related to the\nresulting practical algorithm. Specifically, in addition to the distribution\nsupport, EMaQ explicitly considers the number of samples and the proposal\ndistribution, allowing us to derive new sub-optimality bounds which can serve\nas a novel measure of complexity for offline RL problems. In the offline RL\nsetting -- the main focus of this work -- EMaQ matches and outperforms prior\nstate-of-the-art in the D4RL benchmarks. In the online RL setting, we\ndemonstrate that EMaQ is competitive with Soft Actor Critic. The key\ncontributions of our empirical findings are demonstrating the importance of\ncareful generative model design for estimating behavior policies, and an\nintuitive notion of complexity for offline RL problems. With its simple\ninterpretation and fewer moving parts, such as no explicit function\napproximator representing the policy, EMaQ serves as a strong yet easy to\nimplement baseline for future work.\n",
		"date": [
			"2020-07-21",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.11091",
		"pdf_url": "http://arxiv.org/pdf/2007.11091.pdf"
	},
	"370": {
		"title": "A Parallel Evolutionary Multiple-Try Metropolis Markov Chain Monte Carlo\n  Algorithm for Sampling Spatial Partitions",
		"creator": [
			"Cho, Wendy K. Tam",
			"Liu, Yan Y."
		],
		"subject": [
			"Statistics - Computation",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  We develop an Evolutionary Markov Chain Monte Carlo (EMCMC) algorithm for\nsampling spatial partitions that lie within a large and complex spatial state\nspace. Our algorithm combines the advantages of evolutionary algorithms (EAs)\nas optimization heuristics for state space traversal and the theoretical\nconvergence properties of Markov Chain Monte Carlo algorithms for sampling from\nunknown distributions. Local optimality information that is identified via a\ndirected search by our optimization heuristic is used to adaptively update a\nMarkov chain in a promising direction within the framework of a Multiple-Try\nMetropolis Markov Chain model that incorporates a generalized\nMetropolis-Hasting ratio. We further expand the reach of our EMCMC algorithm by\nharnessing the computational power afforded by massively parallel architecture\nthrough the integration of a parallel EA framework that guides Markov chains\nrunning in parallel.\n",
		"date": "2020-07-22",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2007.11461",
			"Statistics and Computing 31, Article 10 (2021)",
			"doi:10.1007/s11222-020-09977-z"
		],
		"pdf_url": "http://arxiv.org/pdf/2007.11461.pdf"
	},
	"371": {
		"title": "An integral-based spectral method for inextensible slender fibers in\n  Stokes flow",
		"creator": [
			"Maxian, Ondrej",
			"Mogilner, Alex",
			"Donev, Aleksandar"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"65M70, 65R20, 76Z05, 76D07"
		],
		"description": [
			"  Every animal cell is filled with a cytoskeleton, a dynamic gel made of\ninextensible fibers, such as microtubules, actin fibers, and intermediate\nfilaments, all suspended in a viscous fluid. Numerical simulation of this gel\nis challenging because the fiber aspect ratios can be as large as $10^4$. We\ndescribe a new method for rapidly computing the dynamics of inextensible\nslender filaments in periodically-sheared Stokes flow. The dynamics of the\nfilaments are governed by a nonlocal slender body theory which we partially\nreformulate in terms of the Rotne-Prager-Yamakawa hydrodynamic tensor. To\nenforce inextensibility, we parameterize the space of inextensible fiber\nmotions and strictly confine the dynamics to the manifold of inextensible\nconfigurations. To do this, we introduce a set of Lagrange multipliers for the\ntensile force densities on the filaments and impose the constraint of no\nvirtual work in an $L^2$ weak sense. We augment this approach with a spectral\ndiscretization of the local and nonlocal slender body theory operators which is\nlinear in the number of unknowns and gives improved spatial accuracy over\napproaches based on solving a line tension equation. For dynamics, we develop a\nsecond-order semi-implicit temporal integrator which requires at most a few\nevaluations of nonlocal hydrodynamics and a few block diagonal linear solves\nper time step. After demonstrating the improved accuracy and robustness of our\napproach through numerical examples, we apply our formulation to a permanently\ncross-linked actin mesh in a background oscillatory shear flow. We observe a\ncharacteristic frequency at which the network transitions from quasi-static,\nprimarily elastic behavior to dynamic, primarily viscous behavior. We find that\nnonlocal hydrodynamics increases the viscous modulus by as much as 25%, even\nfor semi-dilute fiber suspensions.\n",
			"Comment: 84 pages, 12 figures"
		],
		"date": [
			"2020-07-22",
			"2020-10-28"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2007.11728",
			"Phys. Rev. Fluids 6, 014102 (2021)",
			"doi:10.1103/PhysRevFluids.6.014102"
		],
		"pdf_url": "http://arxiv.org/pdf/2007.11728.pdf"
	},
	"372": {
		"title": "Performance-Driven Cascade Controller Tuning with Bayesian Optimization",
		"creator": [
			"Khosravi, Mohammad",
			"Behrunani, Varsha",
			"Myszkorowski, Piotr",
			"Smith, Roy S.",
			"Rupenyan, Alisa",
			"Lygeros, John"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  We propose a performance-based autotuning method for cascade control systems,\nwhere the parameters of a linear axis drive motion controller from two control\nloops are tuned jointly. Using Bayesian optimization as all parameters are\ntuned simultaneously, the method is guaranteed to converge asymptotically to\nthe global optimum of the cost. The data-efficiency and performance of the\nmethod are studied numerically for several training configurations and compared\nnumerically to those achieved with classical tuning methods and to the\nexhaustive evaluation of the cost. On the real system, the tracking performance\nand robustness against disturbances are compared experimentally to nominal\ntuning. The numerical study and the experimental data both demonstrate that the\nproposed automated tuning method is efficient in terms of required tuning\niterations, robust to disturbances, and results in improved tracking.\n",
			"Comment: 9 pages, 9 figures"
		],
		"date": "2020-07-24",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2007.12536",
			"doi:10.1109/TIE.2021.3050356"
		],
		"pdf_url": "http://arxiv.org/pdf/2007.12536.pdf"
	},
	"373": {
		"title": "Maximum Mutation Reinforcement Learning for Scalable Control",
		"creator": [
			"Suri, Karush",
			"Shi, Xiao Qi",
			"Plataniotis, Konstantinos N.",
			"Lawryshyn, Yuri A."
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Neural and Evolutionary Computing",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Advances in Reinforcement Learning (RL) have demonstrated data efficiency and\noptimal control over large state spaces at the cost of scalable performance.\nGenetic methods, on the other hand, provide scalability but depict\nhyperparameter sensitivity towards evolutionary operations. However, a\ncombination of the two methods has recently demonstrated success in scaling RL\nagents to high-dimensional action spaces. Parallel to recent developments, we\npresent the Evolution-based Soft Actor-Critic (ESAC), a scalable RL algorithm.\nWe abstract exploration from exploitation by combining Evolution Strategies\n(ES) with Soft Actor-Critic (SAC). Through this lens, we enable dominant skill\ntransfer between offsprings by making use of soft winner selections and genetic\ncrossovers in hindsight and simultaneously improve hyperparameter sensitivity\nin evolutions using the novel Automatic Mutation Tuning (AMT). AMT gradually\nreplaces the entropy framework of SAC allowing the population to succeed at the\ntask while acting as randomly as possible, without making use of\nbackpropagation updates. In a study of challenging locomotion tasks consisting\nof high-dimensional action spaces and sparse rewards, ESAC demonstrates\nimproved performance and sample efficiency in comparison to the Maximum Entropy\nframework. Additionally, ESAC presents efficacious use of hardware resources\nand algorithm overhead. A complete implementation of ESAC can be found at\nkarush17.github.io/esac-web/.\n",
			"Comment: 10+3 Pages"
		],
		"date": [
			"2020-07-24",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.13690",
		"pdf_url": "http://arxiv.org/pdf/2007.13690.pdf"
	},
	"374": {
		"title": "From Sound Representation to Model Robustness",
		"creator": [
			"Esmaeilpour, Mohammad",
			"Cardinal, Patrick",
			"Koerich, Alessandro Lameiras"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Audio and Speech Processing",
			"Computer Science - Machine Learning",
			"Computer Science - Sound"
		],
		"description": [
			"  In this paper, we investigate the impact of different standard environmental\nsound representations (spectrograms) on the recognition performance and\nadversarial attack robustness of a victim residual convolutional neural\nnetwork. Averaged over various experiments on three benchmarking environmental\nsound datasets, we found the ResNet-18 model outperforms other deep learning\narchitectures such as GoogLeNet and AlexNet both in terms of classification\naccuracy and the number of training parameters. Therefore we set this model as\nour front-end classifier for subsequent investigations. Herein, we measure the\nimpact of different settings required for generating more informative\nmel-frequency cepstral coefficient (MFCC), short-time Fourier transform (STFT),\nand discrete wavelet transform (DWT) representations on our front-end model.\nThis measurement involves comparing the classification performance over the\nadversarial robustness. On the balance of average budgets allocated by\nadversary and the cost of attack, we demonstrate an inverse relationship\nbetween recognition accuracy and model robustness against six attack\nalgorithms. Moreover, our experimental results show that while the ResNet-18\nmodel trained on DWT spectrograms achieves the highest recognition accuracy,\nattacking this model is relatively more costly for the adversary compared to\nother 2D representations.\n",
			"Comment: 12 pages"
		],
		"date": [
			"2020-07-27",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.13703",
		"pdf_url": "http://arxiv.org/pdf/2007.13703.pdf"
	},
	"375": {
		"title": "UAV-Assisted Intelligent Reflecting Surface Symbiotic Radio System",
		"creator": [
			"Hua, Meng",
			"Yang, Luxi",
			"Wu, Qingqing",
			"Pan, Cunhua",
			"Li, Chunguo",
			"Swindlehurst, A. Lee"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Signal Processing",
			"Computer Science - Information Theory"
		],
		"description": [
			"  This paper investigates a symbiotic unmanned aerial vehicle (UAV)-assisted\nintelligent reflecting surface (IRS) radio system, where the UAV is leveraged\nto help the IRS reflect its own signals to the base station, and meanwhile\nenhance the UAV transmission by passive beamforming at the IRS. First, we\nconsider the weighted sum bit error rate (BER) minimization problem among all\nIRSs by jointly optimizing the UAV trajectory, IRS phase shift matrix, and IRS\nscheduling, subject to the minimum primary rate requirements. To tackle this\ncomplicated problem, a relaxation-based algorithm is proposed. We prove that\nthe converged relaxation scheduling variables are binary, which means that no\nreconstruct strategy is needed, and thus the UAV rate constraints are\nautomatically satisfied. Second, we consider the fairness BER optimization\nproblem. We find that the relaxation-based method cannot solve this fairness\nBER problem since the minimum primary rate requirements may not be satisfied by\nthe binary reconstruction operation. To address this issue, we first transform\nthe binary constraints into a series of equivalent equality constraints. Then,\na penalty-based algorithm is proposed to obtain a suboptimal solution.\nNumerical results are provided to evaluate the performance of the proposed\ndesigns under different setups, as compared with benchmarks.\n",
			"Comment: This paper a preprinted version, which has been submitted to IEEE\n  journal"
		],
		"date": [
			"2020-07-28",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.14029",
		"pdf_url": "http://arxiv.org/pdf/2007.14029.pdf"
	},
	"376": {
		"title": "A Probabilistic Approach to Driver Assistance for Delay Reduction at\n  Congested Highway Lane Drops",
		"creator": [
			"Mehr, Goodarz",
			"Eskandarian, Azim"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  This paper proposes an onboard advance warning system based on a\nprobabilistic prediction model that advises vehicles on when to change lanes\nfor an upcoming lane drop. Using several traffic- and driver-related parameters\nsuch as the distribution of inter-vehicle headway distances, the prediction\nmodel calculates the likelihood of utilizing one or multiple lane changes to\nsuccessfully reach a target position on the road. When approaching a lane drop,\nthe onboard system projects current vehicle conditions into the future and uses\nthe model to continuously estimate the success probability of changing lanes\nbefore reaching the lane-end, and advises the driver or autonomous vehicle to\nstart a lane changing maneuver when that probability drops below a certain\nthreshold. In a simulation case study, the proposed system was used on a\nsegment of the I-81 interstate highway with two lane drops - transitioning from\nfour lanes to two lanes - to advise vehicles on avoiding the lane drops. The\nresults indicate that the proposed system can reduce average delay by up to 50%\nand maximum delay by up to 33%, depending on traffic flow and the ratio of\nvehicles equipped with the advance warning system.\n",
			"Comment: Manuscript accepted for publication in the International Journal of\n  Transportation Science and Technology. This manuscript version is made\n  available under the CC-BY-NC-ND 4.0 license\n  (http://creativecommons.org/licenses/by-nc-nd/4.0/)"
		],
		"date": [
			"2020-07-26",
			"2021-01-17"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2007.14232",
			"doi:10.1016/j.ijtst.2020.10.002"
		],
		"pdf_url": "http://arxiv.org/pdf/2007.14232.pdf"
	},
	"377": {
		"title": "Toward Agile Maneuvers in Highly Constrained Spaces: Learning from\n  Hallucination",
		"creator": [
			"Xiao, Xuesu",
			"Liu, Bo",
			"Warnell, Garrett",
			"Stone, Peter"
		],
		"subject": "Computer Science - Robotics",
		"description": [
			"  While classical approaches to autonomous robot navigation currently enable\noperation in certain environments, they break down in tightly constrained\nspaces, e.g., where the robot needs to engage in agile maneuvers to squeeze\nbetween obstacles. Recent machine learning techniques have the potential to\naddress this shortcoming, but existing approaches require vast amounts of\nnavigation experience for training, during which the robot must operate in\nclose proximity to obstacles and risk collision. In this paper, we propose to\nside-step this requirement by introducing a new machine learning paradigm for\nautonomous navigation called learning from hallucination (LfH), which can use\ntraining data collected in completely safe environments to compute navigation\ncontrollers that result in fast, smooth, and safe navigation in highly\nconstrained environments. Our experimental results show that the proposed LfH\nsystem outperforms three autonomous navigation baselines on a real robot and\ngeneralizes well to unseen environments, including those based on both\nclassical and machine learning techniques.\n",
			"Comment: Accepted by IEEE Robotics and Automation Letters (RA-L)"
		],
		"date": [
			"2020-07-28",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.14479",
		"pdf_url": "http://arxiv.org/pdf/2007.14479.pdf"
	},
	"378": {
		"title": "Video compression with low complexity CNN-based spatial resolution\n  adaptation",
		"creator": [
			"Ma, Di",
			"Zhang, Fan",
			"Bull, David R."
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"Computer Science - Multimedia"
		],
		"description": "  It has recently been demonstrated that spatial resolution adaptation can be\nintegrated within video compression to improve overall coding performance by\nspatially down-sampling before encoding and super-resolving at the decoder.\nSignificant improvements have been reported when convolutional neural networks\n(CNNs) were used to perform the resolution up-sampling. However, this approach\nsuffers from high complexity at the decoder due to the employment of CNN-based\nsuper-resolution. In this paper, a novel framework is proposed which supports\nthe flexible allocation of complexity between the encoder and decoder. This\napproach employs a CNN model for video down-sampling at the encoder and uses a\nLanczos3 filter to reconstruct full resolution at the decoder. The proposed\nmethod was integrated into the HEVC HM 16.20 software and evaluated on JVET UHD\ntest sequences using the All Intra configuration. The experimental results\ndemonstrate the potential of the proposed approach, with significant bitrate\nsavings (more than 10%) over the original HEVC HM, coupled with reduced\ncomputational complexity at both encoder (29%) and decoder (10%).\n",
		"date": "2020-07-29",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2007.14726",
			"doi:10.1117/12.2567633"
		],
		"pdf_url": "http://arxiv.org/pdf/2007.14726.pdf"
	},
	"379": {
		"title": "Mirostat: A Neural Text Decoding Algorithm that Directly Controls\n  Perplexity",
		"creator": [
			"Basu, Sourya",
			"Ramachandran, Govardana Sachitanandam",
			"Keskar, Nitish Shirish",
			"Varshney, Lav R."
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Information Theory"
		],
		"description": [
			"  Neural text decoding is important for generating high-quality texts using\nlanguage models. To generate high-quality text, popular decoding algorithms\nlike top-k, top-p (nucleus), and temperature-based sampling truncate or distort\nthe unreliable low probability tail of the language model. Though these methods\ngenerate high-quality text after parameter tuning, they are ad hoc. Not much is\nknown about the control they provide over the statistics of the output, which\nis important since recent reports show text quality is highest for a specific\nrange of likelihoods. Here, first we provide a theoretical analysis of\nperplexity in top-k, top-p, and temperature sampling, finding that\ncross-entropy behaves approximately linearly as a function of p in top-p\nsampling whereas it is a nonlinear function of k in top-k sampling, under\nZipfian statistics. We use this analysis to design a feedback-based adaptive\ntop-k text decoding algorithm called mirostat that generates text (of any\nlength) with a predetermined value of perplexity, and thereby high-quality text\nwithout any tuning. Experiments show that for low values of k and p in top-k\nand top-p sampling, perplexity drops significantly with generated text length,\nwhich is also correlated with excessive repetitions in the text (the boredom\ntrap). On the other hand, for large values of k and p, we find that perplexity\nincreases with generated text length, which is correlated with incoherence in\nthe text (confusion trap). Mirostat avoids both traps: experiments show that\ncross-entropy has a near-linear relation with repetition in generated text.\nThis relation is almost independent of the sampling method but slightly\ndependent on the model used. Hence, for a given language model, control over\nperplexity also gives control over repetitions. Experiments with human raters\nfor fluency, coherence, and quality further verify our findings.\n",
			"Comment: 25 pages, 12 figures"
		],
		"date": [
			"2020-07-29",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.14966",
		"pdf_url": "http://arxiv.org/pdf/2007.14966.pdf"
	},
	"380": {
		"title": "Robust and Heavy-Tailed Mean Estimation Made Simple, via Regret\n  Minimization",
		"creator": [
			"Hopkins, Samuel B.",
			"Li, Jerry",
			"Zhang, Fred"
		],
		"subject": [
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Machine Learning",
			"Mathematics - Statistics Theory",
			"Statistics - Machine Learning"
		],
		"description": [
			"  We study the problem of estimating the mean of a distribution in high\ndimensions when either the samples are adversarially corrupted or the\ndistribution is heavy-tailed. Recent developments in robust statistics have\nestablished efficient and (near) optimal procedures for both settings. However,\nthe algorithms developed on each side tend to be sophisticated and do not\ndirectly transfer to the other, with many of them having ad-hoc or complicated\nanalyses.\n  In this paper, we provide a meta-problem and a duality theorem that lead to a\nnew unified view on robust and heavy-tailed mean estimation in high dimensions.\nWe show that the meta-problem can be solved either by a variant of the Filter\nalgorithm from the recent literature on robust estimation or by the quantum\nentropy scoring scheme (QUE), due to Dong, Hopkins and Li (NeurIPS '19). By\nleveraging our duality theorem, these results translate into simple and\nefficient algorithms for both robust and heavy-tailed settings. Furthermore,\nthe QUE-based procedure has run-time that matches the fastest known algorithms\non both fronts.\n  Our analysis of Filter is through the classic regret bound of the\nmultiplicative weights update method. This connection allows us to avoid the\ntechnical complications in previous works and improve upon the run-time\nanalysis of a gradient-descent-based algorithm for robust mean estimation by\nCheng, Diakonikolas, Ge and Soltanolkotabi (ICML '20).\n",
			"Comment: 40 pages"
		],
		"date": [
			"2020-07-31",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2007.15839",
		"pdf_url": "http://arxiv.org/pdf/2007.15839.pdf"
	},
	"381": {
		"title": "Relation-aware Meta-learning for Market Segment Demand Prediction with\n  Limited Records",
		"creator": [
			"Shi, Jiatu",
			"Yao, Huaxiu",
			"Wu, Xian",
			"Li, Tong",
			"Lin, Zedong",
			"Wang, Tengfei",
			"Zhao, Binqiang"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Information Retrieval"
		],
		"description": [
			"  E-commerce business is revolutionizing our shopping experiences by providing\nconvenient and straightforward services. One of the most fundamental problems\nis how to balance the demand and supply in market segments to build an\nefficient platform. While conventional machine learning models have achieved\ngreat success on data-sufficient segments, it may fail in a large-portion of\nsegments in E-commerce platforms, where there are not sufficient records to\nlearn well-trained models. In this paper, we tackle this problem in the context\nof market segment demand prediction. The goal is to facilitate the learning\nprocess in the target segments by leveraging the learned knowledge from\ndata-sufficient source segments. Specifically, we propose a novel algorithm,\nRMLDP, to incorporate a multi-pattern fusion network (MPFN) with a\nmeta-learning paradigm. The multi-pattern fusion network considers both local\nand seasonal temporal patterns for segment demand prediction. In the\nmeta-learning paradigm, transferable knowledge is regarded as the model\nparameter initialization of MPFN, which are learned from diverse source\nsegments. Furthermore, we capture the segment relations by combining\ndata-driven segment representation and segment knowledge graph representation\nand tailor the segment-specific relations to customize transferable model\nparameter initialization. Thus, even with limited data, the target segment can\nquickly find the most relevant transferred knowledge and adapt to the optimal\nparameters. We conduct extensive experiments on two large-scale industrial\ndatasets. The results justify that our RMLDP outperforms a set of\nstate-of-the-art baselines. Besides, RMLDP has been deployed in Taobao, a\nreal-world E-commerce platform. The online A/B testing results further\ndemonstrate the practicality of RMLDP.\n",
			"Comment: First two authors contributed equally; Accepted by WSDM 2021"
		],
		"date": [
			"2020-08-01",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2008.00181",
		"pdf_url": "http://arxiv.org/pdf/2008.00181.pdf"
	},
	"382": {
		"title": "Semi-supervised deep learning based on label propagation in a 2D\n  embedded space",
		"creator": [
			"Benato, Barbara Caroline",
			"Gomes, Jancarlo Ferreira",
			"Telea, Alexandru Cristian",
			"Falcão, Alexandre Xavier"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"68T07, 68T09, 68T10",
			"I.5.1",
			"I.5.2"
		],
		"description": [
			"  While convolutional neural networks need large labeled sets for training\nimages, expert human supervision of such datasets can be very laborious.\nProposed solutions propagate labels from a small set of supervised images to a\nlarge set of unsupervised ones to obtain sufficient truly-and-artificially\nlabeled samples to train a deep neural network model. Yet, such solutions need\nmany supervised images for validation. We present a loop in which a deep neural\nnetwork (VGG-16) is trained from a set with more correctly labeled samples\nalong iterations, created by using t-SNE to project the features of its last\nmax-pooling layer into a 2D embedded space in which labels are propagated using\nthe Optimum-Path Forest semi-supervised classifier. As the labeled set improves\nalong iterations, it improves the features of the neural network. We show that\nthis can significantly improve classification results on test data (using only\n1\\% to 5\\% of supervised samples) of three private challenging datasets and two\npublic ones.\n",
			"Comment: 7 pages, 5 figures"
		],
		"date": [
			"2020-08-02",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2008.00558",
		"pdf_url": "http://arxiv.org/pdf/2008.00558.pdf"
	},
	"383": {
		"title": "Public risk perception and emotion on Twitter during the Covid-19\n  pandemic",
		"creator": [
			"Dyer, Joel",
			"Kolic, Blas"
		],
		"subject": [
			"Computer Science - Social and Information Networks",
			"Computer Science - Computers and Society",
			"62P15, 91D30",
			"J.4"
		],
		"description": [
			"  Successful navigation of the Covid-19 pandemic is predicated on public\ncooperation with safety measures and appropriate perception of risk, in which\nemotion and attention play important roles. Signatures of public emotion and\nattention are present in social media data, thus natural language analysis of\nthis text enables near-to-real-time monitoring of indicators of public risk\nperception. We compare key epidemiological indicators of the progression of the\npandemic with indicators of the public perception of the pandemic constructed\nfrom ~20 million unique Covid-19-related tweets from 12 countries posted\nbetween 10th March -- 14th June 2020. We find evidence of psychophysical\nnumbing: Twitter users increasingly fixate on mortality, but in a decreasingly\nemotional and increasingly analytic tone. Semantic network analysis based on\nword co-occurrences reveals changes in the emotional framing of Covid-19\ncasualties that are consistent with this hypothesis. We also find that the\naverage attention afforded to national Covid-19 mortality rates is modelled\naccurately with the Weber-Fechner and power law functions of sensory\nperception. Our parameter estimates for these models are consistent with\nestimates from psychological experiments, and indicate that users in this\ndataset exhibit differential sensitivity by country to the national Covid-19\ndeath rates. Our work illustrates the potential utility of social media for\nmonitoring public risk perception and guiding public communication during\ncrisis scenarios.\n",
			"Comment: 29 pages (main text: 19 pages; supplementary material: 10 pages), 9\n  Figures"
		],
		"date": [
			"2020-08-03",
			"2020-12-07"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2008.00854",
			"Appl Netw Sci 5, 99 (2020)",
			"doi:10.1007/s41109-020-00334-7"
		],
		"pdf_url": "http://arxiv.org/pdf/2008.00854.pdf"
	},
	"384": {
		"title": "Swipe dynamics as a means of authentication: results from a Bayesian\n  unsupervised approach",
		"creator": [
			"Lamb, Parker",
			"Millar, Alexander",
			"Fuentes, Ramon"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Statistics - Applications"
		],
		"description": [
			"  The field of behavioural biometrics stands as an appealing alternative to\nmore traditional biometric systems due to the ease of use from a user\nperspective and potential robustness to presentation attacks. This paper\nfocuses its attention to a specific type of behavioural biometric utilising\nswipe dynamics, also referred to as touch gestures. In touch gesture\nauthentication, a user swipes across the touchscreen of a mobile device to\nperform an authentication attempt. A key characteristic of touch gesture\nauthentication and new behavioural biometrics in general is the lack of\navailable data to train and validate models. From a machine learning\nperspective, this presents the classic curse of dimensionality problem and the\nmethodology presented here focuses on Bayesian unsupervised models as they are\nwell suited to such conditions. This paper presents results from a set of\nexperiments consisting of 38 sessions with labelled victim as well as blind and\nover-the-shoulder presentation attacks. Three models are compared using this\ndataset; two single-mode models: a shrunk covariance estimate and a Bayesian\nGaussian distribution, as well as a Bayesian non-parametric infinite mixture of\nGaussians, modelled as a Dirichlet Process. Equal error rates (EER) for the\nthree models are compared and attention is paid to how these vary across the\ntwo single-mode models at differing numbers of enrolment samples.\n",
			"Comment: 9 pages, 7 figures; Layout and editing improved"
		],
		"date": [
			"2020-07-27",
			"2020-10-13"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2008.01013",
			"doi:10.1109/IJCB48548.2020.9304876"
		],
		"pdf_url": "http://arxiv.org/pdf/2008.01013.pdf"
	},
	"385": {
		"title": "E-Tree Learning: A Novel Decentralized Model Learning Framework for Edge\n  AI",
		"creator": [
			"Yang, Lei",
			"Lu, Yanyan",
			"Cao, Jiannong",
			"Huang, Jiaming",
			"Zhang, Mingjin"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Traditionally, AI models are trained on the central cloud with data collected\nfrom end devices. This leads to high communication cost, long response time and\nprivacy concerns. Recently Edge empowered AI, namely Edge AI, has been proposed\nto support AI model learning and deployment at the network edge closer to the\ndata sources. Existing research including federated learning adopts a\ncentralized architecture for model learning where a central server aggregates\nthe model updates from the clients/workers. The centralized architecture has\ndrawbacks such as performance bottleneck, poor scalability and single point of\nfailure. In this paper, we propose a novel decentralized model learning\napproach, namely E-Tree, which makes use of a well-designed tree structure\nimposed on the edge devices. The tree structure and the locations and orders of\naggregation on the tree are optimally designed to improve the training\nconvergency and model accuracy. In particular, we design an efficient device\nclustering algorithm, named by KMA, for E-Tree by taking into account the data\ndistribution on the devices as well as the the network distance. Evaluation\nresults show E-Tree significantly outperforms the benchmark approaches such as\nfederated learning and Gossip learning under NonIID data in terms of model\naccuracy and convergency.\n",
			"Comment: IEEE Internet of Things Journal, 2020"
		],
		"date": [
			"2020-08-04",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2008.01553",
			"doi:10.1109/JIOT.2021.3052195"
		],
		"pdf_url": "http://arxiv.org/pdf/2008.01553.pdf"
	},
	"386": {
		"title": "MORTON: Detection of Malicious Routines in Large-Scale DNS Traffic",
		"creator": [
			"Daihes, Yael",
			"Tzaban, Hen",
			"Nadler, Asaf",
			"Shabtai, Asaf"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": "  In this paper, we present MORTON, a method that identifies compromised\ndevices in enterprise networks based on the existence of routine DNS\ncommunication between devices and disreputable host names. With its compact\nrepresentation of the input data and use of efficient signal processing and a\nneural network for classification, MORTON is designed to be accurate, robust,\nand scalable. We evaluate MORTON using a large dataset of corporate DNS logs\nand compare it with two recently proposed beaconing detection methods aimed at\ndetecting malware communication. The results demonstrate that while MORTON's\naccuracy in a synthetic experiment is comparable to that of the other methods,\nit outperforms those methods in terms of its ability to detect sophisticated\nbot communication techniques, such as multistage channels, as well as in its\nrobustness and efficiency. In a real-world evaluation, which includes\npreviously unreported threats, MORTON and the two compared methods were\ndeployed to monitor the (unlabeled) DNS traffic of two global enterprises for a\nweek-long period; this evaluation demonstrates the effectiveness of MORTON in\nreal-world scenarios and showcases its superiority in terms of true and false\npositive rates.\n",
		"date": [
			"2020-08-05",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2008.02003",
		"pdf_url": "http://arxiv.org/pdf/2008.02003.pdf"
	},
	"387": {
		"title": "Neural Light Transport for Relighting and View Synthesis",
		"creator": [
			"Zhang, Xiuming",
			"Fanello, Sean",
			"Tsai, Yun-Ta",
			"Sun, Tiancheng",
			"Xue, Tianfan",
			"Pandey, Rohit",
			"Orts-Escolano, Sergio",
			"Davidson, Philip",
			"Rhemann, Christoph",
			"Debevec, Paul",
			"Barron, Jonathan T.",
			"Ramamoorthi, Ravi",
			"Freeman, William T."
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Graphics"
		],
		"description": [
			"  The light transport (LT) of a scene describes how it appears under different\nlighting and viewing directions, and complete knowledge of a scene's LT enables\nthe synthesis of novel views under arbitrary lighting. In this paper, we focus\non image-based LT acquisition, primarily for human bodies within a light stage\nsetup. We propose a semi-parametric approach to learn a neural representation\nof LT that is embedded in the space of a texture atlas of known geometric\nproperties, and model all non-diffuse and global LT as residuals added to a\nphysically-accurate diffuse base rendering. In particular, we show how to fuse\npreviously seen observations of illuminants and views to synthesize a new image\nof the same scene under a desired lighting condition from a chosen viewpoint.\nThis strategy allows the network to learn complex material effects (such as\nsubsurface scattering) and global illumination, while guaranteeing the physical\ncorrectness of the diffuse LT (such as hard shadows). With this learned LT, one\ncan relight the scene photorealistically with a directional light or an HDRI\nmap, synthesize novel views with view-dependent effects, or do both\nsimultaneously, all in a unified framework using a set of sparse, previously\nseen observations. Qualitative and quantitative experiments demonstrate that\nour neural LT (NLT) outperforms state-of-the-art solutions for relighting and\nview synthesis, without separate treatment for both problems that prior work\nrequires.\n",
			"Comment: Camera-ready version for TOG 2021. Project Page:\n  http://nlt.csail.mit.edu/"
		],
		"date": [
			"2020-08-09",
			"2021-01-20"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2008.03806",
			"doi:10.1145/3446328"
		],
		"pdf_url": "http://arxiv.org/pdf/2008.03806.pdf"
	},
	"388": {
		"title": "Deep Sketch-guided Cartoon Video Inbetweening",
		"creator": [
			"Li, Xiaoyu",
			"Zhang, Bo",
			"Liao, Jing",
			"Sander, Pedro V."
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"I.2.6",
			"I.4.9"
		],
		"description": [
			"  We propose a novel framework to produce cartoon videos by fetching the color\ninformation from two input keyframes while following the animated motion guided\nby a user sketch. The key idea of the proposed approach is to estimate the\ndense cross-domain correspondence between the sketch and cartoon video frames,\nand employ a blending module with occlusion estimation to synthesize the middle\nframe guided by the sketch. After that, the input frames and the synthetic\nframe equipped with established correspondence are fed into an arbitrary-time\nframe interpolation pipeline to generate and refine additional inbetween\nframes. Finally, a module to preserve temporal consistency is employed.\nCompared to common frame interpolation methods, our approach can address frames\nwith relatively large motion and also has the flexibility to enable users to\ncontrol the generated video sequences by editing the sketch guidance. By\nexplicitly considering the correspondence between frames and the sketch, we can\nachieve higher quality results than other image synthesis methods. Our results\nshow that our system generalizes well to different movie frames, achieving\nbetter results than existing solutions.\n",
			"Comment: 15 pages, 16 figures"
		],
		"date": [
			"2020-08-10",
			"2021-01-18"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2008.04149",
			"doi:10.1109/TVCG.2021.3049419"
		],
		"pdf_url": "http://arxiv.org/pdf/2008.04149.pdf"
	},
	"389": {
		"title": "The Mathematical Foundations of Physical Systems Modeling Languages",
		"creator": [
			"Benveniste, Albert",
			"Caillaud, Benoît",
			"Malandain, Mathias"
		],
		"subject": "Computer Science - Programming Languages",
		"description": "  Modern modeling languages for general physical systems, such as Modelica,\nAmesim, or Simscape, rely on Differential Algebraic Equations (DAE), i.e.,\nconstraints of the form f(dot{x},x,u)=0. This drastically facilitates modeling\nfrom first principles of the physics and the reuse of models. In this paper we\ndevelop the mathematical theory needed to establish the development of\ncompilers and tools for DAE based physical modeling languages on solid\nmathematical bases. Unlike Ordinary Differential Equations, DAE exhibit subtle\nissues because of the notion of differentiation index and related latent\nequations -- ODE are DAE of index zero for which no latent equation needs to be\nconsidered. Prior to generating execution code and calling solvers, the\ncompilation of such languages requires a nontrivial \\emph{structural analysis}\nstep that reduces the differentiation index to a level acceptable by DAE\nsolvers. The models supported by tools of the Modelica class involve multiple\nmodes with mode-dependent DAE based dynamics and state-dependent mode\nswitching. Multimode DAE are much more difficult than DAE. The main difficulty\nis the handling of the events of mode change. Unfortunately, the large\nliterature devoted to the mathematical analysis of DAEs does not cover the\nmultimode case, typically saying nothing about mode changes. This lack of\nfoundations causes numerous difficulties to the existing modeling tools. Some\nmodels are well handled, others are not, with no clear boundary between the two\nclasses. In this paper, we develop a comprehensive mathematical approach\nsupporting compilation and code generation for this class of languages. Its\ncore is the structural analysis of multimode DAE systems. As a byproduct of\nthis structural analysis, we propose well sound criteria for accepting or\nrejecting models. For our mathematical development, we rely on nonstandard\nanalysis, which allows us to cast hybrid systems dynamics to discrete time\ndynamics with infinitesimal step size, thus providing a uniform framework for\nhandling both continuous dynamics and mode change events.\n",
		"date": [
			"2020-08-12",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2008.05166",
		"pdf_url": "http://arxiv.org/pdf/2008.05166.pdf"
	},
	"390": {
		"title": "Cautious Adaptation For Reinforcement Learning in Safety-Critical\n  Settings",
		"creator": [
			"Zhang, Jesse",
			"Cheung, Brian",
			"Finn, Chelsea",
			"Levine, Sergey",
			"Jayaraman, Dinesh"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Reinforcement learning (RL) in real-world safety-critical target settings\nlike urban driving is hazardous, imperiling the RL agent, other agents, and the\nenvironment. To overcome this difficulty, we propose a \"safety-critical\nadaptation\" task setting: an agent first trains in non-safety-critical \"source\"\nenvironments such as in a simulator, before it adapts to the target environment\nwhere failures carry heavy costs. We propose a solution approach, CARL, that\nbuilds on the intuition that prior experience in diverse environments equips an\nagent to estimate risk, which in turn enables relative safety through\nrisk-averse, cautious adaptation. CARL first employs model-based RL to train a\nprobabilistic model to capture uncertainty about transition dynamics and\ncatastrophic states across varied source environments. Then, when exploring a\nnew safety-critical environment with unknown dynamics, the CARL agent plans to\navoid actions that could lead to catastrophic states. In experiments on car\ndriving, cartpole balancing, half-cheetah locomotion, and robotic object\nmanipulation, CARL successfully acquires cautious exploration behaviors,\nyielding higher rewards with fewer failures than strong RL adaptation\nbaselines. Website at https://sites.google.com/berkeley.edu/carl.\n",
			"Comment: 15 pages, 8 figures, ICML 2020. Website with code:\n  https://sites.google.com/berkeley.edu/carl"
		],
		"date": "2020-08-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2008.06622",
			"Proceedings of the 37th International Conference on Machine\n  Learning, PMLR 119:11055-11065, 2020"
		],
		"pdf_url": "http://arxiv.org/pdf/2008.06622.pdf"
	},
	"391": {
		"title": "An efficient numerical method for condition number constrained\n  covariance matrix approximation",
		"creator": "Wang, Shaoxin",
		"subject": [
			"Mathematics - Numerical Analysis",
			"65F35, 15A12, 15A60"
		],
		"description": [
			"  In the high-dimensional data setting, the sample covariance matrix is\nsingular. In order to get a numerically stable and positive definite\nmodification of the sample covariance matrix in the high-dimensional data\nsetting, in this paper we consider the condition number constrained covariance\nmatrix approximation problem and present its explicit solution with respect to\nthe Frobenius norm. The condition number constraint guarantees the numerical\nstability and positive definiteness of the approximation form simultaneously.\nBy exploiting the special structure of the data matrix in the high-dimensional\ndata setting, we also propose some new algorithms based on efficient matrix\ndecomposition techniques. Numerical experiments are also given to show the\ncomputational efficiency of the proposed algorithms.\n",
			"Comment: 22 pages,3 figures, published by Applied Mathematics and Computation"
		],
		"date": [
			"2020-08-16",
			"2021-01-18"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2008.06851",
			"doi:10.1016/j.amc.2020.125925"
		],
		"pdf_url": "http://arxiv.org/pdf/2008.06851.pdf"
	},
	"392": {
		"title": "Population-Scale Study of Human Needs During the COVID-19 Pandemic:\n  Analysis and Implications",
		"creator": [
			"Suh, Jina",
			"Horvitz, Eric",
			"White, Ryen W.",
			"Althoff, Tim"
		],
		"subject": [
			"Computer Science - Computers and Society",
			"Computer Science - Information Retrieval"
		],
		"description": "  Most work to date on mitigating the COVID-19 pandemic is focused urgently on\nbiomedicine and epidemiology. Yet, pandemic-related policy decisions cannot be\nmade on health information alone. Decisions need to consider the broader\nimpacts on people and their needs. Quantifying human needs across the\npopulation is challenging as it requires high geo-temporal granularity, high\ncoverage across the population, and appropriate adjustment for seasonal and\nother external effects. Here, we propose a computational methodology, building\non Maslow's hierarchy of needs, that can capture a holistic view of relative\nchanges in needs following the pandemic through a difference-in-differences\napproach that corrects for seasonality and volume variations. We apply this\napproach to characterize changes in human needs across physiological,\nsocioeconomic, and psychological realms in the US, based on more than 35\nbillion search interactions spanning over 36,000 ZIP codes over a period of 14\nmonths. The analyses reveal that the expression of basic human needs has\nincreased exponentially while higher-level aspirations declined during the\npandemic in comparison to the pre-pandemic period. In exploring the timing and\nvariations in statewide policies, we find that the durations of\nshelter-in-place mandates have influenced social and emotional needs\nsignificantly. We demonstrate that potential barriers to addressing critical\nneeds, such as support for unemployment and domestic violence, can be\nidentified through web search interactions. Our approach and results suggest\nthat population-scale monitoring of shifts in human needs can inform policies\nand recovery efforts for current and anticipated needs.\n",
		"date": [
			"2020-08-16",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2008.07045",
		"pdf_url": "http://arxiv.org/pdf/2008.07045.pdf"
	},
	"393": {
		"title": "Ordinal Pattern Kernel for Brain Connectivity Network Classification",
		"creator": [
			"Ma, Kai",
			"Jie, Biao",
			"Zhang, Daoqiang"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Brain connectivity networks, which characterize the functional or structural\ninteraction of brain regions, has been widely used for brain disease\nclassification. Kernel-based method, such as graph kernel (i.e., kernel defined\non graphs), has been proposed for measuring the similarity of brain networks,\nand yields the promising classification performance. However, most of graph\nkernels are built on unweighted graph (i.e., network) with edge present or not,\nand neglecting the valuable weight information of edges in brain connectivity\nnetwork, with edge weights conveying the strengths of temporal correlation or\nfiber connection between brain regions. Accordingly, in this paper, we present\nan ordinal pattern kernel for brain connectivity network classification.\nDifferent with existing graph kernels that measures the topological similarity\nof unweighted graphs, the proposed ordinal pattern kernels calculate the\nsimilarity of weighted networks by comparing ordinal patterns from weighted\nnetworks.\n  To evaluate the effectiveness of the proposed ordinal kernel, we further\ndevelop a depth-first-based ordinal pattern kernel, and perform extensive\nexperiments in a real dataset of brain disease from ADNI database. The results\ndemonstrate that our proposed ordinal pattern kernel can achieve better\nclassification performance compared with state-of-the-art graph kernels.\n",
			"Comment: 10 pages, 3 figures"
		],
		"date": [
			"2020-08-17",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2008.07719",
		"pdf_url": "http://arxiv.org/pdf/2008.07719.pdf"
	},
	"394": {
		"title": "Bayesian geoacoustic inversion using mixture density network",
		"creator": [
			"Wu, Guoli",
			"Dong, Hefeng",
			"Song, Junqiang",
			"Zhang, Jingya"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning",
			"Physics - Geophysics"
		],
		"description": "  Bayesian geoacoustic inversion problems are conventionally solved by Markov\nchain Monte Carlo methods or its variants, which are computationally expensive.\nThis paper extends the classic Bayesian geoacoustic inversion framework by\nderiving important geoacoustic statistics of Bayesian geoacoustic inversion\nfrom the multidimensional posterior probability density (PPD) using the mixture\ndensity network (MDN) theory. These statistics make it convenient to train the\nnetwork directly on the whole parameter space and get the multidimensional PPD\nof model parameters. The present approach provides a much more efficient way to\nsolve geoacoustic inversion problems in Bayesian inference framework. The\nnetwork is trained on a simulated dataset of surface-wave dispersion curves\nwith shear-wave velocities as labels and tested on both synthetic and real data\ncases. The results show that the network gives reliable predictions and has\ngood generalization performance on unseen data. Once trained, the network can\nrapidly (within seconds) give a fully probabilistic solution which is\ncomparable to Monte Carlo methods. It provides an promising approach for\nreal-time inversion.\n",
		"date": [
			"2020-08-18",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2008.07902",
		"pdf_url": "http://arxiv.org/pdf/2008.07902.pdf"
	},
	"395": {
		"title": "Reliable Traffic Monitoring Mechanisms Based on Blockchain in Vehicular\n  Networks",
		"creator": [
			"Guo, Jianxiong",
			"Ding, Xingjian",
			"Wu, Weili"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Computer Science - Computer Science and Game Theory"
		],
		"description": [
			"  The real-time traffic monitoring is a fundamental mission in a smart city to\nunderstand traffic conditions and avoid dangerous incidents. In this paper, we\npropose a reliable and efficient traffic monitoring system that integrates\nblockchain and the Internet of vehicles technologies effectively. It can\ncrowdsource its tasks of traffic information collection to vehicles that run on\nthe road instead of installing cameras in every corner. First, we design a\nlightweight blockchain-based information trading framework to model the\ninteractions between traffic administration and vehicles. It guarantees\nreliability, efficiency, and security during executing trading. Second, we\ndefine the utility functions for the entities in this system and come up with a\nbudgeted auction mechanism that motivates vehicles to undertake the collection\ntasks actively. In our algorithm, it not only ensures that the total payment to\nthe selected vehicles does not exceed a given budget, but also maintains the\ntruthfulness of auction process that avoids some vehicles to offer unreal bids\nfor getting greater utilities. Finally, we conduct a group of numerical\nsimulations to evaluate the reliability of our trading framework and\nperformance of our algorithms, whose results demonstrate their correctness and\nefficiency perfectly.\n",
			"Comment: in IEEE Transactions on Reliability"
		],
		"date": "2020-08-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2008.08761",
			"doi:10.1109/TR.2020.3046556"
		],
		"pdf_url": "http://arxiv.org/pdf/2008.08761.pdf"
	},
	"396": {
		"title": "Image quality assessment for closed-loop computer-assisted lung\n  ultrasound",
		"creator": [
			"Baum, Zachary M C",
			"Bonmati, Ester",
			"Cristoni, Lorenzo",
			"Walden, Andrew",
			"Prados, Ferran",
			"Kanber, Baris",
			"Barratt, Dean C",
			"Hawkes, David J",
			"Parker, Geoffrey J M",
			"Wheeler-Kingshott, Claudia A M Gandini",
			"Hu, Yipeng"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  We describe a novel, two-stage computer assistance system for lung anomaly\ndetection using ultrasound imaging in the intensive care setting to improve\noperator performance and patient stratification during coronavirus pandemics.\nThe proposed system consists of two deep-learning-based models: a quality\nassessment module that automates predictions of image quality, and a diagnosis\nassistance module that determines the likelihood-oh-anomaly in ultrasound\nimages of sufficient quality. Our two-stage strategy uses a novelty detection\nalgorithm to address the lack of control cases available for training the\nquality assessment classifier. The diagnosis assistance module can then be\ntrained with data that are deemed of sufficient quality, guaranteed by the\nclosed-loop feedback mechanism from the quality assessment module. Using more\nthan 25000 ultrasound images from 37 COVID-19-positive patients scanned at two\nhospitals, plus 12 control cases, this study demonstrates the feasibility of\nusing the proposed machine learning approach. We report an accuracy of 86% when\nclassifying between sufficient and insufficient quality images by the quality\nassessment module. For data of sufficient quality - as determined by the\nquality assessment module - the mean classification accuracy, sensitivity, and\nspecificity in detecting COVID-19-positive cases were 0.95, 0.91, and 0.97,\nrespectively, across five holdout test data sets unseen during the training of\nany networks within the proposed system. Overall, the integration of the two\nmodules yields accurate, fast, and practical acquisition guidance and\ndiagnostic assistance for patients with suspected respiratory conditions at\npoint-of-care.\n",
			"Comment: 7 pages, 3 figures - Accepted to SPIE Medical Imaging 2021"
		],
		"date": [
			"2020-08-20",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2008.08840",
		"pdf_url": "http://arxiv.org/pdf/2008.08840.pdf"
	},
	"397": {
		"title": "TAnoGAN: Time Series Anomaly Detection with Generative Adversarial\n  Networks",
		"creator": [
			"Bashar, Md Abul",
			"Nayak, Richi"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Anomaly detection in time series data is a significant problem faced in many\napplication areas such as manufacturing, medical imaging and cyber-security.\nRecently, Generative Adversarial Networks (GAN) have gained attention for\ngeneration and anomaly detection in image domain. In this paper, we propose a\nnovel GAN-based unsupervised method called TAnoGan for detecting anomalies in\ntime series when a small number of data points are available. We evaluate\nTAnoGan with 46 real-world time series datasets that cover a variety of\ndomains. Extensive experimental results show that TAnoGan performs better than\ntraditional and neural network models.\n",
			"Comment: Made some minor changes. This is the accepted version of the paper at\n  AusDM'20"
		],
		"date": [
			"2020-08-21",
			"2020-09-24"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2008.09567",
			"2020 IEEE Symposium Series on Computational Intelligence (SSCI)",
			"doi:10.1109/SSCI47803.2020.9308512"
		],
		"pdf_url": "http://arxiv.org/pdf/2008.09567.pdf"
	},
	"398": {
		"title": "DNN2LR: Interpretation-inspired Feature Crossing for Real-world Tabular\n  Data",
		"creator": [
			"Liu, Zhaocheng",
			"Liu, Qiang",
			"Zhang, Haoli",
			"Chen, Yuntian"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  For sake of reliability, it is necessary for models in real-world\napplications to be both powerful and globally interpretable. Simple\nclassifiers, e.g., Logistic Regression (LR), are globally interpretable, but\nnot powerful enough to model complex nonlinear interactions among features in\ntabular data. Meanwhile, Deep Neural Networks (DNNs) have shown great\neffectiveness for modeling tabular data, but is not globally interpretable. In\nthis work, we find local piece-wise interpretations in DNN of a specific\nfeature are usually inconsistent in different samples, which is caused by\nfeature interactions in the hidden layers. Accordingly, we can design an\nautomatic feature crossing method to find feature interactions in DNN, and use\nthem as cross features in LR. We give definition of the interpretation\ninconsistency in DNN, based on which a novel feature crossing method called\nDNN2LR is proposed. Extensive experiments have been conducted on four public\ndatasets and two real-world datasets. The final model, i.e., a LR model\nempowered with cross features, generated by DNN2LR can outperform the complex\nDNN model, as well as several state-of-the-art feature crossing methods. The\nexperimental results strongly verify the effectiveness and efficiency of\nDNN2LR, especially on real-world datasets with large numbers of feature fields.\n",
		"date": [
			"2020-08-22",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2008.09775",
		"pdf_url": "http://arxiv.org/pdf/2008.09775.pdf"
	},
	"399": {
		"title": "Neighbourhood-Insensitive Point Cloud Normal Estimation Network",
		"creator": [
			"Wang, Zirui",
			"Prisacariu, Victor Adrian"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  We introduce a novel self-attention-based normal estimation network that is\nable to focus softly on relevant points and adjust the softness by learning a\ntemperature parameter, making it able to work naturally and effectively within\na large neighbourhood range. As a result, our model outperforms all existing\nnormal estimation algorithms by a large margin, achieving 94.1% accuracy in\ncomparison with the previous state of the art of 91.2%, with a 25x smaller\nmodel and 12x faster inference time. We also use point-to-plane Iterative\nClosest Point (ICP) as an application case to show that our normal estimations\nlead to faster convergence than normal estimations from other methods, without\nmanually fine-tuning neighbourhood range parameters. Code available at\nhttps://code.active.vision.\n",
			"Comment: Accepted in BMVC 2020 as oral presentation. Code available at\n  https://code.active.vision and project page at http://ninormal.active.vision"
		],
		"date": [
			"2020-08-23",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2008.09965",
		"pdf_url": "http://arxiv.org/pdf/2008.09965.pdf"
	},
	"400": {
		"title": "On the $k$ Nearest-Neighbor Path Distance from the Typical Intersection\n  in the Manhattan Poisson Line Cox Process",
		"creator": [
			"Koufos, Konstantinos",
			"Dhillon, Harpreet S.",
			"Dianati, Mehrdad",
			"Dettmann, Carl P."
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": "  In this paper, we consider a Cox point process driven by the Manhattan\nPoisson line process. We calculate the exact cumulative distribution function\n(CDF) of the path distance (L1 norm) between a randomly selected intersection\nand the $k$-th nearest node of the Cox process. The CDF is expressed as a sum\nover the integer partition function $p\\!\\left(k\\right)$, which allows us to\nnumerically evaluate the CDF in a simple manner for practical values of $k$.\nThese distance distributions can be used to study the $k$-coverage of broadcast\nsignals transmitted from a \\ac{RSU} located at an intersection in intelligent\ntransport systems (ITS). Also, they can be insightful for network dimensioning\nin vehicle-to-everything (V2X) systems, because they can yield the exact\ndistribution of network load within a cell, provided that the \\ac{RSU} is\nplaced at an intersection. Finally, they can find useful applications in other\nbranches of science like spatial databases, emergency response planning, and\ndistricting. We corroborate the applicability of our distance distribution\nmodel using the map of an urban area.\n",
		"date": [
			"2020-08-24",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2008.10670",
		"pdf_url": "http://arxiv.org/pdf/2008.10670.pdf"
	},
	"401": {
		"title": "Probabilistic Deep Learning for Instance Segmentation",
		"creator": [
			"Rumberger, Josef Lorenz",
			"Mais, Lisa",
			"Kainmueller, Dagmar"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Probabilistic convolutional neural networks, which predict distributions of\npredictions instead of point estimates, led to recent advances in many areas of\ncomputer vision, from image reconstruction to semantic segmentation. Besides\nstate of the art benchmark results, these networks made it possible to quantify\nlocal uncertainties in the predictions. These were used in active learning\nframeworks to target the labeling efforts of specialist annotators or to assess\nthe quality of a prediction in a safety-critical environment. However, for\ninstance segmentation problems these methods are not frequently used so far. We\nseek to close this gap by proposing a generic method to obtain model-inherent\nuncertainty estimates within proposal-free instance segmentation models.\nFurthermore, we analyze the quality of the uncertainty estimates with a metric\nadapted from semantic segmentation. We evaluate our method on the BBBC010 C.\\\nelegans dataset, where it yields competitive performance while also predicting\nuncertainty estimates that carry information about object-level inaccuracies\nlike false splits and false merges. We perform a simulation to show the\npotential use of such uncertainty estimates in guided proofreading.\n",
			"Comment: ECCV 2020 BioImage Computing Workshop"
		],
		"date": [
			"2020-08-24",
			"2020-12-17"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2008.10678",
			"doi:10.1007/978-3-030-66415-2_29"
		],
		"pdf_url": "http://arxiv.org/pdf/2008.10678.pdf"
	},
	"402": {
		"title": "What is being transferred in transfer learning?",
		"creator": [
			"Neyshabur, Behnam",
			"Sedghi, Hanie",
			"Zhang, Chiyuan"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  One desired capability for machines is the ability to transfer their\nknowledge of one domain to another where data is (usually) scarce. Despite\nample adaptation of transfer learning in various deep learning applications, we\nyet do not understand what enables a successful transfer and which part of the\nnetwork is responsible for that. In this paper, we provide new tools and\nanalyses to address these fundamental questions. Through a series of analyses\non transferring to block-shuffled images, we separate the effect of feature\nreuse from learning low-level statistics of data and show that some benefit of\ntransfer learning comes from the latter. We present that when training from\npre-trained weights, the model stays in the same basin in the loss landscape\nand different instances of such model are similar in feature space and close in\nparameter space.\n",
			"Comment: Equal contribution, authors ordered randomly"
		],
		"date": [
			"2020-08-26",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2008.11687",
			"NeurIPS 2020"
		],
		"pdf_url": "http://arxiv.org/pdf/2008.11687.pdf"
	},
	"403": {
		"title": "Path homology and temporal networks",
		"creator": [
			"Chowdhury, Samir",
			"Huntsman, Steve",
			"Yutin, Matvey"
		],
		"subject": [
			"Computer Science - Social and Information Networks",
			"Mathematics - Algebraic Topology"
		],
		"description": "  We present an algorithm to compute path homology for simple digraphs, and use\nit to topologically analyze various small digraphs en route to an analysis of\ncomplex temporal networks which exhibit such digraphs as underlying motifs. The\ndigraphs analyzed include all digraphs, directed acyclic graphs, and undirected\ngraphs up to certain numbers of vertices, as well as some specially constructed\ncases. Using information from this analysis, we identify small digraphs\ncontributing to path homology in dimension $2$ for three temporal networks, and\nrelate these digraphs to network behavior. We conclude that path homology can\nprovide insight into temporal network structure and vice versa.\n",
		"date": "2020-08-26",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2008.11885",
			"doi:10.1007/978-3-030-65351-4_51"
		],
		"pdf_url": "http://arxiv.org/pdf/2008.11885.pdf"
	},
	"404": {
		"title": "On Transfer Learning of Traditional Frequency and Time Domain Features\n  in Turning",
		"creator": [
			"Yesilli, Melih C.",
			"Khasawneh, Firas A."
		],
		"subject": [
			"Electrical Engineering and Systems Science - Signal Processing",
			"Computer Science - Machine Learning"
		],
		"description": "  There has been an increasing interest in leveraging machine learning tools\nfor chatter prediction and diagnosis in discrete manufacturing processes. Some\nof the most common features for studying chatter include traditional signal\nprocessing tools such as Fast Fourier Transform (FFT), Power Spectral Density\n(PSD), and the Auto-correlation Function (ACF). In this study, we use these\ntools in a supervised learning setting to identify chatter in accelerometer\nsignals obtained from a turning experiment. The experiment is performed using\nfour different tool overhang lengths with varying cutting speed and the depth\nof cut. We then examine the resulting signals and tag them as either chatter or\nchatter-free. The tagged signals are then used to train a classifier. The\nclassification methods include the most common algorithms: Support Vector\nMachine (SVM), Logistic Regression (LR), Random Forest (RF), and Gradient Boost\n(GB). Our results show that features extracted from the Fourier spectrum are\nthe most informative when training a classifier and testing on data from the\nsame cutting configuration yielding accuracy as high as %96. However, the\naccuracy drops significantly when training and testing on two different\nconfigurations with different structural eigenfrequencies. Thus, we conclude\nthat while these traditional features can be highly tuned to a certain process,\ntheir transfer learning ability is limited. We also compare our results against\ntwo other methods with rising popularity in the literature: Wavelet Packet\nTransform (WPT) and Ensemble Empirical Mode Decomposition (EEMD). The latter\ntwo methods, especially EEMD, show better transfer learning capabilities for\nour dataset.\n",
		"date": "2020-08-28",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2008.12691",
			"doi:10.1115/MSEC2020-8274"
		],
		"pdf_url": "http://arxiv.org/pdf/2008.12691.pdf"
	},
	"405": {
		"title": "VR-Caps: A Virtual Environment for Capsule Endoscopy",
		"creator": [
			"Incetan, Kagan",
			"Celik, Ibrahim Omer",
			"Obeid, Abdulhamid",
			"Gokceler, Guliz Irem",
			"Ozyoruk, Kutsev Bengisu",
			"Almalioglu, Yasin",
			"Chen, Richard J.",
			"Mahmood, Faisal",
			"Gilbert, Hunter",
			"Durr, Nicholas J.",
			"Turan, Mehmet"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Current capsule endoscopes and next-generation robotic capsules for diagnosis\nand treatment of gastrointestinal diseases are complex cyber-physical platforms\nthat must orchestrate complex software and hardware functions. The desired\ntasks for these systems include visual localization, depth estimation, 3D\nmapping, disease detection and segmentation, automated navigation, active\ncontrol, path realization and optional therapeutic modules such as targeted\ndrug delivery and biopsy sampling. Data-driven algorithms promise to enable\nmany advanced functionalities for capsule endoscopes, but real-world data is\nchallenging to obtain. Physically-realistic simulations providing synthetic\ndata have emerged as a solution to the development of data-driven algorithms.\nIn this work, we present a comprehensive simulation platform for capsule\nendoscopy operations and introduce VR-Caps, a virtual active capsule\nenvironment that simulates a range of normal and abnormal tissue conditions\n(e.g., inflated, dry, wet etc.) and varied organ types, capsule endoscope\ndesigns (e.g., mono, stereo, dual and 360{\\deg}camera), and the type, number,\nstrength, and placement of internal and external magnetic sources that enable\nactive locomotion. VR-Caps makes it possible to both independently or jointly\ndevelop, optimize, and test medical imaging and analysis software for the\ncurrent and next-generation endoscopic capsule systems. To validate this\napproach, we train state-of-the-art deep neural networks to accomplish various\nmedical image analysis tasks using simulated data from VR-Caps and evaluate the\nperformance of these models on real medical data. Results demonstrate the\nusefulness and effectiveness of the proposed virtual platform in developing\nalgorithms that quantify fractional coverage, camera trajectory, 3D map\nreconstruction, and disease classification.\n",
			"Comment: 18 pages, 14 figures"
		],
		"date": [
			"2020-08-29",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2008.12949",
		"pdf_url": "http://arxiv.org/pdf/2008.12949.pdf"
	},
	"406": {
		"title": "Pairwise Learning for Name Disambiguation in Large-Scale Heterogeneous\n  Academic Networks",
		"creator": [
			"Sun, Qingyun",
			"Peng, Hao",
			"Li, Jianxin",
			"Wang, Senzhang",
			"Dong, Xiangyu",
			"Zhao, Liangxuan",
			"Yu, Philip S.",
			"He, Lifang"
		],
		"subject": [
			"Computer Science - Digital Libraries",
			"Computer Science - Machine Learning",
			"Computer Science - Social and Information Networks",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Name disambiguation aims to identify unique authors with the same name.\nExisting name disambiguation methods always exploit author attributes to\nenhance disambiguation results. However, some discriminative author attributes\n(e.g., email and affiliation) may change because of graduation or job-hopping,\nwhich will result in the separation of the same author's papers in digital\nlibraries. Although these attributes may change, an author's co-authors and\nresearch topics do not change frequently with time, which means that papers\nwithin a period have similar text and relation information in the academic\nnetwork. Inspired by this idea, we introduce Multi-view Attention-based\nPairwise Recurrent Neural Network (MA-PairRNN) to solve the name disambiguation\nproblem. We divided papers into small blocks based on discriminative author\nattributes and blocks of the same author will be merged according to pairwise\nclassification results of MA-PairRNN. MA-PairRNN combines heterogeneous graph\nembedding learning and pairwise similarity learning into a framework. In\naddition to attribute and structure information, MA-PairRNN also exploits\nsemantic information by meta-path and generates node representation in an\ninductive way, which is scalable to large graphs. Furthermore, a semantic-level\nattention mechanism is adopted to fuse multiple meta-path based\nrepresentations. A Pseudo-Siamese network consisting of two RNNs takes two\npaper sequences in publication time order as input and outputs their\nsimilarity. Results on two real-world datasets demonstrate that our framework\nhas a significant and consistent improvement of performance on the name\ndisambiguation task. It was also demonstrated that MA-PairRNN can perform well\nwith a small amount of training data and have better generalization ability\nacross different research areas.\n",
			"Comment: accepted by ICDM 2020 as regular paper"
		],
		"date": [
			"2020-08-30",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2008.13099",
		"pdf_url": "http://arxiv.org/pdf/2008.13099.pdf"
	},
	"407": {
		"title": "Machine learning thermal circuit network model for thermal design\n  optimization of electronic circuit board layout with transient heating chips",
		"creator": [
			"Otaki, Daiki",
			"Nonaka, Hirofumi",
			"Yamada, Noboru"
		],
		"subject": [
			"Physics - Applied Physics",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Systems and Control",
			"J.6"
		],
		"description": [
			"  This paper describes a method combining Bayesian optimization (BO) and a\nlamped-capacitance thermal circuit network model that is effective for speeding\nup the thermal design optimization of an electronic circuit board layout with\ntransient heating chips. As electronic devices have become smaller and more\ncomplex, the importance of thermal design optimization to ensure heat\ndissipation performance has increased. However, such thermal design\noptimization is difficult because it is necessary to consider various\ntrade-offs associated with packaging and transient temperature changes of\nheat-generating components. This study aims to improve the performance of\nthermal design optimization by artificial intelligence. BO using a Gaussian\nprocess was combined with the lamped-capacitance thermal circuit network model,\nand its performance was verified by case studies. As a result, BO successfully\nfound the ideal circuit board layout as well as particle swarm optimization\n(PSO) and genetic algorithm (GA) could. The CPU time for BO was 1/5 and 1/4 of\nthat for PSO and GA, respectively. In addition, BO found a non-intuitive\noptimal solution in approximately 7 minutes from 10 million layout patterns. It\nwas estimated that this was 1/1000 of the CPU time required for analyzing all\nlayout patterns.\n",
			"Comment: 13 pages, 7 figures"
		],
		"date": [
			"2020-08-27",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2008.13571",
		"pdf_url": "http://arxiv.org/pdf/2008.13571.pdf"
	},
	"408": {
		"title": "Machine Reasoning Explainability",
		"creator": [
			"Cyras, Kristijonas",
			"Badrinath, Ramamurthy",
			"Mohalik, Swarup Kumar",
			"Mujumdar, Anusha",
			"Nikou, Alexandros",
			"Previti, Alessandro",
			"Sundararajan, Vaishnavi",
			"Feljan, Aneta Vulgarakis"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Logic in Computer Science",
			"I.2.0",
			"I.2.m",
			"F.4.1"
		],
		"description": "  As a field of AI, Machine Reasoning (MR) uses largely symbolic means to\nformalize and emulate abstract reasoning. Studies in early MR have notably\nstarted inquiries into Explainable AI (XAI) -- arguably one of the biggest\nconcerns today for the AI community. Work on explainable MR as well as on MR\napproaches to explainability in other areas of AI has continued ever since. It\nis especially potent in modern MR branches, such as argumentation, constraint\nand logic programming, planning. We hereby aim to provide a selective overview\nof MR explainability techniques and studies in hopes that insights from this\nlong track of research will complement well the current XAI landscape. This\ndocument reports our work in-progress on MR explainability.\n",
		"date": [
			"2020-09-01",
			"2020-12-01"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.00418",
		"pdf_url": "http://arxiv.org/pdf/2009.00418.pdf"
	},
	"409": {
		"title": "XCSP3-core: A Format for Representing Constraint\n  Satisfaction/Optimization Problems",
		"creator": [
			"Boussemart, Frédéric",
			"Lecoutre, Christophe",
			"Audemard, Gilles",
			"Piette, Cédric"
		],
		"subject": "Computer Science - Artificial Intelligence",
		"description": [
			"  In this document, we introduce XCSP3-core, a subset of XCSP3 that allows us\nto represent constraint satisfaction/optimization problems. The interest of\nXCSP3-core is multiple: (i) focusing on the most popular frameworks (CSP and\nCOP) and constraints, (ii) facilitating the parsing process by means of\ndedicated XCSP3-core parsers written in Java and C++ (using callback\nfunctions), (iii) and defining a core format for comparisons (competitions) of\nconstraint solvers.\n",
			"Comment: arXiv admin note: substantial text overlap with arXiv:1611.03398"
		],
		"date": [
			"2020-09-01",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.00514",
		"pdf_url": "http://arxiv.org/pdf/2009.00514.pdf"
	},
	"410": {
		"title": "SPAN: Spatial Pyramid Attention Network forImage Manipulation\n  Localization",
		"creator": [
			"Hu, Xuefeng",
			"Zhang, Zhihan",
			"Jiang, Zhenye",
			"Chaudhuri, Syomantak",
			"Yang, Zhenheng",
			"Nevatia, Ram"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"I.4.9"
		],
		"description": [
			"  We present a novel framework, Spatial Pyramid Attention Network (SPAN) for\ndetection and localization of multiple types of image manipulations. The\nproposed architecture efficiently and effectively models the relationship\nbetween image patches at multiple scales by constructing a pyramid of local\nself-attention blocks. The design includes a novel position projection to\nencode the spatial positions of the patches. SPAN is trained on a generic,\nsynthetic dataset but can also be fine tuned for specific datasets; The\nproposed method shows significant gains in performance on standard datasets\nover previous state-of-the-art methods.\n",
			"Comment: Accepted at ECCV 2020\n  (https://link.springer.com/chapter/10.1007%2F978-3-030-58589-1_19) Code\n  Available at https://github.com/ZhiHanZ/IRIS0-SPAN/"
		],
		"date": [
			"2020-09-01",
			"2021-01-13"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2009.00726",
			"doi:10.1007/978-3-030-58589-1_19",
			"doi:10.1007/978-3-030-58589-1_19",
			"doi:10.1007/978-3-030-58589-1_19",
			"doi:10.1007/978-3-030-58589-1_19"
		],
		"pdf_url": "http://arxiv.org/pdf/2009.00726.pdf"
	},
	"411": {
		"title": "Survey of Machine Learning Accelerators",
		"creator": [
			"Reuther, Albert",
			"Michaleas, Peter",
			"Jones, Michael",
			"Gadepally, Vijay",
			"Samsi, Siddharth",
			"Kepner, Jeremy"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  New machine learning accelerators are being announced and released each month\nfor a variety of applications from speech recognition, video object detection,\nassisted driving, and many data center applications. This paper updates the\nsurvey of of AI accelerators and processors from last year's IEEE-HPEC paper.\nThis paper collects and summarizes the current accelerators that have been\npublicly announced with performance and power consumption numbers. The\nperformance and power values are plotted on a scatter graph and a number of\ndimensions and observations from the trends on this plot are discussed and\nanalyzed. For instance, there are interesting trends in the plot regarding\npower consumption, numerical precision, and inference versus training. This\nyear, there are many more announced accelerators that are implemented with many\nmore architectures and technologies from vector engines, dataflow engines,\nneuromorphic designs, flash-based analog memory processing, and photonic-based\nprocessing.\n",
			"Comment: 12 pages, 2 figures, IEEE-HPEC conference, Waltham, MA, September\n  21-25, 2020. arXiv admin note: text overlap with arXiv:1908.11348"
		],
		"date": "2020-08-31",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2009.00993",
			"doi:10.1109/HPEC43674.2020.9286149"
		],
		"pdf_url": "http://arxiv.org/pdf/2009.00993.pdf"
	},
	"412": {
		"title": "DARTS-: Robustly Stepping out of Performance Collapse Without Indicators",
		"creator": [
			"Chu, Xiangxiang",
			"Wang, Xiaoxing",
			"Zhang, Bo",
			"Lu, Shun",
			"Wei, Xiaolin",
			"Yan, Junchi"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Despite the fast development of differentiable architecture search (DARTS),\nit suffers from long-standing performance instability, which extremely limits\nits application. Existing robustifying methods draw clues from the resulting\ndeteriorated behavior instead of finding out its causing factor. Various\nindicators such as Hessian eigenvalues are proposed as a signal to stop\nsearching before the performance collapses. However, these indicator-based\nmethods tend to easily reject good architectures if the thresholds are\ninappropriately set, let alone the searching is intrinsically noisy. In this\npaper, we undertake a more subtle and direct approach to resolve the collapse.\nWe first demonstrate that skip connections have a clear advantage over other\ncandidate operations, where it can easily recover from a disadvantageous state\nand become dominant. We conjecture that this privilege is causing degenerated\nperformance. Therefore, we propose to factor out this benefit with an auxiliary\nskip connection, ensuring a fairer competition for all operations. We call this\napproach DARTS-. Extensive experiments on various datasets verify that it can\nsubstantially improve robustness. Our code is available at\nhttps://github.com/Meituan-AutoML/DARTS- .\n",
			"Comment: Accepted to ICLR2021"
		],
		"date": [
			"2020-09-02",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.01027",
		"pdf_url": "http://arxiv.org/pdf/2009.01027.pdf"
	},
	"413": {
		"title": "Deterministic Decremental Reachability, SCC, and Shortest Paths via\n  Directed Expanders and Congestion Balancing",
		"creator": [
			"Bernstein, Aaron",
			"Gutenberg, Maximilian Probst",
			"Saranurak, Thatchaphol"
		],
		"subject": "Computer Science - Data Structures and Algorithms",
		"description": [
			"  Let $G = (V,E,w)$ be a weighted, digraph subject to a sequence of adversarial\nedge deletions. In the decremental single-source reachability problem (SSR), we\nare given a fixed source $s$ and the goal is to maintain a data structure that\ncan answer path-queries $s \\rightarrowtail v$ for any $v \\in V$. In the more\ngeneral single-source shortest paths (SSSP) problem the goal is to return an\napproximate shortest path to $v$, and in the SCC problem the goal is to\nmaintain strongly connected components of $G$ and to answer path queries within\neach component. All of these problems have been very actively studied over the\npast two decades, but all the fast algorithms are randomized and, more\nsignificantly, they can only answer path queries if they assume a weaker model:\nthey assume an oblivious adversary which is not adaptive and must fix the\nupdate sequence in advance. This assumption significantly limits the use of\nthese data structures, most notably preventing them from being used as\nsubroutines in static algorithms. All the above problems are notoriously\ndifficult in the adaptive setting. In fact, the state-of-the-art is still the\nEven and Shiloach tree, which dates back all the way to 1981 and achieves total\nupdate time $O(mn)$. We present the first algorithms to break through this\nbarrier:\n  1) deterministic decremental SSR/SCC with total update time $mn^{2/3 + o(1)}$\n  2) deterministic decremental SSSP with total update time $n^{2+2/3+o(1)}$.\n  To achieve these results, we develop two general techniques of broader\ninterest for working with dynamic graphs: 1) a generalization of expander-based\ntools to dynamic directed graphs, and 2) a technique that we call congestion\nbalancing and which provides a new method for maintaining flow under\nadversarial deletions. Using the second technique, we provide the first\nnear-optimal algorithm for decremental bipartite matching.\n",
			"Comment: Reuploaded with some generalizations of previous theorems"
		],
		"date": [
			"2020-09-05",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.02584",
		"pdf_url": "http://arxiv.org/pdf/2009.02584.pdf"
	},
	"414": {
		"title": "Improving colonoscopy lesion classification using semi-supervised deep\n  learning",
		"creator": [
			"Golhar, Mayank",
			"Bobrow, Taylor L.",
			"Khoshknab, MirMilad Pourmousavi",
			"Jit, Simran",
			"Ngamruengphong, Saowanee",
			"Durr, Nicholas J."
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  While data-driven approaches excel at many image analysis tasks, the\nperformance of these approaches is often limited by a shortage of annotated\ndata available for training. Recent work in semi-supervised learning has shown\nthat meaningful representations of images can be obtained from training with\nlarge quantities of unlabeled data, and that these representations can improve\nthe performance of supervised tasks. Here, we demonstrate that an unsupervised\njigsaw learning task, in combination with supervised training, results in up to\na 9.8% improvement in correctly classifying lesions in colonoscopy images when\ncompared to a fully-supervised baseline. We additionally benchmark improvements\nin domain adaptation and out-of-distribution detection, and demonstrate that\nsemi-supervised learning outperforms supervised learning in both cases. In\ncolonoscopy applications, these metrics are important given the skill required\nfor endoscopic assessment of lesions, the wide variety of endoscopy systems in\nuse, and the homogeneity that is typical of labeled datasets.\n",
			"Comment: 10 pages, 5 figures"
		],
		"date": "2020-09-07",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2009.03162",
			"IEEE Access, vol. 9, pp. 631-640, 2021",
			"doi:10.1109/ACCESS.2020.3047544"
		],
		"pdf_url": "http://arxiv.org/pdf/2009.03162.pdf"
	},
	"415": {
		"title": "Data-assisted combustion simulations with dynamic submodel assignment\n  using random forests",
		"creator": [
			"Chung, Wai Tong",
			"Mishra, Aashwin Ananda",
			"Perakis, Nikolaos",
			"Ihme, Matthias"
		],
		"subject": [
			"Physics - Fluid Dynamics",
			"Computer Science - Machine Learning",
			"Physics - Computational Physics",
			"Statistics - Applications"
		],
		"description": [
			"  In this investigation, we outline a data-assisted approach that employs\nrandom forest classifiers for local and dynamic combustion submodel assignment\nin turbulent-combustion simulations. This method is applied in simulations of a\nsingle-element GOX/GCH4 rocket combustor; a priori as well as a posteriori\nassessments are conducted to (i) evaluate the accuracy and adjustability of the\nclassifier for targeting different quantities-of-interest (QoIs), and (ii)\nassess improvements, resulting from the data-assisted combustion model\nassignment, in predicting target QoIs during simulation runtime. Results from\nthe a priori study show that random forests, trained with local flow properties\nas input variables and combustion model errors as training labels, assign three\ndifferent combustion models - finite-rate chemistry (FRC), flamelet progress\nvariable (FPV) model, and inert mixing (IM) - with reasonable classification\nperformance even when targeting multiple QoIs. Applications in a posteriori\nstudies demonstrate improved predictions from data-assisted simulations, in\ntemperature and CO mass fraction, when compared with monolithic FPV\ncalculations. These results demonstrate that this data-driven framework holds\npromise for the dynamic combustion submodel assignment in reacting flow\nsimulations.\n",
			"Comment: Accepted version; 23 pages, 12 figures"
		],
		"date": [
			"2020-09-08",
			"2021-01-17"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2009.04023",
			"Combustion and Flame 227 (2021) 172-185",
			"doi:10.1016/j.combustflame.2020.12.041"
		],
		"pdf_url": "http://arxiv.org/pdf/2009.04023.pdf"
	},
	"416": {
		"title": "A Normal Sequence Compressed by PPM$^*$ but not by Lempel-Ziv 78",
		"creator": [
			"Jordon, Liam",
			"Moser, Philippe"
		],
		"subject": [
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Information Theory"
		],
		"description": "  In this paper we compare the difference in performance of two of the\nPrediction by Partial Matching (PPM) family of compressors (PPM$^*$ and the\noriginal Bounded PPM algorithm) and the Lempel-Ziv 78 (LZ) algorithm. We\nconstruct an infinite binary sequence whose worst-case compression ratio for\nPPM$^*$ is $0$, while Bounded PPM's and LZ's best-case compression ratios are\nat least $1/2$ and $1$ respectively. This sequence is an enumeration of all\nbinary strings in order of length, i.e. all strings of length $1$ followed by\nall strings of length $2$ and so on. It is therefore normal, and is built using\nrepetitions of de Bruijn strings of increasing order\n",
		"date": "2020-09-10",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2009.04827",
			"doi:10.1007/978-3-030-67731-2_28"
		],
		"pdf_url": "http://arxiv.org/pdf/2009.04827.pdf"
	},
	"417": {
		"title": "Citing and referencing habits in Medicine and Social Sciences journals\n  in 2019",
		"creator": [
			"Santos, Erika Alves dos",
			"Peroni, Silvio",
			"Mucheroni, Marcos Luiz"
		],
		"subject": "Computer Science - Digital Libraries",
		"description": [
			"  This article explores citing and referencing systems in Social Sciences and\nMedicine articles from different theoretical and practical perspectives,\nconsidering bibliographic references as a facet of descriptive representation.\nThe analysis of citing and referencing elements (i.e. bibliographic references,\nmentions, quotations, and respective in-text reference pointers) identified\nciting and referencing habits within disciplines under consideration and errors\noccurring over the long term as stated by previous studies now expanded. Future\nexpected trends of information retrieval from bibliographic metadata was\ngathered by approaching these referencing elements from the FRBR Entities\nconcepts. Reference styles do not fully accomplish with their role of guiding\nauthors and publishers on providing concise and well-structured bibliographic\nmetadata within bibliographic references. Trends on representative description\nrevision suggest a predicted distancing on the ways information is approached\nby bibliographic references and bibliographic catalogs adopting FRBR concepts,\nincluding the description levels adopted by each of them under the perspective\nof the FRBR Entities concept. This study was based on a subset of Medicine and\nSocial Sciences articles published in 2019 and, therefore, it may not be taken\nas a final and broad coverage. Future studies expanding these approaches to\nother disciplines and chronological periods are encouraged. By approaching\nciting and referencing issues as descriptive representation's facets, findings\non this study may encourage further studies that will support Information\nScience and Computer Science on providing tools to become bibliographic\nmetadata description simpler, better structured and more efficient facing the\nrevision of descriptive representation actually in progress.\n",
			"Comment: Accepted for publication on 18 January 2021 in Journal of\n  Documentation"
		],
		"date": [
			"2020-09-11",
			"2021-01-20"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2009.05588",
			"doi:10.1108/JD-08-2020-0144"
		],
		"pdf_url": "http://arxiv.org/pdf/2009.05588.pdf"
	},
	"418": {
		"title": "A Tutorial on Ultra-Reliable and Low-Latency Communications in 6G:\n  Integrating Domain Knowledge into Deep Learning",
		"creator": [
			"She, Changyang",
			"Sun, Chengjian",
			"Gu, Zhouyou",
			"Li, Yonghui",
			"Yang, Chenyang",
			"Poor, H. Vincent",
			"Vucetic, Branka"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Signal Processing",
			"Computer Science - Information Theory",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  As one of the key communication scenarios in the 5th and also the 6th\ngeneration (6G) of mobile communication networks, ultra-reliable and\nlow-latency communications (URLLC) will be central for the development of\nvarious emerging mission-critical applications. State-of-the-art mobile\ncommunication systems do not fulfill the end-to-end delay and overall\nreliability requirements of URLLC. In particular, a holistic framework that\ntakes into account latency, reliability, availability, scalability, and\ndecision making under uncertainty is lacking. Driven by recent breakthroughs in\ndeep neural networks, deep learning algorithms have been considered as\npromising ways of developing enabling technologies for URLLC in future 6G\nnetworks. This tutorial illustrates how domain knowledge (models, analytical\ntools, and optimization frameworks) of communications and networking can be\nintegrated into different kinds of deep learning algorithms for URLLC. We first\nprovide some background of URLLC and review promising network architectures and\ndeep learning frameworks for 6G. To better illustrate how to improve learning\nalgorithms with domain knowledge, we revisit model-based analytical tools and\ncross-layer optimization frameworks for URLLC. Following that, we examine the\npotential of applying supervised/unsupervised deep learning and deep\nreinforcement learning in URLLC and summarize related open problems. Finally,\nwe provide simulation and experimental results to validate the effectiveness of\ndifferent learning algorithms and discuss future directions.\n",
			"Comment: This work has been accepted by Proceedings of the IEEE"
		],
		"date": [
			"2020-09-13",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.06010",
		"pdf_url": "http://arxiv.org/pdf/2009.06010.pdf"
	},
	"419": {
		"title": "High-Resolution Deep Image Matting",
		"creator": [
			"Yu, Haichao",
			"Xu, Ning",
			"Huang, Zilong",
			"Zhou, Yuqian",
			"Shi, Humphrey"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Image matting is a key technique for image and video editing and composition.\nConventionally, deep learning approaches take the whole input image and an\nassociated trimap to infer the alpha matte using convolutional neural networks.\nSuch approaches set state-of-the-arts in image matting; however, they may fail\nin real-world matting applications due to hardware limitations, since\nreal-world input images for matting are mostly of very high resolution. In this\npaper, we propose HDMatt, a first deep learning based image matting approach\nfor high-resolution inputs. More concretely, HDMatt runs matting in a\npatch-based crop-and-stitch manner for high-resolution inputs with a novel\nmodule design to address the contextual dependency and consistency issues\nbetween different patches. Compared with vanilla patch-based inference which\ncomputes each patch independently, we explicitly model the cross-patch\ncontextual dependency with a newly-proposed Cross-Patch Contextual module (CPC)\nguided by the given trimap. Extensive experiments demonstrate the effectiveness\nof the proposed method and its necessity for high-resolution inputs. Our HDMatt\napproach also sets new state-of-the-art performance on Adobe Image Matting and\nAlphaMatting benchmarks and produce impressive visual results on more\nreal-world high-resolution images.\n",
			"Comment: AAAI 2021"
		],
		"date": [
			"2020-09-14",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.06613",
		"pdf_url": "http://arxiv.org/pdf/2009.06613.pdf"
	},
	"420": {
		"title": "Pilot: Winner of the Human-Agent Negotiation Challenge at IJCAI 2020",
		"creator": [
			"Chawla, Kushal",
			"Lucas, Gale"
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Artificial Intelligence",
			"I.2"
		],
		"description": [
			"  This document describes our agent Pilot, winner of the Human-Agent\nNegotiation Challenge at ANAC, IJCAI 2020. Pilot is a virtual human that\nparticipates in a sequence of three negotiations with a human partner. Our\nsystem is based on the Interactive Arbitration Guide Online (IAGO) negotiation\nframework. We leverage prior Affective Computing and Psychology research in\nnegotiations to guide various key principles that define the behavior and\npersonality of our agent.\n",
			"Comment: Winner at ANAC, IJCAI 2020"
		],
		"date": [
			"2020-09-14",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.06781",
		"pdf_url": "http://arxiv.org/pdf/2009.06781.pdf"
	},
	"421": {
		"title": "MATS: An Interpretable Trajectory Forecasting Representation for\n  Planning and Control",
		"creator": [
			"Ivanovic, Boris",
			"Elhafsi, Amine",
			"Rosman, Guy",
			"Gaidon, Adrien",
			"Pavone, Marco"
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": [
			"  Reasoning about human motion is a core component of modern human-robot\ninteractive systems. In particular, one of the main uses of behavior prediction\nin autonomous systems is to inform robot motion planning and control. However,\na majority of planning and control algorithms reason about system dynamics\nrather than the predicted agent tracklets (i.e., ordered sets of waypoints)\nthat are commonly output by trajectory forecasting methods, which can hinder\ntheir integration. Towards this end, we propose Mixtures of Affine Time-varying\nSystems (MATS) as an output representation for trajectory forecasting that is\nmore amenable to downstream planning and control use. Our approach leverages\nsuccessful ideas from probabilistic trajectory forecasting works to learn\ndynamical system representations that are well-studied in the planning and\ncontrol literature. We integrate our predictions with a proposed multimodal\nplanning methodology and demonstrate significant computational efficiency\nimprovements on a large-scale autonomous driving dataset.\n",
			"Comment: 14 pages, 6 figures, 1 table. All code, models, and data can be found\n  at https://github.com/StanfordASL/MATS . Conference on Robot Learning (CoRL)\n  2020"
		],
		"date": [
			"2020-09-16",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.07517",
		"pdf_url": "http://arxiv.org/pdf/2009.07517.pdf"
	},
	"422": {
		"title": "Video Compression with CNN-based Post Processing",
		"creator": [
			"Zhang, Fan",
			"Ma, Di",
			"Feng, Chen",
			"Bull, David R."
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  In recent years, video compression techniques have been significantly\nchallenged by the rapidly increased demands associated with high quality and\nimmersive video content. Among various compression tools, post-processing can\nbe applied on reconstructed video content to mitigate visible compression\nartefacts and to enhance overall perceptual quality. Inspired by advances in\ndeep learning, we propose a new CNN-based post-processing approach, which has\nbeen integrated with two state-of-the-art coding standards, VVC and AV1. The\nresults show consistent coding gains on all tested sequences at various spatial\nresolutions, with average bit rate savings of 4.0% and 5.8% against original\nVVC and AV1 respectively (based on the assessment of PSNR). This network has\nalso been trained with perceptually inspired loss functions, which have further\nimproved reconstruction quality based on perceptual quality assessment (VMAF),\nwith average coding gains of 13.9% over VVC and 10.5% against AV1.\n",
		"date": [
			"2020-09-16",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2009.07583",
			"doi:10.1109/MMUL.2021.3052437"
		],
		"pdf_url": "http://arxiv.org/pdf/2009.07583.pdf"
	},
	"423": {
		"title": "Multiple Exemplars-based Hallucinationfor Face Super-resolution and\n  Editing",
		"creator": [
			"Wang, Kaili",
			"Oramas, Jose",
			"Tuytelaars, Tinne"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Given a really low-resolution input image of a face (say 16x16 or 8x8\npixels), the goal of this paper is to reconstruct a high-resolution version\nthereof. This, by itself, is an ill-posed problem, as the high-frequency\ninformation is missing in the low-resolution input and needs to be\nhallucinated, based on prior knowledge about the image content. Rather than\nrelying on a generic face prior, in this paper, we explore the use of a set of\nexemplars, i.e. other high-resolution images of the same person. These guide\nthe neural network as we condition the output on them. Multiple exemplars work\nbetter than a single one. To combine the information from multiple exemplars\neffectively, we introduce a pixel-wise weight generation module. Besides\nstandard face super-resolution, our method allows to perform subtle face\nediting simply by replacing the exemplars with another set with different\nfacial features. A user study is conducted and shows the super-resolved images\ncan hardly be distinguished from real images on the CelebA dataset. A\nqualitative comparison indicates our model outperforms methods proposed in the\nliterature on the CelebA and WebFace dataset.\n",
			"Comment: accepted in ACCV 2020"
		],
		"date": [
			"2020-09-16",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.07827",
		"pdf_url": "http://arxiv.org/pdf/2009.07827.pdf"
	},
	"424": {
		"title": "Arbitrary Video Style Transfer via Multi-Channel Correlation",
		"creator": [
			"Deng, Yingying",
			"Tang, Fan",
			"Dong, Weiming",
			"Huang, Haibin",
			"Ma, Chongyang",
			"Xu, Changsheng"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": "  Video style transfer is getting more attention in AI community for its\nnumerous applications such as augmented reality and animation productions.\nCompared with traditional image style transfer, performing this task on video\npresents new challenges: how to effectively generate satisfactory stylized\nresults for any specified style, and maintain temporal coherence across frames\nat the same time. Towards this end, we propose Multi-Channel Correction network\n(MCCNet), which can be trained to fuse the exemplar style features and input\ncontent features for efficient style transfer while naturally maintaining the\ncoherence of input videos. Specifically, MCCNet works directly on the feature\nspace of style and content domain where it learns to rearrange and fuse style\nfeatures based on their similarity with content features. The outputs generated\nby MCC are features containing the desired style patterns which can further be\ndecoded into images with vivid style textures. Moreover, MCCNet is also\ndesigned to explicitly align the features to input which ensures the output\nmaintains the content structures as well as the temporal continuity. To further\nimprove the performance of MCCNet under complex light conditions, we also\nintroduce the illumination loss during training. Qualitative and quantitative\nevaluations demonstrate that MCCNet performs well in both arbitrary video and\nimage style transfer tasks.\n",
		"date": [
			"2020-09-16",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.08003",
		"pdf_url": "http://arxiv.org/pdf/2009.08003.pdf"
	},
	"425": {
		"title": "Indoor environment data time-series reconstruction using autoencoder\n  neural networks",
		"creator": [
			"Liguori, Antonio",
			"Markovic, Romana",
			"Dam, Thi Thu Ha",
			"Frisch, Jérôme",
			"van Treeck, Christoph",
			"Causone, Francesco"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  As the number of installed meters in buildings increases, there is a growing\nnumber of data time-series that could be used to develop data-driven models to\nsupport and optimize building operation. However, building data sets are often\ncharacterized by errors and missing values, which are considered, by the recent\nresearch, among the main limiting factors on the performance of the proposed\nmodels. Motivated by the need to address the problem of missing data in\nbuilding operation, this work presents a data-driven approach to fill these\ngaps. In this study, three different autoencoder neural networks are trained to\nreconstruct missing short-term indoor environment data time-series in a data\nset collected in an office building in Aachen, Germany. This consisted of a\nfour year-long monitoring campaign in and between the years 2014 and 2017, of\n84 different rooms. The models are applicable for different time-series\nobtained from room automation, such as indoor air temperature, relative\nhumidity and $CO_{2}$ data streams. The results prove that the proposed methods\noutperform classic numerical approaches and they result in reconstructing the\ncorresponding variables with average RMSEs of 0.42 {\\deg}C, 1.30 % and 78.41\nppm, respectively.\n",
			"Comment: Accepted in Building and Environment"
		],
		"date": [
			"2020-09-17",
			"2021-01-21"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2009.08155",
			"Building and Environment 191 (2021) 107623",
			"doi:10.1016/j.buildenv.2021.107623"
		],
		"pdf_url": "http://arxiv.org/pdf/2009.08155.pdf"
	},
	"426": {
		"title": "RECON: Relation Extraction using Knowledge Graph Context in a Graph\n  Neural Network",
		"creator": [
			"Bastos, Anson",
			"Nadgeri, Abhishek",
			"Singh, Kuldeep",
			"Mulang', Isaiah Onando",
			"Shekarpour, Saeedeh",
			"Hoffart, Johannes",
			"Kaul, Manohar"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  In this paper, we present a novel method named RECON, that automatically\nidentifies relations in a sentence (sentential relation extraction) and aligns\nto a knowledge graph (KG). RECON uses a graph neural network to learn\nrepresentations of both the sentence as well as facts stored in a KG, improving\nthe overall extraction quality. These facts, including entity attributes\n(label, alias, description, instance-of) and factual triples, have not been\ncollectively used in the state of the art methods. We evaluate the effect of\nvarious forms of representing the KG context on the performance of RECON. The\nempirical evaluation on two standard relation extraction datasets shows that\nRECON significantly outperforms all state of the art methods on NYT Freebase\nand Wikidata datasets. RECON reports 87.23 F1 score (Vs 82.29 baseline) on\nWikidata dataset whereas on NYT Freebase, reported values are 87.5(P@10) and\n74.1(P@30) compared to the previous baseline scores of 81.3(P@10) and\n63.1(P@30).\n",
			"Comment: The Web Conference 2021 (WWW'21) full paper"
		],
		"date": [
			"2020-09-18",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.08694",
		"pdf_url": "http://arxiv.org/pdf/2009.08694.pdf"
	},
	"427": {
		"title": "DVG-Face: Dual Variational Generation for Heterogeneous Face Recognition",
		"creator": [
			"Fu, Chaoyou",
			"Wu, Xiang",
			"Hu, Yibo",
			"Huang, Huaibo",
			"He, Ran"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Heterogeneous Face Recognition (HFR) refers to matching cross-domain faces\nand plays a crucial role in public security. Nevertheless, HFR is confronted\nwith challenges from large domain discrepancy and insufficient heterogeneous\ndata. In this paper, we formulate HFR as a dual generation problem, and tackle\nit via a novel Dual Variational Generation (DVG-Face) framework. Specifically,\na dual variational generator is elaborately designed to learn the joint\ndistribution of paired heterogeneous images. However, the small-scale paired\nheterogeneous training data may limit the identity diversity of sampling. In\norder to break through the limitation, we propose to integrate abundant\nidentity information of large-scale visible data into the joint distribution.\nFurthermore, a pairwise identity preserving loss is imposed on the generated\npaired heterogeneous images to ensure their identity consistency. As a\nconsequence, massive new diverse paired heterogeneous images with the same\nidentity can be generated from noises. The identity consistency and identity\ndiversity properties allow us to employ these generated images to train the HFR\nnetwork via a contrastive learning mechanism, yielding both domain-invariant\nand discriminative embedding features. Concretely, the generated paired\nheterogeneous images are regarded as positive pairs, and the images obtained\nfrom different samplings are considered as negative pairs. Our method achieves\nsuperior performances over state-of-the-art methods on seven challenging\ndatabases belonging to five HFR tasks, including NIR-VIS, Sketch-Photo,\nProfile-Frontal Photo, Thermal-VIS, and ID-Camera. The related code will be\nreleased at https://github.com/BradyFU.\n",
			"Comment: Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI)"
		],
		"date": [
			"2020-09-20",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.09399",
		"pdf_url": "http://arxiv.org/pdf/2009.09399.pdf"
	},
	"428": {
		"title": "Achieving Proportionality up to the Maximin Item with Indivisible Goods",
		"creator": [
			"Baklanov, Artem",
			"Garimidi, Pranav",
			"Gkatzelis, Vasilis",
			"Schoepflin, Daniel"
		],
		"subject": [
			"Computer Science - Computer Science and Game Theory",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  We study the problem of fairly allocating indivisible goods and focus on the\nclassic fairness notion of proportionality. The indivisibility of the goods is\nlong known to pose highly non-trivial obstacles to achieving fairness, and a\nvery vibrant line of research has aimed to circumvent them using appropriate\nnotions of approximate fairness. Recent work has established that even\napproximate versions of proportionality (PROPx) may be impossible to achieve\neven for small instances, while the best known achievable approximations\n(PROP1) are much weaker. We introduce the notion of proportionality up to the\nmaximin item (PROPm) and show how to reach an allocation satisfying this notion\nfor any instance involving up to five agents with additive valuations. PROPm\nprovides a well-motivated middle-ground between PROP1 and PROPx, while also\ncapturing some elements of the well-studied maximin share (MMS) benchmark:\nanother relaxation of proportionality that has attracted a lot of attention.\n",
			"Comment: Changes to wording throughout and changes to framing of section 8"
		],
		"date": [
			"2020-09-20",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.09508",
		"pdf_url": "http://arxiv.org/pdf/2009.09508.pdf"
	},
	"429": {
		"title": "On the Effectiveness of Weight-Encoded Neural Implicit 3D Shapes",
		"creator": [
			"Davies, Thomas",
			"Nowrouzezahrai, Derek",
			"Jacobson, Alec"
		],
		"subject": [
			"Computer Science - Graphics",
			"Computer Science - Computational Geometry",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  A neural implicit outputs a number indicating whether the given query point\nin space is inside, outside, or on a surface. Many prior works have focused on\n_latent-encoded_ neural implicits, where a latent vector encoding of a specific\nshape is also fed as input. While affording latent-space interpolation, this\ncomes at the cost of reconstruction accuracy for any _single_ shape. Training a\nspecific network for each 3D shape, a _weight-encoded_ neural implicit may\nforgo the latent vector and focus reconstruction accuracy on the details of a\nsingle shape. While previously considered as an intermediary representation for\n3D scanning tasks or as a toy-problem leading up to latent-encoding tasks,\nweight-encoded neural implicits have not yet been taken seriously as a 3D shape\nrepresentation. In this paper, we establish that weight-encoded neural\nimplicits meet the criteria of a first-class 3D shape representation. We\nintroduce a suite of technical contributions to improve reconstruction\naccuracy, convergence, and robustness when learning the signed distance field\ninduced by a polygonal mesh -- the _de facto_ standard representation. Viewed\nas a lossy compression, our conversion outperforms standard techniques from\ngeometry processing. Compared to previous latent- and weight-encoded neural\nimplicits we demonstrate superior robustness, scalability, and performance.\n",
		"date": [
			"2020-09-17",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.09808",
		"pdf_url": "http://arxiv.org/pdf/2009.09808.pdf"
	},
	"430": {
		"title": "Energy-based Surprise Minimization for Multi-Agent Value Factorization",
		"creator": [
			"Suri, Karush",
			"Shi, Xiao Qi",
			"Plataniotis, Konstantinos",
			"Lawryshyn, Yuri"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Multiagent Systems",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Multi-Agent Reinforcement Learning (MARL) has demonstrated significant\nsuccess in training decentralised policies in a centralised manner by making\nuse of value factorization methods. However, addressing surprise across\nspurious states and approximation bias remain open problems for multi-agent\nsettings. Towards this goal, we introduce the Energy-based MIXer (EMIX), an\nalgorithm which minimizes surprise utilizing the energy across agents. Our\ncontributions are threefold; (1) EMIX introduces a novel surprise minimization\ntechnique across multiple agents in the case of multi-agent\npartially-observable settings. (2) EMIX highlights a practical use of energy\nfunctions in MARL with theoretical guarantees and experiment validations of the\nenergy operator. Lastly, (3) EMIX extends Maxmin Q-learning for addressing\noverestimation bias across agents in MARL. In a study of challenging StarCraft\nII micromanagement scenarios, EMIX demonstrates consistent stable performance\nfor multiagent surprise minimization. Moreover, our ablation study highlights\nthe necessity of the energy-based scheme and the need for elimination of\noverestimation bias in MARL. Our implementation of EMIX can be found at\nkarush17.github.io/emix-web/.\n",
			"Comment: Preprint, Under Review"
		],
		"date": [
			"2020-09-16",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.09842",
		"pdf_url": "http://arxiv.org/pdf/2009.09842.pdf"
	},
	"431": {
		"title": "Solution Concepts in Hierarchical Games under Bounded Rationality with\n  Applications to Autonomous Driving",
		"creator": [
			"Sarkar, Atrisha",
			"Czarnecki, Krzysztof"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computer Science and Game Theory",
			"Computer Science - Multiagent Systems",
			"Computer Science - Robotics"
		],
		"description": "  With autonomous vehicles (AV) set to integrate further into regular human\ntraffic, there is an increasing consensus of treating AV motion planning as a\nmulti-agent problem. However, the traditional game theoretic assumption of\ncomplete rationality is too strong for the purpose of human driving, and there\nis a need for understanding human driving as a \\emph{bounded rational} activity\nthrough a behavioral game theoretic lens. To that end, we adapt three\nmetamodels of bounded rational behavior; two based on Quantal level-k and one\nbased on Nash equilibrium with quantal errors. We formalize the different\nsolution concepts that can be applied in the context of hierarchical games, a\nframework used in multi-agent motion planning, for the purpose of creating game\ntheoretic models of driving behavior. Furthermore, based on a contributed\ndataset of human driving at a busy urban intersection with a total of ~4k\nagents and ~44k decision points, we evaluate the behavior models on the basis\nof model fit to naturalistic data, as well as their predictive capacity. Our\nresults suggest that among the behavior models evaluated, modeling driving\nbehavior as pure strategy NE with quantal errors at the level of maneuvers with\nbounds sampling of actions at the level of trajectories provides the best fit\nto naturalistic driving behavior, and there is a significant impact of\nsituational factors on the performance of behavior models.\n",
		"date": [
			"2020-09-21",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.10033",
		"pdf_url": "http://arxiv.org/pdf/2009.10033.pdf"
	},
	"432": {
		"title": "Early detection of the advanced persistent threat attack using\n  performance analysis of deep learning",
		"creator": [
			"Joloudari, Javad Hassannataj",
			"Haderbadi, Mojtaba",
			"Mashmool, Amir",
			"GhasemiGol, Mohammad",
			"S., Shahab",
			"Mosavi, Amir"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  One of the most common and important destructive attacks on the victim system\nis Advanced Persistent Threat (APT)-attack. The APT attacker can achieve his\nhostile goals by obtaining information and gaining financial benefits regarding\nthe infrastructure of a network. One of the solutions to detect a secret APT\nattack is using network traffic. Due to the nature of the APT attack in terms\nof being on the network for a long time and the fact that the network may crash\nbecause of high traffic, it is difficult to detect this type of attack. Hence,\nin this study, machine learning methods such as C5.0 decision tree, Bayesian\nnetwork and deep neural network are used for timely detection and\nclassification of APT-attacks on the NSL-KDD dataset. Moreover, 10-fold cross\nvalidation method is used to experiment these models. As a result, the accuracy\n(ACC) of the C5.0 decision tree, Bayesian network and 6-layer deep learning\nmodels is obtained as 95.64%, 88.37% and 98.85%, respectively, and also, in\nterms of the important criterion of the false positive rate (FPR), the FPR\nvalue for the C5.0 decision tree, Bayesian network and 6-layer deep learning\nmodels is obtained as 2.56, 10.47 and 1.13, respectively. Other criterions such\nas sensitivity, specificity, accuracy, false negative rate and F-measure are\nalso investigated for the models, and the experimental results show that the\ndeep learning model with automatic multi-layered extraction of features has the\nbest performance for timely detection of an APT-attack comparing to other\nclassification models.\n",
			"Comment: 38 pages, 15 figures, 5 tables"
		],
		"date": "2020-09-19",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2009.10524",
			"doi:10.1109/ACCESS.2020.3029202"
		],
		"pdf_url": "http://arxiv.org/pdf/2009.10524.pdf"
	},
	"433": {
		"title": "Machine-learning physics from unphysics: Finding deconfinement\n  temperature in lattice Yang-Mills theories from outside the scaling window",
		"creator": [
			"Boyda, D. L.",
			"Chernodub, M. N.",
			"Gerasimeniuk, N. V.",
			"Goy, V. A.",
			"Liubimov, S. D.",
			"Molochkov, A. V."
		],
		"subject": [
			"High Energy Physics - Lattice",
			"Computer Science - Machine Learning",
			"High Energy Physics - Theory"
		],
		"description": [
			"  We study the machine learning techniques applied to the lattice gauge\ntheory's critical behavior, particularly to the confinement/deconfinement phase\ntransition in the SU(2) and SU(3) gauge theories. We find that the neural\nnetwork, trained on lattice configurations of gauge fields at an unphysical\nvalue of the lattice parameters as an input, builds up a gauge-invariant\nfunction, and finds correlations with the target observable that is valid in\nthe physical region of the parameter space. In particular, if the algorithm\naimed to predict the Polyakov loop as the deconfining order parameter, it\nbuilds a trace of the gauge group matrices along a closed loop in the time\ndirection. As a result, the neural network, trained at one unphysical value of\nthe lattice coupling $\\beta$ predicts the order parameter in the whole region\nof the $\\beta$ values with good precision. We thus demonstrate that the machine\nlearning techniques may be used as a numerical analog of the analytical\ncontinuation from easily accessible but physically uninteresting regions of the\ncoupling space to the interesting but potentially not accessible regions.\n",
			"Comment: 9 pages, 14 figures; v2: discussions added"
		],
		"date": [
			"2020-09-23",
			"2020-10-24"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2009.10971",
			"Phys. Rev. D 103, 014509 (2021)",
			"doi:10.1103/PhysRevD.103.014509"
		],
		"pdf_url": "http://arxiv.org/pdf/2009.10971.pdf"
	},
	"434": {
		"title": "Adjusted Measures for Feature Selection Stability for Data Sets with\n  Similar Features",
		"creator": [
			"Bommert, Andrea",
			"Rahnenführer, Jörg"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": "  For data sets with similar features, for example highly correlated features,\nmost existing stability measures behave in an undesired way: They consider\nfeatures that are almost identical but have different identifiers as different\nfeatures. Existing adjusted stability measures, that is, stability measures\nthat take into account the similarities between features, have major\ntheoretical drawbacks. We introduce new adjusted stability measures that\novercome these drawbacks. We compare them to each other and to existing\nstability measures based on both artificial and real sets of selected features.\nBased on the results, we suggest using one new stability measure that considers\nhighly similar features as exchangeable.\n",
		"date": "2020-09-25",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2009.12075",
			"doi:10.1007/978-3-030-64583-0_19"
		],
		"pdf_url": "http://arxiv.org/pdf/2009.12075.pdf"
	},
	"435": {
		"title": "SOUP: Spatial-Temporal Demand Forecasting and Competitive Supply",
		"creator": [
			"Zheng, Bolong",
			"Hu, Qi",
			"Ming, Lingfeng",
			"Hu, Jilin",
			"Chen, Lu",
			"Zheng, Kai",
			"Jensen, Christian S."
		],
		"subject": [
			"Computer Science - Databases",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": "  We consider a setting with an evolving set of requests for transportation\nfrom an origin to a destination before a deadline and a set of agents capable\nof servicing the requests. In this setting, an assignment authority is to\nassign agents to requests such that the average idle time of the agents is\nminimized. An example is the scheduling of taxis (agents) to meet incoming\nrequests for trips while ensuring that the taxis are empty as little as\npossible. In this paper, we study the problem of spatial-temporal demand\nforecasting and competitive supply (SOUP). We address the problem in two steps.\nFirst, we build a granular model that provides spatial-temporal predictions of\nrequests. Specifically, we propose a Spatial-Temporal Graph Convolutional\nSequential Learning (ST-GCSL) algorithm that predicts the service requests\nacross locations and time slots. Second, we provide means of routing agents to\nrequest origins while avoiding competition among the agents. In particular, we\ndevelop a demand-aware route planning (DROP) algorithm that considers both the\nspatial-temporal predictions and the supplydemand state. We report on extensive\nexperiments with realworld and synthetic data that offer insight into the\nperformance of the solution and show that it is capable of outperforming the\nstate-of-the-art proposals.\n",
		"date": [
			"2020-09-24",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.12157",
		"pdf_url": "http://arxiv.org/pdf/2009.12157.pdf"
	},
	"436": {
		"title": "Potential Features of ICU Admission in X-ray Images of COVID-19 Patients",
		"creator": [
			"Gomes, Douglas P. S.",
			"Ulhaq, Anwaar",
			"Paul, Manoranjan",
			"Horry, Michael J.",
			"Chakraborty, Subrata",
			"Saha, Manas",
			"Debnath, Tanmoy",
			"Rahaman, D. M. Motiur"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  X-ray images may present non-trivial features with predictive information of\npatients that develop severe symptoms of COVID-19. If true, this hypothesis may\nhave practical value in allocating resources to particular patients while using\na relatively inexpensive imaging technique. The difficulty of testing such a\nhypothesis comes from the need for large sets of labelled data, which need to\nbe well-annotated and should contemplate the post-imaging severity outcome.\nThis paper presents an original methodology for extracting semantic features\nthat correlate to severity from a data set with patient ICU admission labels\nthrough interpretable models. The methodology employs a neural network trained\nto recognise lung pathologies to extract the semantic features, which are then\nanalysed with low-complexity models to limit overfitting while increasing\ninterpretability. This analysis points out that only a few features explain\nmost of the variance between patients that developed severe symptoms. When\napplied to an unrelated larger data set with pathology-related clinical notes,\nthe method has shown to be capable of selecting images for the learned\nfeatures, which could translate some information about their common locations\nin the lung. Besides attesting separability on patients that eventually develop\nsevere symptoms, the proposed methods represent a statistical approach\nhighlighting the importance of features related to ICU admission that may have\nbeen only qualitatively reported. While handling limited data sets, notable\nmethodological aspects are adopted, such as presenting a state-of-the-art lung\nsegmentation network and the use of low-complexity models to avoid overfitting.\nThe code for methodology and experiments is also available.\n",
		"date": [
			"2020-09-26",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.12597",
		"pdf_url": "http://arxiv.org/pdf/2009.12597.pdf"
	},
	"437": {
		"title": "KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense\n  Reasoning",
		"creator": [
			"Liu, Ye",
			"Wan, Yao",
			"He, Lifang",
			"Peng, Hao",
			"Yu, Philip S."
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Symbolic Computation"
		],
		"description": [
			"  Generative commonsense reasoning which aims to empower machines to generate\nsentences with the capacity of reasoning over a set of concepts is a critical\nbottleneck for text generation. Even the state-of-the-art pre-trained language\ngeneration models struggle at this task and often produce implausible and\nanomalous sentences. One reason is that they rarely consider incorporating the\nknowledge graph which can provide rich relational information among the\ncommonsense concepts. To promote the ability of commonsense reasoning for text\ngeneration, we propose a novel knowledge graph augmented pre-trained language\ngeneration model KG-BART, which encompasses the complex relations of concepts\nthrough the knowledge graph and produces more logical and natural sentences as\noutput. Moreover, KG-BART can leverage the graph attention to aggregate the\nrich concept semantics that enhances the model generalization on unseen concept\nsets. Experiments on benchmark CommonGen dataset verify the effectiveness of\nour proposed approach by comparing with several strong pre-trained language\ngeneration models, particularly KG-BART outperforms BART by 5.80, 4.60, in\nterms of BLEU-3, 4. Moreover, we also show that the generated context by our\nmodel can work as background scenarios to benefit downstream commonsense QA\ntasks.\n",
			"Comment: 10 pages, 7 figures, Appear in AAAI 2021"
		],
		"date": [
			"2020-09-26",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.12677",
		"pdf_url": "http://arxiv.org/pdf/2009.12677.pdf"
	},
	"438": {
		"title": "Neural Proof Nets",
		"creator": [
			"Kogkalidis, Konstantinos",
			"Moortgat, Michael",
			"Moot, Richard"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning",
			"Computer Science - Logic in Computer Science"
		],
		"description": [
			"  Linear logic and the linear {\\lambda}-calculus have a long standing tradition\nin the study of natural language form and meaning. Among the proof calculi of\nlinear logic, proof nets are of particular interest, offering an attractive\ngeometric representation of derivations that is unburdened by the bureaucratic\ncomplications of conventional prooftheoretic formats. Building on recent\nadvances in set-theoretic learning, we propose a neural variant of proof nets\nbased on Sinkhorn networks, which allows us to translate parsing as the problem\nof extracting syntactic primitives and permuting them into alignment. Our\nmethodology induces a batch-efficient, end-to-end differentiable architecture\nthat actualizes a formally grounded yet highly efficient neuro-symbolic parser.\nWe test our approach on {\\AE}Thel, a dataset of type-logical derivations for\nwritten Dutch, where it manages to correctly transcribe raw text sentences into\nproofs and terms of the linear {\\lambda}-calculus with an accuracy of as high\nas 70%.\n",
			"Comment: 14 pages, CoNLL2020"
		],
		"date": "2020-09-26",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2009.12702",
			"Proceedings of the 24th Conference on Computational Natural\n  Language Learning (2020)",
			"doi:10.18653/v1/2020.conll-1.3"
		],
		"pdf_url": "http://arxiv.org/pdf/2009.12702.pdf"
	},
	"439": {
		"title": "Decentralized Age-of-Information Bandits",
		"creator": [
			"Prasad, Archiki",
			"Jain, Vishal",
			"Moharir, Sharayu"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Computer Science - Information Theory"
		],
		"description": [
			"  Age-of-Information (AoI) is a performance metric for scheduling systems that\nmeasures the freshness of the data available at the intended destination. AoI\nis formally defined as the time elapsed since the destination received the\nrecent most update from the source. We consider the problem of scheduling to\nminimize the cumulative AoI in a multi-source multi-channel setting. Our focus\nis on the setting where channel statistics are unknown and we model the problem\nas a distributed multi-armed bandit problem. For an appropriately defined AoI\nregret metric, we provide analytical performance guarantees of an existing\nUCB-based policy for the distributed multi-armed bandit problem. In addition,\nwe propose a novel policy based on Thomson Sampling and a hybrid policy that\ntries to balance the trade-off between the aforementioned policies. Further, we\ndevelop AoI-aware variants of these policies in which each source takes its\ncurrent AoI into account while making decisions. We compare the performance of\nvarious policies via simulations.\n",
			"Comment: Long-form version of paper accepted at IEEE WCNC 2021"
		],
		"date": [
			"2020-09-27",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.12961",
		"pdf_url": "http://arxiv.org/pdf/2009.12961.pdf"
	},
	"440": {
		"title": "Robust Model Predictive Longitudinal Position Tracking Control for an\n  Autonomous Vehicle Based on Multiple Models",
		"creator": [
			"Kempf, André",
			"Herrmann-Wicklmayr, Markus",
			"Müller, Steffen"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Computer Science - Robotics"
		],
		"description": [
			"  The aim of this work is to control the longitudinal position of an autonomous\nvehicle with an internal combustion engine. The powertrain has an inherent\ndead-time characteristic and constraints on physical states apply since the\nvehicle is neither able to accelerate arbitrarily strong, nor to drive\narbitrarily fast. A model predictive controller (MPC) is able to cope with both\nof the aforementioned system properties. MPC heavily relies on a model and\ntherefore a strategy on how to obtain multiple linear state space prediction\nmodels of the nonlinear system via input/output data system identification from\nacceleration data is given. The models are identified in different regions of\nthe vehicle dynamics in order to obtain more accurate predictions. The still\nremaining plant-model mismatch can be expressed as an additive disturbance\nwhich can be handled through robust control theory. Therefore modifications to\nthe models for applying robust MPC tracking control theory are described. Then\na controller which guarantees robust constraint satisfaction and recursive\nfeasibility is designed. As a next step, modifications to apply the controller\non multiple models are discussed. In this context, a model switching strategy\nis provided and theoretical and computational limitations are pointed out.\nLastly, simulation results are presented and discussed, including computational\nload when switching between systems.\n",
			"Comment: Accepted for 2020 IEEE Symposium Series on Computational Intelligence\n  (IEEE SSCI)"
		],
		"date": [
			"2020-09-28",
			"2020-10-21"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2009.13406",
			"doi:10.1109/SSCI47803.2020.9308186"
		],
		"pdf_url": "http://arxiv.org/pdf/2009.13406.pdf"
	},
	"441": {
		"title": "Robust Monotonic Convergent Iterative Learning Control Design: an\n  LMI-based Method",
		"creator": "Su, Lanlan",
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": "  This work investigates robust monotonic convergent iterative learning control\n(ILC) for uncertain linear systems in both time and frequency domains, and the\nILC algorithm optimizing the convergence speed in terms of $l_{2}$ norm of\nerror signals is derived. Firstly, it is shown that the robust monotonic\nconvergence of the ILC system can be established equivalently by the positive\ndefiniteness of a matrix polynomial over some set. Then, a necessary and\nsufficient condition in the form of sum of squares (SOS) for the positive\ndefiniteness is proposed, which is amendable to the feasibility of linear\nmatrix inequalities (LMIs). Based on such a condition, the optimal ILC\nalgorithm that maximizes the convergence speed is obtained by solving a set of\nconvex optimization problems. Moreover, the order of the learning function can\nbe chosen arbitrarily so that the designers have the flexibility to decide the\ncomplexity of the learning algorithm.\n",
		"date": [
			"2020-09-28",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2009.13574",
		"pdf_url": "http://arxiv.org/pdf/2009.13574.pdf"
	},
	"442": {
		"title": "Explainable Online Validation of Machine Learning Models for Practical\n  Applications",
		"creator": [
			"Fuhl, Wolfgang",
			"Rong, Yao",
			"Motz, Thomas",
			"Scheidt, Michael",
			"Hartel, Andreas",
			"Koch, Andreas",
			"Kasneci, Enkelejda"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Statistics - Machine Learning"
		],
		"description": "  We present a reformulation of the regression and classification, which aims\nto validate the result of a machine learning algorithm. Our reformulation\nsimplifies the original problem and validates the result of the machine\nlearning algorithm using the training data. Since the validation of machine\nlearning algorithms must always be explainable, we perform our experiments with\nthe kNN algorithm as well as with an algorithm based on conditional\nprobabilities, which is proposed in this work. For the evaluation of our\napproach, three publicly available data sets were used and three classification\nand two regression problems were evaluated. The presented algorithm based on\nconditional probabilities is also online capable and requires only a fraction\nof memory compared to the kNN algorithm.\n",
		"date": [
			"2020-10-02",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.00821",
		"pdf_url": "http://arxiv.org/pdf/2010.00821.pdf"
	},
	"443": {
		"title": "Weight and Gradient Centralization in Deep Neural Networks",
		"creator": [
			"Fuhl, Wolfgang",
			"Kasneci, Enkelejda"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": "  Batch normalization is currently the most widely used variant of internal\nnormalization for deep neural networks. Additional work has shown that the\nnormalization of weights and additional conditioning as well as the\nnormalization of gradients further improve the generalization. In this work, we\ncombine several of these methods and thereby increase the generalization of the\nnetworks. The advantage of the newer methods compared to the batch\nnormalization is not only increased generalization, but also that these methods\nonly have to be applied during training and, therefore, do not influence the\nrunning time during use. Link to CUDA code\nhttps://atreus.informatik.uni-tuebingen.de/seafile/d/8e2ab8c3fdd444e1a135/\n",
		"date": [
			"2020-10-02",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.00866",
		"pdf_url": "http://arxiv.org/pdf/2010.00866.pdf"
	},
	"444": {
		"title": "Rotated Ring, Radial and Depth Wise Separable Radial Convolutions",
		"creator": [
			"Fuhl, Wolfgang",
			"Kasneci, Enkelejda"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Simple image rotations significantly reduce the accuracy of deep neural\nnetworks. Moreover, training with all possible rotations increases the data\nset, which also increases the training duration. In this work, we address\ntrainable rotation invariant convolutions as well as the construction of nets,\nsince fully connected layers can only be rotation invariant with a\none-dimensional input. On the one hand, we show that our approach is\nrotationally invariant for different models and on different public data sets.\nWe also discuss the influence of purely rotational invariant features on\naccuracy. The rotationally adaptive convolution models presented in this work\nare more computationally intensive than normal convolution models. Therefore,\nwe also present a depth wise separable approach with radial convolution. Link\nto CUDA code\nhttps://atreus.informatik.uni-tuebingen.de/seafile/d/8e2ab8c3fdd444e1a135/\n",
		"date": [
			"2020-10-02",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.00873",
		"pdf_url": "http://arxiv.org/pdf/2010.00873.pdf"
	},
	"445": {
		"title": "DIRV: Dense Interaction Region Voting for End-to-End Human-Object\n  Interaction Detection",
		"creator": [
			"Fang, Hao-Shu",
			"Xie, Yichen",
			"Shao, Dian",
			"Lu, Cewu"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Recent years, human-object interaction (HOI) detection has achieved\nimpressive advances. However, conventional two-stage methods are usually slow\nin inference. On the other hand, existing one-stage methods mainly focus on the\nunion regions of interactions, which introduce unnecessary visual information\nas disturbances to HOI detection. To tackle the problems above, we propose a\nnovel one-stage HOI detection approach DIRV in this paper, based on a new\nconcept called interaction region for the HOI problem. Unlike previous methods,\nour approach concentrates on the densely sampled interaction regions across\ndifferent scales for each human-object pair, so as to capture the subtle visual\nfeatures that is most essential to the interaction. Moreover, in order to\ncompensate for the detection flaws of a single interaction region, we introduce\na novel voting strategy that makes full use of those overlapped interaction\nregions in place of conventional Non-Maximal Suppression (NMS). Extensive\nexperiments on two popular benchmarks: V-COCO and HICO-DET show that our\napproach outperforms existing state-of-the-arts by a large margin with the\nhighest inference speed and lightest network architecture. We achieved 56.1 mAP\non V-COCO without addtional input. Our code is publicly available at:\nhttps://github.com/MVIG-SJTU/DIRV\n",
			"Comment: Paper is accepted. Code available at:\n  https://github.com/MVIG-SJTU/DIRV"
		],
		"date": [
			"2020-10-02",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.01005",
		"pdf_url": "http://arxiv.org/pdf/2010.01005.pdf"
	},
	"446": {
		"title": "If beam search is the answer, what was the question?",
		"creator": [
			"Meister, Clara",
			"Vieira, Tim",
			"Cotterell, Ryan"
		],
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  Quite surprisingly, exact maximum a posteriori (MAP) decoding of neural\nlanguage generators frequently leads to low-quality results. Rather, most\nstate-of-the-art results on language generation tasks are attained using beam\nsearch despite its overwhelmingly high search error rate. This implies that the\nMAP objective alone does not express the properties we desire in text, which\nmerits the question: if beam search is the answer, what was the question? We\nframe beam search as the exact solution to a different decoding objective in\norder to gain insights into why high probability under a model alone may not\nindicate adequacy. We find that beam search enforces uniform information\ndensity in text, a property motivated by cognitive science. We suggest a set of\ndecoding objectives that explicitly enforce this property and find that exact\ndecoding with these objectives alleviates the problems encountered when\ndecoding poorly calibrated language generation models. Additionally, we analyze\nthe text produced using various decoding strategies and see that, in our neural\nmachine translation experiments, the extent to which this property is adhered\nto strongly correlates with BLEU.\n",
			"Comment: EMNLP 2020"
		],
		"date": [
			"2020-10-06",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.02650",
		"pdf_url": "http://arxiv.org/pdf/2010.02650.pdf"
	},
	"447": {
		"title": "Support-set bottlenecks for video-text representation learning",
		"creator": [
			"Patrick, Mandela",
			"Huang, Po-Yao",
			"Asano, Yuki",
			"Metze, Florian",
			"Hauptmann, Alexander",
			"Henriques, João",
			"Vedaldi, Andrea"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  The dominant paradigm for learning video-text representations -- noise\ncontrastive learning -- increases the similarity of the representations of\npairs of samples that are known to be related, such as text and video from the\nsame sample, and pushes away the representations of all other pairs. We posit\nthat this last behaviour is too strict, enforcing dissimilar representations\neven for samples that are semantically-related -- for example, visually similar\nvideos or ones that share the same depicted action. In this paper, we propose a\nnovel method that alleviates this by leveraging a generative model to naturally\npush these related samples together: each sample's caption must be\nreconstructed as a weighted combination of other support samples' visual\nrepresentations. This simple idea ensures that representations are not\noverly-specialized to individual samples, are reusable across the dataset, and\nresults in representations that explicitly encode semantics shared between\nsamples, unlike noise contrastive learning. Our proposed method outperforms\nothers by a large margin on MSR-VTT, VATEX and ActivityNet, and MSVD for\nvideo-to-text and text-to-video retrieval.\n",
			"Comment: Accepted as spotlight paper at the International Conference on\n  Learning Representations (ICLR) 2021"
		],
		"date": [
			"2020-10-06",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.02824",
		"pdf_url": "http://arxiv.org/pdf/2010.02824.pdf"
	},
	"448": {
		"title": "Stochastic parameterization with VARX processes",
		"creator": [
			"Verheul, Nick",
			"Crommelin, Daan"
		],
		"subject": [
			"Statistics - Methodology",
			"Computer Science - Machine Learning",
			"Mathematics - Numerical Analysis",
			"Physics - Atmospheric and Oceanic Physics",
			"Physics - Data Analysis, Statistics and Probability",
			"62F30 (Primary) 60H10, 65C20, 68U20, 70K70 (Secondary)"
		],
		"description": "  In this study we investigate a data-driven stochastic methodology to\nparameterize small-scale features in a prototype multiscale dynamical system,\nthe Lorenz '96 (L96) model. We propose to model the small-scale features using\na vector autoregressive process with exogenous variable (VARX), estimated from\ngiven sample data. To reduce the number of parameters of the VARX we impose a\ndiagonal structure on its coefficient matrices. We apply the VARX to two\ndifferent configurations of the 2-layer L96 model, one with common parameter\nchoices giving unimodal invariant probability distributions for the L96 model\nvariables, and one with non-standard parameters giving trimodal distributions.\nWe show through various statistical criteria that the proposed VARX performs\nvery well for the unimodal configuration, while keeping the number of\nparameters linear in the number of model variables. We also show that the\nparameterization performs accurately for the very challenging trimodal L96\nconfiguration by allowing for a dense (non-diagonal) VARX covariance matrix.\n",
		"date": "2020-10-07",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2010.03293",
			"Commun. Appl. Math. Comput. Sci. 16 (2021) 33-57",
			"doi:10.2140/camcos.2021.16.33"
		],
		"pdf_url": "http://arxiv.org/pdf/2010.03293.pdf"
	},
	"449": {
		"title": "Robust Semi-Supervised Learning with Out of Distribution Data",
		"creator": [
			"Zhao, Xujiang",
			"Krishnateja, Killamsetty",
			"Iyer, Rishabh",
			"Chen, Feng"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  Recent Semi-supervised learning (SSL) works show significant improvement in\nSSL algorithms' performance using better-unlabeled data representations.\nHowever, recent work [Oliver et al., 2018] shows that the SSL algorithm's\nperformance could degrade when the unlabeled set has out-of-distribution\nexamples (OODs). In this work, we first study the critical causes of OOD's\nnegative impact on SSL algorithms. We found that (1) the OOD's effect on the\nSSL algorithm's performance increases as its distance to the decision boundary\ndecreases, and (2) Batch Normalization (BN), a popular module, could degrade\nthe performance instead of improving the performance when the unlabeled set\ncontains OODs. To address the above causes, we proposed a novel unified-robust\nSSL approach that can be easily extended to many existing SSL algorithms, and\nimprove their robustness against OODs. In particular, we propose a simple\nmodification of batch normalization, called weighted batch normalization, that\nimproves BN's robustness against OODs. We also developed two efficient\nhyper-parameter optimization algorithms that have different tradeoffs in\ncomputational efficiency and accuracy. Extensive experiments on synthetic and\nreal-world datasets prove that our proposed approaches significantly improves\nthe robustness of four representative SSL algorithms against OODs compared with\nfour state-of-the-art robust SSL approaches.\n",
			"Comment: Preprint"
		],
		"date": [
			"2020-10-07",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.03658",
		"pdf_url": "http://arxiv.org/pdf/2010.03658.pdf"
	},
	"450": {
		"title": "Baseline and Triangulation Geometry in a Standard Plenoptic Camera",
		"creator": [
			"Hahne, Christopher",
			"Aggoun, Amar",
			"Velisavljevic, Vladan",
			"Fiebig, Susanne",
			"Pesch, Matthias"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Computational Geometry",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Physics - Optics"
		],
		"description": [
			"  In this paper, we demonstrate light field triangulation to determine depth\ndistances and baselines in a plenoptic camera. Advances in micro lenses and\nimage sensors have enabled plenoptic cameras to capture a scene from different\nviewpoints with sufficient spatial resolution. While object distances can be\ninferred from disparities in a stereo viewpoint pair using triangulation, this\nconcept remains ambiguous when applied in the case of plenoptic cameras. We\npresent a geometrical light field model allowing the triangulation to be\napplied to a plenoptic camera in order to predict object distances or specify\nbaselines as desired. It is shown that distance estimates from our novel method\nmatch those of real objects placed in front of the camera. Additional benchmark\ntests with an optical design software further validate the model's accuracy\nwith deviations of less than +-0.33 % for several main lens types and focus\nsettings. A variety of applications in the automotive and robotics field can\nbenefit from this estimation model.\n",
			"Comment: clarified remarks around Eqs.(16-17)"
		],
		"date": [
			"2020-10-09",
			"2021-01-20"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2010.04638",
			"International Journal of Computer Vision, volume 126, pages 21-35\n  (2018)",
			"doi:10.1007/s11263-017-1036-4"
		],
		"pdf_url": "http://arxiv.org/pdf/2010.04638.pdf"
	},
	"451": {
		"title": "A Series of Unfortunate Counterfactual Events: the Role of Time in\n  Counterfactual Explanations",
		"creator": [
			"Ferrario, Andrea",
			"Loi, Michele"
		],
		"subject": "Computer Science - Artificial Intelligence",
		"description": [
			"  Counterfactual explanations are a prominent example of post-hoc\ninterpretability methods in the explainable Artificial Intelligence research\ndomain. They provide individuals with alternative scenarios and a set of\nrecommendations to achieve a sought-after machine learning model outcome.\nRecently, the literature has identified desiderata of counterfactual\nexplanations, such as feasibility, actionability and sparsity that should\nsupport their applicability in real-world contexts. However, we show that the\nliterature has neglected the problem of the time dependency of counterfactual\nexplanations. We argue that, due to their time dependency and because of the\nprovision of recommendations, even feasible, actionable and sparse\ncounterfactual explanations may not be appropriate in real-world applications.\nThis is due to the possible emergence of what we call \"unfortunate\ncounterfactual events.\" These events may occur due to the retraining of machine\nlearning models whose outcomes have to be explained via counterfactual\nexplanation. Series of unfortunate counterfactual events frustrate the efforts\nof those individuals who successfully implemented the recommendations of\ncounterfactual explanations. This negatively affects people's trust in the\nability of institutions to provide machine learning-supported decisions\nconsistently. We introduce an approach to address the problem of the emergence\nof unfortunate counterfactual events that makes use of histories of\ncounterfactual explanations. In the final part of the paper we propose an\nethical analysis of two distinct strategies to cope with the challenge of\nunfortunate counterfactual events. We show that they respond to an ethically\nresponsible imperative to preserve the trustworthiness of credit lending\norganizations, the decision models they employ, and the social-economic\nfunction of credit lending.\n",
			"Comment: 11 pages, 1 figure"
		],
		"date": [
			"2020-10-09",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.04687",
		"pdf_url": "http://arxiv.org/pdf/2010.04687.pdf"
	},
	"452": {
		"title": "Cache Updating Strategy Minimizing the Age of Information with\n  Time-Varying Files' Popularities",
		"creator": [
			"Tang, Haoyue",
			"Ciblat, Philippe",
			"Wang, Jintao",
			"Wigger, Michele",
			"Yates, Roy D."
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  We consider updating strategies for a local cache which downloads\ntime-sensitive files from a remote server through a bandwidth-constrained link.\nThe files are requested randomly from the cache by local users according to a\npopularity distribution which varies over time according to a Markov chain\nstructure. We measure the freshness of the requested time-sensitive files\nthrough their Age of Information (AoI). The goal is then to minimize the\naverage AoI of all requested files by appropriately designing the local cache's\ndownloading strategy. To achieve this goal, the original problem is relaxed and\ncast into a Constrained Markov Decision Problem (CMDP), which we solve using a\nLagrangian approach and Linear Programming. Inspired by this solution for the\nrelaxed problem, we propose a practical cache updating strategy that meets all\nthe constraints of the original problem. Under certain assumptions, the\npractical updating strategy is shown to be optimal for the original problem in\nthe asymptotic regime of a large number of files.\n  For a finite number of files, we show the gain of our practical updating\nstrategy over the traditional square-root-law strategy (which is optimal for\nfixed non time-varying file popularities) through numerical simulations.\n",
			"Comment: To appear ITW2020"
		],
		"date": [
			"2020-10-09",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.04787",
		"pdf_url": "http://arxiv.org/pdf/2010.04787.pdf"
	},
	"453": {
		"title": "Contrastive Explanations for Reinforcement Learning via Embedded Self\n  Predictions",
		"creator": [
			"Lin, Zhengxian",
			"Lam, Kim-Ho",
			"Fern, Alan"
		],
		"subject": "Computer Science - Artificial Intelligence",
		"description": [
			"  We investigate a deep reinforcement learning (RL) architecture that supports\nexplaining why a learned agent prefers one action over another. The key idea is\nto learn action-values that are directly represented via human-understandable\nproperties of expected futures. This is realized via the embedded\nself-prediction (ESP)model, which learns said properties in terms of human\nprovided features. Action preferences can then be explained by contrasting the\nfuture properties predicted for each action. To address cases where there are a\nlarge number of features, we develop a novel method for computing minimal\nsufficient explanations from anESP. Our case studies in three domains,\nincluding a complex strategy game, show that ESP models can be effectively\nlearned and support insightful explanations.\n",
			"Comment: Published (Oral) at ICLR 2021"
		],
		"date": [
			"2020-10-11",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.05180",
		"pdf_url": "http://arxiv.org/pdf/2010.05180.pdf"
	},
	"454": {
		"title": "A kernel-independent sum-of-Gaussians method by de la Vall\\'ee-Poussin\n  sums",
		"creator": [
			"Liang, Jiuyang",
			"Gao, Zixuan",
			"Xu, Zhenli"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"Physics - Computational Physics",
			"65D15, 42A16, 70F10"
		],
		"description": [
			"  Approximation of interacting kernels by sum of Gaussians (SOG) is frequently\nrequired in many applications of scientific and engineering computing in order\nto construct efficient algorithms for kernel summation or convolution problems.\nIn this paper, we propose a kernel-independent SOG method by introducing the de\nla Vall\\'ee-Poussin sum and Chebyshev polynomials. The SOG works for general\ninteracting kernels and the lower bound of Gaussian bandwidths is tunable and\nthus the Gaussians can be easily summed by fast Gaussian algorithms. The number\nof Gaussians can be further reduced via the model reduction based on the\nbalanced truncation based on the square root method. Numerical results on the\naccuracy and model reduction efficiency show attractive performance of the\nproposed method.\n",
			"Comment: 15 pages, 3 figures, 2 tables. The algorithm code available at\n  https://github.com/ZXGao97/VPMR.git"
		],
		"date": [
			"2020-10-11",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.05192",
		"pdf_url": "http://arxiv.org/pdf/2010.05192.pdf"
	},
	"455": {
		"title": "Genetic Bi-objective Optimization Approach to Habitability Score",
		"creator": [
			"Krishna, Sriram",
			"Pentapati, Niharika"
		],
		"subject": [
			"Computer Science - Neural and Evolutionary Computing",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  The search for life outside the Solar System is an endeavour of astronomers\nall around the world. With hundreds of exoplanets being discovered due to\nadvances in astronomy, there is a need to classify the habitability of these\nexoplanets. This is typically done using various metrics such as the Earth\nSimilarity Index or the Planetary Habitability Index. In this paper, Genetic\nAlgorithms are used to evaluate the best possible habitability scores using the\nCobb-Douglas Habitability Score. Genetic Algorithm is a classic evolutionary\nalgorithm used for solving optimization problems. It is based on Darwin's\ntheory of evolution, \"Survival of the fittest\". The working of the algorithm is\nestablished through comparison with various benchmark functions and extended\nits functionality to Multi-Objective optimization. The Cobb-Douglas\nHabitability Function is formulated as a bi-objective as well as a single\nobjective optimization problem to find the optimal values to maximize the\nCobb-Douglas Habitability Score for a set of promising exoplanets.\n",
			"Comment: 15 pages, 9 figures, granted for publication in Communications in\n  Computer and Information Science (CCIS) proceedings by Springer Nature,\n  presented at the International Conference on Modeling, Machine Learning and\n  Astronomy (MMLA19)"
		],
		"date": "2020-10-12",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2010.05494",
			"doi:10.1007/978-981-33-6463-9_12"
		],
		"pdf_url": "http://arxiv.org/pdf/2010.05494.pdf"
	},
	"456": {
		"title": "Remote Electrical Tilt Optimization via Safe Reinforcement Learning",
		"creator": [
			"Vannella, Filippo",
			"Iakovidis, Grigorios",
			"Hakim, Ezeddin Al",
			"Aumayr, Erik",
			"Feghhi, Saman"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Remote Electrical Tilt (RET) optimization is an efficient method for\nadjusting the vertical tilt angle of Base Stations (BSs) antennas in order to\noptimize Key Performance Indicators (KPIs) of the network. Reinforcement\nLearning (RL) provides a powerful framework for RET optimization because of its\nself-learning capabilities and adaptivity to environmental changes. However, an\nRL agent may execute unsafe actions during the course of its interaction, i.e.,\nactions resulting in undesired network performance degradation. Since the\nreliability of services is critical for Mobile Network Operators (MNOs), the\nprospect of performance degradation has prohibited the real-world deployment of\nRL methods for RET optimization. In this work, we model the RET optimization\nproblem in the Safe Reinforcement Learning (SRL) framework with the goal of\nlearning a tilt control strategy providing performance improvement guarantees\nwith respect to a safe baseline. We leverage a recent SRL method, namely Safe\nPolicy Improvement through Baseline Bootstrapping (SPIBB), to learn an improved\npolicy from an offline dataset of interactions collected by the safe baseline.\nOur experiments show that the proposed approach is able to learn a safe and\nimproved tilt update policy, providing a higher degree of reliability and\npotential for real-world network deployment.\n",
		"date": [
			"2020-10-12",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.05842",
		"pdf_url": "http://arxiv.org/pdf/2010.05842.pdf"
	},
	"457": {
		"title": "Explain2Attack: Text Adversarial Attacks via Cross-Domain\n  Interpretability",
		"creator": [
			"Hossam, Mahmoud",
			"Le, Trung",
			"Zhao, He",
			"Phung, Dinh"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Cryptography and Security",
			"I.5.0",
			"I.2.0"
		],
		"description": [
			"  Training robust deep learning models for down-stream tasks is a critical\nchallenge. Research has shown that down-stream models can be easily fooled with\nadversarial inputs that look like the training data, but slightly perturbed, in\na way imperceptible to humans. Understanding the behavior of natural language\nmodels under these attacks is crucial to better defend these models against\nsuch attacks. In the black-box attack setting, where no access to model\nparameters is available, the attacker can only query the output information\nfrom the targeted model to craft a successful attack. Current black-box\nstate-of-the-art models are costly in both computational complexity and number\nof queries needed to craft successful adversarial examples. For real world\nscenarios, the number of queries is critical, where less queries are desired to\navoid suspicion towards an attacking agent. In this paper, we propose\nExplain2Attack, a black-box adversarial attack on text classification task.\nInstead of searching for important words to be perturbed by querying the target\nmodel, Explain2Attack employs an interpretable substitute model from a similar\ndomain to learn word importance scores. We show that our framework either\nachieves or out-performs attack rates of the state-of-the-art models, yet with\nlower queries cost and higher efficiency.\n",
			"Comment: Preprint for accepted paper at 25th International Conference on\n  Pattern Recognition (ICPR 2020)"
		],
		"date": [
			"2020-10-14",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.06812",
		"pdf_url": "http://arxiv.org/pdf/2010.06812.pdf"
	},
	"458": {
		"title": "Interpolation and Amalgamation for Arrays with MaxDiff (Extended\n  Version)",
		"creator": [
			"Ghilardi, Silvio",
			"Gianola, Alessandro",
			"Kapur, Deepak"
		],
		"subject": "Computer Science - Logic in Computer Science",
		"description": "  In this paper, the theory of McCarthy's extensional arrays enriched with a\nmaxdiff operation (this operation returns the biggest index where two given\narrays differ) is proposed. It is known from the literature that a diff\noperation is required for the theory of arrays in order to enjoy the Craig\ninterpolation property at the quantifier-free level. However, the diff\noperation introduced in the literature is merely instrumental to this purpose\nand has only a purely formal meaning (it is obtained from the Skolemization of\nthe extensionality axiom). Our maxdiff operation significantly increases the\nlevel of expressivity; however, obtaining interpolation results for the\nresulting theory becomes a surprisingly hard task. We obtain such results via a\nthorough semantic analysis of the models of the theory and of their\namalgamation properties. The results are modular with respect to the index\ntheory and it is shown how to convert them into concrete interpolation\nalgorithms via a hierarchical approach.\n",
		"date": [
			"2020-10-14",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.07082",
		"pdf_url": "http://arxiv.org/pdf/2010.07082.pdf"
	},
	"459": {
		"title": "Disentangled Dynamic Graph Deep Generation",
		"creator": [
			"Zhang, Wenbin",
			"Zhang, Liming",
			"Pfoser, Dieter",
			"Zhao, Liang"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Social and Information Networks"
		],
		"description": [
			"  Deep generative models for graphs have exhibited promising performance in\never-increasing domains such as design of molecules (i.e, graph of atoms) and\nstructure prediction of proteins (i.e., graph of amino acids). Existing work\ntypically focuses on static rather than dynamic graphs, which are actually very\nimportant in the applications such as protein folding, molecule reactions, and\nhuman mobility. Extending existing deep generative models from static to\ndynamic graphs is a challenging task, which requires to handle the\nfactorization of static and dynamic characteristics as well as mutual\ninteractions among node and edge patterns. Here, this paper proposes a novel\nframework of factorized deep generative models to achieve interpretable dynamic\ngraph generation. Various generative models are proposed to characterize\nconditional independence among node, edge, static, and dynamic factors. Then,\nvariational optimization strategies as well as dynamic graph decoders are\nproposed based on newly designed factorized variational autoencoders and\nrecurrent graph deconvolutions. Extensive experiments on multiple datasets\ndemonstrate the effectiveness of the proposed models.\n",
			"Comment: Accepted to SDM21"
		],
		"date": [
			"2020-10-14",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.07276",
		"pdf_url": "http://arxiv.org/pdf/2010.07276.pdf"
	},
	"460": {
		"title": "Pose Refinement Graph Convolutional Network for Skeleton-based Action\n  Recognition",
		"creator": [
			"Li, Shijie",
			"Yi, Jinhui",
			"Farha, Yazan Abu",
			"Gall, Juergen"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  With the advances in capturing 2D or 3D skeleton data, skeleton-based action\nrecognition has received an increasing interest over the last years. As\nskeleton data is commonly represented by graphs, graph convolutional networks\nhave been proposed for this task. While current graph convolutional networks\naccurately recognize actions, they are too expensive for robotics applications\nwhere limited computational resources are available. In this paper, we\ntherefore propose a highly efficient graph convolutional network that addresses\nthe limitations of previous works. This is achieved by a parallel structure\nthat gradually fuses motion and spatial information and by reducing the\ntemporal resolution as early as possible. Furthermore, we explicitly address\nthe issue that human poses can contain errors. To this end, the network first\nrefines the poses before they are further processed to recognize the action. We\ntherefore call the network Pose Refinement Graph Convolutional Network.\nCompared to other graph convolutional networks, our network requires 86\\%-93\\%\nless parameters and reduces the floating point operations by 89%-96% while\nachieving a comparable accuracy. It therefore provides a much better trade-off\nbetween accuracy, memory footprint and processing time, which makes it suitable\nfor robotics applications.\n",
			"Comment: Accepted for publication in IEEE Robotics and Automation Letters\n  (RA-L)"
		],
		"date": [
			"2020-10-14",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.07367",
		"pdf_url": "http://arxiv.org/pdf/2010.07367.pdf"
	},
	"461": {
		"title": "Harnessing Uncertainty in Domain Adaptation for MRI Prostate Lesion\n  Segmentation",
		"creator": [
			"Chiou, Eleni",
			"Giganti, Francesco",
			"Punwani, Shonit",
			"Kokkinos, Iasonas",
			"Panagiotaki, Eleftheria"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": [
			"  The need for training data can impede the adoption of novel imaging\nmodalities for learning-based medical image analysis. Domain adaptation methods\npartially mitigate this problem by translating training data from a related\nsource domain to a novel target domain, but typically assume that a one-to-one\ntranslation is possible. Our work addresses the challenge of adapting to a more\ninformative target domain where multiple target samples can emerge from a\nsingle source sample. In particular we consider translating from mp-MRI to\nVERDICT, a richer MRI modality involving an optimized acquisition protocol for\ncancer characterization. We explicitly account for the inherent uncertainty of\nthis mapping and exploit it to generate multiple outputs conditioned on a\nsingle input. Our results show that this allows us to extract systematically\nbetter image representations for the target domain, when used in tandem with\nboth simple, CycleGAN-based baselines, as well as more powerful approaches that\nintegrate discriminative segmentation losses and/or residual adapters. When\ncompared to its deterministic counterparts, our approach yields substantial\nimprovements across a broad range of dataset sizes, increasingly strong\nbaselines, and evaluation measures.\n",
			"Comment: Accepted at MICCAI 2020. Code is available at\n  https://github.com/elchiou/DA"
		],
		"date": [
			"2020-10-14",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.07411",
		"pdf_url": "http://arxiv.org/pdf/2010.07411.pdf"
	},
	"462": {
		"title": "Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and\n  Goals of Human Trust in AI",
		"creator": [
			"Jacovi, Alon",
			"Marasović, Ana",
			"Miller, Tim",
			"Goldberg, Yoav"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computers and Society"
		],
		"description": [
			"  Trust is a central component of the interaction between people and AI, in\nthat 'incorrect' levels of trust may cause misuse, abuse or disuse of the\ntechnology. But what, precisely, is the nature of trust in AI? What are the\nprerequisites and goals of the cognitive mechanism of trust, and how can we\npromote them, or assess whether they are being satisfied in a given\ninteraction? This work aims to answer these questions. We discuss a model of\ntrust inspired by, but not identical to, sociology's interpersonal trust (i.e.,\ntrust between people). This model rests on two key properties of the\nvulnerability of the user and the ability to anticipate the impact of the AI\nmodel's decisions. We incorporate a formalization of 'contractual trust', such\nthat trust between a user and an AI is trust that some implicit or explicit\ncontract will hold, and a formalization of 'trustworthiness' (which detaches\nfrom the notion of trustworthiness in sociology), and with it concepts of\n'warranted' and 'unwarranted' trust. We then present the possible causes of\nwarranted trust as intrinsic reasoning and extrinsic behavior, and discuss how\nto design trustworthy AI, how to evaluate whether trust has manifested, and\nwhether it is warranted. Finally, we elucidate the connection between trust and\nXAI using our formalization.\n",
			"Comment: Accepted to ACM FAccT 2021"
		],
		"date": [
			"2020-10-14",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.07487",
		"pdf_url": "http://arxiv.org/pdf/2010.07487.pdf"
	},
	"463": {
		"title": "The LL(finite) strategy for optimal LL(k) parsing",
		"creator": "Belcak, Peter",
		"subject": [
			"Computer Science - Programming Languages",
			"Computer Science - Computation and Language",
			"Computer Science - Formal Languages and Automata Theory"
		],
		"description": [
			"  The LL(finite) parsing strategy for parsing of LL(k) grammars where k needs\nnot to be known is presented. The strategy parses input in linear time, uses\narbitrary but always minimal lookahead necessary to disambiguate between\nalternatives of nonterminals, and it is optimal in the number of lookahead\nterminal scans performed. Modifications to the algorithm are shown that allow\nfor resolution of grammar ambiguities by precedence -- effectively interpreting\nthe input as a parsing expression grammar -- as well as for the use of\npredicates, and a proof of concept, the open-source parser generator Astir,\nemploys the LL(finite) strategy in the output it generates.\n",
			"Comment: An error was found in one of the algorithms for weak LL(k) grammars"
		],
		"date": [
			"2020-10-15",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.07874",
		"pdf_url": "http://arxiv.org/pdf/2010.07874.pdf"
	},
	"464": {
		"title": "RAT iLQR: A Risk Auto-Tuning Controller to Optimally Account for\n  Stochastic Model Mismatch",
		"creator": [
			"Nishimura, Haruki",
			"Mehr, Negar",
			"Gaidon, Adrien",
			"Schwager, Mac"
		],
		"subject": "Computer Science - Robotics",
		"description": [
			"  Successful robotic operation in stochastic environments relies on accurate\ncharacterization of the underlying probability distributions, yet this is often\nimperfect due to limited knowledge. This work presents a control algorithm that\nis capable of handling such distributional mismatches. Specifically, we propose\na novel nonlinear MPC for distributionally robust control, which plans locally\noptimal feedback policies against a worst-case distribution within a given KL\ndivergence bound from a Gaussian distribution. Leveraging mathematical\nequivalence between distributionally robust control and risk-sensitive optimal\ncontrol, our framework also provides an algorithm to dynamically adjust the\nrisk-sensitivity level online for risk-sensitive control. The benefits of the\ndistributional robustness as well as the automatic risk-sensitivity adjustment\nare demonstrated in a dynamic collision avoidance scenario where the predictive\ndistribution of human motion is erroneous.\n",
			"Comment: To appear in IEEE Robotics and Automation Letters"
		],
		"date": [
			"2020-10-16",
			"2021-01-18"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2010.08174",
			"doi:10.1109/LRA.2020.3048660"
		],
		"pdf_url": "http://arxiv.org/pdf/2010.08174.pdf"
	},
	"465": {
		"title": "Autonomous Robotic Suction to Clear the Surgical Field for Hemostasis\n  using Image-based Blood Flow Detection",
		"creator": [
			"Richter, Florian",
			"Shen, Shihao",
			"Liu, Fei",
			"Huang, Jingbin",
			"Funk, Emily K.",
			"Orosco, Ryan K.",
			"Yip, Michael C."
		],
		"subject": "Computer Science - Robotics",
		"description": [
			"  Autonomous robotic surgery has seen significant progression over the last\ndecade with the aims of reducing surgeon fatigue, improving procedural\nconsistency, and perhaps one day take over surgery itself. However, automation\nhas not been applied to the critical surgical task of controlling tissue and\nblood vessel bleeding--known as hemostasis. The task of hemostasis covers a\nspectrum of bleeding sources and a range of blood velocity, trajectory, and\nvolume. In an extreme case, an un-controlled blood vessel fills the surgical\nfield with flowing blood. In this work, we present the first, automated\nsolution for hemostasis through development of a novel probabilistic blood flow\ndetection algorithm and a trajectory generation technique that guides\nautonomous suction tools towards pooling blood. The blood flow detection\nalgorithm is tested in both simulated scenes and in a real-life trauma scenario\ninvolving a hemorrhage that occurred during thyroidectomy. The complete\nsolution is tested in a physical lab setting with the da Vinci Research Kit\n(dVRK) and a simulated surgical cavity for blood to flow through. The results\nshow that our automated solution has accurate detection, a fast reaction time,\nand effective removal of the flowing blood. Therefore, the proposed methods are\npowerful tools to clearing the surgical field which can be followed by either a\nsurgeon or future robotic automation developments to close the vessel rupture.\n",
			"Comment: Accepted to IEEE Robotics and Automation Letters January, 2021, 8\n  pages, 8 figures, 1 table"
		],
		"date": [
			"2020-10-16",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.08441",
		"pdf_url": "http://arxiv.org/pdf/2010.08441.pdf"
	},
	"466": {
		"title": "CT Image Segmentation for Inflamed and Fibrotic Lungs Using a\n  Multi-Resolution Convolutional Neural Network",
		"creator": [
			"Gerard, Sarah E.",
			"Herrmann, Jacob",
			"Xin, Yi",
			"Martin, Kevin T.",
			"Rezoagli, Emanuele",
			"Ippolito, Davide",
			"Bellani, Giacomo",
			"Cereda, Maurizio",
			"Guo, Junfeng",
			"Hoffman, Eric A.",
			"Kaczka, David W.",
			"Reinhardt, Joseph M."
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  The purpose of this study was to develop a fully-automated segmentation\nalgorithm, robust to various density enhancing lung abnormalities, to\nfacilitate rapid quantitative analysis of computed tomography images. A\npolymorphic training approach is proposed, in which both specifically labeled\nleft and right lungs of humans with COPD, and nonspecifically labeled lungs of\nanimals with acute lung injury, were incorporated into training a single neural\nnetwork. The resulting network is intended for predicting left and right lung\nregions in humans with or without diffuse opacification and consolidation.\nPerformance of the proposed lung segmentation algorithm was extensively\nevaluated on CT scans of subjects with COPD, confirmed COVID-19, lung cancer,\nand IPF, despite no labeled training data of the latter three diseases. Lobar\nsegmentations were obtained using the left and right lung segmentation as input\nto the LobeNet algorithm. Regional lobar analysis was performed using\nhierarchical clustering to identify radiographic subtypes of COVID-19. The\nproposed lung segmentation algorithm was quantitatively evaluated using\nsemi-automated and manually-corrected segmentations in 87 COVID-19 CT images,\nachieving an average symmetric surface distance of $0.495 \\pm 0.309$ mm and\nDice coefficient of $0.985 \\pm 0.011$. Hierarchical clustering identified four\nradiographical phenotypes of COVID-19 based on lobar fractions of consolidated\nand poorly aerated tissue. Lower left and lower right lobes were consistently\nmore afflicted with poor aeration and consolidation. However, the most severe\ncases demonstrated involvement of all lobes. The polymorphic training approach\nwas able to accurately segment COVID-19 cases with diffuse consolidation\nwithout requiring COVID-19 cases for training.\n",
		"date": [
			"2020-10-16",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2010.08582",
			"Sci Rep 11, 1455 (2021)",
			"doi:10.1038/s41598-020-80936-4"
		],
		"pdf_url": "http://arxiv.org/pdf/2010.08582.pdf"
	},
	"467": {
		"title": "Causal Transfer Random Forest: Combining Logged Data and Randomized\n  Experiments for Robust Prediction",
		"creator": [
			"Zeng, Shuxi",
			"Bayir, Murat Ali",
			"Pfeiffer III, Joesph J.",
			"Charles, Denis",
			"Kiciman, Emre"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  It is often critical for prediction models to be robust to distributional\nshifts between training and testing data. From a causal perspective, the\nchallenge is to distinguish the stable causal relationships from the unstable\nspurious correlations across shifts. We describe a causal transfer random\nforest (CTRF) that combines existing training data with a small amount of data\nfrom a randomized experiment to train a model which is robust to the feature\nshifts and therefore transfers to a new targeting distribution. Theoretically,\nwe justify the robustness of the approach against feature shifts with the\nknowledge from causal learning. Empirically, we evaluate the CTRF using both\nsynthetic data experiments and real-world experiments in the Bing Ads platform,\nincluding a click prediction task and in the context of an end-to-end\ncounterfactual optimization system. The proposed CTRF produces robust\npredictions and outperforms most baseline methods compared in the presence of\nfeature shifts.\n",
			"Comment: 9 pages, 7 figures, 2 tables, accepted to WSDM 2021"
		],
		"date": [
			"2020-10-16",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.08710",
		"pdf_url": "http://arxiv.org/pdf/2010.08710.pdf"
	},
	"468": {
		"title": "Evidential Sparsification of Multimodal Latent Spaces in Conditional\n  Variational Autoencoders",
		"creator": [
			"Itkina, Masha",
			"Ivanovic, Boris",
			"Senanayake, Ransalu",
			"Kochenderfer, Mykel J.",
			"Pavone, Marco"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Robotics",
			"I.2.10",
			"I.2.9",
			"I.2.6"
		],
		"description": [
			"  Discrete latent spaces in variational autoencoders have been shown to\neffectively capture the data distribution for many real-world problems such as\nnatural language understanding, human intent prediction, and visual scene\nrepresentation. However, discrete latent spaces need to be sufficiently large\nto capture the complexities of real-world data, rendering downstream tasks\ncomputationally challenging. For instance, performing motion planning in a\nhigh-dimensional latent representation of the environment could be intractable.\nWe consider the problem of sparsifying the discrete latent space of a trained\nconditional variational autoencoder, while preserving its learned\nmultimodality. As a post hoc latent space reduction technique, we use\nevidential theory to identify the latent classes that receive direct evidence\nfrom a particular input condition and filter out those that do not. Experiments\non diverse tasks, such as image generation and human behavior prediction,\ndemonstrate the effectiveness of our proposed technique at reducing the\ndiscrete latent sample space size of a model while maintaining its learned\nmultimodality.\n",
			"Comment: 21 pages, 15 figures, 34th Conference on Neural Information\n  Processing Systems (NeurIPS 2020)"
		],
		"date": [
			"2020-10-18",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.09164",
		"pdf_url": "http://arxiv.org/pdf/2010.09164.pdf"
	},
	"469": {
		"title": "Discovering Discriminative Geometric Features with Self-Supervised\n  Attention for Vehicle Re-Identification and Beyond",
		"creator": [
			"Li, Ming",
			"Huang, Xinming",
			"Zhang, Ziming"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  In the literature of vehicle re-identification (ReID), intensive manual\nlabels such as landmarks, critical parts or semantic segmentation masks are\noften required to improve the performance. Such extra information helps to\ndetect locally geometric features as a part of representation learning for\nvehicles. In contrast, in this paper, we aim to address the challenge of {\\em\nautomatically} learning to detect geometric features as landmarks {\\em with no\nextra labels}. To the best of our knowledge, we are the {\\em first} to\nsuccessfully learn discriminative geometric features for vehicle ReID based on\nself-supervised attention. Specifically, we implement an end-to-end trainable\ndeep network architecture consisting of three branches: (1) a global branch as\nbackbone for image feature extraction, (2) an attentional branch for producing\nattention masks, and (3) a self-supervised branch for regularizing the\nattention learning with rotated images to locate geometric features. %Our\nnetwork design naturally leads to an end-to-end multi-task joint optimization.\nWe conduct comprehensive experiments on three benchmark datasets for vehicle\nReID, \\ie VeRi-776, CityFlow-ReID, and VehicleID, and demonstrate our\nstate-of-the-art performance. %of our approach with the capability of capturing\ninformative vehicle parts with no corresponding manual labels. We also show the\ngood generalization of our approach in other ReID tasks such as person ReID and\nmulti-target multi-camera (MTMC) vehicle tracking. {\\em Our demo code is\nattached in the supplementary file.}\n",
		"date": [
			"2020-10-19",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.09221",
		"pdf_url": "http://arxiv.org/pdf/2010.09221.pdf"
	},
	"470": {
		"title": "Recursive Frank-Wolfe algorithms",
		"creator": "Kolmogorov, Vladimir",
		"subject": [
			"Mathematics - Optimization and Control",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  In the last decade there has been a resurgence of interest in Frank-Wolfe\n(FW) style methods for optimizing a smooth convex function over a polytope.\nExamples of recently developed techniques include {\\em Decomposition-invariant\nConditional Gradient} (DiCG), {\\em Blended Condition Gradient} (BCG), and {\\em\nFrank-Wolfe with in-face directions} (IF-FW) methods. We introduce two\nextensions of these techniques. First, we augment DiCG with the {\\em working\nset} strategy, and show how to optimize over the working set using {\\em shadow\nsimplex steps}. Second, we generalize in-face Frank-Wolfe directions to\npolytopes in which faces cannot be efficiently computed, and also describe a\ngeneric recursive procedure that can be used in conjunction with several\nFW-style techniques. Experimental results indicate that these extensions are\ncapable of speeding up original algorithms by orders of magnitude for certain\napplications.\n",
		"date": [
			"2020-10-19",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.09567",
		"pdf_url": "http://arxiv.org/pdf/2010.09567.pdf"
	},
	"471": {
		"title": "Power pooling: An adaptive pooling function for weakly labelled sound\n  event detection",
		"creator": [
			"Liu, Yuzhuo",
			"Chen, Hangting",
			"YunWang",
			"Zhang, Pengyuan"
		],
		"subject": [
			"Computer Science - Sound",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Audio and Speech Processing"
		],
		"description": "  Access to large corpora with strongly labelled sound events is expensive and\ndifficult in engineering applications. Much research turns to address the\nproblem of how to detect both the types and the timestamps of sound events with\nweak labels that only specify the types. This task can be treated as a multiple\ninstance learning (MIL) problem, and the key to it is the design of a pooling\nfunction. In this paper, we propose an adaptive power pooling function which\ncan automatically adapt to various sound sources. On two public datasets, the\nproposed power pooling function outperforms the state-of-the-art linear softmax\npooling on both coarsegrained and fine-grained metrics. Notably, it improves\nthe event-based F1 score (which evaluates the detection of event onsets and\noffsets) by 11.4% and 10.2% relative on the two datasets. While this paper\nfocuses on sound event detection applications, the proposed method can be\napplied to MIL tasks in other domains.\n",
		"date": [
			"2020-10-19",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.09985",
		"pdf_url": "http://arxiv.org/pdf/2010.09985.pdf"
	},
	"472": {
		"title": "American Sign Language Identification Using Hand Trackpoint Analysis",
		"creator": [
			"Bajaj, Yugam",
			"Malhotra, Puru"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Sign Language helps people with Speaking and Hearing Disabilities communicate\nwith others efficiently. Sign Language identification is a challenging area in\nthe field of computer vision and recent developments have been able to achieve\nnear perfect results for the task, though some challenges are yet to be solved.\nIn this paper we propose a novel machine learning based pipeline for American\nSign Language identification using hand track points. We convert a hand gesture\ninto a series of hand track point coordinates that serve as an input to our\nsystem. In order to make the solution more efficient, we experimented with 28\ndifferent combinations of pre-processing techniques, each run on three\ndifferent machine learning algorithms namely k-Nearest Neighbours, Random\nForests and a Neural Network. Their performance was contrasted to determine the\nbest pre-processing scheme and algorithm pair. Our system achieved an Accuracy\nof 95.66% to identify American sign language gestures.\n",
			"Comment: 12 Pages, 6 Images"
		],
		"date": [
			"2020-10-20",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.10590",
		"pdf_url": "http://arxiv.org/pdf/2010.10590.pdf"
	},
	"473": {
		"title": "Heterogeneous Hypergraph Embedding for Graph Classification",
		"creator": [
			"Sun, Xiangguo",
			"Yin, Hongzhi",
			"Liu, Bo",
			"Chen, Hongxu",
			"Cao, Jiuxin",
			"Shao, Yingxia",
			"Hung, Nguyen Quoc Viet"
		],
		"subject": "Computer Science - Social and Information Networks",
		"description": [
			"  Recently, graph neural networks have been widely used for network embedding\nbecause of their prominent performance in pairwise relationship learning. In\nthe real world, a more natural and common situation is the coexistence of\npairwise relationships and complex non-pairwise relationships, which is,\nhowever, rarely studied. In light of this, we propose a graph neural\nnetwork-based representation learning framework for heterogeneous hypergraphs,\nan extension of conventional graphs, which can well characterize multiple\nnon-pairwise relations. Our framework first projects the heterogeneous\nhypergraph into a series of snapshots and then we take the Wavelet basis to\nperform localized hypergraph convolution. Since the Wavelet basis is usually\nmuch sparser than the Fourier basis, we develop an efficient polynomial\napproximation to the basis to replace the time-consuming Laplacian\ndecomposition. Extensive evaluations have been conducted and the experimental\nresults show the superiority of our method. In addition to the standard tasks\nof network embedding evaluation such as node classification, we also apply our\nmethod to the task of spammers detection and the superior performance of our\nframework shows that relationships beyond pairwise are also advantageous in the\nspammer detection.\n",
			"Comment: Accepted by WSDM2021"
		],
		"date": [
			"2020-10-20",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.10728",
		"pdf_url": "http://arxiv.org/pdf/2010.10728.pdf"
	},
	"474": {
		"title": "LCD -- Line Clustering and Description for Place Recognition",
		"creator": [
			"Taubner, Felix",
			"Tschopp, Florian",
			"Novkovic, Tonci",
			"Siegwart, Roland",
			"Furrer, Fadri"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Robotics"
		],
		"description": [
			"  Current research on visual place recognition mostly focuses on aggregating\nlocal visual features of an image into a single vector representation.\nTherefore, high-level information such as the geometric arrangement of the\nfeatures is typically lost. In this paper, we introduce a novel learning-based\napproach to place recognition, using RGB-D cameras and line clusters as visual\nand geometric features. We state the place recognition problem as a problem of\nrecognizing clusters of lines instead of individual patches, thus maintaining\nstructural information. In our work, line clusters are defined as lines that\nmake up individual objects, hence our place recognition approach can be\nunderstood as object recognition. 3D line segments are detected in RGB-D images\nusing state-of-the-art techniques. We present a neural network architecture\nbased on the attention mechanism for frame-wise line clustering. A similar\nneural network is used for the description of these clusters with a compact\nembedding of 128 floating point numbers, trained with triplet loss on training\ndata obtained from the InteriorNet dataset. We show experiments on a large\nnumber of indoor scenes and compare our method with the bag-of-words\nimage-retrieval approach using SIFT and SuperPoint features and the global\ndescriptor NetVLAD. Trained only on synthetic data, our approach generalizes\nwell to real-world data captured with Kinect sensors, while also providing\ninformation about the geometric arrangement of instances.\n",
			"Comment: Accepted for International Conference on 3D Vision (3DV) 2020"
		],
		"date": "2020-10-21",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2010.10867",
			"2020 International Conference on 3D Vision (3DV)",
			"doi:10.1109/3DV50981.2020.00101"
		],
		"pdf_url": "http://arxiv.org/pdf/2010.10867.pdf"
	},
	"475": {
		"title": "A Wigner-Eckart Theorem for Group Equivariant Convolution Kernels",
		"creator": [
			"Lang, Leon",
			"Weiler, Maurice"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  Group equivariant convolutional networks (GCNNs) endow classical\nconvolutional networks with additional symmetry priors, which can lead to a\nconsiderably improved performance. Recent advances in the theoretical\ndescription of GCNNs revealed that such models can generally be understood as\nperforming convolutions with G-steerable kernels, that is, kernels that satisfy\nan equivariance constraint themselves. While the G-steerability constraint has\nbeen derived, it has to date only been solved for specific use cases - a\ngeneral characterization of G-steerable kernel spaces is still missing. This\nwork provides such a characterization for the practically relevant case of G\nbeing any compact group. Our investigation is motivated by a striking analogy\nbetween the constraints underlying steerable kernels on the one hand and\nspherical tensor operators from quantum mechanics on the other hand. By\ngeneralizing the famous Wigner-Eckart theorem for spherical tensor operators,\nwe prove that steerable kernel spaces are fully understood and parameterized in\nterms of 1) generalized reduced matrix elements, 2) Clebsch-Gordan\ncoefficients, and 3) harmonic basis functions on homogeneous spaces.\n",
			"Comment: 100 pages"
		],
		"date": [
			"2020-10-21",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.10952",
		"pdf_url": "http://arxiv.org/pdf/2010.10952.pdf"
	},
	"476": {
		"title": "Runtime vs Scheduler: Analyzing Dask's Overheads",
		"creator": [
			"Böhm, Stanislav",
			"Beránek, Jakub"
		],
		"subject": "Computer Science - Distributed, Parallel, and Cluster Computing",
		"description": "  Dask is a distributed task framework which is commonly used by data\nscientists to parallelize Python code on computing clusters with little\nprogramming effort. It uses a sophisticated work-stealing scheduler which has\nbeen hand-tuned to execute task graphs as efficiently as possible. But is\nscheduler optimization a worthwhile effort for Dask? Our paper shows on many\nreal world task graphs that even a completely random scheduler is surprisingly\ncompetitive with its built-in scheduler and that the main bottleneck of Dask\nlies in its runtime overhead. We develop a drop-in replacement for the Dask\ncentral server written in Rust which is backwards compatible with existing Dask\nprograms. Thanks to its efficient runtime, our server implementation is able to\nscale up to larger clusters than Dask and consistently outperforms it on a\nvariety of task graphs, despite the fact that it uses a simpler scheduling\nalgorithm.\n",
		"date": "2020-10-21",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2010.11105",
			"doi:10.1109/WORKS51914.2020.00006"
		],
		"pdf_url": "http://arxiv.org/pdf/2010.11105.pdf"
	},
	"477": {
		"title": "Density of States Graph Kernels",
		"creator": [
			"Huang, Leo",
			"Graven, Andrew",
			"Bindel, David"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Social and Information Networks",
			"Mathematics - Numerical Analysis"
		],
		"description": "  A fundamental problem on graph-structured data is that of quantifying\nsimilarity between graphs. Graph kernels are an established technique for such\ntasks; in particular, those based on random walks and return probabilities have\nproven to be effective in wide-ranging applications, from bioinformatics to\nsocial networks to computer vision. However, random walk kernels generally\nsuffer from slowness and tottering, an effect which causes walks to\noveremphasize local graph topology, undercutting the importance of global\nstructure. To correct for these issues, we recast return probability graph\nkernels under the more general framework of density of states -- a framework\nwhich uses the lens of spectral analysis to uncover graph motifs and properties\nhidden within the interior of the spectrum -- and use our interpretation to\nconstruct scalable, composite density of states based graph kernels which\nbalance local and global information, leading to higher classification\naccuracies on a host of benchmark datasets.\n",
		"date": [
			"2020-10-21",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.11341",
		"pdf_url": "http://arxiv.org/pdf/2010.11341.pdf"
	},
	"478": {
		"title": "A New Block Preconditioner for Implicit Runge-Kutta Methods for\n  Parabolic PDE Problems",
		"creator": [
			"Rana, Md Masud",
			"Howle, Victoria E.",
			"Long, Katharine",
			"Meek, Ashley",
			"Milestone, William"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"65F08"
		],
		"description": [
			"  A new preconditioner based on a block $LDU$ factorization with algebraic\nmultigrid subsolves for scalability is introduced for the large, structured\nsystems appearing in implicit Runge-Kutta time integration of parabolic partial\ndifferential equations. This preconditioner is compared in condition number and\neigenvalue distribution, and in numerical experiments with others in the\nliterature: block Jacobi, block Gauss-Seidel, and the optimized block\nGauss-Seidel method of Staff, Mardal, and Nilssen [{\\em Modeling,\nIdentification and Control}, 27 (2006), pp. 109-123]. Experiments are run on\ntwo test problems, a $2D$ heat equation and a model advection-diffusion\nproblem, using implicit Runge-Kutta methods with two to seven stages. We find\nthat the new preconditioner outperforms the others, with the improvement\nbecoming more pronounced as spatial discretization is refined and as temporal\norder is increased.\n",
			"Comment: 20 pages"
		],
		"date": [
			"2020-10-21",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.11377",
		"pdf_url": "http://arxiv.org/pdf/2010.11377.pdf"
	},
	"479": {
		"title": "Revisiting Wireless Internet Connectivity: 5G vs Wi-Fi 6",
		"creator": [
			"Oughton, Edward J",
			"Lehr, William",
			"Katsaros, Konstantinos",
			"Selinis, Ioannis",
			"Bubley, Dean",
			"Kusuma, Julius"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": "  In recent years, significant attention has been directed toward the fifth\ngeneration of wireless broadband connectivity known as `5G`, currently being\ndeployed by Mobile Network Operators. Surprisingly, there has been considerably\nless attention paid to `Wi-Fi 6`, the new IEEE 802.1ax standard in the family\nof Wireless Local Area Network technologies with features targeting private,\nedge-networks. This paper revisits the suitability of cellular and Wi-Fi in\ndelivering high-speed wireless Internet connectivity. Both technologies aspire\nto deliver significantly enhanced performance, enabling each to deliver much\nfaster wireless broadband connectivity, and provide further support for the\nInternet of Things and Machine-to-Machine communications, positioning the two\ntechnologies as technical substitutes in many usage scenarios. We conclude that\nboth are likely to play important roles in the future, and simultaneously serve\nas competitors and complements. We anticipate that 5G will remain the preferred\ntechnology for wide-area coverage, while Wi-Fi 6 will remain the preferred\ntechnology for indoor use, thanks to its much lower deployment costs. However,\nthe traditional boundaries that differentiated earlier generations of cellular\nand Wi-Fi are blurring. Proponents of one technology may argue for the benefits\nof their chosen technology displacing the other, requesting regulatory policies\nthat would serve to tilt the marketplace in their favour. We believe such\nefforts need to be resisted, and that both technologies have important roles to\nplay in the marketplace, based on the needs of heterogeneous use cases. Both\ntechnologies should contribute to achieving the goal of providing affordable,\nreliable, and ubiquitously available high-capacity wireless broadband\nconnectivity.\n",
		"date": [
			"2020-10-22",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.11601",
		"pdf_url": "http://arxiv.org/pdf/2010.11601.pdf"
	},
	"480": {
		"title": "In Search of Robust Measures of Generalization",
		"creator": [
			"Dziugaite, Gintare Karolina",
			"Drouin, Alexandre",
			"Neal, Brady",
			"Rajkumar, Nitarshan",
			"Caballero, Ethan",
			"Wang, Linbo",
			"Mitliagkas, Ioannis",
			"Roy, Daniel M."
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  One of the principal scientific challenges in deep learning is explaining\ngeneralization, i.e., why the particular way the community now trains networks\nto achieve small training error also leads to small error on held-out data from\nthe same population. It is widely appreciated that some worst-case theories --\nsuch as those based on the VC dimension of the class of predictors induced by\nmodern neural network architectures -- are unable to explain empirical\nperformance. A large volume of work aims to close this gap, primarily by\ndeveloping bounds on generalization error, optimization error, and excess risk.\nWhen evaluated empirically, however, most of these bounds are numerically\nvacuous. Focusing on generalization bounds, this work addresses the question of\nhow to evaluate such bounds empirically. Jiang et al. (2020) recently described\na large-scale empirical study aimed at uncovering potential causal\nrelationships between bounds/measures and generalization. Building on their\nstudy, we highlight where their proposed methods can obscure failures and\nsuccesses of generalization measures in explaining generalization. We argue\nthat generalization measures should instead be evaluated within the framework\nof distributional robustness.\n",
			"Comment: 27 pages, 11 figures, 34th Conference on Neural Information\n  Processing Systems (NeurIPS 2020), Vancouver, Canada"
		],
		"date": [
			"2020-10-22",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.11924",
		"pdf_url": "http://arxiv.org/pdf/2010.11924.pdf"
	},
	"481": {
		"title": "Sharper convergence bounds of Monte Carlo Rademacher Averages through\n  Self-Bounding functions",
		"creator": "Pellegrina, Leonardo",
		"subject": [
			"Computer Science - Machine Learning",
			"Mathematics - Probability",
			"Statistics - Machine Learning"
		],
		"description": "  We derive sharper probabilistic concentration bounds for the Monte Carlo\nEmpirical Rademacher Averages (MCERA), which are proved through recent results\non the concentration of self-bounding functions. Our novel bounds are\ncharacterized by convergence rates that depend on data-dependent characteristic\nquantities of the set of functions under consideration, such as the empirical\nwimpy variance, an essential improvement w.r.t. standard bounds based on the\nmethods of bounded differences. For this reason, our new results are applicable\nto yield sharper bounds to (Local) Rademacher Averages. We also derive improved\nnovel variance-dependent bounds for the special case where only one vector of\nRademacher random variables is used to compute the MCERA, through the\napplication of Bousquet's inequality and novel data-dependent bounds to the\nwimpy variance. Then, we leverage the framework of self-bounding functions to\nderive novel probabilistic bounds to the supremum deviations, that may be of\nindependent interest.\n",
		"date": [
			"2020-10-22",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.12103",
		"pdf_url": "http://arxiv.org/pdf/2010.12103.pdf"
	},
	"482": {
		"title": "Accelerating computational modeling and design of high-entropy alloys",
		"creator": [
			"Singh, Rahul",
			"Sharma, Aayush",
			"Singh, Prashant",
			"Balasubramanian, Ganesh",
			"Johnson, Duane D."
		],
		"subject": [
			"Condensed Matter - Materials Science",
			"Computer Science - Computational Engineering, Finance, and Science"
		],
		"description": [
			"  With huge design spaces for unique chemical and mechanical properties, we\nremove a roadblock to computational design of {high-entropy alloys} using a\nmetaheuristic hybrid Cuckoo Search (CS) for \"on-the-fly\" construction of\nSuper-Cell Random APproximates (SCRAPs) having targeted atomic site and pair\nprobabilities on arbitrary crystal lattices. Our hybrid-CS schema overcomes\nlarge, discrete combinatorial optimization by ultrafast global solutions that\nscale linearly in system size and strongly in parallel, e.g. a 4-element,\n128-atom model [a $10^{73+}$ space] is found in seconds -- a reduction of\n13,000+ over current strategies. With model-generation eliminated as a\nbottleneck, computational alloy design can be performed that is currently\nimpossible or impractical. We showcase the method for real alloys with varying\nshort-range order. Being problem-agnostic, our hybrid-CS schema offers numerous\napplications in diverse fields.\n",
			"Comment: 10 pages, 6 figures, submitted to Nature Computational Science"
		],
		"date": "2020-10-22",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2010.12107",
			"Nature Computational Science 1, 54-61 (2021)",
			"doi:10.1038/s43588-020-00006-7"
		],
		"pdf_url": "http://arxiv.org/pdf/2010.12107.pdf"
	},
	"483": {
		"title": "The Case for Distance-Bounded Spatial Approximations",
		"creator": [
			"Zacharatou, Eleni Tzirita",
			"Kipf, Andreas",
			"Sabek, Ibrahim",
			"Pandey, Varun",
			"Doraiswamy, Harish",
			"Markl, Volker"
		],
		"subject": "Computer Science - Databases",
		"description": [
			"  Spatial approximations have been traditionally used in spatial databases to\naccelerate the processing of complex geometric operations. However,\napproximations are typically only used in a first filtering step to determine a\nset of candidate spatial objects that may fulfill the query condition. To\nprovide accurate results, the exact geometries of the candidate objects are\ntested against the query condition, which is typically an expensive operation.\nNevertheless, many emerging applications (e.g., visualization tools) require\ninteractive responses, while only needing approximate results. Besides,\nreal-world geospatial data is inherently imprecise, which makes exact data\nprocessing unnecessary. Given the uncertainty associated with spatial data and\nthe relaxed precision requirements of many applications, this vision paper\nadvocates for approximate spatial data processing techniques that omit exact\ngeometric tests and provide final answers solely on the basis of (fine-grained)\napproximations. Thanks to recent hardware advances, this vision can be realized\ntoday. Furthermore, our approximate techniques employ a distance-based error\nbound, i.e., a bound on the maximum spatial distance between false (or missing)\nand exact results which is crucial for meaningful analyses. This bound allows\nto control the precision of the approximation and trade accuracy for\nperformance.\n",
			"Comment: 11th Annual Conference on Innovative Data Systems Research (CIDR'21)"
		],
		"date": [
			"2020-10-23",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.12548",
		"pdf_url": "http://arxiv.org/pdf/2010.12548.pdf"
	},
	"484": {
		"title": "A Graph Theoretical Approach for Testing Binomiality of Reversible\n  Chemical Reaction Networks",
		"creator": [
			"Rahkooy, Hamid",
			"Montero, Cristian Vargas"
		],
		"subject": [
			"Computer Science - Symbolic Computation",
			"Mathematics - Commutative Algebra"
		],
		"description": "  We study binomiality of the steady state ideals of chemical reaction\nnetworks. Considering rate constants as indeterminates, the concept of\nunconditional binomiality has been introduced and an algorithm based on linear\nalgebra has been proposed in a recent work for reversible chemical reaction\nnetworks, which has a polynomial time complexity upper bound on the number of\nspecies and reactions. In this article, using a modified version of\nspecies--reaction graphs, we present an algorithm based on graph theory which\nperforms by adding and deleting edges and changing the labels of the edges in\norder to test unconditional binomiality. We have implemented our graph\ntheoretical algorithm as well as the linear algebra one in Maple and made\nexperiments on biochemical models. Our experiments show that the performance of\nthe graph theoretical approach is similar to or better than the linear algebra\napproach, while it is drastically faster than Groebner basis and quantifier\nelimination methods.\n",
		"date": [
			"2020-10-23",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.12615",
		"pdf_url": "http://arxiv.org/pdf/2010.12615.pdf"
	},
	"485": {
		"title": "Multi-Graph Tensor Networks",
		"creator": [
			"Xu, Yao Lei",
			"Konstantinidis, Kriton",
			"Mandic, Danilo P."
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  The irregular and multi-modal nature of numerous modern data sources poses\nserious challenges for traditional deep learning algorithms. To this end,\nrecent efforts have generalized existing algorithms to irregular domains\nthrough graphs, with the aim to gain additional insights from data through the\nunderlying graph topology. At the same time, tensor-based methods have\ndemonstrated promising results in bypassing the bottlenecks imposed by the\nCurse of Dimensionality. In this paper, we introduce a novel Multi-Graph Tensor\nNetwork (MGTN) framework, which exploits both the ability of graphs to handle\nirregular data sources and the compression properties of tensor networks in a\ndeep learning setting. The potential of the proposed framework is demonstrated\nthrough an MGTN based deep Q agent for Foreign Exchange (FOREX) algorithmic\ntrading. By virtue of the MGTN, a FOREX currency graph is leveraged to impose\nan economically meaningful structure on this demanding task, resulting in a\nhighly superior performance against three competing models and at a drastically\nlower complexity.\n",
			"Comment: NeurIPS 2020 - First Workshop on Quantum Tensor Networks in Machine\n  Learning"
		],
		"date": [
			"2020-10-25",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.13209",
		"pdf_url": "http://arxiv.org/pdf/2010.13209.pdf"
	},
	"486": {
		"title": "Emotion controllable speech synthesis using emotion-unlabeled dataset\n  with the assistance of cross-domain speech emotion recognition",
		"creator": [
			"Cai, Xiong",
			"Dai, Dongyang",
			"Wu, Zhiyong",
			"Li, Xiang",
			"Li, Jingbei",
			"Meng, Helen"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Audio and Speech Processing",
			"Computer Science - Sound",
			"I.2"
		],
		"description": [
			"  Neural text-to-speech (TTS) approaches generally require a huge number of\nhigh quality speech data, which makes it difficult to obtain such a dataset\nwith extra emotion labels. In this paper, we propose a novel approach for\nemotional TTS synthesis on a TTS dataset without emotion labels. Specifically,\nour proposed method consists of a cross-domain speech emotion recognition (SER)\nmodel and an emotional TTS model. Firstly, we train the cross-domain SER model\non both SER and TTS datasets. Then, we use emotion labels on the TTS dataset\npredicted by the trained SER model to build an auxiliary SER task and jointly\ntrain it with the TTS model. Experimental results show that our proposed method\ncan generate speech with the specified emotional expressiveness and nearly no\nhindering on the speech quality.\n",
			"Comment: icassp2021 final version"
		],
		"date": [
			"2020-10-26",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.13350",
		"pdf_url": "http://arxiv.org/pdf/2010.13350.pdf"
	},
	"487": {
		"title": "What is the best data augmentation for 3D brain tumor segmentation?",
		"creator": [
			"Cirillo, Marco Domenico",
			"Abramian, David",
			"Eklund, Anders"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  Training segmentation networks requires large annotated datasets, which in\nmedical imaging can be hard to obtain. Despite this fact, data augmentation has\nin our opinion not been fully explored for brain tumor segmentation. In this\nproject we apply different types of data augmentation (flipping, rotation,\nscaling, brightness adjustment, elastic deformation) when training a standard\n3D U-Net, and demonstrate that augmentation significantly improves the\nnetwork's performance in many cases. Our conclusion is that brightness\naugmentation and elastic deformation work best, and that combinations of\ndifferent augmentation techniques do not provide further improvement compared\nto only using one augmentation technique. Our code is available at\nhttps://github.com/mdciri/3D-augmentation-techniques.\n",
		"date": [
			"2020-10-26",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.13372",
		"pdf_url": "http://arxiv.org/pdf/2010.13372.pdf"
	},
	"488": {
		"title": "Distance Computations in the Hybrid Network Model via Oracle Simulations",
		"creator": [
			"Censor-Hillel, Keren",
			"Leitersdorf, Dean",
			"Polosukhin, Volodymyr"
		],
		"subject": "Computer Science - Distributed, Parallel, and Cluster Computing",
		"description": [
			"  The Hybrid network model was introduced in [Augustine et al., SODA '20] for\nlaying down a theoretical foundation for networks which combine two possible\nmodes of communication: One mode allows high-bandwidth communication with\nneighboring nodes, and the other allows low-bandwidth communication over few\nlong-range connections at a time. This fundamentally abstracts networks such as\nhybrid data centers, and class-based software-defined networks.\n  Our technical contribution is a \\emph{density-aware} approach that allows us\nto simulate a set of \\emph{oracles} for an overlay skeleton graph over a Hybrid\nnetwork.\n  As applications of our oracle simulations, with additional machinery that we\nprovide, we derive fast algorithms for fundamental distance-related tasks. One\nof our core contributions is an algorithm in the Hybrid model for computing\n\\emph{exact} weighted shortest paths from $\\tilde O(n^{1/3})$ sources which\ncompletes in $\\tilde O(n^{1/3})$ rounds w.h.p. This improves, in both the\nruntime and the number of sources, upon the algorithm of [Kuhn and Schneider,\nPODC '20], which computes shortest paths from a single source in $\\tilde\nO(n^{2/5})$ rounds w.h.p.\n  We additionally show a 2-approximation for weighted diameter and a\n$(1+\\epsilon)$-approximation for unweighted diameter, both in $\\tilde\nO(n^{1/3})$ rounds w.h.p., which is comparable to the $\\tilde \\Omega(n^{1/3})$\nlower bound of [Kuhn and Schneider, PODC '20] for a\n$(2-\\epsilon)$-approximation for weighted diameter and an exact unweighted\ndiameter. We also provide fast distance \\emph{approximations} from multiple\nsources and fast approximations for eccentricities.\n",
			"Comment: To appear in STACS 2021"
		],
		"date": [
			"2020-10-26",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.13831",
		"pdf_url": "http://arxiv.org/pdf/2010.13831.pdf"
	},
	"489": {
		"title": "Are Multi-language Design Smells Fault-prone? An Empirical Study",
		"creator": [
			"Abidi, Mouna",
			"Rahman, Md Saidur",
			"Openja, Moses",
			"Khomh, Foutse"
		],
		"subject": "Computer Science - Software Engineering",
		"description": "  Nowadays, modern applications are developed using components written in\ndifferent programming languages. These systems introduce several advantages.\nHowever, as the number of languages increases, so does the challenges related\nto the development and maintenance of these systems. In such situations,\ndevelopers may introduce design smells (i.e., anti-patterns and code smells)\nwhich are symptoms of poor design and implementation choices. Design smells are\ndefined as poor design and coding choices that can negatively impact the\nquality of a software program despite satisfying functional requirements.\nStudies on mono-language systems suggest that the presence of design smells\naffects code comprehension, thus making systems harder to maintain. However,\nthese studies target only mono-language systems and do not consider the\ninteraction between different programming languages. In this paper, we present\nan approach to detect multi-language design smells in the context of JNI\nsystems. We then investigate the prevalence of those design smells.\nSpecifically, we detect 15 design smells in 98 releases of nine open-source JNI\nprojects. Our results show that the design smells are prevalent in the selected\nprojects and persist throughout the releases of the systems. We observe that in\nthe analyzed systems, 33.95% of the files involving communications between Java\nand C/C++ contains occurrences of multi-language design smells. Some kinds of\nsmells are more prevalent than others, e.g., Unused Parameters, Too Much\nScattering, Unused Method Declaration. Our results suggest that files with\nmulti-language design smells can often be more associated with bugs than files\nwithout these smells, and that specific smells are more correlated to\nfault-proneness than others.\n",
		"date": [
			"2020-10-27",
			"2020-11-02"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2010.14331",
			"ACM Transactions on Software Engineering and Methodology (TOSEM)\n  2020"
		],
		"pdf_url": "http://arxiv.org/pdf/2010.14331.pdf"
	},
	"490": {
		"title": "Detecting Stance in Media on Global Warming",
		"creator": [
			"Luo, Yiwei",
			"Card, Dallas",
			"Jurafsky, Dan"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Citing opinions is a powerful yet understudied strategy in argumentation. For\nexample, an environmental activist might say, \"Leading scientists agree that\nglobal warming is a serious concern,\" framing a clause which affirms their own\nstance (\"that global warming is serious\") as an opinion endorsed (\"[scientists]\nagree\") by a reputable source (\"leading\"). In contrast, a global warming denier\nmight frame the same clause as the opinion of an untrustworthy source with a\npredicate connoting doubt: \"Mistaken scientists claim [...].\" Our work studies\nopinion-framing in the global warming (GW) debate, an increasingly partisan\nissue that has received little attention in NLP. We introduce Global Warming\nStance Dataset (GWSD), a dataset of stance-labeled GW sentences, and train a\nBERT classifier to study novel aspects of argumentation in how different sides\nof a debate represent their own and each other's opinions. From 56K news\narticles, we find that similar linguistic devices for self-affirming and\nopponent-doubting discourse are used across GW-accepting and skeptic media,\nthough GW-skeptical media shows more opponent-doubt. We also find that authors\noften characterize sources as hypocritical, by ascribing opinions expressing\nthe author's own view to source entities known to publicly endorse the opposing\nview. We release our stance dataset, model, and lexicons of framing devices for\nfuture work on opinion-framing and the automatic detection of GW stance.\n",
			"Comment: 9 pages, 6 figures"
		],
		"date": [
			"2020-10-28",
			"2021-01-16"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2010.15149",
			"Findings of ACL: EMNLP 2020"
		],
		"pdf_url": "http://arxiv.org/pdf/2010.15149.pdf"
	},
	"491": {
		"title": "Identifying Entangled Physics Relationships through Sparse Matrix\n  Decomposition to Inform Plasma Fusion Design",
		"creator": [
			"Fernández-Godino, M. Giselle",
			"Grosskopf, Michael J.",
			"Nakhleh, Julia B.",
			"Wilson, Brandon M.",
			"Kline, John",
			"Srinivasan, Gowri"
		],
		"subject": [
			"Physics - Plasma Physics",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  A sustainable burn platform through inertial confinement fusion (ICF) has\nbeen an ongoing challenge for over 50 years. Mitigating engineering limitations\nand improving the current design involves an understanding of the complex\ncoupling of physical processes. While sophisticated simulations codes are used\nto model ICF implosions, these tools contain necessary numerical approximation\nbut miss physical processes that limit predictive capability. Identification of\nrelationships between controllable design inputs to ICF experiments and\nmeasurable outcomes (e.g. yield, shape) from performed experiments can help\nguide the future design of experiments and development of simulation codes, to\npotentially improve the accuracy of the computational models used to simulate\nICF experiments. We use sparse matrix decomposition methods to identify\nclusters of a few related design variables. Sparse principal component analysis\n(SPCA) identifies groupings that are related to the physical origin of the\nvariables (laser, hohlraum, and capsule). A variable importance analysis finds\nthat in addition to variables highly correlated with neutron yield such as\npicket power and laser energy, variables that represent a dramatic change of\nthe ICF design such as number of pulse steps are also very important. The\nobtained sparse components are then used to train a random forest (RF)\nsurrogate for predicting total yield. The RF performance on the training and\ntesting data compares with the performance of the RF surrogate trained using\nall design variables considered. This work is intended to inform design changes\nin future ICF experiments by augmenting the expert intuition and simulations\nresults.\n",
			"Comment: 8 pages, 7 figures"
		],
		"date": "2020-10-28",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.15208",
		"pdf_url": "http://arxiv.org/pdf/2010.15208.pdf"
	},
	"492": {
		"title": "Speech-Based Emotion Recognition using Neural Networks and Information\n  Visualization",
		"creator": [
			"Almahmoud, Jumana",
			"Kikkeri, Kruthika"
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Emotions recognition is commonly employed for health assessment. However, the\ntypical metric for evaluation in therapy is based on patient-doctor appraisal.\nThis process can fall into the issue of subjectivity, while also requiring\nhealthcare professionals to deal with copious amounts of information. Thus,\nmachine learning algorithms can be a useful tool for the classification of\nemotions. While several models have been developed in this domain, there is a\nlack of userfriendly representations of the emotion classification systems for\ntherapy. We propose a tool which enables users to take speech samples and\nidentify a range of emotions (happy, sad, angry, surprised, neutral, clam,\ndisgust, and fear) from audio elements through a machine learning model. The\ndashboard is designed based on local therapists' needs for intuitive\nrepresentations of speech data in order to gain insights and informative\nanalyses of their sessions with their patients.\n",
			"Comment: IEEE Vis 2020 Abstract"
		],
		"date": "2020-10-28",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2010.15229",
			"IEEE Vis 2020 Abstract"
		],
		"pdf_url": "http://arxiv.org/pdf/2010.15229.pdf"
	},
	"493": {
		"title": "DeviceTTS: A Small-Footprint, Fast, Stable Network for On-Device\n  Text-to-Speech",
		"creator": [
			"Huang, Zhiying",
			"Li, Hao",
			"Lei, Ming"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Audio and Speech Processing",
			"Computer Science - Sound"
		],
		"description": [
			"  With the number of smart devices increasing, the demand for on-device\ntext-to-speech (TTS) increases rapidly. In recent years, many prominent\nEnd-to-End TTS methods have been proposed, and have greatly improved the\nquality of synthesized speech. However, to ensure the qualified speech, most\nTTS systems depend on large and complex neural network models, and it's hard to\ndeploy these TTS systems on-device. In this paper, a small-footprint, fast,\nstable network for on-device TTS is proposed, named as DeviceTTS. DeviceTTS\nmakes use of a duration predictor as a bridge between encoder and decoder so as\nto avoid the problem of words skipping and repeating in Tacotron. As we all\nknow, model size is a key factor for on-device TTS. For DeviceTTS, Deep\nFeedforward Sequential Memory Network (DFSMN) is used as the basic component.\nMoreover, to speed up inference, mix-resolution decoder is proposed for balance\nthe inference speed and speech quality. Experiences are done with WORLD and\nLPCNet vocoder. Finally, with only 1.4 million model parameters and 0.099\nGFLOPS, DeviceTTS achieves comparable performance with Tacotron and FastSpeech.\nAs far as we know, the DeviceTTS can meet the needs of most of the devices in\npractical application.\n",
			"Comment: 5 pages, 1 figure, Submitted to ICASSP2021"
		],
		"date": [
			"2020-10-28",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.15311",
		"pdf_url": "http://arxiv.org/pdf/2010.15311.pdf"
	},
	"494": {
		"title": "Channel Estimation and Equalization for CP-OFDM-based OTFS in Fractional\n  Doppler Channels",
		"creator": [
			"Hashimoto, Noriyuki",
			"Osawa, Noboru",
			"Yamazaki, Kosuke",
			"Ibi, Shinsuke"
		],
		"subject": [
			"Computer Science - Information Theory",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": "  Orthogonal time frequency and space (OTFS) modulation is a promising\ntechnology that satisfies high Doppler requirements for future mobile systems.\nOTFS modulation encodes information symbols and pilot symbols into the\ntwo-dimensional (2D) delay-Doppler (DD) domain. The received symbols suffer\nfrom inter-Doppler interference (IDI) in the fading channels with fractional\nDoppler shifts that are sampled at noninteger indices in the DD domain. IDI has\nbeen treated as an unavoidable effect because the fractional Doppler shifts\ncannot be obtained directly from the received pilot symbols. In this paper, we\nprovide a solution to channel estimation for fractional Doppler channels. The\nproposed estimation provides new insight into the OTFS input-output relation in\nthe DD domain as a 2D circular convolution with a small approximation.\nAccording to the input-output relation, we also provide a low-complexity\nchannel equalization method using the estimated channel information. We\ndemonstrate the error performance of the proposed channel estimation and\nequalization in several channels by simulations. The simulation results show\nthat in high-mobility environments, the total system utilizing the proposed\nmethods outperforms orthogonal frequency division multiplexing (OFDM) with\nideal channel estimation and a conventional channel estimation method using a\npseudo sequence.\n",
		"date": [
			"2020-10-29",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.15396",
		"pdf_url": "http://arxiv.org/pdf/2010.15396.pdf"
	},
	"495": {
		"title": "Multi-Constitutive Neural Network for Large Deformation Poromechanics\n  Problem",
		"creator": [
			"Zhang, Qi",
			"Chen, Yilin",
			"Yang, Ziyi",
			"Darve, Eric"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Physics - Geophysics"
		],
		"description": [
			"  In this paper, we study the problem of large-strain consolidation in\nporomechanics with deep neural networks (DNN). Given different material\nproperties and different loading conditions, the goal is to predict pore\npressure and settlement. We propose a novel method \"multi-constitutive neural\nnetwork\" (MCNN) such that one model can solve several different constitutive\nlaws. We introduce a one-hot encoding vector as an additional input vector,\nwhich is used to label the constitutive law we wish to solve. Then we build a\nDNN which takes $(\\hat{X}, \\hat{t})$ as input along with a constitutive law\nlabel and outputs the corresponding solution. It is the first time, to our\nknowledge, that we can evaluate multi-constitutive laws through only one\ntraining process while still obtaining good accuracies. We found that MCNN\ntrained to solve multiple PDEs outperforms individual neural network solvers\ntrained with PDE in some cases.\n",
			"Comment: Camera-ready (final) paper of the Third Workshop on Machine Learning\n  and the Physical Sciences (NeurIPS 2020), Vancouver Add more figures despite\n  the workshop is closed"
		],
		"date": [
			"2020-10-11",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.15549",
		"pdf_url": "http://arxiv.org/pdf/2010.15549.pdf"
	},
	"496": {
		"title": "Compensating data shortages in manufacturing with monotonicity knowledge",
		"creator": [
			"von Kurnatowski, Martin",
			"Schmid, Jochen",
			"Link, Patrick",
			"Zache, Rebekka",
			"Morand, Lukas",
			"Kraft, Torsten",
			"Schmidt, Ingo",
			"Stoll, Anke"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Mathematics - Optimization and Control",
			"68T30, 90C34"
		],
		"description": [
			"  Optimization in engineering requires appropriate models. In this article, a\nregression method for enhancing the predictive power of a model by exploiting\nexpert knowledge in the form of shape constraints, or more specifically,\nmonotonicity constraints, is presented. Incorporating such information is\nparticularly useful when the available data sets are small or do not cover the\nentire input space, as is often the case in manufacturing applications. The\nregression subject to the considered monotonicity constraints is set up as a\nsemi-infinite optimization problem, and an adaptive solution algorithm is\nproposed. The method is applicable in multiple dimensions and can be extended\nto more general shape constraints. It is tested and validated on two real-world\nmanufacturing processes, namely laser glass bending and press hardening of\nsheet metal. It is found that the resulting models both comply well with the\nexpert's monotonicity knowledge and predict the training data accurately. The\nsuggested approach leads to lower root-mean-squared errors than comparative\nmethods from the literature for the sparse data sets considered in this work.\n",
			"Comment: 22 pages, 6 figures"
		],
		"date": [
			"2020-10-29",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.15955",
		"pdf_url": "http://arxiv.org/pdf/2010.15955.pdf"
	},
	"497": {
		"title": "Virtual Surfaces and Attitude Aware Planning and Behaviours for Negative\n  Obstacle Navigation",
		"creator": [
			"Hines, Thomas",
			"Stepanas, Kazys",
			"Talbot, Fletcher",
			"Sa, Inkyu",
			"Lewis, Jake",
			"Hernandez, Emili",
			"Kottege, Navinda",
			"Hudson, Nicolas"
		],
		"subject": "Computer Science - Robotics",
		"description": [
			"  This paper presents an autonomous navigation system for ground robots\ntraversing aggressive unstructured terrain through a cohesive arrangement of\nmapping, deliberative planning and reactive behaviour modules. All systems are\naware of terrain slope, visibility and vehicle orientation, enabling robots to\nrecognize, plan and react around unobserved areas and overcome negative\nobstacles, slopes, steps, overhangs and narrow passageways. This is one of\npioneer works to explicitly and simultaneously couple mapping, planning and\nreactive components in dealing with negative obstacles. The system was deployed\non three heterogeneous ground robots for the DARPA Subterranean Challenge, and\nwe present results in Urban and Cave environments, along with simulated\nscenarios, that demonstrate this approach.\n",
			"Comment: 8 pages, 11 figures, submitted to RA-L"
		],
		"date": [
			"2020-10-29",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.16018",
		"pdf_url": "http://arxiv.org/pdf/2010.16018.pdf"
	},
	"498": {
		"title": "Pencil Beamforming Increases Human Exposure to ElectroMagnetic Fields:\n  True or False?",
		"creator": [
			"Chiaraviglio, Luca",
			"Rossetti, Simone",
			"Saida, Sara",
			"Bartoletti, Stefania",
			"Blefari-Melazzi, Nicola"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": "  According to a very popular belief - very widespread among non-scientific\ncommunities - the exploitation of narrow beams, a.k.a. \"pencil beamforming\",\nresults in a prompt increase of exposure levels radiated by 5G Base Stations\n(BSs). To face such concern with a scientific approach, in this work we propose\na novel localization-enhanced pencil beamforming technique, in which the\ntraffic beams are tuned in accordance with the uncertainty localization levels\nof User Equipment (UE). Compared to currently deployed beamforming techniques,\nwhich generally employ beams of fixed width, we exploit the localization\nfunctionality made available by the 5G architecture to synthesize the direction\nand the width of each pencil beam towards each served UE. We then evaluate the\neffectiveness of pencil beamforming in terms of ElectroMagnetic Field (EMF)\nexposure and UE throughput levels over different realistic case-studies.\nResults, obtained from a publicly released open-source simulator, dispel the\nmyth: the adoption of localization-enhanced pencil beamforming triggers a\nprompt reduction of exposure w.r.t. other alternative techniques, which include\ne.g., beams of fixed width and cellular coverage not exploiting beamforming.\nThe EMF reduction is achieved not only for the UE that are served by the pencil\nbeams, but also over the whole territory (including the locations in proximity\nto the 5G BS). In addition, large throughput levels - adequate for most of 5G\nservices - can be guaranteed when each UE is individually served by one\ndedicated beam.\n",
		"date": [
			"2020-10-30",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2010.16288",
		"pdf_url": "http://arxiv.org/pdf/2010.16288.pdf"
	},
	"499": {
		"title": "Modular-Relatedness for Continual Learning",
		"creator": [
			"Shaker, Ammar",
			"Yu, Shujian",
			"Alesiani, Francesco"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  In this paper, we propose a continual learning (CL) technique that is\nbeneficial to sequential task learners by improving their retained accuracy and\nreducing catastrophic forgetting. The principal target of our approach is the\nautomatic extraction of modular parts of the neural network and then estimating\nthe relatedness between the tasks given these modular components. This\ntechnique is applicable to different families of CL methods such as\nregularization-based (e.g., the Elastic Weight Consolidation) or the\nrehearsal-based (e.g., the Gradient Episodic Memory) approaches where episodic\nmemory is needed. Empirical results demonstrate remarkable performance gain (in\nterms of robustness to forgetting) for methods such as EWC and GEM based on our\ntechnique, especially when the memory budget is very limited.\n",
			"Comment: We realized one conclusion in the submission is erroneous and\n  disconnected from the results shown in one theorem is. We decide to withdraw\n  the current version to avoid misleading conclusion"
		],
		"date": [
			"2020-11-02",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.01272",
		"pdf_url": "http://arxiv.org/pdf/2011.01272.pdf"
	},
	"500": {
		"title": "Recent Advances on the Graph Isomorphism Problem",
		"creator": [
			"Grohe, Martin",
			"Neuen, Daniel"
		],
		"subject": [
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Discrete Mathematics",
			"Mathematics - Combinatorics",
			"05C85",
			"F.2.2",
			"G.2.2"
		],
		"description": [
			"  We give an overview of recent advances on the graph isomorphism problem. Our\nmain focus will be on Babai's quasi-polynomial time isomorphism test and\nsubsequent developments that led to the design of isomorphism algorithms with a\nquasi-polynomial parameterized running time of the from\n$n^{\\text{polylog}(k)}$, where $k$ is a graph parameter such as the maximum\ndegree. A second focus will be the combinatorial Weisfeiler-Leman algorithm.\n",
			"Comment: arXiv admin note: text overlap with arXiv:2002.06997"
		],
		"date": [
			"2020-11-02",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.01366",
		"pdf_url": "http://arxiv.org/pdf/2011.01366.pdf"
	},
	"501": {
		"title": "Mitigating Backdoor Attacks in Federated Learning",
		"creator": [
			"Wu, Chen",
			"Yang, Xian",
			"Zhu, Sencun",
			"Mitra, Prasenjit"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Machine Learning"
		],
		"description": "  Malicious clients can attack federated learning systems using malicious data,\nincluding backdoor samples, during the training phase. The compromised global\nmodel will perform well on the validation dataset designed for the task, but a\nsmall subset of data with backdoor patterns may trigger the model to make a\nwrong prediction. There has been an arms race between attackers who tried to\nconceal attacks and defenders who tried to detect attacks during the\naggregation stage of training on the server-side. In this work, we propose a\nnew and effective method to mitigate backdoor attacks after the training phase.\nSpecifically, we design a federated pruning method to remove redundant neurons\nin the network and then adjust the model's extreme weight values. Our\nexperiments conducted on distributed Fashion-MNIST show that our method can\nreduce the average attack success rate from 99.7% to 1.9% with a 5.5% loss of\ntest accuracy on the validation dataset. To minimize the pruning influence on\ntest accuracy, we can fine-tune after pruning, and the attack success rate\ndrops to 6.4%, with only a 1.7% loss of test accuracy. Further experiments\nunder Distributed Backdoor Attacks on CIFAR-10 also show promising results that\nthe average attack success rate drops more than 70% with less than 2% loss of\ntest accuracy on the validation dataset.\n",
		"date": [
			"2020-10-28",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.01767",
		"pdf_url": "http://arxiv.org/pdf/2011.01767.pdf"
	},
	"502": {
		"title": "FASTCloud: A framework of assessment and selection for trustworthy cloud\n  service based on QoS",
		"creator": "Li, Xiang",
		"subject": "Computer Science - Distributed, Parallel, and Cluster Computing",
		"description": "  By virtue of technology and benefit advantages, cloud computing has\nincreasingly attracted a large number of potential cloud consumers (PCC) plan\nto migrate the traditional business to the cloud service. However, trust has\nbecome one of the most challenging issues that prevent the PCC from adopting\ncloud services, especially in trustworthy cloud service selection. Besides, due\nto the diversity and dynamic of quality of service (QoS) in the cloud\nenvironment, the existing trust assessment methods based on the single constant\nvalue of QoS attribute and the subjective weight assignment are not good enough\nto provide an effective solution for PCCs to identify and select a trustworthy\ncloud service among a wide range of functionally-equivalent cloud service\nproviders (CSPs). To address the challenge, a novel assessment and selection\nframework for trustworthy cloud service, FASTCloud, is proposed in this study.\nThis framework facilitates PCCs to select a trustworthy cloud service based on\ntheir actual QoS requirements. In order to accurately and efficiently assess\nthe trust level of cloud services, a QoS-based trust assessment model is\nproposed. This model represents a trust level assessment method based on the\ninterval multiple attributes with an objective weight assignment method based\non the deviation maximization to adaptively determine the trust level of\ndifferent cloud services provisioned by candidate CSPs. The advantage of the\nproposed trust level assessment method in time complexity is demonstrated by\nthe performance analysis and comparison. The experimental result of a case\nstudy with an open-source dataset shows that the trust model is efficient in\ncloud service trust assessment and the FASTCloud can effectively help PCCs\nselect a trustworthy cloud service.\n",
		"date": [
			"2020-11-01",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.01871",
		"pdf_url": "http://arxiv.org/pdf/2011.01871.pdf"
	},
	"503": {
		"title": "Evolving test instances of the Hamiltonian completion problem",
		"creator": [
			"Lechien, Thibault",
			"Jooken, Jorik",
			"De Causmaecker, Patrick"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Discrete Mathematics",
			"Computer Science - Neural and Evolutionary Computing",
			"F.2.2",
			"G.2.2"
		],
		"description": [
			"  Predicting and comparing algorithm performance on graph instances is\nchallenging for multiple reasons. First, there is usually no standard set of\ninstances to benchmark performance. Second, using existing graph generators\nresults in a restricted spectrum of difficulty and the resulting graphs are\nusually not diverse enough to draw sound conclusions. That is why recent work\nproposes a new methodology to generate a diverse set of instances by using an\nevolutionary algorithm. We can then analyze the resulting graphs and get key\ninsights into which attributes are most related to algorithm performance. We\ncan also fill observed gaps in the instance space in order to generate graphs\nwith previously unseen combinations of features. This methodology is applied to\nthe instance space of the Hamiltonian completion problem using two different\nsolvers, namely the Concorde TSP Solver and a multi-start local search\nalgorithm.\n",
			"Comment: 12 pages, 12 figures, minor revisions in section 4"
		],
		"date": [
			"2020-10-05",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.02291",
		"pdf_url": "http://arxiv.org/pdf/2011.02291.pdf"
	},
	"504": {
		"title": "An SMT-Based Approach for Verifying Binarized Neural Networks",
		"creator": [
			"Amir, Guy",
			"Wu, Haoze",
			"Barrett, Clark",
			"Katz, Guy"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Mathematics - Optimization and Control"
		],
		"description": [
			"  Deep learning has emerged as an effective approach for creating modern\nsoftware systems, with neural networks often surpassing hand-crafted systems.\nUnfortunately, neural networks are known to suffer from various safety and\nsecurity issues. Formal verification is a promising avenue for tackling this\ndifficulty, by formally certifying that networks are correct. We propose an\nSMT-based technique for verifying Binarized Neural Networks - a popular kind of\nneural network, where some weights have been binarized in order to render the\nneural network more memory and energy efficient, and quicker to evaluate. One\nnovelty of our technique is that it allows the verification of neural networks\nthat include both binarized and non-binarized components. Neural network\nverification is computationally very difficult, and so we propose here various\noptimizations, integrated into our SMT procedure as deduction steps, as well as\nan approach for parallelizing verification queries. We implement our technique\nas an extension to the Marabou framework, and use it to evaluate the approach\non popular binarized neural network architectures.\n",
			"Comment: This is a preprint version of a paper that will appear at TACAS 2021"
		],
		"date": [
			"2020-11-05",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.02948",
		"pdf_url": "http://arxiv.org/pdf/2011.02948.pdf"
	},
	"505": {
		"title": "Efficient image retrieval using multi neural hash codes and bloom\n  filters",
		"creator": "Chakrabarti, Sourin",
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": [
			"  This paper aims to deliver an efficient and modified approach for image\nretrieval using multiple neural hash codes and limiting the number of queries\nusing bloom filters by identifying false positives beforehand. Traditional\napproaches involving neural networks for image retrieval tasks tend to use\nhigher layers for feature extraction. But it has been seen that the activations\nof lower layers have proven to be more effective in a number of scenarios. In\nour approach, we have leveraged the use of local deep convolutional neural\nnetworks which combines the powers of both the features of lower and higher\nlayers for creating feature maps which are then compressed using PCA and fed to\na bloom filter after binary sequencing using a modified multi k-means approach.\nThe feature maps obtained are further used in the image retrieval process in a\nhierarchical coarse-to-fine manner by first comparing the images in the higher\nlayers for semantically similar images and then gradually moving towards the\nlower layers searching for structural similarities. While searching, the neural\nhashes for the query image are again calculated and queried in the bloom filter\nwhich tells us whether the query image is absent in the set or maybe present.\nIf the bloom filter doesn't necessarily rule out the query, then it goes into\nthe image retrieval process. This approach can be particularly helpful in cases\nwhere the image store is distributed since the approach supports parallel\nquerying.\n",
			"Comment: 2020 IEEE International Conference for Innovation in Technology.\n  Asian Journal for Convergence in Technology(AJCT) Volume VI Issue III"
		],
		"date": [
			"2020-11-06",
			"2020-11-18"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2011.03234",
			"doi:10.1109/INOCON50539.2020.9298228"
		],
		"pdf_url": "http://arxiv.org/pdf/2011.03234.pdf"
	},
	"506": {
		"title": "Do We Need to Compensate for Motion Distortion and Doppler Effects in\n  Spinning Radar Navigation?",
		"creator": [
			"Burnett, Keenan",
			"Schoellig, Angela P.",
			"Barfoot, Timothy D."
		],
		"subject": [
			"Computer Science - Robotics",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": [
			"  In order to tackle the challenge of unfavorable weather conditions such as\nrain and snow, radar is being revisited as a parallel sensing modality to\nvision and lidar. Recent works have made tremendous progress in applying\nspinning radar to odometry and place recognition. However, these works have so\nfar ignored the impact of motion distortion and Doppler effects on\nspinning-radar-based navigation, which may be significant in the self-driving\ncar domain where speeds can be high. In this work, we demonstrate the effect of\nthese distortions on radar odometry using the Oxford Radar RobotCar Dataset and\nmetric localization using our own data-taking platform. We revisit a\nlightweight estimator that can recover the motion between a pair of radar scans\nwhile accounting for both effects. Our conclusion is that both motion\ndistortion and the Doppler effect are significant in different aspects of\nspinning radar navigation, with the former more prominent than the latter. Code\nfor this project can be found at:\nhttps://github.com/keenan-burnett/yeti_radar_odometry\n",
			"Comment: Accepted for publication in ICRA/RA-L 2021. Version 3"
		],
		"date": [
			"2020-11-06",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.03512",
		"pdf_url": "http://arxiv.org/pdf/2011.03512.pdf"
	},
	"507": {
		"title": "The Twelvefold Way of Non-Sequential Lossless Compression",
		"creator": [
			"Rahman, Taha Ameen ur",
			"Barbehenn, Alton S.",
			"Chen, Xinan",
			"Dbouk, Hassan",
			"Douglas, James A.",
			"Geng, Yuncong",
			"George, Ian",
			"Harvill, John B.",
			"Jeon, Sung Woo",
			"Kansal, Kartik K.",
			"Lee, Kiwook",
			"Levick, Kelly A.",
			"Li, Bochao",
			"Li, Ziyue",
			"Murthy, Yashaswini",
			"Muthuveeru-Subramaniam, Adarsh",
			"Olmez, S. Yagiz",
			"Tomei, Matthew J.",
			"Veeravalli, Tanya",
			"Wang, Xuechao",
			"Wayman, Eric A.",
			"Wu, Fan",
			"Xu, Peng",
			"Yan, Shen",
			"Zhang, Heling",
			"Zhang, Yibo",
			"Zhang, Yifan",
			"Zhao, Yibo",
			"Basu, Sourya",
			"Varshney, Lav R."
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  Many information sources are not just sequences of distinguishable symbols\nbut rather have invariances governed by alternative counting paradigms such as\npermutations, combinations, and partitions. We consider an entire\nclassification of these invariances called the twelvefold way in enumerative\ncombinatorics and develop a method to characterize lossless compression limits.\nExplicit computations for all twelve settings are carried out for i.i.d.\nuniform and Bernoulli distributions. Comparisons among settings provide\nquantitative insight.\n",
			"Comment: DCC 2021"
		],
		"date": [
			"2020-11-08",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.04069",
		"pdf_url": "http://arxiv.org/pdf/2011.04069.pdf"
	},
	"508": {
		"title": "Reliable Off-policy Evaluation for Reinforcement Learning",
		"creator": [
			"Wang, Jie",
			"Gao, Rui",
			"Zha, Hongyuan"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  In a sequential decision-making problem, off-policy evaluation estimates the\nexpected cumulative reward of a target policy using logged trajectory data\ngenerated from a different behavior policy, without execution of the target\npolicy. Reinforcement learning in high-stake environments, such as healthcare\nand education, is often limited to off-policy settings due to safety or ethical\nconcerns, or inability of exploration. Hence it is imperative to quantify the\nuncertainty of the off-policy estimate before deployment of the target policy.\nIn this paper, we propose a novel framework that provides robust and optimistic\ncumulative reward estimates using one or multiple logged trajectories data.\nLeveraging methodologies from distributionally robust optimization, we show\nthat with proper selection of the size of the distributional uncertainty set,\nthese estimates serve as confidence bounds with non-asymptotic and asymptotic\nguarantees under stochastic or adversarial environments. Our results are also\ngeneralized to batch reinforcement learning and are supported by empirical\nanalysis.\n",
			"Comment: 39 pages, 4 figures"
		],
		"date": [
			"2020-11-08",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.04102",
		"pdf_url": "http://arxiv.org/pdf/2011.04102.pdf"
	},
	"509": {
		"title": "Improved deep learning techniques in gravitational-wave data analysis",
		"creator": [
			"Xia, Heming",
			"Shao, Lijing",
			"Zhao, Junjie",
			"Cao, Zhoujian"
		],
		"subject": [
			"Astrophysics - High Energy Astrophysical Phenomena",
			"Computer Science - Machine Learning",
			"General Relativity and Quantum Cosmology",
			"Statistics - Machine Learning"
		],
		"description": [
			"  In recent years, convolutional neural network (CNN) and other deep learning\nmodels have been gradually introduced into the area of gravitational-wave (GW)\ndata processing. Compared with the traditional matched-filtering techniques,\nCNN has significant advantages in efficiency in GW signal detection tasks. In\naddition, matched-filtering techniques are based on the template bank of the\nexisting theoretical waveform, which makes it difficult to find GW signals\nbeyond theoretical expectation. In this paper, based on the task of GW\ndetection of binary black holes, we introduce the optimization techniques of\ndeep learning, such as batch normalization and dropout, to CNN models. Detailed\nstudies of model performance are carried out. Through this study, we recommend\nto use batch normalization and dropout techniques in CNN models in GW signal\ndetection tasks. Furthermore, we investigate the generalization ability of CNN\nmodels on different parameter ranges of GW signals. We point out that CNN\nmodels are robust to the variation of the parameter range of the GW waveform.\nThis is a major advantage of deep learning models over matched-filtering\ntechniques.\n",
			"Comment: 13 pages, 11 figures; accepted by PRD"
		],
		"date": [
			"2020-11-09",
			"2020-12-23"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2011.04418",
			"Phys. Rev. D 103, 024040 (2021)",
			"doi:10.1103/PhysRevD.103.024040"
		],
		"pdf_url": "http://arxiv.org/pdf/2011.04418.pdf"
	},
	"510": {
		"title": "Deep reinforcement learning for RAN optimization and control",
		"creator": [
			"Chen, Yu",
			"Chen, Jie",
			"Krishnamurthi, Ganesh",
			"Yang, Huijing",
			"Wang, Huahui",
			"Zhao, Wenjie"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Due to the high variability of the traffic in the radio access network (RAN),\nfixed network configurations are not flexible enough to achieve optimal\nperformance. Our vendors provide several settings of the eNodeB to optimize the\nRAN performance, such as media access control scheduler, loading balance, etc.\nBut the detailed mechanisms of the eNodeB configurations are usually very\ncomplicated and not disclosed, not to mention the large key performance\nindicators (KPIs) space needed to be considered. These make constructing a\nsimulator, offline tuning, or rule-based solutions difficult. We aim to build\nan intelligent controller without strong assumption or domain knowledge about\nthe RAN and can run 24/7 without supervision. To achieve this goal, we first\nbuild a closed-loop control testbed RAN in a lab environment with one eNodeB\nprovided by one of the largest wireless vendors and four smartphones. Next, we\nbuild a double Q network agent trained with the live feedback of the key\nperformance indicators from the RAN. Our work proved the effectiveness of\napplying deep reinforcement learning to improve network performance in a real\nRAN network environment.\n",
			"Comment: 6 pages, 2 figures"
		],
		"date": [
			"2020-11-09",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.04607",
		"pdf_url": "http://arxiv.org/pdf/2011.04607.pdf"
	},
	"511": {
		"title": "Explainable COVID-19 Detection Using Chest CT Scans and Deep Learning",
		"creator": [
			"Alshazly, Hammam",
			"Linse, Christoph",
			"Barth, Erhardt",
			"Martinetz, Thomas"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  This paper explores how well deep learning models trained on chest CT images\ncan diagnose COVID-19 infected people in a fast and automated process. To this\nend, we adopt advanced deep network architectures and propose a transfer\nlearning strategy using custom-sized input tailored for each deep architecture\nto achieve the best performance. We conduct extensive sets of experiments on\ntwo CT image datasets, namely the SARS-CoV-2 CT-scan and the COVID19-CT. The\nobtained results show superior performances for our models compared with\nprevious studies, where our best models achieve average accuracy, precision,\nsensitivity, specificity and F1 score of 99.4%, 99.6%, 99.8%, 99.6% and 99.4%\non the SARS-CoV-2 dataset; and 92.9%, 91.3%, 93.7%, 92.2% and 92.5% on the\nCOVID19-CT dataset, respectively. Furthermore, we apply two visualization\ntechniques to provide visual explanations for the models' predictions. The\nvisualizations show well-separated clusters for CT images of COVID-19 from\nother lung diseases, and accurate localizations of the COVID-19 associated\nregions.\n",
		"date": "2020-11-09",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2011.05317",
			"Sensors - 2021",
			"doi:10.3390/s21020455"
		],
		"pdf_url": "http://arxiv.org/pdf/2011.05317.pdf"
	},
	"512": {
		"title": "Stability of Gradient Learning Dynamics in Continuous Games: Vector\n  Action Spaces",
		"creator": [
			"Chasnov, Benjamin J.",
			"Calderone, Daniel",
			"Açıkmeşe, Behçet",
			"Burden, Samuel A.",
			"Ratliff, Lillian J."
		],
		"subject": [
			"Computer Science - Computer Science and Game Theory",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": [
			"  Towards characterizing the optimization landscape of games, this paper\nanalyzes the stability of gradient-based dynamics near fixed points of\ntwo-player continuous games. We introduce the quadratic numerical range as a\nmethod to characterize the spectrum of game dynamics and prove the robustness\nof equilibria to variations in learning rates. By decomposing the game Jacobian\ninto symmetric and skew-symmetric components, we assess the contribution of a\nvector field's potential and rotational components to the stability of\ndifferential Nash equilibria. Our results show that in zero-sum games, all Nash\nare stable and robust; in potential games, all stable points are Nash. For\ngeneral-sum games, we provide a sufficient condition for instability. We\nconclude with a numerical example in which learning with timescale separation\nresults in faster convergence.\n",
			"Comment: extension of arXiv:2011.03650 to vector action spaces. Submitted to\n  IEEE L-CSS"
		],
		"date": [
			"2020-11-06",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.05562",
		"pdf_url": "http://arxiv.org/pdf/2011.05562.pdf"
	},
	"513": {
		"title": "Reliability Model for Incentive-Driven IoT Energy Services",
		"creator": [
			"Abusafia, Amani",
			"Bouguettaya, Athman"
		],
		"subject": "Computer Science - Distributed, Parallel, and Cluster Computing",
		"description": [
			"  We propose a novel reliability model for composing energy service requests.\nThe proposed model is based on consumers' behavior and history of energy\nrequests. The reliability model ensures the maximum incentives to providers.\nIncentives are used as a green solution to increase IoT users' participation in\na crowdsourced energy sharing environment. Additionally, adaptive and priority\nscheduling compositions are proposed to compose the most reliable energy\nrequests while maximizing providers' incentives. A set of experiments is\nconducted to evaluate the proposed approaches. Experimental results prove the\nefficiency of the proposed approaches.\n",
			"Comment: 10 pages, 10 figures, This paper is accepted in the 2020 EAI\n  International Conference on Mobile and Ubiquitous Systems: Computing,\n  Networking and Services (EAI MobiQuitous 2020)"
		],
		"date": [
			"2020-11-11",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.06159",
		"pdf_url": "http://arxiv.org/pdf/2011.06159.pdf"
	},
	"514": {
		"title": "Performance of Bounded-Rational Agents With the Ability to Self-Modify",
		"creator": [
			"Tětek, Jakub",
			"Sklenka, Marek",
			"Gavenčiak, Tomáš"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computers and Society"
		],
		"description": [
			"  Self-modification of agents embedded in complex environments is hard to\navoid, whether it happens via direct means (e.g. own code modification) or\nindirectly (e.g. influencing the operator, exploiting bugs or the environment).\nIt has been argued that intelligent agents have an incentive to avoid modifying\ntheir utility function so that their future instances work towards the same\ngoals.\n  Everitt et al. (2016) formally show that providing an option to self-modify\nis harmless for perfectly rational agents. We show that this result is no\nlonger true for agents with bounded rationality. In such agents,\nself-modification may cause exponential deterioration in performance and\ngradual misalignment of a previously aligned agent. We investigate how the size\nof this effect depends on the type and magnitude of imperfections in the\nagent's rationality (1-4 below). We also discuss model assumptions and the\nwider problem and framing space.\n  We examine four ways in which an agent can be bounded-rational: it either (1)\ndoesn't always choose the optimal action, (2) is not perfectly aligned with\nhuman values, (3) has an inaccurate model of the environment, or (4) uses the\nwrong temporal discounting factor. We show that while in the cases (2)-(4) the\nmisalignment caused by the agent's imperfection does not increase over time,\nwith (1) the misalignment may grow exponentially.\n",
			"Comment: Fixed minor problems; To appear in SafeAI @ AAAI 2021"
		],
		"date": [
			"2020-11-12",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.06275",
		"pdf_url": "http://arxiv.org/pdf/2011.06275.pdf"
	},
	"515": {
		"title": "First steps toward a simple but efficient model-free control synthesis\n  for variable-speed wind turbines",
		"creator": [
			"Lafont, Frédéric",
			"Balmat, Jean-François",
			"Join, Cédric",
			"Fliess, Michel"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Mathematics - Optimization and Control"
		],
		"description": [
			"  Although variable-speed three-blade wind turbines are nowadays quite popular,\ntheir control remains a challenging task. We propose a new easily implementable\nmodel-free control approach with the corresponding intelligent controllers.\nSeveral convincing computer simulations, including some fault accommodations,\nshows that model-free controllers are more efficient and robust than classic\nproportional-integral controllers.\n",
			"Comment: 4th European Conference on Electrical Engineering & Computer Science\n  (EECS 2020), Bern (Switzerland), December 21-23, 2020"
		],
		"date": "2020-11-12",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2011.06415",
			"doi:10.46300/9106.2020.14.146"
		],
		"pdf_url": "http://arxiv.org/pdf/2011.06415.pdf"
	},
	"516": {
		"title": "On a question of Haemers regarding vectors in the nullspace of Seidel\n  matrices",
		"creator": [
			"Akbari, Saieed",
			"Cioabă, Sebastian M.",
			"Goudarzi, Samira",
			"Niaparast, Aidin",
			"Tajdini, Artin"
		],
		"subject": [
			"Mathematics - Combinatorics",
			"Computer Science - Discrete Mathematics"
		],
		"description": "  In 2011, Haemers asked the following question: If $S$ is the Seidel matrix of\na graph of order $n$ and $S$ is singular, does there exist an eigenvector of\n$S$ corresponding to $0$ which has only $\\pm 1$ elements?\n  In this paper, we construct infinite families of graphs which give a negative\nanswer to this question. One of our constructions implies that for every\nnatural number $N$, there exists a graph whose Seidel matrix $S$ is singular\nsuch that for any integer vector in the nullspace of $S$, the absolute value of\nany entry in this vector is more than $N$. We also derive some characteristics\nof vectors in the nullspace of Seidel matrices, which lead to some necessary\nconditions for the singularity of Seidel matrices. Finally, we obtain some\nproperties of the graphs which affirm the above question.\n",
		"date": [
			"2020-11-12",
			"2021-01-21"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2011.06435",
			"doi:10.1016/j.laa.2021.01.003"
		],
		"pdf_url": "http://arxiv.org/pdf/2011.06435.pdf"
	},
	"517": {
		"title": "Invariants of Self-Intersected N-Periodics in the Elliptic Billiard",
		"creator": [
			"Garcia, Ronaldo",
			"Reznik, Dan"
		],
		"subject": [
			"Mathematics - Metric Geometry",
			"Computer Science - Computational Geometry",
			"Computer Science - Robotics",
			"Computer Science - Symbolic Computation",
			"51M04 51N20 51N35 68T20"
		],
		"description": [
			"  We study self-intersected N-periodics in the elliptic billiard, describing\nnew facts about their geometry (e.g., self-intersected 4-periodics have\nvertices concyclic with the foci). We also check if some invariants listed in\n\"Eighty New Invariants of N-Periodics in the Elliptic Billiard\" (2020),\narXiv:2004.12497, remain invariant in the self-intersected case. Toward that\nend, we derive explicit expressions for many low-N simple and self-intersected\ncases. We identify two special cases (one simple, one self-intersected) where a\nquantity prescribed to be invariant is actually variable.\n",
			"Comment: 24 pages, 14 figures, 3 tables, and 21 videos"
		],
		"date": [
			"2020-11-12",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.06640",
		"pdf_url": "http://arxiv.org/pdf/2011.06640.pdf"
	},
	"518": {
		"title": "EDITOR: an Edit-Based Transformer with Repositioning for Neural Machine\n  Translation with Soft Lexical Constraints",
		"creator": [
			"Xu, Weijia",
			"Carpuat, Marine"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  We introduce an Edit-Based Transformer with Repositioning (EDITOR), which\nmakes sequence generation flexible by seamlessly allowing users to specify\npreferences in output lexical choice. Building on recent models for\nnon-autoregressive sequence generation (Gu et al., 2019), EDITOR generates new\nsequences by iteratively editing hypotheses. It relies on a novel reposition\noperation designed to disentangle lexical choice from word positioning\ndecisions, while enabling efficient oracles for imitation learning and parallel\nedits at decoding time. Empirically, EDITOR uses soft lexical constraints more\neffectively than the Levenshtein Transformer (Gu et al., 2019) while speeding\nup decoding dramatically compared to constrained beam search (Post and Vilar,\n2018). EDITOR also achieves comparable or better translation quality with\nfaster decoding speed than the Levenshtein Transformer on standard\nRomanian-English, English-German, and English-Japanese machine translation\ntasks.\n",
			"Comment: TACL 2021"
		],
		"date": [
			"2020-11-13",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.06868",
		"pdf_url": "http://arxiv.org/pdf/2011.06868.pdf"
	},
	"519": {
		"title": "Channel Tiling for Improved Performance and Accuracy of Optical Neural\n  Network Accelerators",
		"creator": [
			"Li, Shurui",
			"Miscuglio, Mario",
			"Sorger, Volker J.",
			"Gupta, Puneet"
		],
		"subject": [
			"Computer Science - Emerging Technologies",
			"Computer Science - Hardware Architecture"
		],
		"description": [
			"  Low latency, high throughput inference on Convolution Neural Networks (CNNs)\nremains a challenge, especially for applications requiring large input or large\nkernel sizes. 4F optics provides a solution to accelerate CNNs by converting\nconvolutions into Fourier-domain point-wise multiplications that are\ncomputationally 'free' in optical domain. However, existing 4F CNN systems\nsuffer from the all-positive sensor readout issue which makes the\nimplementation of a multi-channel, multi-layer CNN not scalable or even\nimpractical. In this paper we propose a simple channel tiling scheme for 4F CNN\nsystems that utilizes the high resolution of 4F system to perform channel\nsummation inherently in optical domain before sensor detection, so the outputs\nof different channels can be correctly accumulated. Compared to state of the\nart, channel tiling gives similar accuracy, significantly better robustness to\nsensing quantization (33\\% improvement in required sensing precision) error and\nnoise (10dB reduction in tolerable sensing noise), 0.5X total filters required,\n10-50X+ throughput improvement and as much as 3X reduction in required output\ncamera resolution/bandwidth. Not requiring any additional optical hardware, the\nproposed channel tiling approach addresses an important throughput and\nprecision bottleneck of high-speed, massively-parallel optical 4F computing\nsystems.\n",
			"Comment: 11 pages, 8 figures"
		],
		"date": [
			"2020-11-14",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.07391",
		"pdf_url": "http://arxiv.org/pdf/2011.07391.pdf"
	},
	"520": {
		"title": "A Survey on the Explainability of Supervised Machine Learning",
		"creator": [
			"Burkart, Nadia",
			"Huber, Marco F."
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Predictions obtained by, e.g., artificial neural networks have a high\naccuracy but humans often perceive the models as black boxes. Insights about\nthe decision making are mostly opaque for humans. Particularly understanding\nthe decision making in highly sensitive areas such as healthcare or fifinance,\nis of paramount importance. The decision-making behind the black boxes requires\nit to be more transparent, accountable, and understandable for humans. This\nsurvey paper provides essential definitions, an overview of the different\nprinciples and methodologies of explainable Supervised Machine Learning (SML).\nWe conduct a state-of-the-art survey that reviews past and recent explainable\nSML approaches and classifies them according to the introduced definitions.\nFinally, we illustrate principles by means of an explanatory case study and\ndiscuss important future directions.\n",
			"Comment: Accepted for publication at the Journal of Artificial Intelligence\n  Research (JAIR)"
		],
		"date": "2020-11-16",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2011.07876",
			"Journal of Artificial Intelligence Research (JAIR), 70:245-317,\n  2021",
			"doi:10.1613/jair.1.12228"
		],
		"pdf_url": "http://arxiv.org/pdf/2011.07876.pdf"
	},
	"521": {
		"title": "Memory-Rate Tradeoff for Caching with Uncoded Placement under Nonuniform\n  File Popularity",
		"creator": [
			"Deng, Yong",
			"Dong, Min"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  For caching with nonuniform file popularity, we aim to characterize the\nmemory-rate tradeoff under uncoded cache placement. We consider the recently\nproposed Modified Coded Caching Scheme (MCCS) with the optimized cache\nplacement based on the popularity-first approach to minimize the average\ndelivery rate. We introduce two information-theoretic lower bounds on the\naverage rate for caching under uncoded placement. For $K = 2$ users, we show\nthat the optimized MCCS attains the lower bound and is optimal for caching with\nuncoded placement. For general $K$ users with distinct file requests, the\noptimized MCCS attains the popularity-first-based lower bound. When there are\nredundant file requests among $K$ users, we show a possible gap between the\noptimized MCCS and the lower bounds, which is attributed to zero-padding\ncommonly used for coded delivery. We analyze the impact of zero-padding and its\nlimitation. Simulation study shows that the loss is very small in general and\nonly exists in some limited cases.\n",
			"Comment: To appear in the Asilomar Conference on Signals, Systems, and\n  Computers, 2020"
		],
		"date": [
			"2020-11-16",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.08122",
		"pdf_url": "http://arxiv.org/pdf/2011.08122.pdf"
	},
	"522": {
		"title": "Demonstrations of Cooperative Perception: Safety and Robustness in\n  Connected and Automated Vehicle Operations",
		"creator": [
			"Shan, Mao",
			"Narula, Karan",
			"Wong, Yung Fei",
			"Worrall, Stewart",
			"Khan, Malik",
			"Alexander, Paul",
			"Nebot, Eduardo"
		],
		"subject": "Computer Science - Robotics",
		"description": "  Cooperative perception, or collective perception (CP) is an emerging and\npromising technology for intelligent transportation systems (ITS). It enables\nan ITS station (ITS-S) to share its local perception information with others by\nmeans of vehicle-to-X (V2X) communication, thereby achieving improved\nefficiency and safety in road transportation. In this paper, we present our\nrecent progress on the development of a connected and automated vehicle (CAV)\nand intelligent roadside unit (IRSU). We present three different experiments to\ndemonstrate the use of CP service within intelligent infrastructure to improve\nawareness of vulnerable road users (VRU) and thus safety for CAVs in various\ntraffic scenarios. We demonstrate in the experiments that a connected vehicle\n(CV) can \"see\" a pedestrian around the corners. More importantly, we\ndemonstrate how CAVs can autonomously and safely interact with walking and\nrunning pedestrians, relying only on the CP information from the IRSU through\nvehicle-to-infrastructure (V2I) communication. This is one of the first\ndemonstrations of urban vehicle automation using only CP information. We also\naddress in the paper the handling of collective perception messages (CPMs)\nreceived from the IRSU, and passing them through a pipeline of CP information\ncoordinate transformation with uncertainty, multiple road user tracking, and\neventually path planning/decision making within the CAV. The experimental\nresults were obtained with manually driven CV, fully autonomous CAV, and an\nIRSU retrofitted with vision and laser sensors and a road user tracking system.\n",
		"date": [
			"2020-11-17",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.08581",
		"pdf_url": "http://arxiv.org/pdf/2011.08581.pdf"
	},
	"523": {
		"title": "Environmental Pollution Prediction of NOx by Process Analysis and\n  Predictive Modelling in Natural Gas Turbine Power Plants",
		"creator": "Rezazadeh, Alan",
		"subject": [
			"Electrical Engineering and Systems Science - Signal Processing",
			"Computer Science - Machine Learning",
			"Physics - Atmospheric and Oceanic Physics",
			"Physics - Data Analysis, Statistics and Probability"
		],
		"description": [
			"  The main objective of this paper is to propose K-Nearest-Neighbor (KNN)\nalgorithm for predicting NOx emissions from natural gas electrical generation\nturbines. The process of producing electricity is dynamic and rapidly changing\ndue to many factors such as weather and electrical grid requirements. Gas\nturbine equipment are also a dynamic part of the electricity generation since\nthe equipment characteristics and thermodynamics behavior change as the\nturbines age. Regular maintenance of turbines are also another dynamic part of\nthe electrical generation process, affecting the performance of equipment. This\nanalysis discovered using KNN, trained on relatively small dataset produces the\nmost accurate prediction rates. This statement can be logically explained as\nKNN finds the K nearest neighbor to the current input parameters and estimates\na rated average of historically similar observations as prediction.\n  This paper incorporates ambient weather conditions, electrical output as well\nas turbine performance factors to build a machine learning model to predict NOx\nemissions. The model can be used to optimize the operational processes for\nreduction in harmful emissions and increasing overall operational efficiency.\nLatent algorithms such as Principle Component Algorithms (PCA) have been used\nfor monitoring the equipment performance behavior change which deeply\ninfluences process paraments and consequently determines NOx emissions. Typical\nstatistical methods of machine learning performance evaluations such as\nmultivariate analysis, clustering and residual analysis have been used\nthroughout the paper.\n",
			"Comment: 12 pages, 9 tables, 7 figures"
		],
		"date": [
			"2020-11-05",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.08978",
		"pdf_url": "http://arxiv.org/pdf/2011.08978.pdf"
	},
	"524": {
		"title": "Continuous Emotion Recognition with Spatiotemporal Convolutional Neural\n  Networks",
		"creator": [
			"Teixeira, Thomas",
			"Granger, Eric",
			"Koerich, Alessandro Lameiras"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Facial expressions are one of the most powerful ways for depicting specific\npatterns in human behavior and describing human emotional state. Despite the\nimpressive advances of affective computing over the last decade, automatic\nvideo-based systems for facial expression recognition still cannot handle\nproperly variations in facial expression among individuals as well as\ncross-cultural and demographic aspects. Nevertheless, recognizing facial\nexpressions is a difficult task even for humans. In this paper, we investigate\nthe suitability of state-of-the-art deep learning architectures based on\nconvolutional neural networks (CNNs) for continuous emotion recognition using\nlong video sequences captured in-the-wild. This study focuses on deep learning\nmodels that allow encoding spatiotemporal relations in videos considering a\ncomplex and multi-dimensional emotion space, where values of valence and\narousal must be predicted. We have developed and evaluated convolutional\nrecurrent neural networks combining 2D-CNNs and long short term-memory units,\nand inflated 3D-CNN models, which are built by inflating the weights of a\npre-trained 2D-CNN model during fine-tuning, using application-specific videos.\nExperimental results on the challenging SEWA-DB dataset have shown that these\narchitectures can effectively be fine-tuned to encode the spatiotemporal\ninformation from successive raw pixel images and achieve state-of-the-art\nresults on such a dataset.\n",
			"Comment: 33 pages"
		],
		"date": [
			"2020-11-18",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.09280",
		"pdf_url": "http://arxiv.org/pdf/2011.09280.pdf"
	},
	"525": {
		"title": "Data Driven Modeling of Interfacial Traction Separation Relations using\n  a Thermodynamically Consistent Neural Network",
		"creator": [
			"Wei, Congjie",
			"Zhang, Jiaxin",
			"Liechti, Kenneth M.",
			"Wu, Chenglin"
		],
		"subject": "Computer Science - Computational Engineering, Finance, and Science",
		"description": "  For multilayer structures, interfacial failure is one of the most important\nelements related to device reliability. For cohesive zone modelling,\ntraction-separation relations represent the adhesive interactions across\ninterfaces. However, existing theoretical models do not currently capture\ntraction-separation relations that have been extracted using direct methods,\nparticularly under mixed-mode conditions. Given the complexity of the problem,\nmodels derived from the neural network approach are attractive. Although they\ncan be trained to fit data along the loading paths taken in a particular set of\nmixed-mode fracture experiments, they may fail to obey physical laws for paths\nnot covered by the training data sets. In this paper, a thermodynamically\nconsistent neural network (TCNN) approach is established to model the\nconstitutive behavior of interfaces when faced with sparse training data sets.\nAccordingly, three conditions are examined and implemented here: (i)\nthermodynamic consistency, (ii) maximum energy dissipation path control and\n(iii) J-integral conservation. These conditions are treated as constraints and\nare implemented as such in the loss function. The feasibility of this approach\nis demonstrated by comparing the modeling results with a range of physical\nconstraints. Moreover, a Bayesian optimization algorithm is then adopted to\noptimize the weight factors associated with each of the constraints in order to\novercome convergence issues that can arise when multiple constraints are\npresent. The resultant numerical implementation of the ideas presented here\nproduced well-behaved, mixed-mode traction separation surfaces that maintained\nthe fidelity of the experimental data that was provided as input. The proposed\napproach heralds a new autonomous, point-to-point constitutive modeling concept\nfor interface mechanics.\n",
		"date": [
			"2020-11-17",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.09946",
		"pdf_url": "http://arxiv.org/pdf/2011.09946.pdf"
	},
	"526": {
		"title": "MultiStar: Instance Segmentation of Overlapping Objects with Star-Convex\n  Polygons",
		"creator": [
			"Walter, Florin C.",
			"Damrich, Sebastian",
			"Hamprecht, Fred A."
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": [
			"  Instance segmentation of overlapping objects in biomedical images remains a\nlargely unsolved problem. We take up this challenge and present MultiStar, an\nextension to the popular instance segmentation method StarDist. The key novelty\nof our method is that we identify pixels at which objects overlap and use this\ninformation to improve proposal sampling and to avoid suppressing proposals of\ntruly overlapping objects. This allows us to apply the ideas of StarDist to\nimages with overlapping objects, while incurring only a small overhead compared\nto the established method. MultiStar shows promising results on two datasets\nand has the advantage of using a simple and easy to train network architecture.\n",
			"Comment: Accepted for ISBI 2021"
		],
		"date": [
			"2020-11-26",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.13228",
		"pdf_url": "http://arxiv.org/pdf/2011.13228.pdf"
	},
	"527": {
		"title": "Understand Watchdogs: Discover How Game Bot Get Discovered",
		"creator": [
			"Park, Eunji",
			"Park, Kyung Ho",
			"Kim, Huy Kang"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  The game industry has long been troubled by malicious activities utilizing\ngame bots. The game bots disturb other game players and destroy the\nenvironmental system of the games. For these reasons, the game industry put\ntheir best efforts to detect the game bots among players' characters using the\nlearning-based detections. However, one problem with the detection\nmethodologies is that they do not provide rational explanations about their\ndecisions. To resolve this problem, in this work, we investigate the\nexplainabilities of the game bot detection. We develop the XAI model using a\ndataset from the Korean MMORPG, AION, which includes game logs of human players\nand game bots. More than one classification model has been applied to the\ndataset to be analyzed by applying interpretable models. This provides us\nexplanations about the game bots' behavior, and the truthfulness of the\nexplanations has been evaluated. Besides, interpretability contributes to\nminimizing false detection, which imposes unfair restrictions on human players.\n",
			"Comment: 9 pages, 3 figures, 3 tables, this paper is accepted in ICAART 2021"
		],
		"date": [
			"2020-11-26",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.13374",
		"pdf_url": "http://arxiv.org/pdf/2011.13374.pdf"
	},
	"528": {
		"title": "A Data-Driven Study of Commonsense Knowledge using the ConceptNet\n  Knowledge Base",
		"creator": [
			"Shen, Ke",
			"Kejriwal, Mayank"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computation and Language"
		],
		"description": "  Acquiring commonsense knowledge and reasoning is recognized as an important\nfrontier in achieving general Artificial Intelligence (AI). Recent research in\nthe Natural Language Processing (NLP) community has demonstrated significant\nprogress in this problem setting. Despite this progress, which is mainly on\nmultiple-choice question answering tasks in limited settings, there is still a\nlack of understanding (especially at scale) of the nature of commonsense\nknowledge itself. In this paper, we propose and conduct a systematic study to\nenable a deeper understanding of commonsense knowledge by doing an empirical\nand structural analysis of the ConceptNet knowledge base. ConceptNet is a\nfreely available knowledge base containing millions of commonsense assertions\npresented in natural language. Detailed experimental results on three carefully\ndesigned research questions, using state-of-the-art unsupervised graph\nrepresentation learning ('embedding') and clustering techniques, reveal deep\nsubstructures in ConceptNet relations, allowing us to make data-driven and\ncomputational claims about the meaning of phenomena such as 'context' that are\ntraditionally discussed only in qualitative terms. Furthermore, our methodology\nprovides a case study in how to use data-science and computational\nmethodologies for understanding the nature of an everyday (yet complex)\npsychological phenomenon that is an essential feature of human intelligence.\n",
		"date": [
			"2020-11-28",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.14084",
		"pdf_url": "http://arxiv.org/pdf/2011.14084.pdf"
	},
	"529": {
		"title": "A comparison of handcrafted, parameterized, and learnable features for\n  speech separation",
		"creator": [
			"Zhu, Wenbo",
			"Wang, Mou",
			"Zhang, Xiao-Lei",
			"Rahardja, Susanto"
		],
		"subject": "Computer Science - Sound",
		"description": "  The design of acoustic features is important for speech separation. It can be\nroughly categorized into three classes: handcrafted, parameterized, and\nlearnable features. Among them, learnable features, which are trained with\nseparation networks jointly in an end-to-end fashion, become a new trend of\nmodern speech separation research, e.g. convolutional time domain audio\nseparation network (Conv-Tasnet), while handcrafted and parameterized features\nare also shown competitive in very recent studies. However, a systematic\ncomparison across the three kinds of acoustic features has not been conducted\nyet. In this paper, we compare them in the framework of Conv-Tasnet by setting\nits encoder and decoder with different acoustic features. We also generalize\nthe handcrafted multi-phase gammatone filterbank (MPGTF) to a new parameterized\nmulti-phase gammatone filterbank (ParaMPGTF). Experimental results on the\nWSJ0-2mix corpus show that (i) if the decoder is learnable, then setting the\nencoder to STFT, MPGTF, ParaMPGTF, and learnable features lead to similar\nperformance; and (ii) when the pseudo-inverse transforms of STFT, MPGTF, and\nParaMPGTF are used as the decoders, the proposed ParaMPGTF performs better than\nthe other two handcrafted features.\n",
		"date": [
			"2020-11-29",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.14295",
		"pdf_url": "http://arxiv.org/pdf/2011.14295.pdf"
	},
	"530": {
		"title": "SoMin.ai: Personality-Driven Content Generation Platform",
		"creator": [
			"Farseev, Aleksandr",
			"Yang, Qi",
			"Filchenkov, Andrey",
			"Lepikhin, Kirill",
			"Chu-Farseeva, Yu-Yi",
			"Loo, Daron-Benjamin"
		],
		"subject": [
			"Computer Science - Multimedia",
			"Computer Science - Information Retrieval",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  In this technical demonstration, we showcase the World's first\npersonality-driven marketing content generation platform, called SoMin.ai. The\nplatform combines deep multi-view personality profiling framework and style\ngenerative adversarial networks facilitating the automatic creation of content\nthat appeals to different human personality types. The platform can be used for\nthe enhancement of the social networking user experience as well as for content\nmarketing routines. Guided by the MBTI personality type, automatically derived\nfrom a user social network content, SoMin.ai generates new social media content\nbased on the preferences of other users with a similar personality type aiming\nat enhancing the user experience on social networking venues as well\ndiversifying the efforts of marketers when crafting new content for digital\nmarketing campaigns. The real-time user feedback to the platform via the\nplatform's GUI fine-tunes the content generation model and the evaluation\nresults demonstrate the promising performance of the proposed multi-view\npersonality profiling framework when being applied in the content generation\nscenario. By leveraging content generation at a large scale, marketers will be\nable to execute more effective digital marketing campaigns at a lower cost.\n",
			"Comment: WSDM 2021 - Demonstration"
		],
		"date": [
			"2020-11-30",
			"2021-01-17"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2011.14615",
			"doi:10.1145/3437963.3441714"
		],
		"pdf_url": "http://arxiv.org/pdf/2011.14615.pdf"
	},
	"531": {
		"title": "Probabilistic Load Forecasting Based on Adaptive Online Learning",
		"creator": [
			"Álvarez, Verónica",
			"Mazuelas, Santiago",
			"Lozano, José A."
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Load forecasting is crucial for multiple energy management tasks such as\nscheduling generation capacity, planning supply and demand, and minimizing\nenergy trade costs. Such relevance has increased even more in recent years due\nto the integration of renewable energies, electric cars, and microgrids.\nConventional load forecasting techniques obtain single-value load forecasts by\nexploiting consumption patterns of past load demand. However, such techniques\ncannot assess intrinsic uncertainties in load demand, and cannot capture\ndynamic changes in consumption patterns. To address these problems, this paper\npresents a method for probabilistic load forecasting based on the adaptive\nonline learning of hidden Markov models. We propose learning and forecasting\ntechniques with theoretical guarantees, and experimentally assess their\nperformance in multiple scenarios. In particular, we develop adaptive online\nlearning techniques that update model parameters recursively, and sequential\nprediction techniques that obtain probabilistic forecasts using the most recent\nparameters. The performance of the method is evaluated using multiple datasets\ncorresponding with regions that have different sizes and display assorted\ntime-varying consumption patterns. The results show that the proposed method\ncan significantly improve the performance of existing techniques for a wide\nrange of scenarios.\n",
			"Comment: \\c{opyright} 2021 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"
		],
		"date": [
			"2020-11-30",
			"2021-01-15"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2011.14721",
			"doi:10.1109/TPWRS.2021.3050837"
		],
		"pdf_url": "http://arxiv.org/pdf/2011.14721.pdf"
	},
	"532": {
		"title": "Minimax Converse for Identification via Channels",
		"creator": "Watanabe, Shun",
		"subject": "Computer Science - Information Theory",
		"description": [
			"  A minimax converse for the identification via channels is derived. By this\nconverse, a general formula for the identification capacity, which coincides\nwith the transmission capacity, is proved without the assumption of the strong\nconverse property. Furthermore, the optimal second-order coding rate of the\nidentification via channels is characterized when the type I error probability\nis non-vanishing and the type II error probability is vanishing. Our converse\nis built upon the so-called partial channel resolvability approach; however,\nthe minimax argument enables us to circumvent a flaw reported in the\nliterature.\n",
			"Comment: 18 pages, no figure"
		],
		"date": [
			"2020-11-30",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.14741",
		"pdf_url": "http://arxiv.org/pdf/2011.14741.pdf"
	},
	"533": {
		"title": "Vertex Sparsification for Edge Connectivity in Polynomial Time",
		"creator": "Liu, Yang P.",
		"subject": "Computer Science - Data Structures and Algorithms",
		"description": [
			"  An important open question in the area of vertex sparsification is whether\n$(1+\\epsilon)$-approximate cut-preserving vertex sparsifiers with size close to\nthe number of terminals exist. The work Chalermsook et al. (SODA 2021)\nintroduced a relaxation called connectivity-$c$ mimicking networks, which asks\nto construct a vertex sparsifier which preserves connectivity among $k$\nterminals exactly up to the value of $c$, and showed applications to dynamic\nconnectivity data structures and survivable network design. We show that\nconnectivity-$c$ mimicking networks with $\\widetilde{O}(kc^3)$ edges exist and\ncan be constructed in polynomial time in $n$ and $c$, improving over the\nresults of Chalermsook et al. (SODA 2021) for any $c \\ge \\log n$, whose\nruntimes depended exponentially on $c$.\n",
			"Comment: 16 pages, changed license"
		],
		"date": [
			"2020-11-30",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2011.15101",
		"pdf_url": "http://arxiv.org/pdf/2011.15101.pdf"
	},
	"534": {
		"title": "Use of Remote Sensing Data to Identify Air Pollution Signatures in India",
		"creator": [
			"KN, Sivaramakrishnan",
			"Deka, Lipika",
			"Gupta, Manik"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computers and Society"
		],
		"description": "  Air quality has major impact on a country's socio-economic position and\nidentifying major air pollution sources is at the heart of tackling the issue.\nSpatially and temporally distributed air quality data acquisition across a\ncountry as varied as India has been a challenge to such analysis. The launch of\nthe Sentinel-5P satellite has helped in the observation of a wider variety of\nair pollutants than measured before at a global scale on a daily basis. In this\nchapter, spatio-temporal multi pollutant data retrieved from Sentinel-5P\nsatellite is used to cluster states as well as districts in India and\nassociated average monthly pollution signature and trends depicted by each of\nthe clusters are derived and presented.The clustering signatures can be used to\nidentify states and districts based on the types of pollutants emitted by\nvarious pollution sources.\n",
		"date": [
			"2020-12-01",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.00402",
		"pdf_url": "http://arxiv.org/pdf/2012.00402.pdf"
	},
	"535": {
		"title": "Distributed Training and Optimization Of Neural Networks",
		"creator": [
			"Vlimant, Jean-Roch",
			"Yin, Junqi"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"High Energy Physics - Experiment"
		],
		"description": [
			"  Deep learning models are yielding increasingly better performances thanks to\nmultiple factors. To be successful, model may have large number of parameters\nor complex architectures and be trained on large dataset. This leads to large\nrequirements on computing resource and turn around time, even more so when\nhyper-parameter optimization is done (e.g search over model architectures).\nWhile this is a challenge that goes beyond particle physics, we review the\nvarious ways to do the necessary computations in parallel, and put it in the\ncontext of high energy physics.\n",
			"Comment: 20 pages, 4 figures, 2 tables, Submitted for review. To appear in\n  \"Artificial Intelligence for Particle Physics\", World Scientific Publishing"
		],
		"date": [
			"2020-12-03",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.01839",
		"pdf_url": "http://arxiv.org/pdf/2012.01839.pdf"
	},
	"536": {
		"title": "Performance Indicators Contributing To Success At The Group And Play-Off\n  Stages Of The 2019 Rugby World Cup",
		"creator": [
			"Bunker, Rory",
			"Spencer, Kirsten"
		],
		"subject": [
			"Statistics - Applications",
			"Computer Science - Machine Learning"
		],
		"description": "  Performance indicators that contributed to success at the group stage and\nplay-off stages of the 2019 Rugby World Cup were analysed using publicly\navailable data obtained from the official tournament website using both a\nnon-parametric statistical technique, Wilcoxon's signed rank test, and a\ndecision rules technique from machine learning called RIPPER. Our statistical\nresults found that ball carry effectiveness (percentage of ball carries that\npenetrated the opposition gain-line) and total metres gained (kick metres plus\ncarry metres) were found to contribute to success at both stages of the\ntournament and that indicators that contributed to success during the group\nstages (dominating possession, making more ball carries, making more passes,\nwinning more rucks, and making less tackles) did not contribute to success at\nthe play-off stage. Our results using RIPPER found that low ball carries and a\nlow lineout success percentage jointly contributed to losing at the group\nstage, while winning a low number of rucks and carrying over the gain-line a\nsufficient number of times contributed to winning at the play-off stage of the\ntournament. The results emphasise the need for teams to adapt their playing\nstrategies from the group stage to the play-off stage at tournament in order to\nbe successful.\n",
		"date": "2020-10-29",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2012.02099",
			"doi:10.14198/jhse.2022.173.18"
		],
		"pdf_url": "http://arxiv.org/pdf/2012.02099.pdf"
	},
	"537": {
		"title": "Rethinking movie genre classification with fine-grained semantic\n  clustering",
		"creator": [
			"Fish, Edward",
			"Weinbren, Jon",
			"Gilbert, Andrew"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Information Retrieval",
			"Computer Science - Machine Learning",
			"Computer Science - Multimedia"
		],
		"description": "  Movie genre classification is an active research area in machine learning.\nHowever, due to the limited labels available, there can be large semantic\nvariations between movies within a single genre definition. We expand these\n'coarse' genre labels by identifying 'fine-grained' semantic information within\nthe multi-modal content of movies. By leveraging pre-trained 'expert' networks,\nwe learn the influence of different combinations of modes for multi-label genre\nclassification. Using a contrastive loss, we continue to fine-tune this\n'coarse' genre classification network to identify high-level intertextual\nsimilarities between the movies across all genre labels. This leads to a more\n'fine-grained' and detailed clustering, based on semantic similarities while\nstill retaining some genre information. Our approach is demonstrated on a newly\nintroduced multi-modal 37,866,450 frame, 8,800 movie trailer dataset,\nMMX-Trailer-20, which includes pre-computed audio, location, motion, and image\nembeddings.\n",
		"date": [
			"2020-12-04",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.02639",
		"pdf_url": "http://arxiv.org/pdf/2012.02639.pdf"
	},
	"538": {
		"title": "ACN-Sim: An Open-Source Simulator for Data-Driven Electric Vehicle\n  Charging Research",
		"creator": [
			"Lee, Zachary J.",
			"Sharma, Sunash",
			"Johansson, Daniel",
			"Low, Steven H."
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  ACN-Sim is a data-driven, open-source simulation environment designed to\naccelerate research in the field of smart electric vehicle (EV) charging. It\nfills the need in this community for a widely available, realistic simulation\nenvironment in which researchers can evaluate algorithms and test assumptions.\nACN-Sim provides a modular, extensible architecture, which models the\ncomplexity of real charging systems, including battery charging behavior and\nunbalanced three-phase infrastructure. It also integrates with a broader\necosystem of research tools. These include ACN-Data, an open dataset of EV\ncharging sessions, which provides realistic simulation scenarios and ACN-Live,\na framework for field-testing charging algorithms. It also integrates with grid\nsimulators like MATPOWER, PandaPower and OpenDSS, and OpenAI Gym for training\nreinforcement learning agents.\n",
			"Comment: 9 pages, 8 figures. [v2] Update timezone issue with Fig. 8 where\n  x-axis and background load was shifted by 3 hours"
		],
		"date": [
			"2020-12-04",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.02809",
		"pdf_url": "http://arxiv.org/pdf/2012.02809.pdf"
	},
	"539": {
		"title": "The Impact of a STEM-based Entrepreneurship Program on the\n  Entrepreneurial Intention of Secondary School Female Students",
		"creator": [
			"Shahin, Mojtaba",
			"Ilic, Olivia",
			"Gonsalvez, Chris",
			"Whittle, Jon"
		],
		"subject": "Computer Science - Computers and Society",
		"description": [
			"  Despite dedicated effort and research in the last two decades, the\nentrepreneurship field is still limited by little evidence-based knowledge of\nthe impacts of entrepreneurship programs on the entrepreneurial intention of\nstudents in pre-university levels of study. Further, gender equity continues to\nbe an issue in the entrepreneurial sector, particularly in STEM-focused\nentrepreneurship. In this context, this study was designed to explore the\neffects of a one-day female-focused STEM-based entrepreneurship program (for\nbrevity, we call it the OzGirlsEntrepreneurship program) on the entrepreneurial\nintention of secondary school female students. The study collected data from\ntwo surveys completed by 193 secondary school female students, aged 14-16\nyears, who participated in the OzGirlsEntrepreneurship program. This program\nencouraged girls to develop and implement creative computational solutions to\nsocially relevant problems, with an Internet of Things (IoT) component using\nthe micro:bit device. The findings reveal that a key factor in the development\nof entrepreneurial attitudes in young female students is associated with\nsoft-skills development, particularly in the areas of creative thinking,\nrisk-taking, problem-solving, and leadership development. The importance of\nmeaningful human connections, including positive role modelling and peer to\npeer learning were also important factors in fostering entrepreneurial intent.\nWith these factors in mind, our findings highlight that the\nOzGirlsEntrepreneurship program substantially increased the entrepreneurial\nintention of secondary school female students. In addition, this study offers\nactionable implications and recommendations to develop and deliver\nentrepreneurship education programs for secondary school level students.\n",
			"Comment: 20 Pages, Accepted to appear in International Entrepreneurship and\n  Management Journal (IEMJ), Springer, 2020"
		],
		"date": [
			"2020-12-04",
			"2021-01-16"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2012.03746",
			"International Entrepreneurship and Management Journal (2021)",
			"doi:10.1007/s11365-020-00713-7"
		],
		"pdf_url": "http://arxiv.org/pdf/2012.03746.pdf"
	},
	"540": {
		"title": "Virtual-Link: A Scalable Multi-Producer, Multi-Consumer Message Queue\n  Architecture for Cross-Core Communication",
		"creator": [
			"Wu, Qinzhe",
			"Beard, Jonathan",
			"Ekanayake, Ashen",
			"Gerstlauer, Andreas",
			"John, Lizy K."
		],
		"subject": "Computer Science - Hardware Architecture",
		"description": "  Cross-core communication is increasingly a bottleneck as the number of\nprocessing elements increase per system-on-chip. Typical hardware solutions to\ncross-core communication are often inflexible; while software solutions are\nflexible, they have performance scaling limitations. A key problem, as we will\nshow, is that of shared state in software-based message queue mechanisms. This\npaper proposes Virtual-Link (VL), a novel light-weight communication mechanism\nwith hardware support to facilitate M:N lock-free data movement. VL reduces the\namount of coherent shared state, which is a bottleneck for many approaches, to\nzero. VL provides further latency benefit by keeping data on the fast path\n(i.e., within the on-chip interconnect). VL enables directed cache-injection\n(stashing) between PEs on the coherence bus, reducing the latency for\ncore-to-core communication. VL is particularly effective for fine-grain tasks\non streaming data. Evaluation on a full system simulator with 7 benchmarks\nshows that VL achieves a 2.09x speedup over state-of-the-art software-based\ncommunication mechanisms, while reducing memory traffic by 61%.\n",
		"date": [
			"2020-12-09",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.05181",
		"pdf_url": "http://arxiv.org/pdf/2012.05181.pdf"
	},
	"541": {
		"title": "Visual Perception Generalization for Vision-and-Language Navigation via\n  Meta-Learning",
		"creator": [
			"Wang, Ting",
			"Wu, Zongkai",
			"Wang, Donglin"
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Vision-and-language navigation (VLN) is a challenging task that requires an\nagent to navigate in real-world environments by understanding natural language\ninstructions and visual information received in real-time. Prior works have\nimplemented VLN tasks on continuous environments or physical robots, all of\nwhich use a fixed camera configuration due to the limitations of datasets, such\nas 1.5 meters height, 90 degrees horizontal field of view (HFOV), etc. However,\nreal-life robots with different purposes have multiple camera configurations,\nand the huge gap in visual information makes it difficult to directly transfer\nthe learned navigation model between various robots. In this paper, we propose\na visual perception generalization strategy based on meta-learning, which\nenables the agent to fast adapt to a new camera configuration with a few shots.\nIn the training phase, we first locate the generalization problem to the visual\nperception module, and then compare two meta-learning algorithms for better\ngeneralization in seen and unseen environments. One of them uses the\nModel-Agnostic Meta-Learning (MAML) algorithm that requires a few shot\nadaptation, and the other refers to a metric-based meta-learning method with a\nfeature-wise affine transformation layer. The experiment results show that our\nstrategy successfully adapts the learned navigation model to a new camera\nconfiguration, and the two algorithms show their advantages in seen and unseen\nenvironments respectively.\n",
			"Comment: 8 pages, 4 figures, preprinted version"
		],
		"date": [
			"2020-12-09",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.05446",
		"pdf_url": "http://arxiv.org/pdf/2012.05446.pdf"
	},
	"542": {
		"title": "Imitating Interactive Intelligence",
		"creator": [
			"Abramson, Josh",
			"Ahuja, Arun",
			"Barr, Iain",
			"Brussee, Arthur",
			"Carnevale, Federico",
			"Cassin, Mary",
			"Chhaparia, Rachita",
			"Clark, Stephen",
			"Damoc, Bogdan",
			"Dudzik, Andrew",
			"Georgiev, Petko",
			"Guy, Aurelia",
			"Harley, Tim",
			"Hill, Felix",
			"Hung, Alden",
			"Kenton, Zachary",
			"Landon, Jessica",
			"Lillicrap, Timothy",
			"Mathewson, Kory",
			"Mokrá, Soňa",
			"Muldal, Alistair",
			"Santoro, Adam",
			"Savinov, Nikolay",
			"Varma, Vikrant",
			"Wayne, Greg",
			"Williams, Duncan",
			"Wong, Nathaniel",
			"Yan, Chen",
			"Zhu, Rui"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Multiagent Systems"
		],
		"description": "  A common vision from science fiction is that robots will one day inhabit our\nphysical spaces, sense the world as we do, assist our physical labours, and\ncommunicate with us through natural language. Here we study how to design\nartificial agents that can interact naturally with humans using the\nsimplification of a virtual environment. This setting nevertheless integrates a\nnumber of the central challenges of artificial intelligence (AI) research:\ncomplex visual perception and goal-directed physical control, grounded language\ncomprehension and production, and multi-agent social interaction. To build\nagents that can robustly interact with humans, we would ideally train them\nwhile they interact with humans. However, this is presently impractical.\nTherefore, we approximate the role of the human with another learned agent, and\nuse ideas from inverse reinforcement learning to reduce the disparities between\nhuman-human and agent-agent interactive behaviour. Rigorously evaluating our\nagents poses a great challenge, so we develop a variety of behavioural tests,\nincluding evaluation by humans who watch videos of agents or interact directly\nwith them. These evaluations convincingly demonstrate that interactive training\nand auxiliary losses improve agent behaviour beyond what is achieved by\nsupervised learning of actions alone. Further, we demonstrate that agent\ncapabilities generalise beyond literal experiences in the dataset. Finally, we\ntrain evaluation models whose ratings of agents agree well with human\njudgement, thus permitting the evaluation of new agent models without\nadditional effort. Taken together, our results in this virtual environment\nprovide evidence that large-scale human behavioural imitation is a promising\ntool to create intelligent, interactive agents, and the challenge of reliably\nevaluating such agents is possible to surmount.\n",
		"date": [
			"2020-12-10",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.05672",
		"pdf_url": "http://arxiv.org/pdf/2012.05672.pdf"
	},
	"543": {
		"title": "Sylvester Matrix Based Similarity Estimation Method for Automation of\n  Defect Detection in Textile Fabrics",
		"creator": [
			"Kumari, R. M. L. N.",
			"Bandara, G. A. C. T.",
			"Dissanayake, Maheshi B."
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": [
			"  Fabric defect detection is a crucial quality control step in the textile\nmanufacturing industry. In this article, machine vision system based on the\nSylvester Matrix Based Similarity Method (SMBSM) is proposed to automate the\ndefect detection process. The algorithm involves six phases, namely resolution\nmatching, image enhancement using Histogram Specification and Median-Mean Based\nSub-Image-Clipped Histogram Equalization, image registration through alignment\nand hysteresis process, image subtraction, edge detection, and fault detection\nby means of the rank of the Sylvester matrix. The experimental results\ndemonstrate that the proposed method is robust and yields an accuracy of 93.4%,\nprecision of 95.8%, with 2275 ms computational speed.\n",
			"Comment: Journal of Sensors, Hindawi"
		],
		"date": "2020-12-08",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2012.05800",
			"Journal of Sensors,Volume 2021, Article ID 6625421",
			"doi:10.1155/2021/6625421"
		],
		"pdf_url": "http://arxiv.org/pdf/2012.05800.pdf"
	},
	"544": {
		"title": "Exploring wav2vec 2.0 on speaker verification and language\n  identification",
		"creator": [
			"Fan, Zhiyun",
			"Li, Meng",
			"Zhou, Shiyu",
			"Xu, Bo"
		],
		"subject": [
			"Computer Science - Sound",
			"Computer Science - Computation and Language",
			"Electrical Engineering and Systems Science - Audio and Speech Processing"
		],
		"description": [
			"  Wav2vec 2.0 is a recently proposed self-supervised framework for speech\nrepresentation learning. It follows a two-stage training process of\npre-training and fine-tuning, and performs well in speech recognition tasks\nespecially ultra-low resource cases. In this work, we attempt to extend\nself-supervised framework to speaker verification and language identification.\nFirst, we use some preliminary experiments to indicate that wav2vec 2.0 can\ncapture the information about the speaker and language. Then we demonstrate the\neffectiveness of wav2vec 2.0 on the two tasks respectively. For speaker\nverification, we obtain a new state-of-the-art result, Equal Error Rate (EER)\nof 3.61% on the VoxCeleb1 dataset. For language identification, we obtain an\nEER of 12.02% on 1 second condition and an EER of 3.47% on full-length\ncondition of the AP17-OLR dataset. Finally, we utilize one model to achieve the\nunified modeling by the multi-task learning for the two tasks.\n",
			"Comment: Self-supervised, speaker verification, language identification,\n  multi-task learning, wav2vec 2.0"
		],
		"date": [
			"2020-12-11",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.06185",
		"pdf_url": "http://arxiv.org/pdf/2012.06185.pdf"
	},
	"545": {
		"title": "Risk & returns around FOMC press conferences: a novel perspective from\n  computer vision",
		"creator": "Marchal, Alexis",
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"Quantitative Finance - General Finance"
		],
		"description": [
			"  I propose a new tool to characterize the resolution of uncertainty around\nFOMC press conferences. It relies on the construction of a measure capturing\nthe level of discussion complexity between the Fed Chair and reporters during\nthe Q&A sessions. I show that complex discussions are associated with higher\nequity returns and a drop in realized volatility. The method creates an\nattention score by quantifying how much the Chair needs to rely on reading\ninternal documents to be able to answer a question. This is accomplished by\nbuilding a novel dataset of video images of the press conferences and\nleveraging recent deep learning algorithms from computer vision. This\nalternative data provides new information on nonverbal communication that\ncannot be extracted from the widely analyzed FOMC transcripts. This paper can\nbe seen as a proof of concept that certain videos contain valuable information\nfor the study of financial markets.\n",
			"Comment: 20 pages"
		],
		"date": [
			"2020-12-11",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.06573",
		"pdf_url": "http://arxiv.org/pdf/2012.06573.pdf"
	},
	"546": {
		"title": "One-Shot Learning with Triplet Loss for Vegetation Classification Tasks",
		"creator": [
			"Uzhinskiy, Alexander",
			"Ososkov, Gennady",
			"Goncharov, Pavel",
			"Nechaevskiy, Andrey",
			"Smetanin, Artem"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Triplet loss function is one of the options that can significantly improve\nthe accuracy of the One-shot Learning tasks. Starting from 2015, many projects\nuse Siamese networks and this kind of loss for face recognition and object\nclassification. In our research, we focused on two tasks related to vegetation.\nThe first one is plant disease detection on 25 classes of five crops (grape,\ncotton, wheat, cucumbers, and corn). This task is motivated because harvest\nlosses due to diseases is a serious problem for both large farming structures\nand rural families. The second task is the identification of moss species (5\nclasses). Mosses are natural bioaccumulators of pollutants; therefore, they are\nused in environmental monitoring programs. The identification of moss species\nis an important step in the sample preprocessing. In both tasks, we used\nself-collected image databases. We tried several deep learning architectures\nand approaches. Our Siamese network architecture with a triplet loss function\nand MobileNetV2 as a base network showed the most impressive results in both\nabove-mentioned tasks. The average accuracy for plant disease detection\namounted to over 97.8% and 97.6% for moss species classification.\n",
		"date": [
			"2020-12-14",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.07403",
		"pdf_url": "http://arxiv.org/pdf/2012.07403.pdf"
	},
	"547": {
		"title": "Synchronous LoRa Communication by Exploiting Large-Area Out-of-Band\n  Synchronization",
		"creator": [
			"Beltramelli, Luca",
			"Mahmood, Aamir",
			"Ferrari, Paolo",
			"Österberg, Patrik",
			"Gidlund, Mikael",
			"Sisinni, Emiliano"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  Many new narrowband low-power wide-area networks (LPWANs) (e.g., LoRaWAN,\nSigfox) have opted to use pure ALOHA-like access for its reduced control\noverhead and asynchronous transmissions. Although asynchronous access reduces\nthe energy consumption of IoT devices, the network performance suffers from\nhigh intra-network interference in dense deployments. Contrarily, synchronous\naccess can improve throughput and fairness, but it requires time\nsynchronization. Unfortunately, maintaining synchronization over the narrowband\nLPWANs wastes channel time and transmission opportunities. In this paper, we\npropose the use of out-of-band time-dissemination to relatively synchronize\nLoRa devices and thereby facilitate resource-efficient slotted uplink\ncommunication. To this end, we conceptualize and analyze a co-designed\nsynchronization and random access mechanism that can effectively exploit\ntechnologies providing limited time accuracy, such as FM radio data system\n(FM-RDS). While considering the LoRa-specific parameters, we derive the\nthroughput of the proposed mechanism, compare it to a generic synchronous\nrandom access using in-band synchronization, and design the communication\nparameters under time uncertainty. We scrutinize the transmission time\nuncertainty of a device by introducing a clock error model that accounts for\nthe errors in the synchronization source, local clock, propagation delay, and\ntransceiver's transmission time uncertainty. We characterize the time\nuncertainty of FM-RDS with hardware measurements and perform simulations to\nevaluate the proposed solution. The results, presented in terms of success\nprobability, throughput, and fairness for a single-cell scenario, suggest that\nFM-RDS, despite its poor absolute synchronization, can be used effectively to\nrealize slotted LoRa communication with performance similar to that of more\naccurate time-dissemination technologies.\n",
			"Comment: 12 pages, 8 figures, final version to appear in IEEE Internet of\n  Things Journal"
		],
		"date": "2020-12-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2012.07480",
			"doi:10.1109/JIOT.2020.3041818"
		],
		"pdf_url": "http://arxiv.org/pdf/2012.07480.pdf"
	},
	"548": {
		"title": "Energy efficiency of slotted LoRaWAN communication with out-of-band\n  synchronization",
		"creator": [
			"Beltramelli, Luca",
			"Mahmood, Aamir",
			"Österberg, Patrik",
			"Gidlund, Mikael",
			"Ferrari, Paolo",
			"Sisinni, Emiliano"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  Although the idea of using wireless links for covering large areas is not\nnew, the advent of LPWANs has recently started changing the game. Simple,\nrobust, narrowband modulation schemes permit the implementation of low-cost\nradio devices offering high receiver sensitivity, thus improving the overall\nlink budget. The several technologies belonging to the LPWAN family, including\nthe well-known LoRaWAN solution, provide a cost-effective answer to many\nInternet-of-things (IoT) applications, requiring wireless communication capable\nof supporting large networks of many devices (e.g., smart metering). Generally,\nthe adopted MAC strategy is based on pure ALOHA, which, among other things,\nallows to minimize the traffic overhead under constrained duty cycle\nlimitations of the unlicensed bands. Unfortunately, ALOHA suffers from poor\nscalability, rapidly collapsing in dense networks. This work investigates the\ndesign of an improved LoRaWAN MAC scheme based on slotted ALOHA. In particular,\nthe required time dissemination is provided by out-of-band communications\nleveraging on FM-RDS broadcasting. An experimental setup based on low-cost\nhardware is used to characterize the obtainable synchronization performance and\nderive a timing error model. Consequently, improvements in success probability\nand energy efficiency have been validated by means of simulations in very large\nnetworks with up to 10000 nodes. It is shown that the advantage of the proposed\nscheme over conventional LoRaWAN communication is up to 100% when short update\ntime and large payload are required. Similar results are obtained regarding the\nenergy efficiency improvement, which is close to 100% for relatively short\ntransmission intervals and long message duration; however, due to the\nadditional overhead for listening to the time dissemination messages,\nefficiency gain can be negative for short-duration messages fastly repeating.\n",
			"Comment: 11 pages, 7 figures, 2 tables, to appear in IEEE Transactions on\n  Instrumentation and Measurement"
		],
		"date": "2020-12-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2012.07579",
			"doi:10.1109/TIM.2021.3051238"
		],
		"pdf_url": "http://arxiv.org/pdf/2012.07579.pdf"
	},
	"549": {
		"title": "Policy Gradient RL Algorithms as Directed Acyclic Graphs",
		"creator": "Luis, Juan Jose Garau",
		"subject": "Computer Science - Machine Learning",
		"description": "  Meta Reinforcement Learning (RL) methods focus on automating the design of RL\nalgorithms that generalize to a wide range of environments. The framework\nintroduced in (Anonymous, 2020) addresses the problem by representing different\nRL algorithms as Directed Acyclic Graphs (DAGs), and using an evolutionary meta\nlearner to modify these graphs and find good agent update rules. While the\nsearch language used to generate graphs in the paper serves to represent\nnumerous already-existing RL algorithms (e.g., DQN, DDQN), it has limitations\nwhen it comes to representing Policy Gradient algorithms. In this work we try\nto close this gap by extending the original search language and proposing\ngraphs for five different Policy Gradient algorithms: VPG, PPO, DDPG, TD3, and\nSAC.\n",
		"date": [
			"2020-12-14",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.07763",
		"pdf_url": "http://arxiv.org/pdf/2012.07763.pdf"
	},
	"550": {
		"title": "Noisy Linear Convergence of Stochastic Gradient Descent for CV@R\n  Statistical Learning under Polyak-{\\L}ojasiewicz Conditions",
		"creator": "Kalogerias, Dionysios S.",
		"subject": [
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Signal Processing",
			"Electrical Engineering and Systems Science - Systems and Control",
			"Mathematics - Optimization and Control",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Conditional Value-at-Risk ($\\mathrm{CV@R}$) is one of the most popular\nmeasures of risk, which has been recently considered as a performance criterion\nin supervised statistical learning, as it is related to desirable operational\nfeatures in modern applications, such as safety, fairness, distributional\nrobustness, and prediction error stability. However, due to its variational\ndefinition, $\\mathrm{CV@R}$ is commonly believed to result in difficult\noptimization problems, even for smooth and strongly convex loss functions. We\ndisprove this statement by establishing noisy (i.e., fixed-accuracy) linear\nconvergence of stochastic gradient descent for sequential $\\mathrm{CV@R}$\nlearning, for a large class of not necessarily strongly-convex (or even convex)\nloss functions satisfying a set-restricted Polyak-Lojasiewicz inequality. This\nclass contains all smooth and strongly convex losses, confirming that classical\nproblems, such as linear least squares regression, can be solved efficiently\nunder the $\\mathrm{CV@R}$ criterion, just as their risk-neutral versions. Our\nresults are illustrated numerically on such a risk-aware ridge regression task,\nalso verifying their validity in practice.\n",
			"Comment: 17 pages, 2 figures. From v2 onwards: Significant updates to the\n  technical content, fixed some errors/nonsense in the results and their proofs"
		],
		"date": [
			"2020-12-14",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.07785",
		"pdf_url": "http://arxiv.org/pdf/2012.07785.pdf"
	},
	"551": {
		"title": "Friedrichs Learning: Weak Solutions of Partial Differential Equations\n  via Deep Learning",
		"creator": [
			"Chen, Fan",
			"Huang, Jianguo",
			"Wang, Chunmei",
			"Yang, Haizhao"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"Computer Science - Machine Learning"
		],
		"description": "  This paper proposes Friedrichs learning as a novel deep learning methodology\nthat can learn the weak solutions of PDEs via a minmax formulation, which\ntransforms the PDE problem into a minimax optimization problem to identify weak\nsolutions. The name \"Friedrichs learning\" is for highlighting the close\nrelationship between our learning strategy and Friedrichs theory on symmetric\nsystems of PDEs. The weak solution and the test function in the weak\nformulation are parameterized as deep neural networks in a mesh-free manner,\nwhich are alternately updated to approach the optimal solution networks\napproximating the weak solution and the optimal test function, respectively.\nExtensive numerical results indicate that our mesh-free method can provide\nreasonably good solutions to a wide range of PDEs defined on regular and\nirregular domains in various dimensions, where classical numerical methods such\nas finite difference methods and finite element methods may be tedious or\ndifficult to be applied.\n",
		"date": [
			"2020-12-14",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.08023",
		"pdf_url": "http://arxiv.org/pdf/2012.08023.pdf"
	},
	"552": {
		"title": "Neural Collapse with Cross-Entropy Loss",
		"creator": [
			"Lu, Jianfeng",
			"Steinerberger, Stefan"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Mathematics - Classical Analysis and ODEs"
		],
		"description": "  We consider the variational problem of cross-entropy loss with $n$ feature\nvectors on a unit hypersphere in $\\mathbb{R}^d$. We prove that when $d \\geq n -\n1$, the global minimum is given by the simplex equiangular tight frame, which\njustifies the neural collapse behavior. We also prove that as $n \\rightarrow\n\\infty$ with fixed $d$, the minimizing points will distribute uniformly on the\nhypersphere and show a connection with the frame potential of Benedetto &\nFickus.\n",
		"date": [
			"2020-12-15",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.08465",
		"pdf_url": "http://arxiv.org/pdf/2012.08465.pdf"
	},
	"553": {
		"title": "A novel Two-Factor HoneyToken Authentication Mechanism",
		"creator": [
			"Papaspirou, Vassilis",
			"Maglaras, Leandros",
			"Ferrag, Mohamed Amine",
			"Kantzavelou, Ioanna",
			"Janicke, Helge",
			"Douligeris, Christos"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": [
			"  The majority of systems rely on user authentication on passwords, but\npasswords have so many weaknesses and widespread use that easily raise\nsignificant security concerns, regardless of their encrypted form. Users hold\nthe same password for different accounts, administrators never check password\nfiles for flaws that might lead to a successful cracking, and the lack of a\ntight security policy regarding regular password replacement are a few problems\nthat need to be addressed. The proposed research work aims at enhancing this\nsecurity mechanism, prevent penetrations, password theft, and attempted\nbreak-ins towards securing computing systems. The selected solution approach is\ntwo-folded; it implements a two-factor authentication scheme to prevent\nunauthorized access, accompanied by Honeyword principles to detect corrupted or\nstolen tokens. Both can be integrated into any platform or web application with\nthe use of QR codes and a mobile phone.\n",
			"Comment: 7 pages, 6 figures"
		],
		"date": [
			"2020-12-16",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.08782",
		"pdf_url": "http://arxiv.org/pdf/2012.08782.pdf"
	},
	"554": {
		"title": "Multilingual Evidence Retrieval and Fact Verification to Combat Global\n  Disinformation: The Power of Polyglotism",
		"creator": "Roberts, Denisa A. O.",
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Information Retrieval",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  This article investigates multilingual evidence retrieval and fact\nverification as a step to combat global disinformation, a first effort of this\nkind, to the best of our knowledge. The goal is building multilingual systems\nthat retrieve in evidence-rich languages to verify claims in evidence-poor\nlanguages that are more commonly targeted by disinformation. To this end, our\nEnmBERT fact verification system shows evidence of transfer learning ability\nand 400 example mixed English-Romanian dataset is made available for\ncross-lingual transfer learning evaluation.\n",
			"Comment: Accepted ECIR 2021"
		],
		"date": [
			"2020-12-16",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.08919",
		"pdf_url": "http://arxiv.org/pdf/2012.08919.pdf"
	},
	"555": {
		"title": "DAG-based Scheduling with Resource Sharing for Multi-task Applications\n  in a Polyglot GPU Runtime",
		"creator": [
			"Parravicini, Alberto",
			"Delamare, Arnaud",
			"Arnaboldi, Marco",
			"Santambrogio, Marco D."
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Hardware Architecture"
		],
		"description": [
			"  GPUs are readily available in cloud computing and personal devices, but their\nuse for data processing acceleration has been slowed down by their limited\nintegration with common programming languages such as Python or Java. Moreover,\nusing GPUs to their full capabilities requires expert knowledge of asynchronous\nprogramming. In this work, we present a novel GPU run time scheduler for\nmulti-task GPU computations that transparently provides asynchronous execution,\nspace-sharing, and transfer-computation overlap without requiring in advance\nany information about the program dependency structure. We leverage the GrCUDA\npolyglot API to integrate our scheduler with multiple high-level languages and\nprovide a platform for fast prototyping and easy GPU acceleration. We validate\nour work on 6 benchmarks created to evaluate task-parallelism and show an\naverage of 44% speedup against synchronous execution, with no execution time\nslowdown compared to hand-optimized host code written using the C++ CUDA Graphs\nAPI.\n",
			"Comment: 10 pages, to be published in 2021 IEEE International Parallel and\n  Distributed Processing Symposium (IPDPS)"
		],
		"date": [
			"2020-12-17",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.09646",
		"pdf_url": "http://arxiv.org/pdf/2012.09646.pdf"
	},
	"556": {
		"title": "Social Distancing and the Internet: What Can Network Performance\n  Measurements Tell Us?",
		"creator": [
			"Moreira, Jessica De Oliveira",
			"Pasarkar, Amey Praveen",
			"Chen, Wenjun",
			"Hu, Wenkai",
			"Janak, Jan",
			"Schulzrinne, Henning"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": [
			"  The COVID-19 pandemic and related restrictions forced many to work, learn,\nand socialize from home over the internet. There appears to be consensus that\ninternet infrastructure in the developed world handled the resulting traffic\nsurge well. In this paper, we study network measurement data collected by the\nFederal Communications Commission's Measuring Broadband America program before\nand during the pandemic in the United States (US). We analyze the data to\nunderstand the impact of lockdown orders on the performance of fixed broadband\ninternet infrastructure across the US, and also attempt to correlate internet\nusage patterns with the changing behavior of users during lockdown. We found\nthe key metrics such as change in data usage to be generally consistent with\nthe literature. Through additional analysis, we found differences between metro\nand rural areas, changes in weekday, weekend, and hourly internet usage\npatterns, and indications of network congestion for some users.\n",
			"Comment: 12 pages, submitted to TPRC48"
		],
		"date": [
			"2020-12-17",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.09850",
		"pdf_url": "http://arxiv.org/pdf/2012.09850.pdf"
	},
	"557": {
		"title": "RAICC: Revealing Atypical Inter-Component Communication in Android Apps",
		"creator": [
			"Samhi, Jordan",
			"Bartel, Alexandre",
			"Bissyandé, Tegawendé F.",
			"Klein, Jacques"
		],
		"subject": "Computer Science - Software Engineering",
		"description": [
			"  Inter-Component Communication (ICC) is a key mechanism in Android. It enables\ndevelopers to compose rich functionalities and explore reuse within and across\napps. Unfortunately, as reported by a large body of literature, ICC is rather\n\"complex and largely unconstrained\", leaving room to a lack of precision in\napps modeling. To address the challenge of tracking ICCs within apps, state of\nthe art static approaches such as Epicc, IccTA and Amandroid have focused on\nthe documented framework ICC methods (e.g., startActivity) to build their\napproaches. In this work we show that ICC models inferred in these state of the\nart tools may actually be incomplete: the framework provides other atypical\nways of performing ICCs. To address this limitation in the state of the art, we\npropose RAICC a static approach for modeling new ICC links and thus boosting\nprevious analysis tasks such as ICC vulnerability detection, privacy leaks\ndetection, malware detection, etc. We have evaluated RAICC on 20 benchmark\napps, demonstrating that it improves the precision and recall of uncovered\nleaks in state of the art tools. We have also performed a large empirical\ninvestigation showing that Atypical ICC methods are largely used in Android\napps, although not necessarily for data transfer. We also show that RAICC\nincreases the number of ICC links found by 61.6% on a dataset of real-world\nmalicious apps, and that RAICC enables the detection of new ICC\nvulnerabilities.\n",
			"Comment: In the proceedings of the 43rd International Conference on Software\n  Engineering 2021 (ICSE 2021)"
		],
		"date": [
			"2020-12-17",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.09916",
		"pdf_url": "http://arxiv.org/pdf/2012.09916.pdf"
	},
	"558": {
		"title": "Representation-Free Model Predictive Control for Dynamic Motions in\n  Quadrupeds",
		"creator": [
			"Ding, Yanran",
			"Pandala, Abhishek",
			"Li, Chuanzheng",
			"Shin, Young-Ha",
			"Park, Hae-Won"
		],
		"subject": "Computer Science - Robotics",
		"description": "  This paper presents a novel Representation-Free Model Predictive Control\n(RF-MPC) framework for controlling various dynamic motions of a quadrupedal\nrobot in three dimensional (3D) space. Our formulation directly represents the\nrotational dynamics using the rotation matrix, which liberates us from the\nissues associated with the use of Euler angles and quaternion as the\norientation representations. With a variation-based linearization scheme and a\ncarefully constructed cost function, the MPC control law is transcribed to the\nstandard Quadratic Program (QP) form. The MPC controller can operate at\nreal-time rates of 250 Hz on a quadruped robot. Experimental results including\nperiodic quadrupedal gaits and a controlled backflip validate that our control\nstrategy could stabilize dynamic motions that involve singularity in 3D\nmaneuvers.\n",
		"date": "2020-12-17",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2012.10002",
			"IEEE Transactions on Robotics (T-RO), 2021",
			"doi:10.1109/TRO.2020.3046415"
		],
		"pdf_url": "http://arxiv.org/pdf/2012.10002.pdf"
	},
	"559": {
		"title": "Classification with Strategically Withheld Data",
		"creator": [
			"Krishnaswamy, Anilesh K.",
			"Li, Haoming",
			"Rein, David",
			"Zhang, Hanrui",
			"Conitzer, Vincent"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Science and Game Theory"
		],
		"description": "  Machine learning techniques can be useful in applications such as credit\napproval and college admission. However, to be classified more favorably in\nsuch contexts, an agent may decide to strategically withhold some of her\nfeatures, such as bad test scores. This is a missing data problem with a twist:\nwhich data is missing {\\em depends on the chosen classifier}, because the\nspecific classifier is what may create the incentive to withhold certain\nfeature values. We address the problem of training classifiers that are robust\nto this behavior.\n  We design three classification methods: {\\sc Mincut}, {\\sc Hill-Climbing}\n({\\sc HC}) and Incentive-Compatible Logistic Regression ({\\sc IC-LR}). We show\nthat {\\sc Mincut} is optimal when the true distribution of data is fully known.\nHowever, it can produce complex decision boundaries, and hence be prone to\noverfitting in some cases. Based on a characterization of truthful classifiers\n(i.e., those that give no incentive to strategically hide features), we devise\na simpler alternative called {\\sc HC} which consists of a hierarchical ensemble\nof out-of-the-box classifiers, trained using a specialized hill-climbing\nprocedure which we show to be convergent. For several reasons, {\\sc Mincut} and\n{\\sc HC} are not effective in utilizing a large number of complementarily\ninformative features. To this end, we present {\\sc IC-LR}, a modification of\nLogistic Regression that removes the incentive to strategically drop features.\nWe also show that our algorithms perform well in experiments on real-world data\nsets, and present insights into their relative performance in different\nsettings.\n",
		"date": [
			"2020-12-18",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.10203",
		"pdf_url": "http://arxiv.org/pdf/2012.10203.pdf"
	},
	"560": {
		"title": "A closed form scale bound for the $(\\epsilon, \\delta)$-differentially\n  private Gaussian Mechanism valid for all privacy regimes",
		"creator": "Vinterbo, Staal A.",
		"subject": [
			"Computer Science - Cryptography and Security",
			"Statistics - Machine Learning"
		],
		"description": [
			"  The standard closed form lower bound on $\\sigma$ for providing $(\\epsilon,\n\\delta)$-differential privacy by adding zero mean Gaussian noise with variance\n$\\sigma^2$ is $\\sigma > \\Delta\\sqrt {2}(\\epsilon^{-1}) \\sqrt {\\log \\left(\n5/4\\delta^{-1} \\right)}$ for $\\epsilon \\in (0,1)$. We present a similar closed\nform bound $\\sigma \\geq \\Delta (\\epsilon\\sqrt{2})^{-1} \\left(\\sqrt{az+\\epsilon}\n+ s\\sqrt{az}\\right)$ for $z=-\\log(4\\delta(1-\\delta))$ and $(a,s)=(1,1)$ if\n$\\delta \\leq 1/2$ and $(a,s)=(\\pi/4,-1)$ otherwise. Our bound is valid for all\n$\\epsilon > 0$ and is always lower (better). We also present a sufficient\ncondition for $(\\epsilon, \\delta)$-differential privacy when adding noise\ndistributed according to even and log-concave densities supported everywhere.\n",
			"Comment: 11 pages. Version 2 improves on the bound"
		],
		"date": [
			"2020-12-18",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.10523",
		"pdf_url": "http://arxiv.org/pdf/2012.10523.pdf"
	},
	"561": {
		"title": "A Graph Reasoning Network for Multi-turn Response Selection via\n  Customized Pre-training",
		"creator": [
			"Liu, Yongkang",
			"Feng, Shi",
			"Wang, Daling",
			"Song, Kaisong",
			"Ren, Feiliang",
			"Zhang, Yifei"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  We investigate response selection for multi-turn conversation in\nretrieval-based chatbots. Existing studies pay more attention to the matching\nbetween utterances and responses by calculating the matching score based on\nlearned features, leading to insufficient model reasoning ability. In this\npaper, we propose a graph-reasoning network (GRN) to address the problem. GRN\nfirst conducts pre-training based on ALBERT using next utterance prediction and\nutterance order prediction tasks specifically devised for response selection.\nThese two customized pre-training tasks can endow our model with the ability of\ncapturing semantical and chronological dependency between utterances. We then\nfine-tune the model on an integrated network with sequence reasoning and graph\nreasoning structures. The sequence reasoning module conducts inference based on\nthe highly summarized context vector of utterance-response pairs from the\nglobal perspective. The graph reasoning module conducts the reasoning on the\nutterance-level graph neural network from the local perspective. Experiments on\ntwo conversational reasoning datasets show that our model can dramatically\noutperform the strong baseline methods and can achieve performance which is\nclose to human-level.\n",
			"Comment: Accepted by AAAI 2021;10 pages,6 figures"
		],
		"date": [
			"2020-12-20",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.11099",
		"pdf_url": "http://arxiv.org/pdf/2012.11099.pdf"
	},
	"562": {
		"title": "Self-Supervised Learning for Visual Summary Identification in Scientific\n  Publications",
		"creator": [
			"Yamamoto, Shintaro",
			"Lauscher, Anne",
			"Ponzetto, Simone Paolo",
			"Glavaš, Goran",
			"Morishima, Shigeo"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Computation and Language"
		],
		"description": "  Providing visual summaries of scientific publications can increase\ninformation access for readers and thereby help deal with the exponential\ngrowth in the number of scientific publications. Nonetheless, efforts in\nproviding visual publication summaries have been few and far apart, primarily\nfocusing on the biomedical domain. This is primarily because of the limited\navailability of annotated gold standards, which hampers the application of\nrobust and high-performing supervised learning techniques. To address these\nproblems we create a new benchmark dataset for selecting figures to serve as\nvisual summaries of publications based on their abstracts, covering several\ndomains in computer science. Moreover, we develop a self-supervised learning\napproach, based on heuristic matching of inline references to figures with\nfigure captions. Experiments in both biomedical and computer science domains\nshow that our model is able to outperform the state of the art despite being\nself-supervised and therefore not relying on any annotated training data.\n",
		"date": [
			"2020-12-21",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.11213",
		"pdf_url": "http://arxiv.org/pdf/2012.11213.pdf"
	},
	"563": {
		"title": "FedeRank: User Controlled Feedback with Federated Recommender Systems",
		"creator": [
			"Anelli, Vito Walter",
			"Deldjoo, Yashar",
			"Di Noia, Tommaso",
			"Ferrara, Antonio",
			"Narducci, Fedelucio"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Recommender systems have shown to be a successful representative of how data\navailability can ease our everyday digital life. However, data privacy is one\nof the most prominent concerns in the digital era. After several data breaches\nand privacy scandals, the users are now worried about sharing their data. In\nthe last decade, Federated Learning has emerged as a new privacy-preserving\ndistributed machine learning paradigm. It works by processing data on the user\ndevice without collecting data in a central repository. We present FedeRank\n(https://split.to/federank), a federated recommendation algorithm. The system\nlearns a personal factorization model onto every device. The training of the\nmodel is a synchronous process between the central server and the federated\nclients. FedeRank takes care of computing recommendations in a distributed\nfashion and allows users to control the portion of data they want to share. By\ncomparing with state-of-the-art algorithms, extensive experiments show the\neffectiveness of FedeRank in terms of recommendation accuracy, even with a\nsmall portion of shared user data. Further analysis of the recommendation\nlists' diversity and novelty guarantees the suitability of the algorithm in\nreal production environments.\n",
			"Comment: Accepted for publishing at 43rd European Conference on Information\n  Retrieval (ECIR 2021)"
		],
		"date": [
			"2020-12-15",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.11328",
		"pdf_url": "http://arxiv.org/pdf/2012.11328.pdf"
	},
	"564": {
		"title": "Cross-domain Retrieval in the Legal and Patent Domains: a\n  Reproducibility Study",
		"creator": [
			"Althammer, Sophia",
			"Hofstätter, Sebastian",
			"Hanbury, Allan"
		],
		"subject": "Computer Science - Information Retrieval",
		"description": [
			"  Domain specific search has always been a challenging information retrieval\ntask due to several challenges such as the domain specific language, the unique\ntask setting, as well as the lack of accessible queries and corresponding\nrelevance judgements. In the last years, pretrained language models, such as\nBERT, revolutionized web and news search. Naturally, the community aims to\nadapt these advancements to cross-domain transfer of retrieval models for\ndomain specific search. In the context of legal document retrieval, Shao et al.\npropose the BERT-PLI framework by modeling the Paragraph Level Interactions\nwith the language model BERT. In this paper we reproduce the original\nexperiments, we clarify pre-processing steps, add missing scripts for framework\nsteps and investigate different evaluation approaches, however we are not able\nto reproduce the evaluation results. Contrary to the original paper, we\ndemonstrate that the domain specific paragraph-level modelling does not appear\nto help the performance of the BERT-PLI model compared to paragraph-level\nmodelling with the original BERT. In addition to our legal search\nreproducibility study, we investigate BERT-PLI for document retrieval in the\npatent domain. We find that the BERT-PLI model does not yet achieve performance\nimprovements for patent document retrieval compared to the BM25 baseline.\nFurthermore, we evaluate the BERT-PLI model for cross-domain retrieval between\nthe legal and patent domain on individual components, both on a paragraph and\ndocument-level. We find that the transfer of the BERT-PLI model on the\nparagraph-level leads to comparable results between both domains as well as\nfirst promising results for the cross-domain transfer on the document-level.\nFor reproducibility and transparency as well as to benefit the community we\nmake our source code and the trained models publicly available.\n",
			"Comment: Accepted at ECIR 2021 (Reproducibility paper track)"
		],
		"date": [
			"2020-12-21",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.11405",
		"pdf_url": "http://arxiv.org/pdf/2012.11405.pdf"
	},
	"565": {
		"title": "End-to-End Deep Structured Models for Drawing Crosswalks",
		"creator": [
			"Liang, Justin",
			"Urtasun, Raquel"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  In this paper we address the problem of detecting crosswalks from LiDAR and\ncamera imagery. Towards this goal, given multiple LiDAR sweeps and the\ncorresponding imagery, we project both inputs onto the ground surface to\nproduce a top down view of the scene. We then leverage convolutional neural\nnetworks to extract semantic cues about the location of the crosswalks. These\nare then used in combination with road centerlines from freely available maps\n(e.g., OpenStreetMaps) to solve a structured optimization problem which draws\nthe final crosswalk boundaries. Our experiments over crosswalks in a large city\narea show that 96.6% automation can be achieved.\n",
		"date": [
			"2020-12-21",
			"2021-01-14"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2012.11585",
			"ECCV 2018"
		],
		"pdf_url": "http://arxiv.org/pdf/2012.11585.pdf"
	},
	"566": {
		"title": "Applying Wav2vec2.0 to Speech Recognition in Various Low-resource\n  Languages",
		"creator": [
			"Yi, Cheng",
			"Wang, Jianzhong",
			"Cheng, Ning",
			"Zhou, Shiyu",
			"Xu, Bo"
		],
		"subject": "Computer Science - Computation and Language",
		"description": "  There are several domains that own corresponding widely used feature\nextractors, such as ResNet, BERT, and GPT-x. These models are usually\npre-trained on large amounts of unlabeled data by self-supervision and can be\neffectively applied to downstream tasks. In the speech domain, wav2vec2.0\nstarts to show its powerful representation ability and feasibility of ultra-low\nresource speech recognition on the Librispeech corpus, which belongs to the\naudiobook domain. However, wav2vec2.0 has not been examined on real spoken\nscenarios and languages other than English. To verify its universality over\nlanguages, we apply pre-trained models to solve low-resource speech recognition\ntasks in various spoken languages. We achieve more than 20% relative\nimprovements in six languages compared with previous work. Among these\nlanguages, English achieves a gain of 52.4%. Moreover, using coarse-grained\nmodeling units, such as subword or character, achieves better results than\nfine-grained modeling units, such as phone or letter.\n",
		"date": [
			"2020-12-22",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.12121",
		"pdf_url": "http://arxiv.org/pdf/2012.12121.pdf"
	},
	"567": {
		"title": "BaPipe: Exploration of Balanced Pipeline Parallelism for DNN Training",
		"creator": [
			"Zhao, Letian",
			"Xu, Rui",
			"Wang, Tianqi",
			"Tian, Teng",
			"Wang, Xiaotian",
			"Wu, Wei",
			"Ieong, Chio-in",
			"Jin, Xi"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  The size of deep neural networks (DNNs) grows rapidly as the complexity of\nthe machine learning algorithm increases. To satisfy the requirement of\ncomputation and memory of DNN training, distributed deep learning based on\nmodel parallelism has been widely recognized. We propose a new pipeline\nparallelism training framework, BaPipe, which can automatically explore\npipeline parallelism training methods and balanced partition strategies for DNN\ndistributed training. In BaPipe, each accelerator calculates the forward\npropagation and backward propagation of different parts of networks to\nimplement the intra-batch pipeline parallelism strategy. BaPipe uses a new load\nbalancing automatic exploration strategy that considers the parameters of DNN\nmodels and the computation, memory, and communication resources of accelerator\nclusters. We have trained different DNNs such as VGG-16, ResNet-50, and GNMT on\nGPU clusters and simulated the performance of different FPGA clusters. Compared\nwith state-of-the-art data parallelism and pipeline parallelism frameworks,\nBaPipe provides up to 3.2x speedup and 4x memory reduction in various\nplatforms.\n",
		"date": [
			"2020-12-23",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.12544",
		"pdf_url": "http://arxiv.org/pdf/2012.12544.pdf"
	},
	"568": {
		"title": "Training data-efficient image transformers & distillation through\n  attention",
		"creator": [
			"Touvron, Hugo",
			"Cord, Matthieu",
			"Douze, Matthijs",
			"Massa, Francisco",
			"Sablayrolles, Alexandre",
			"Jégou, Hervé"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Recently, neural networks purely based on attention were shown to address\nimage understanding tasks such as image classification. However, these visual\ntransformers are pre-trained with hundreds of millions of images using an\nexpensive infrastructure, thereby limiting their adoption.\n  In this work, we produce a competitive convolution-free transformer by\ntraining on Imagenet only. We train them on a single computer in less than 3\ndays. Our reference vision transformer (86M parameters) achieves top-1 accuracy\nof 83.1% (single-crop evaluation) on ImageNet with no external data.\n  More importantly, we introduce a teacher-student strategy specific to\ntransformers. It relies on a distillation token ensuring that the student\nlearns from the teacher through attention. We show the interest of this\ntoken-based distillation, especially when using a convnet as a teacher. This\nleads us to report results competitive with convnets for both Imagenet (where\nwe obtain up to 85.2% accuracy) and when transferring to other tasks. We share\nour code and models.\n",
		"date": [
			"2020-12-23",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.12877",
		"pdf_url": "http://arxiv.org/pdf/2012.12877.pdf"
	},
	"569": {
		"title": "AsymptoticNG: A regularized natural gradient optimization algorithm with\n  look-ahead strategy",
		"creator": [
			"Tang, Zedong",
			"Jiang, Fenlong",
			"Song, Junke",
			"Gong, Maoguo",
			"Li, Hao",
			"Yu, Fan",
			"Wang, Zidong",
			"Wang, Min"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"I.2.6",
			"G.1.6"
		],
		"description": [
			"  Optimizers that further adjust the scale of gradient, such as Adam, Natural\nGradient (NG), etc., despite widely concerned and used by the community, are\noften found poor generalization performance, compared with Stochastic Gradient\nDescent (SGD). They tend to converge excellently at the beginning of training\nbut are weak at the end. An immediate idea is to complement the strengths of\nthese algorithms with SGD. However, a truncated replacement of optimizer often\nleads to a crash of the update pattern, and new algorithms often require many\niterations to stabilize their search direction. Driven by this idea and to\naddress this problem, we design and present a regularized natural gradient\noptimization algorithm with look-ahead strategy, named asymptotic natural\ngradient (ANG). According to the total iteration step, ANG dynamic assembles NG\nand Euclidean gradient, and updates parameters along the new direction using\nthe intensity of NG. Validation experiments on CIFAR10 and CIFAR100 data sets\nshow that ANG can update smoothly and stably at the second-order speed, and\nachieve better generalization performance.\n",
			"Comment: 9 pages, 4 figures"
		],
		"date": [
			"2020-12-23",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.13077",
		"pdf_url": "http://arxiv.org/pdf/2012.13077.pdf"
	},
	"570": {
		"title": "Improving the Certified Robustness of Neural Networks via Consistency\n  Regularization",
		"creator": [
			"Xu, Mengting",
			"Zhang, Tao",
			"Li, Zhongnian",
			"Zhang, Daoqiang"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  A range of defense methods have been proposed to improve the robustness of\nneural networks on adversarial examples, among which provable defense methods\nhave been demonstrated to be effective to train neural networks that are\ncertifiably robust to the attacker. However, most of these provable defense\nmethods treat all examples equally during training process, which ignore the\ninconsistent constraint of certified robustness between correctly classified\n(natural) and misclassified examples. In this paper, we explore this\ninconsistency caused by misclassified examples and add a novel consistency\nregularization term to make better use of the misclassified examples.\nSpecifically, we identified that the certified robustness of network can be\nsignificantly improved if the constraint of certified robustness on\nmisclassified examples and correctly classified examples is consistent.\nMotivated by this discovery, we design a new defense regularization term called\nMisclassification Aware Adversarial Regularization (MAAR), which constrains the\noutput probability distributions of all examples in the certified region of the\nmisclassified example. Experimental results show that our proposed MAAR\nachieves the best certified robustness and comparable accuracy on CIFAR-10 and\nMNIST datasets in comparison with several state-of-the-art methods.\n",
			"Comment: 4 pages, appeare in AAAI21-RSEML"
		],
		"date": [
			"2020-12-24",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.13103",
		"pdf_url": "http://arxiv.org/pdf/2012.13103.pdf"
	},
	"571": {
		"title": "Auto-tune POIs: Estimation of distribution algorithms for efficient\n  side-channel analysis",
		"creator": [
			"Rioja, Unai",
			"Batina, Lejla",
			"Flores, Jose Luis",
			"Armendariz, Igor"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": "  Due to the constant increase and versatility of IoT devices that should keep\nsensitive information private, Side-Channel Analysis (SCA) attacks on embedded\ndevices are gaining visibility in the industrial field. The integration and\nvalidation of countermeasures against SCA can be an expensive and cumbersome\nprocess, especially for the less experienced ones, and current certification\nprocedures require to attack the devices under test using multiple SCA\ntechniques and attack vectors, often implying a high degree of complexity. The\ngoal of this paper is to ease one of the most crucial and tedious steps of\nprofiling attacks i.e. the points of interest (POI) selection and hence assist\nthe SCA evaluation process. To this end, we introduce the usage of Estimation\nof Distribution Algorithms (EDAs) in the SCA field in order to automatically\ntune the point of interest selection. We showcase our approach on several\nexperimental use cases, including attacks on unprotected and protected AES\nimplementations over distinct copies of the same device, dismissing in this way\nthe portability issue.\n",
		"date": [
			"2020-12-24",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.13225",
		"pdf_url": "http://arxiv.org/pdf/2012.13225.pdf"
	},
	"572": {
		"title": "Deep Semi-Supervised Embedded Clustering (DSEC) for Stratification of\n  Heart Failure Patients",
		"creator": [
			"Carr, Oliver",
			"Jovanovic, Stojan",
			"Albergante, Luca",
			"Andreotti, Fernando",
			"Dürichen, Robert",
			"Lipunova, Nadia",
			"Baxter, Janie",
			"Khan, Rabia",
			"Irving, Benjamin"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  Determining phenotypes of diseases can have considerable benefits for\nin-hospital patient care and to drug development. The structure of high\ndimensional data sets such as electronic health records are often represented\nthrough an embedding of the data, with clustering methods used to group data of\nsimilar structure. If subgroups are known to exist within data, supervised\nmethods may be used to influence the clusters discovered. We propose to extend\ndeep embedded clustering to a semi-supervised deep embedded clustering\nalgorithm to stratify subgroups through known labels in the data. In this work\nwe apply deep semi-supervised embedded clustering to determine data-driven\npatient subgroups of heart failure from the electronic health records of 4,487\nheart failure and control patients. We find clinically relevant clusters from\nan embedded space derived from heterogeneous data. The proposed algorithm can\npotentially find new undiagnosed subgroups of patients that have different\noutcomes, and, therefore, lead to improved treatments.\n",
			"Comment: 6 pages, 2 figures, HSYS workshop at ICML conference"
		],
		"date": [
			"2020-12-24",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.13233",
		"pdf_url": "http://arxiv.org/pdf/2012.13233.pdf"
	},
	"573": {
		"title": "Experiential Learning Approach for Software Engineering Courses at\n  Higher Education Level",
		"creator": [
			"Gonzalez-Huerta, Javier",
			"Molleri, Jefferson Seide",
			"Šablis, Aivars",
			"Zabardast, Ehsan"
		],
		"subject": [
			"Computer Science - Software Engineering",
			"D.2",
			"D.2.9",
			"D.2.m"
		],
		"description": [
			"  Background: Software project management activities help to introduce software\nprocess models in Software Engineering courses. However, these activities\nshould be adequately aligned with the learning outcomes and support student's\nprogression.\n  Objective: Present and evaluate an approach to help students acquire\ntheoretical and practical knowledge and experience real-world software\nprojects' challenges. The approach combines a serious game and a\ndesign-implement task in which students develop a controlled-scale software\nsystem.\n  Method: To evaluate our approach, we analyzed the students' perceptions\ncollected through an online survey, their project plans, and their final\nreports using thematic analysis.\n  Results: Results suggest that the approach promotes knowledge acquisition,\nenables students' progression, reinforces theoretical concepts, and is properly\naligned with the course's learning outcomes.\n  Conclusion: The approach seems to help to introduce software process models\nin Software Engineering courses. Our experience can also be inspiring for\neducators willing to apply our approach in similar courses.\n",
			"Comment: Submitted to Journal of Computing in Higher Education"
		],
		"date": [
			"2020-12-28",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.14178",
		"pdf_url": "http://arxiv.org/pdf/2012.14178.pdf"
	},
	"574": {
		"title": "IRO: Integrity and Reliability Enhanced Ring ORAM",
		"creator": [
			"He, Wenpeng",
			"Feng, Dan",
			"Wang, Fang",
			"Li, Yue",
			"Lu, Mengting"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Hardware Architecture"
		],
		"description": [
			"  Memory security and reliability are two of the major design concerns in cloud\ncomputing systems. State-of-the-art memory security-reliability co-designs\n(e.g. Synergy) have achieved a good balance on performance, confidentiality,\nintegrity, and reliability. However, these works merely rely on encryption to\nensure data confidentiality, which has been proven unable to prevent\ninformation leakage from memory access patterns. Ring ORAM is an attractive\nconfidential protection protocol to hide memory access patterns to the\nuntrusted storage system. Unfortunately, it does not compatible with the\nsecurity-reliability co-designs. A forced combination would result in more\nsevere performance loss.\n  In this paper, we propose IRO, an Integrity and Reliability enhanced Ring\nORAM design. To reduce the overhead of integrity verification, we propose a low\noverhead integrity tree RIT and use a Minimum Update Subtree Tree (MUST) to\nreduce metadata update overhead. To improve memory reliability, we present\nSecure Replication to provide channel-level error resilience for the ORAM tree\nand use the mirrored channel technique to guarantee the reliability of the\nMUST. Last, we use the error correction pointer (ECP) to repair permanent\nmemory cell fault to further improve device reliability and lifetime. A compact\nmetadata design is used to reduce the storage and consulting overhead of the\nECP.\n  IRO provides strong security and reliability guarantees, while the resulting\nstorage and performance overhead is very small. Our evaluation shows that IRO\nonly increases 7.54% execution time on average over the Baseline under two\nchannels four AES-GCM units setting. With enough AES-GCM units to perform\nconcurrent MAC computing, IRO can reduce 2.14% execution time of the Baseline.\n",
			"Comment: This work has been submitted to the IEEE for possible publication"
		],
		"date": [
			"2020-12-28",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.14318",
		"pdf_url": "http://arxiv.org/pdf/2012.14318.pdf"
	},
	"575": {
		"title": "A circular version of G\\\"odel's T and its abstraction complexity",
		"creator": "Das, Anupam",
		"subject": [
			"Computer Science - Logic in Computer Science",
			"Mathematics - Logic"
		],
		"description": [
			"  Circular and non-wellfounded proofs have become an increasingly popular tool\nfor metalogical treatments of systems with forms of induction and/or recursion.\nIn this work we investigate the expressivity of a variant CT of G\\\"odel's\nsystem T where programs are circularly typed, rather than including an explicit\nrecursion combinator. In particular, we examine the abstraction complexity\n(i.e. type level) of C, and show that the G\\\"odel primitive recursive\nfunctionals may be typed more succinctly with circular derivations, using types\nprecisely one level lower than in T. In fact we give a logical correspondence\nbetween the two settings, interpreting the quantifier-free type 1 theory of\nlevel n+1 T into that of level n C and vice-versa.\n  We also obtain some further results and perspectives on circular\n'derivations', namely strong normalisation and confluence, models based on\nhereditary computable functionals, continuity at type 2, and a translation to\nterms of $\\T$ computing the same functional, at all types.\n",
			"Comment: 74 pages, 9 figures"
		],
		"date": [
			"2020-12-28",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.14421",
		"pdf_url": "http://arxiv.org/pdf/2012.14421.pdf"
	},
	"576": {
		"title": "Paraconsistent Foundations for Probabilistic Reasoning, Programming and\n  Concept Formation",
		"creator": "Goertzel, Ben",
		"subject": "Computer Science - Artificial Intelligence",
		"description": "  It is argued that 4-valued paraconsistent truth values (called here \"p-bits\")\ncan serve as a conceptual, mathematical and practical foundation for highly\nAI-relevant forms of probabilistic logic and probabilistic programming and\nconcept formation.\n  First it is shown that appropriate averaging-across-situations and\nrenormalization of 4-valued p-bits operating in accordance with Constructible\nDuality (CD) logic yields PLN (Probabilistic Logic Networks)\nstrength-and-confidence truth values. Then variations on the Curry-Howard\ncorrespondence are used to map these paraconsistent and probabilistic logics\ninto probabilistic types suitable for use within dependent type based\nprogramming languages.\n  Zach Weber's paraconsistent analysis of the sorites paradox is extended to\nform a paraconsistent / probabilistic / fuzzy analysis of concept boundaries;\nand a paraconsistent version of concept formation via Formal Concept Analysis\nis presented, building on a definition of fuzzy property-value degrees in terms\nof relative entropy on paraconsistent probability distributions.\n  These general points are fleshed out via reference to the realization of\nprobabilistic reasoning and programming and concept formation in the OpenCog\nAGI framework which is centered on collaborative multi-algorithm updating of a\ncommon knowledge metagraph.\n",
		"date": [
			"2020-12-28",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.14474",
		"pdf_url": "http://arxiv.org/pdf/2012.14474.pdf"
	},
	"577": {
		"title": "Gradient Descent Averaging and Primal-dual Averaging for Strongly Convex\n  Optimization",
		"creator": [
			"Tao, Wei",
			"Li, Wei",
			"Pan, Zhisong",
			"Tao, Qing"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Mathematics - Optimization and Control"
		],
		"description": [
			"  Averaging scheme has attracted extensive attention in deep learning as well\nas traditional machine learning. It achieves theoretically optimal convergence\nand also improves the empirical model performance. However, there is still a\nlack of sufficient convergence analysis for strongly convex optimization.\nTypically, the convergence about the last iterate of gradient descent methods,\nwhich is referred to as individual convergence, fails to attain its optimality\ndue to the existence of logarithmic factor. In order to remove this factor, we\nfirst develop gradient descent averaging (GDA), which is a general\nprojection-based dual averaging algorithm in the strongly convex setting. We\nfurther present primal-dual averaging for strongly convex cases (SC-PDA), where\nprimal and dual averaging schemes are simultaneously utilized. We prove that\nGDA yields the optimal convergence rate in terms of output averaging, while\nSC-PDA derives the optimal individual convergence. Several experiments on SVMs\nand deep learning models validate the correctness of theoretical analysis and\neffectiveness of algorithms.\n",
			"Comment: 11 pages, 12 figures"
		],
		"date": [
			"2020-12-28",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.14558",
		"pdf_url": "http://arxiv.org/pdf/2012.14558.pdf"
	},
	"578": {
		"title": "Security Engineering for ISO 21434",
		"creator": [
			"Dantas, Yuri Gil",
			"Nigam, Vivek",
			"Ruess, Harald"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Logic in Computer Science",
			"I.2.4",
			"I.2.5"
		],
		"description": [
			"  The ISO 21434 is a new standard that has been proposed to address the future\nchallenges of automotive cybersecurity. This white paper takes a closer look at\nthe ISO 21434 helping engineers to understand the ISO 21434 parts, the key\nactivities to be carried out and the main artefacts that shall be produced. As\nany certification, obtaining the ISO 21434 certification can be daunting at\nfirst sight. Engineers have to deploy processes that include several security\nrisk assessment methods to produce security arguments and evidence supporting\nitem security claims. In this white paper, we propose a security engineering\napproach that can ease this process by relying on Rigorous Security Assessments\nand Incremental Assessment Maintenance methods supported by automation. We\ndemonstrate by example that the proposed approach can greatly increase the\nquality of the produced artefacts, the efficiency to produce them, as well as\nenable continuous security assessment. Finally, we point out some key research\ndirections that we are investigating to fully realize the proposed approach.\n",
			"Comment: This is a White Paper. This is a preliminary version. Its figures and\n  template are to be finalized by our marketing department. V3 corrects a\n  number of typos"
		],
		"date": [
			"2020-12-30",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.15080",
		"pdf_url": "http://arxiv.org/pdf/2012.15080.pdf"
	},
	"579": {
		"title": "DeepTake: Prediction of Driver Takeover Behavior using Multimodal Data",
		"creator": [
			"Pakdamanian, Erfan",
			"Sheng, Shili",
			"Baee, Sonia",
			"Heo, Seongkook",
			"Kraus, Sarit",
			"Feng, Lu"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Human-Computer Interaction",
			"I.2.6",
			"J.4"
		],
		"description": [
			"  Automated vehicles promise a future where drivers can engage in non-driving\ntasks without hands on the steering wheels for a prolonged period.\nNevertheless, automated vehicles may still need to occasionally hand the\ncontrol back to drivers due to technology limitations and legal requirements.\nWhile some systems determine the need for driver takeover using driver context\nand road condition to initiate a takeover request, studies show that the driver\nmay not react to it. We present DeepTake, a novel deep neural network-based\nframework that predicts multiple aspects of takeover behavior to ensure that\nthe driver is able to safely take over the control when engaged in non-driving\ntasks. Using features from vehicle data, driver biometrics, and subjective\nmeasurements, DeepTake predicts the driver's intention, time, and quality of\ntakeover. We evaluate DeepTake performance using multiple evaluation metrics.\nResults show that DeepTake reliably predicts the takeover intention, time, and\nquality, with an accuracy of 96%, 93%, and 83%, respectively. Results also\nindicate that DeepTake outperforms previous state-of-the-art methods on\npredicting driver takeover time and quality. Our findings have implications for\nthe algorithm development of driver monitoring and state detection.\n",
			"Comment: Accepted to CHI 2021"
		],
		"date": [
			"2020-12-30",
			"2021-01-15"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2012.15441",
			"doi:10.1145/3411764.3445563"
		],
		"pdf_url": "http://arxiv.org/pdf/2012.15441.pdf"
	},
	"580": {
		"title": "Likelihood Ratio Exponential Families",
		"creator": [
			"Brekelmans, Rob",
			"Nielsen, Frank",
			"Makhzani, Alireza",
			"Galstyan, Aram",
			"Steeg, Greg Ver"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Information Theory",
			"Statistics - Machine Learning"
		],
		"description": [
			"  The exponential family is well known in machine learning and statistical\nphysics as the maximum entropy distribution subject to a set of observed\nconstraints, while the geometric mixture path is common in MCMC methods such as\nannealed importance sampling. Linking these two ideas, recent work has\ninterpreted the geometric mixture path as an exponential family of\ndistributions to analyze the thermodynamic variational objective (TVO).\n  We extend these likelihood ratio exponential families to include solutions to\nrate-distortion (RD) optimization, the information bottleneck (IB) method, and\nrecent rate-distortion-classification approaches which combine RD and IB. This\nprovides a common mathematical framework for understanding these methods via\nthe conjugate duality of exponential families and hypothesis testing. Further,\nwe collect existing results to provide a variational representation of\nintermediate RD or TVO distributions as a minimizing an expectation of KL\ndivergences. This solution also corresponds to a size-power tradeoff using the\nlikelihood ratio test and the Neyman Pearson lemma. In thermodynamic\nintegration bounds such as the TVO, we identify the intermediate distribution\nwhose expected sufficient statistics match the log partition function.\n",
			"Comment: NeurIPS Workshop on Deep Learning through Information Geometry"
		],
		"date": [
			"2020-12-31",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.15480",
		"pdf_url": "http://arxiv.org/pdf/2012.15480.pdf"
	},
	"581": {
		"title": "An hp-hierarchical framework for the finite element exterior calculus",
		"creator": [
			"Gates, Robert L.",
			"Bittens, Maximilian"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"Physics - Computational Physics"
		],
		"description": [
			"  The problem of solving partial differential equations (PDEs) on manifolds can\nbe considered to be one of the most general problem formulations encountered in\ncomputational multi-physics. The required covariant forms of balance laws as\nwell as the corresponding covariant forms of the constitutive closing relations\nare naturally expressed using the bundle-valued exterior calculus of\ndifferential forms or related algebraic concepts. It can be argued that the\nappropriate solution method to such PDE problems is given by the finite element\nexterior calculus (FEEC). The aim of this essay is the exposition of a simple,\nefficiently-implementable framework for general hp-adaptivity applicable to the\nFEEC on higher-dimensional manifolds. A problem-independent spectral\nerror-indicator is developed which estimates the error and the spectral decay\nof polynomial coefficients. The spectral decay rate is taken as an\nadmissibility indicator on the polynomial order distribution. Finally, by\nelementary computational examples, it is attempted to demonstrate the power of\nthe method as an engineering tool.\n",
			"Comment: 24 pages, 12 figures"
		],
		"date": [
			"2020-12-31",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2012.15581",
		"pdf_url": "http://arxiv.org/pdf/2012.15581.pdf"
	},
	"582": {
		"title": "Optimizing Optimizers: Regret-optimal gradient descent algorithms",
		"creator": [
			"Casgrain, Philippe",
			"Kratsios, Anastasis"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Mathematics - Optimization and Control",
			"49K10, 49J10, 49M05, 49K27, 49J50, 65K10",
			"F.2.0"
		],
		"description": [
			"  The need for fast and robust optimization algorithms are of critical\nimportance in all areas of machine learning. This paper treats the task of\ndesigning optimization algorithms as an optimal control problem. Using regret\nas a metric for an algorithm's performance, we study the existence, uniqueness\nand consistency of regret-optimal algorithms. By providing first-order\noptimality conditions for the control problem, we show that regret-optimal\nalgorithms must satisfy a specific structure in their dynamics which we show is\nequivalent to performing dual-preconditioned gradient descent on the value\nfunction generated by its regret. Using these optimal dynamics, we provide\nbounds on their rates of convergence to solutions of convex optimization\nproblems. Though closed-form optimal dynamics cannot be obtained in general, we\npresent fast numerical methods for approximating them, generating optimization\nalgorithms which directly optimize their long-term regret. Lastly, these are\nbenchmarked against commonly used optimization algorithms to demonstrate their\neffectiveness.\n",
			"Comment: 12 pages body, 42 pages total, 2 figures"
		],
		"date": [
			"2020-12-31",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.00041",
		"pdf_url": "http://arxiv.org/pdf/2101.00041.pdf"
	},
	"583": {
		"title": "A Zonal Volt/VAR Control Mechanism for High PV Penetration Distribution\n  Systems",
		"creator": [
			"Alrushoud, Asmaa",
			"McEntee, Catie",
			"Lu, Ning"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  This paper presents a zonal Volt/VAR control scheme that coordinates\nPhotovoltaic (PV) inverters for providing voltage regulation on 3-phase\nunbalanced distribution feeders. Voltage sensitivity studies are conducted to\nuncover the dependency between nodal voltage changes and the reactive power\ninjections at nodes with smart PV inverters. A fast incremental clustering\nmethod is developed to divide the distribution feeder into weakly coupled zones\nbased on correlations of nodal voltage sensitivities. Because each zone is\nweakly coupled, voltage of each zone can be controlled independently. Thus, in\neach zone, a rule-based voltage controller will dispatch PV smart inverters to\nprovide reactive power control for correcting the over/under voltages. An\nactual distribution feeder in North Carolina is used as a test bed. Simulation\nresults show that the proposed zonal based Volt/VAR control mechanism can\nmaintain the voltage in the distribution system within limits and solves faster\nthan the centralized controller.\n",
			"Comment: 5 pages, 8 figures, submitted to 2021 IEEE PES General Meeting"
		],
		"date": [
			"2020-12-31",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.00106",
		"pdf_url": "http://arxiv.org/pdf/2101.00106.pdf"
	},
	"584": {
		"title": "Transformer based Automatic COVID-19 Fake News Detection System",
		"creator": [
			"Gundapu, Sunil",
			"Mamidi, Radhika"
		],
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  Recent rapid technological advancements in online social networks such as\nTwitter have led to a great incline in spreading false information and fake\nnews. Misinformation is especially prevalent in the ongoing coronavirus disease\n(COVID-19) pandemic, leading to individuals accepting bogus and potentially\ndeleterious claims and articles. Quick detection of fake news can reduce the\nspread of panic and confusion among the public. For our analysis in this paper,\nwe report a methodology to analyze the reliability of information shared on\nsocial media pertaining to the COVID-19 pandemic. Our best approach is based on\nan ensemble of three transformer models (BERT, ALBERT, and XLNET) to detecting\nfake news. This model was trained and evaluated in the context of the\nConstraintAI 2021 shared task COVID19 Fake News Detection in English. Our\nsystem obtained 0.9855 f1-score on testset and ranked 5th among 160 teams.\n",
			"Comment: First Workshop on Combating Online Hostile Posts in Regional\n  Languages during Emergency Situation, 12 pages"
		],
		"date": [
			"2021-01-01",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.00180",
		"pdf_url": "http://arxiv.org/pdf/2101.00180.pdf"
	},
	"585": {
		"title": "Reinforcement Learning for Flexibility Design Problems",
		"creator": [
			"Wei, Yehua",
			"Zhang, Lei",
			"Zhang, Ruiyi",
			"Si, Shijing",
			"Zhang, Hao",
			"Carin, Lawrence"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  Flexibility design problems are a class of problems that appear in strategic\ndecision-making across industries, where the objective is to design a ($e.g.$,\nmanufacturing) network that affords flexibility and adaptivity. The underlying\ncombinatorial nature and stochastic objectives make flexibility design problems\nchallenging for standard optimization methods. In this paper, we develop a\nreinforcement learning (RL) framework for flexibility design problems.\nSpecifically, we carefully design mechanisms with noisy exploration and\nvariance reduction to ensure empirical success and show the unique advantage of\nRL in terms of fast-adaptation. Empirical results show that the RL-based method\nconsistently finds better solutions compared to classical heuristics.\n",
		"date": [
			"2021-01-01",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.00355",
		"pdf_url": "http://arxiv.org/pdf/2101.00355.pdf"
	},
	"586": {
		"title": "Automatic Defect Detection of Print Fabric Using Convolutional Neural\n  Network",
		"creator": [
			"Chakraborty, Samit",
			"Moore, Marguerite",
			"Parrillo-Chapman, Lisa"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Automatic defect detection is a challenging task because of the variability\nin texture and type of fabric defects. An effective defect detection system\nenables manufacturers to improve the quality of processes and products.\nAutomation across the textile manufacturing systems would reduce fabric wastage\nand increase profitability by saving cost and resources. There are different\ncontemporary research on automatic defect detection systems using image\nprocessing and machine learning techniques. These techniques differ from each\nother based on the manufacturing processes and defect types. Researchers have\nalso been able to establish real-time defect detection system during weaving.\nAlthough, there has been research on patterned fabric defect detection, these\ndefects are related to weaving faults such as holes, and warp and weft defects.\nBut, there has not been any research that is designed to detect defects that\narise during such as spot and print mismatch. This research has fulfilled this\ngap by developing a print fabric database and implementing deep convolutional\nneural network (CNN).\n",
			"Comment: 8 pages, 4 figures, Conference"
		],
		"date": "2021-01-03",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.00703",
			"Digital Fashion Innovation e-Symposium, 2020"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.00703.pdf"
	},
	"587": {
		"title": "Variationally and Intrinsically motivated reinforcement learning for\n  decentralized traffic signal control",
		"creator": [
			"Zhu, Liwen",
			"Peng, Peixi",
			"Lu, Zongqing",
			"Wang, Xiangqian",
			"Tian, Yonghong"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Multiagent Systems"
		],
		"description": "  One of the biggest challenges in multi-agent reinforcement learning is\ncoordination, a typical application scenario of this is traffic signal control.\nRecently, it has attracted a rising number of researchers and has become a hot\nresearch field with great practical significance. In this paper, we propose a\nnovel method called MetaVRS~(Meta Variational RewardShaping) for traffic signal\ncoordination control. By heuristically applying the intrinsic reward to the\nenvironmental reward, MetaVRS can wisely capture the agent-to-agent interplay.\nBesides, latent variables generated by VAE are brought into policy for\nautomatically tradeoff between exploration and exploitation to optimize the\npolicy. In addition, meta learning was used in decoder for faster adaptation\nand better approximation. Empirically, we demonstate that MetaVRS substantially\noutperforms existing methods and shows superior adaptability, which predictably\nhas a far-reaching significance to the multi-agent traffic signal coordination\ncontrol.\n",
		"date": [
			"2021-01-03",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.00746",
		"pdf_url": "http://arxiv.org/pdf/2101.00746.pdf"
	},
	"588": {
		"title": "Experience vs Data: A Case for More Data-informed Retrospective\n  Activities",
		"creator": [
			"Matthies, Christoph",
			"Dobrigkeit, Franziska"
		],
		"subject": "Computer Science - Software Engineering",
		"description": [
			"  Effective Retrospective meetings are vital for ensuring productive\ndevelopment processes because they provide the means for Agile software\ndevelopment teams to discuss and decide on future improvements of their\ncollaboration. Retrospective agendas often include activities that encourage\nsharing ideas and motivate participants to discuss possible improvements. The\noutcomes of these activities steer the future directions of team dynamics and\ninfluence team happiness. However, few empirical evaluations of Retrospective\nactivities are currently available. Additionally, most activities rely on team\nmembers experiences and neglect to take existing project data into account.\nWith this paper we want to make a case for data-driven decision-making\nprinciples, which have largely been adopted in other business areas. Towards\nthis goal we review existing retrospective activities and highlight activities\nthat already use project data as well as activities that could be augmented to\ntake advantage of additional, more subjective data sources. We conclude that\ndata-driven decision-making principles, are advantageous, and yet underused, in\nmodern Agile software development. Making use of project data in retrospective\nactivities would strengthen this principle and is a viable approach as such\ndata can support the teams in making decisions on process improvement.\n",
			"Comment: 5th International Conference on Lean and Agile Software Development\n  (LASD 2021). 23 January 2021"
		],
		"date": [
			"2021-01-05",
			"2021-01-15"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.01528",
			"Lecture Notes in Business Information Processing. Springer\n  International Publishing. pp. 130-144. 2021",
			"doi:10.1007/978-3-030-67084-9_8"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.01528.pdf"
	},
	"589": {
		"title": "Local Translation Services for Neglected Languages",
		"creator": [
			"Noever, David",
			"Kalin, Josh",
			"Ciolino, Matt",
			"Hambrick, Dom",
			"Dozier, Gerry"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning"
		],
		"description": "  Taking advantage of computationally lightweight, but high-quality translators\nprompt consideration of new applications that address neglected languages.\nLocally run translators for less popular languages may assist data projects\nwith protected or personal data that may require specific compliance checks\nbefore posting to a public translation API, but which could render reasonable,\ncost-effective solutions if done with an army of local, small-scale pair\ntranslators. Like handling a specialist's dialect, this research illustrates\ntranslating two historically interesting, but obfuscated languages: 1)\nhacker-speak (\"l33t\") and 2) reverse (or \"mirror\") writing as practiced by\nLeonardo da Vinci. The work generalizes a deep learning architecture to\ntranslatable variants of hacker-speak with lite, medium, and hard vocabularies.\nThe original contribution highlights a fluent translator of hacker-speak in\nunder 50 megabytes and demonstrates a generator for augmenting future datasets\nwith greater than a million bilingual sentence pairs. The long short-term\nmemory, recurrent neural network (LSTM-RNN) extends previous work demonstrating\nan English-to-foreign translation service built from as little as 10,000\nbilingual sentence pairs. This work further solves the equivalent translation\nproblem in twenty-six additional (non-obfuscated) languages and rank orders\nthose models and their proficiency quantitatively with Italian as the most\nsuccessful and Mandarin Chinese as the most challenging. For neglected\nlanguages, the method prototypes novel services for smaller niche translations\nsuch as Kabyle (Algerian dialect) which covers between 5-7 million speakers but\none which for most enterprise translators, has not yet reached development. One\nanticipates the extension of this approach to other important dialects, such as\ntranslating technical (medical or legal) jargon and processing health records.\n",
		"date": [
			"2021-01-05",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.01628",
		"pdf_url": "http://arxiv.org/pdf/2101.01628.pdf"
	},
	"590": {
		"title": "Lockdowns need geographic coordination because of propagation of\n  economic effects through supply chains",
		"creator": [
			"Inoue, Hiroyasu",
			"Murase, Yohsuke",
			"Todo, Yasuyuki"
		],
		"subject": [
			"Computer Science - Social and Information Networks",
			"Physics - Physics and Society"
		],
		"description": [
			"  In order to prevent the spread of COVID-19, governments have often required\nregional or national lockdowns, which have caused extensive economic stagnation\nover broad areas as the shock of the lockdowns has diffused to other regions\nthrough supply chains. Using supply-chain data for 1.6 million firms in Japan,\nthis study examines how governments can mitigate these economic losses when\nthey are obliged to implement lockdowns. Through tests of all combinations of\ntwo-region lockdowns, we find that coordinated, i.e., simultaneous, lockdowns\nyield smaller GDP losses than uncoordinated lockdowns. Furthermore, we test\npractical scenarios in which Japan's 47 regions impose lockdowns over three\nmonths and find that GDP losses are lower if nationwide lockdowns are\ncoordinated than if they are uncoordinated.\n",
			"Comment: arXiv admin note: substantial text overlap with arXiv:2009.06894"
		],
		"date": [
			"2021-01-05",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.01679",
		"pdf_url": "http://arxiv.org/pdf/2101.01679.pdf"
	},
	"591": {
		"title": "dame-flame: A Python Library Providing Fast Interpretable Matching for\n  Causal Inference",
		"creator": [
			"Gupta, Neha R.",
			"Orlandi, Vittorio",
			"Chang, Chia-Rui",
			"Wang, Tianyu",
			"Morucci, Marco",
			"Dey, Pritam",
			"Howell, Thomas J.",
			"Sun, Xian",
			"Ghosal, Angikar",
			"Roy, Sudeepa",
			"Rudin, Cynthia",
			"Volfovsky, Alexander"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Mathematical Software"
		],
		"description": [
			"  dame-flame is a Python package for performing matching for observational\ncausal inference on datasets containing discrete covariates. This package\nimplements the Dynamic Almost Matching Exactly (DAME) and Fast Large-Scale\nAlmost Matching Exactly (FLAME) algorithms, which match treatment and control\nunits on subsets of the covariates. The resulting matched groups are\ninterpretable, because the matches are made on covariates (rather than, for\ninstance, propensity scores), and high-quality, because machine learning is\nused to determine which covariates are important to match on. DAME solves an\noptimization problem that matches units on as many covariates as possible,\nprioritizing matches on important covariates. FLAME approximates the solution\nfound by DAME via a much faster backward feature selection procedure. The\npackage provides several adjustable parameters to adapt the algorithms to\nspecific applications, and can calculate treatment effects after matching.\nDescriptions of these parameters, details on estimating treatment effects, and\nfurther examples, can be found in the documentation at\nhttps://almost-matching-exactly.github.io/DAME-FLAME-Python-Package/\n",
			"Comment: 5 pages, 1 figure; Reference and discussion of CEM corrected"
		],
		"date": [
			"2021-01-05",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.01867",
		"pdf_url": "http://arxiv.org/pdf/2101.01867.pdf"
	},
	"592": {
		"title": "Highway: Efficient Consensus with Flexible Finality",
		"creator": [
			"Kane, Daniel",
			"Fackler, Andreas",
			"Gągol, Adam",
			"Straszak, Damian"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Cryptography and Security"
		],
		"description": "  There has been recently a lot of progress in designing efficient partially\nsynchronous BFT consensus protocols that are meant to serve as core consensus\nengines for Proof of Stake blockchain systems. While the state-of-the-art\nsolutions attain virtually optimal performance under this theoretical model,\nthere is still room for improvement, as several practical aspects of such\nsystems are not captured by this model. Most notably, during regular execution,\ndue to financial incentives in such systems, one expects an overwhelming\nfraction of nodes to honestly follow the protocol rules and only few of them to\nbe faulty, most likely due to temporary network issues. Intuitively, the fact\nthat almost all nodes behave honestly should result in stronger confidence in\nblocks finalized in such periods, however it is not the case under the\nclassical model, where finality is binary.\n  We propose Highway, a new consensus protocol that is safe and live in the\nclassical partially synchronous BFT model, while at the same time offering\npractical improvements over existing solutions. Specifically, block finality in\nHighway is not binary but is expressed by fraction of nodes that would need to\nbreak the protocol rules in order for a block to be reverted. During periods of\nhonest participation finality of blocks might reach well beyond 1/3 (as what\nwould be the maximum for classical protocols), up to even 1 (complete\ncertainty). Having finality defined this way, Highway offers flexibility with\nrespect to the configuration of security thresholds among nodes running the\nprotocol, allowing nodes with lower thresholds to reach finality faster than\nthe ones requiring higher levels of confidence.\n",
		"date": [
			"2021-01-06",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.02159",
		"pdf_url": "http://arxiv.org/pdf/2101.02159.pdf"
	},
	"593": {
		"title": "Analysis of fully discrete finite element methods for 2D Navier--Stokes\n  equations with critical initial data",
		"creator": [
			"Li, Buyang",
			"Ma, Shu",
			"Ueda, Yuki"
		],
		"subject": "Mathematics - Numerical Analysis",
		"description": "  First-order convergence in time and space is proved for a fully discrete\nsemi-implicit finite element method for the two-dimensional Navier--Stokes\nequations with $L^2$ initial data in convex polygonal domains, without extra\nregularity assumptions or grid-ratio conditions. The proof utilises the\nsmoothing properties of the Navier--Stokes equations, an appropriate duality\nargument, and the smallness of the numerical solution in the discrete\n$L^2(0,t_m;H^1)$ norm when $t_m$ is smaller than some constant. Numerical\nexamples are provided to support the theoretical analysis.\n",
		"date": [
			"2021-01-07",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.02444",
		"pdf_url": "http://arxiv.org/pdf/2101.02444.pdf"
	},
	"594": {
		"title": "Triple-entry Accounting, Blockchain and Next of Kin: Towards a\n  Standardization of Ledger Terminology",
		"creator": [
			"Ibañez, Juan Ignacio",
			"Bayer, Chris N.",
			"Tasca, Paolo",
			"Xu, Jiahua"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": "  Triple-entry accounting (TEA) is one of the novelest notions in the\nblockchain world. However, the lack of a consistent and comprehensive set of\ncategories to give account of it impedes a proper apprehension of the concept,\nleading to contradictions and to overlooking its specificity. In order to\nclearly delineate the confines of TEA, we create a typology to distinguish\nbetween essential elements such as accounting and bookkeeping, as well as\nbetween decentralized systems, distributed ledgers and distributed journals.\n",
		"date": [
			"2021-01-04",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.02632",
		"pdf_url": "http://arxiv.org/pdf/2101.02632.pdf"
	},
	"595": {
		"title": "Theorem Proving and Algebra",
		"creator": "Goguen, Joseph A.",
		"subject": [
			"Computer Science - Logic in Computer Science",
			"Computer Science - Programming Languages",
			"Computer Science - Symbolic Computation",
			"68Q65, 03B70 (Primary)",
			"F.3.1",
			"F.3.2",
			"F.4.1",
			"F.1.1",
			"I.1.3"
		],
		"description": [
			"  This book can be seen either as a text on theorem proving that uses\ntechniques from general algebra, or else as a text on general algebra\nillustrated and made concrete by practical exercises in theorem proving. The\nbook considers several different logical systems, including first-order logic,\nHorn clause logic, equational logic, and first-order logic with equality.\nSimilarly, several different proof paradigms are considered. However, we do\nemphasize equational logic, and for simplicity we use only the OBJ3 software\nsystem, though it is used in a rather flexible manner. We do not pursue the\nlofty goal of mechanizing proofs like those of which mathematicians are justly\nso proud; instead, we seek to take steps towards providing mechanical\nassistance for proofs that are useful for computer scientists in developing\nsoftware and hardware. This more modest goal has the advantage of both being\nachievable and having practical benefits.\n  The following topics are covered: many-sorted signature, algebra and\nhomomorphism; term algebra and substitution; equation and satisfaction;\nconditional equations; equational deduction and its completeness; deduction for\nconditional equations; the theorem of constants; interpretation and equivalence\nof theories; term rewriting, termination, confluence and normal form; abstract\nrewrite systems; standard models, abstract data types, initiality, and\ninduction; rewriting and deduction modulo equations; first-order logic, models,\nand proof planning; second-order algebra; order-sorted algebra and rewriting;\nmodules; unification and completion; and hidden algebra. In parallel with these\nare a gradual introduction to OBJ3, applications to group theory, various\nabstract data types (such as number systems, lists, and stacks), propositional\ncalculus, hardware verification, the {\\lambda}-calculus, correctness of\nfunctional programs, and other topics.\n",
			"Comment: 427+ xviii pages, 38 figures, Unfinished book by Joseph A. Goguen,\n  Edited by Kokichi Futatsugi, Narciso Mart\\'i-Oliet and Jos\\'e Meseguer;\n  revised version corrects some strange characters in page xv"
		],
		"date": [
			"2021-01-07",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.02690",
		"pdf_url": "http://arxiv.org/pdf/2101.02690.pdf"
	},
	"596": {
		"title": "Predicting Semen Motility using three-dimensional Convolutional Neural\n  Networks",
		"creator": [
			"Priyansi",
			"Bhattacharjee, Biswaroop",
			"Rahim, Junaid"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Manual and computer aided methods to perform semen analysis are\ntime-consuming, requires extensive training and prone to human error. The use\nof classical machine learning and deep learning based methods using videos to\nperform semen analysis have yielded good results. The state-of-the-art method\nuses regular convolutional neural networks to perform quality assessments on a\nvideo of the provided sample. In this paper we propose an improved deep\nlearning based approach using three-dimensional convolutional neural networks\nto predict sperm motility from microscopic videos of the semen sample. We make\nuse of the VISEM dataset that consists of video and tabular data of semen\nsamples collected from 85 participants. We were able to achieve good results\nfrom significantly less data points. Our models indicate that deep learning\nbased automatic semen analysis may become a valuable and effective tool in\nfertility and IVF labs.\n",
			"Comment: Corrected typos. Made slight changes as per the comments"
		],
		"date": [
			"2021-01-08",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.02888",
		"pdf_url": "http://arxiv.org/pdf/2101.02888.pdf"
	},
	"597": {
		"title": "Graph embeddings for Abusive Language Detection",
		"creator": [
			"Cecillon, Noé",
			"Labatut, Vincent",
			"Dufour, Richard",
			"Linares, Georges"
		],
		"subject": "Computer Science - Social and Information Networks",
		"description": "  Abusive behaviors are common on online social networks. The increasing\nfrequency of antisocial behaviors forces the hosts of online platforms to find\nnew solutions to address this problem. Automating the moderation process has\nthus received a lot of interest in the past few years. Various methods have\nbeen proposed, most based on the exchanged content, and one relying on the\nstructure and dynamics of the conversation. It has the advantage of being\nlanguageindependent, however it leverages a hand-crafted set of topological\nmeasures which are computationally expensive and not necessarily suitable to\nall situations. In the present paper, we propose to use recent graph embedding\napproaches to automatically learn representations of conversational graphs\ndepicting message exchanges. We compare two categories: node vs. whole-graph\nembeddings. We experiment with a total of 8 approaches and apply them to a\ndataset of online messages. We also study more precisely which aspects of the\ngraph structure are leveraged by each approach. Our study shows that the\nrepresentation produced by certain embeddings captures the information conveyed\nby specific topological measures, but misses out other aspects.\n",
		"date": "2021-01-08",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.02988",
			"SN Computer Science, 2:37, 2021, Springer-Nature",
			"doi:10.1007/s42979-020-00413-7"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.02988.pdf"
	},
	"598": {
		"title": "Forecasting Commodity Prices Using Long Short-Term Memory Neural\n  Networks",
		"creator": [
			"Ly, Racine",
			"Traore, Fousseini",
			"Dia, Khadim"
		],
		"subject": [
			"Quantitative Finance - Statistical Finance",
			"Computer Science - Machine Learning",
			"I.6.6"
		],
		"description": [
			"  This paper applies a recurrent neural network (RNN) method to forecast cotton\nand oil prices. We show how these new tools from machine learning, particularly\nLong-Short Term Memory (LSTM) models, complement traditional methods. Our\nresults show that machine learning methods fit reasonably well the data but do\nnot outperform systematically classical methods such as Autoregressive\nIntegrated Moving Average (ARIMA) models in terms of out of sample forecasts.\nHowever, averaging the forecasts from the two type of models provide better\nresults compared to either method. Compared to the ARIMA and the LSTM, the Root\nMean Squared Error (RMSE) of the average forecast was 0.21 and 21.49 percent\nlower respectively for cotton. For oil, the forecast averaging does not provide\nimprovements in terms of RMSE. We suggest using a forecast averaging method and\nextending our analysis to a wide range of commodity prices.\n",
			"Comment: 13 pages, 8 figures, 7 tables, 27 references"
		],
		"date": [
			"2021-01-08",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.03087",
		"pdf_url": "http://arxiv.org/pdf/2101.03087.pdf"
	},
	"599": {
		"title": "Synthetic Glacier SAR Image Generation from Arbitrary Masks Using\n  Pix2Pix Algorithm",
		"creator": [
			"Dietrich-Sussner, Rosanna",
			"Davari, Amirabbas",
			"Seehaus, Thorsten",
			"Braun, Matthias",
			"Christlein, Vincent",
			"Maier, Andreas",
			"Riess, Christian"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  Supervised machine learning requires a large amount of labeled data to\nachieve proper test results. However, generating accurately labeled\nsegmentation maps on remote sensing imagery, including images from synthetic\naperture radar (SAR), is tedious and highly subjective. In this work, we\npropose to alleviate the issue of limited training data by generating synthetic\nSAR images with the pix2pix algorithm. This algorithm uses conditional\nGenerative Adversarial Networks (cGANs) to generate an artificial image while\npreserving the structure of the input. In our case, the input is a segmentation\nmask, from which a corresponding synthetic SAR image is generated. We present\ndifferent models, perform a comparative study and demonstrate that this\napproach synthesizes convincing glaciers in SAR images with promising\nqualitative and quantitative results.\n",
		"date": [
			"2021-01-08",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.03252",
		"pdf_url": "http://arxiv.org/pdf/2101.03252.pdf"
	},
	"600": {
		"title": "FlashP: An Analytical Pipeline for Real-time Forecasting of Time-Series\n  Relational Data",
		"creator": [
			"Yan, Shuyuan",
			"Ding, Bolin",
			"Guo, Wei",
			"Zhou, Jingren",
			"Wei, Zhewei",
			"Jiang, Xiaowei",
			"Xu, Sheng"
		],
		"subject": [
			"Computer Science - Databases",
			"Computer Science - Machine Learning"
		],
		"description": "  Interactive response time is important in analytical pipelines for users to\nexplore a sufficient number of possibilities and make informed business\ndecisions. We consider a forecasting pipeline with large volumes of\nhigh-dimensional time series data. Real-time forecasting can be conducted in\ntwo steps. First, we specify the part of data to be focused on and the measure\nto be predicted by slicing, dicing, and aggregating the data. Second, a\nforecasting model is trained on the aggregated results to predict the trend of\nthe specified measure. While there are a number of forecasting models\navailable, the first step is the performance bottleneck. A natural idea is to\nutilize sampling to obtain approximate aggregations in real time as the input\nto train the forecasting model. Our scalable real-time forecasting system\nFlashP (Flash Prediction) is built based on this idea, with two major\nchallenges to be resolved in this paper: first, we need to figure out how\napproximate aggregations affect the fitting of forecasting models, and\nforecasting results; and second, accordingly, what sampling algorithms we\nshould use to obtain these approximate aggregations and how large the samples\nare. We introduce a new sampling scheme, called GSW sampling, and analyze error\nbounds for estimating aggregations using GSW samples. We introduce how to\nconstruct compact GSW samples with the existence of multiple measures to be\nanalyzed. We conduct experiments to evaluate our solution and compare it with\nalternatives on real data.\n",
		"date": [
			"2021-01-09",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.03298",
		"pdf_url": "http://arxiv.org/pdf/2101.03298.pdf"
	},
	"601": {
		"title": "Joint Prediction of Remaining Useful Life and Failure Type of Train\n  Wheelsets: A Multi-task Learning Approach",
		"creator": "Wang, Weixin",
		"subject": [
			"Computer Science - Machine Learning",
			"Mathematics - Optimization and Control"
		],
		"description": "  The failures of train wheels account for disruptions of train operations and\neven a large portion of train derailments. Remaining useful life (RUL) of a\nwheelset measures the how soon the next failure will arrive, and the failure\ntype reveals how severe the failure will be. RUL prediction is a regression\ntask, whereas failure type is a classification task. In this paper, we propose\na multi-task learning approach to jointly accomplish these two tasks by using a\ncommon input space to achieve more desirable results. We develop a convex\noptimization formulation to integrate both least square loss and the negative\nmaximum likelihood of logistic regression, and model the joint sparsity as the\nL2/L1 norm of the model parameters to couple feature selection across tasks.\nThe experiment results show that our method outperforms the single task\nlearning method by 3% in prediction accuracy.\n",
		"date": [
			"2021-01-10",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.03497",
		"pdf_url": "http://arxiv.org/pdf/2101.03497.pdf"
	},
	"602": {
		"title": "A negotiating protocol for group decision support systems",
		"creator": "Sadji, Safia",
		"subject": "Computer Science - Multiagent Systems",
		"description": [
			"  Our contribution concerns interactive decision support systems for group\ndecision support. Through this study, we apply to implement a decisional\nprocess aiming to represent the multiplicity of actors, their diversity, their\nbehaviors and their interactions. In this context, we contribute to the design\nand development of a group decision support system. The system is modeled by a\nmulti agents system while exploiting a negotiation protocol based on mediation\nand concession. This protocol allows decision-makers to express their\npreferences using multicriteria analysis methods, mainly the method by total\naggregation AHP (Hierarchical Process Analysis) and the method by partial\naggregation PROMETHEE II .\n",
			"Comment: in French"
		],
		"date": "2021-01-10",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.03580",
		"pdf_url": "http://arxiv.org/pdf/2101.03580.pdf",
		"language": "fr"
	},
	"603": {
		"title": "Learning Augmented Index Policy for Optimal Service Placement at the\n  Network Edge",
		"creator": [
			"Xiong, Guojun",
			"Singh, Rahul",
			"Li, Jian"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Computer Science - Machine Learning"
		],
		"description": "  We consider the problem of service placement at the network edge, in which a\ndecision maker has to choose between $N$ services to host at the edge to\nsatisfy the demands of customers. Our goal is to design adaptive algorithms to\nminimize the average service delivery latency for customers. We pose the\nproblem as a Markov decision process (MDP) in which the system state is given\nby describing, for each service, the number of customers that are currently\nwaiting at the edge to obtain the service. However, solving this $N$-services\nMDP is computationally expensive due to the curse of dimensionality. To\novercome this challenge, we show that the optimal policy for a single-service\nMDP has an appealing threshold structure, and derive explicitly the Whittle\nindices for each service as a function of the number of requests from customers\nbased on the theory of Whittle index policy.\n  Since request arrival and service delivery rates are usually unknown and\npossibly time-varying, we then develop efficient learning augmented algorithms\nthat fully utilize the structure of optimal policies with a low learning\nregret. The first of these is UCB-Whittle, and relies upon the principle of\noptimism in the face of uncertainty. The second algorithm, Q-learning-Whittle,\nutilizes Q-learning iterations for each service by using a two time scale\nstochastic approximation. We characterize the non-asymptotic performance of\nUCB-Whittle by analyzing its learning regret, and also analyze the convergence\nproperties of Q-learning-Whittle. Simulation results show that the proposed\npolicies yield excellent empirical performance.\n",
		"date": [
			"2021-01-10",
			"2021-01-13"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.03641",
		"pdf_url": "http://arxiv.org/pdf/2101.03641.pdf"
	},
	"604": {
		"title": "The Gaze and Mouse Signal as additional Source for User Fingerprints in\n  Browser Applications",
		"creator": [
			"Fuhl, Wolfgang",
			"Sanamrad, Nikolai",
			"Kasneci, Enkelejda"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  In this work we inspect different data sources for browser fingerprints. We\nshow which disadvantages and limitations browser statistics have and how this\ncan be avoided with other data sources. Since human visual behavior is a rich\nsource of information and also contains person specific information, it is a\nvaluable source for browser fingerprints. However, human gaze acquisition in\nthe browser also has disadvantages, such as inaccuracies via webcam and the\nrestriction that the user must first allow access to the camera. However, it is\nalso known that the mouse movements and the human gaze correlate and therefore,\nthe mouse movements can be used instead of the gaze signal. In our evaluation\nwe show the influence of all possible combinations of the three information\nsources for user recognition and describe our simple approach in detail. The\ndata and the Matlab code can be downloaded here\nhttps://atreus.informatik.uni-tuebingen.de/seafile/d/8e2ab8c3fdd444e1a135/?p=%2FThe%20Gaze%20and%20Mouse%20Signal%20as%20additional%20Source%20...&mode=list\n",
		"date": [
			"2021-01-11",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.03793",
		"pdf_url": "http://arxiv.org/pdf/2101.03793.pdf"
	},
	"605": {
		"title": "On information projections between multivariate elliptical and\n  location-scale families",
		"creator": "Nielsen, Frank",
		"subject": "Computer Science - Information Theory",
		"description": [
			"  We study information projections with respect to statistical $f$-divergences\nbetween any two location-scale families. We consider a multivariate\ngeneralization of the location-scale families which includes the elliptical and\nthe spherical subfamilies. By using the action of the multivariate\nlocation-scale group, we show how to reduce the calculation of $f$-divergences\nbetween any two location-scale densities to canonical settings involving\nstandard densities, and derive thereof fast Monte Carlo estimators of\n$f$-divergences with good properties. Finally, we prove that the minimum\n$f$-divergence between a prescribed density of a location-scale family and\nanother location-scale family is independent of the prescribed location-scale\nparameter. We interpret geometrically this property.\n",
			"Comment: 23 pages, 2 figures"
		],
		"date": [
			"2021-01-11",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.03839",
		"pdf_url": "http://arxiv.org/pdf/2101.03839.pdf"
	},
	"606": {
		"title": "On Interfacing the Brain with Quantum Computers: An Approach to Listen\n  to the Logic of the Mind",
		"creator": "Miranda, Eduardo Reck",
		"subject": [
			"Computer Science - Emerging Technologies",
			"Computer Science - Sound",
			"Electrical Engineering and Systems Science - Audio and Speech Processing",
			"Quantum Physics"
		],
		"description": [
			"  This chapter presents a quantum computing-based approach to study and harness\nneuronal correlates of mental activity for the development of Brain-Computer\nInterface (BCI) systems. It introduces the notion of a logic of the mind, where\nneurophysiological data are encoded as logical expressions representing mental\nactivity. Effective logical expressions are likely to be extensive, involving\ndozens of variables. Large expressions require considerable computational power\nto be processed. This is problematic for BCI applications because they require\nfast reaction times to execute sequences of commands. Quantum computers hold\nmuch promise in terms of processing speed for some problems, including those\ninvolving logical expressions. Hence, we propose to use quantum computers to\nprocess the logic of the mind. The chapter begins with an introduction to BCI\nand the electroencephalogram, which is the neurophysiological signal that is\nnormally used in BCI. Then, it briefly discusses how the EEG corresponds to\nmental states, followed by an introduction to the logic of the mind. After\nthat, there is an overview of quantum computing, focusing on the basics deemed\nnecessary to understand how it processes logical expressions. An example of a\nBCI system is presented. In a nutshell, the system reads the EEG and builds\nlogical expressions, which are sent to a quantum computer to solve them. In\nturn, the system converts the results into sounds by means of a bespoke\nsynthesiser. Essentially, the BCI here is a musical instrument controlled by\nthe mind of the player. Our BCI is a proof-of-concept aimed at demonstrating\nhow quantum computing may support the development of sophisticated BCI systems.\nThe remaining of the chapter is devoted to technical and practical\nconsiderations on the limitations of current quantum computing hardware\ntechnology and scalability of the system.\n",
			"Comment: 40 pages, 35 figures, pre-publication draft chapter to appear in a\n  book; typos corrected"
		],
		"date": [
			"2020-12-22",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.03887",
		"pdf_url": "http://arxiv.org/pdf/2101.03887.pdf"
	},
	"607": {
		"title": "Learning to Ignore: Fair and Task Independent Representations",
		"creator": [
			"Boedi, Linda H.",
			"Grabner, Helmut"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  Training fair machine learning models, aiming for their interpretability and\nsolving the problem of domain shift has gained a lot of interest in the last\nyears. There is a vast amount of work addressing these topics, mostly in\nseparation. In this work we show that they can be seen as a common framework of\nlearning invariant representations. The representations should allow to predict\nthe target while at the same time being invariant to sensitive attributes which\nsplit the dataset into subgroups. Our approach is based on the simple\nobservation that it is impossible for any learning algorithm to differentiate\nsamples if they have the same feature representation. This is formulated as an\nadditional loss (regularizer) enforcing a common feature representation across\nsubgroups. We apply it to learn fair models and interpret the influence of the\nsensitive attribute. Furthermore it can be used for domain adaptation,\ntransferring knowledge and learning effectively from very few examples. In all\napplications it is essential not only to learn to predict the target, but also\nto learn what to ignore.\n",
		"date": [
			"2021-01-11",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.04047",
		"pdf_url": "http://arxiv.org/pdf/2101.04047.pdf"
	},
	"608": {
		"title": "Lesion2Vec: Deep Metric Learning for Few-Shot Multiple Lesions\n  Recognition in Wireless Capsule Endoscopy Video",
		"creator": [
			"Adewole, Sodiq",
			"Fernandez, Philip",
			"Yeghyayan, Michelle",
			"Jablonski, James",
			"Copland, Andrew",
			"Porter, Michael",
			"Syed, Sana",
			"Brown, Donald"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Effective and rapid detection of lesions in the Gastrointestinal tract is\ncritical to gastroenterologist's response to some life-threatening diseases.\nWireless Capsule Endoscopy (WCE) has revolutionized traditional endoscopy\nprocedure by allowing gastroenterologists visualize the entire GI tract\nnon-invasively. Once the tiny capsule is swallowed, it sequentially capture\nimages of the GI tract at about 2 to 6 frames per second (fps). A single video\ncan last up to 8 hours producing between 30,000 to 100,000 images. Automating\nthe detection of frames containing specific lesion in WCE video would relieve\ngastroenterologists the arduous task of reviewing the entire video before\nmaking diagnosis. While the WCE produces large volume of images, only about 5\\%\nof the frames contain lesions that aid the diagnosis process. Convolutional\nNeural Network (CNN) based models have been very successful in various image\nclassification tasks. However, they suffer excessive parameters, are sample\ninefficient and rely on very large amount of training data. Deploying a CNN\nclassifier for lesion detection task will require time-to-time fine-tuning to\ngeneralize to any unforeseen category. In this paper, we propose a metric-based\nlearning framework followed by a few-shot lesion recognition in WCE data.\nMetric-based learning is a meta-learning framework designed to establish\nsimilarity or dissimilarity between concepts while few-shot learning (FSL) aims\nto identify new concepts from only a small number of examples. We train a\nfeature extractor to learn a representation for different small bowel lesions\nusing metric-based learning. At the testing stage, the category of an unseen\nsample is predicted from only a few support examples, thereby allowing the\nmodel to generalize to a new category that has never been seen before. We\ndemonstrated the efficacy of this method on real patient capsule endoscopy\ndata.\n",
		"date": [
			"2021-01-11",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.04240",
		"pdf_url": "http://arxiv.org/pdf/2101.04240.pdf"
	},
	"609": {
		"title": "Ancillary services in Great Britain during the COVID-19 lockdown: a\n  glimpse of the carbon-free future",
		"creator": [
			"Badesa, Luis",
			"Strbac, Goran",
			"Magill, Matt",
			"Stojkovska, Biljana"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": "  The COVID-19 pandemic led to partial or total lockdowns in several countries\nduring the first half of 2020, which in turn caused a depressed electricity\ndemand. In Great Britain (GB), this low demand combined with large renewable\noutput at times, created conditions that were not expected until renewable\ncapacity increases to meet emissions targets in coming years. The GB system\nexperienced periods of very high instantaneous penetration of non-synchronous\nrenewables, compromising system stability due to the lack of inertia in the\ngrid. In this paper, a detailed analysis of the consequences of the lockdown on\nthe GB electricity system is provided, focusing on the ancillary services\nprocured to guarantee stability. Ancillary-services costs increased by\n{\\pounds}200m in the months of May to July 2020 compared to the same period in\n2019 (a threefold increase), highlighting the importance of ancillary services\nin low-carbon systems. Furthermore, a frequency-secured scheduling model is\nused in the present paper to showcase the future trends that GB is expected to\nexperience, as penetration of renewables increases on the road to net-zero\nemissions by 2050. Several sensitivities are considered, demonstrating that the\nshare of total operating costs represented by ancillary services could reach\n35%.\n",
		"date": [
			"2021-01-12",
			"2021-01-20"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.04387",
			"Applied Energy 285 (2021) 116500",
			"doi:10.1016/j.apenergy.2021.116500"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.04387.pdf"
	},
	"610": {
		"title": "Time and Communication Complexity of Leader Election in Anonymous\n  Networks",
		"creator": [
			"Kowalski, Dariusz R.",
			"Mosteiro, Miguel A."
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"68W15"
		],
		"description": "  We study the problem of randomized Leader Election in synchronous distributed\nnetworks with indistinguishable nodes. We consider algorithms that work on\nnetworks of arbitrary topology in two settings, depending on whether the size\nof the network, i.e., the number of nodes, is known or not. In the former\nsetting, we present a new Leader Election protocol that improves over previous\nwork by lowering message complexity and making it close to a lower bound by a\nfactor of $\\tilde{O}(\\sqrt{t_{mix}\\sqrt{\\Phi}})$, where $\\Phi$ is the\nconductance and $t_{mix}$ is the mixing time of the network graph. We then show\nthat lacking the network size no Leader Election algorithm can guarantee that\nthe election is final with constant probability, even with unbounded\ncommunication. Hence, we further classify the problem as Irrevocable Leader\nElection (the classic one, requiring knowledge of n - as is our first protocol)\nor Revocable Leader Election, and present a new polynomial time and message\ncomplexity Revocable Leader Election algorithm in the setting without knowledge\nof network size. We analyze time and message complexity of our protocols in the\nCongest model of communication.\n",
		"date": [
			"2021-01-12",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.04400",
		"pdf_url": "http://arxiv.org/pdf/2101.04400.pdf"
	},
	"611": {
		"title": "Learning Intuitive Physics with Multimodal Generative Models",
		"creator": [
			"Rezaei-Shoshtari, Sahand",
			"Hogan, Francois Robert",
			"Jenkin, Michael",
			"Meger, David",
			"Dudek, Gregory"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Predicting the future interaction of objects when they come into contact with\ntheir environment is key for autonomous agents to take intelligent and\nanticipatory actions. This paper presents a perception framework that fuses\nvisual and tactile feedback to make predictions about the expected motion of\nobjects in dynamic scenes. Visual information captures object properties such\nas 3D shape and location, while tactile information provides critical cues\nabout interaction forces and resulting object motion when it makes contact with\nthe environment. Utilizing a novel See-Through-your-Skin (STS) sensor that\nprovides high resolution multimodal sensing of contact surfaces, our system\ncaptures both the visual appearance and the tactile properties of objects. We\ninterpret the dual stream signals from the sensor using a Multimodal\nVariational Autoencoder (MVAE), allowing us to capture both modalities of\ncontacting objects and to develop a mapping from visual to tactile interaction\nand vice-versa. Additionally, the perceptual system can be used to infer the\noutcome of future physical interactions, which we validate through simulated\nand real-world experiments in which the resting state of an object is predicted\nfrom given initial conditions.\n",
			"Comment: AAAI 2021"
		],
		"date": [
			"2021-01-12",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.04454",
		"pdf_url": "http://arxiv.org/pdf/2101.04454.pdf"
	},
	"612": {
		"title": "Resolution-invariant Person ReID Based on Feature Transformation and\n  Self-weighted Attention",
		"creator": [
			"Zhang, Ziyue",
			"Jiang, Shuai",
			"Huang, Congzhentao",
			"Da Xu, Richard Yi"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Person Re-identification (ReID) is a critical computer vision task which aims\nto match the same person in images or video sequences. Most current works focus\non settings where the resolution of images is kept the same. However, the\nresolution is a crucial factor in person ReID, especially when the cameras are\nat different distances from the person or the camera's models are different\nfrom each other. In this paper, we propose a novel two-stream network with a\nlightweight resolution association ReID feature transformation (RAFT) module\nand a self-weighted attention (SWA) ReID module to evaluate features under\ndifferent resolutions. RAFT transforms the low resolution features to\ncorresponding high resolution features. SWA evaluates both features to get\nweight factors for the person ReID. Both modules are jointly trained to get a\nresolution-invariant representation. Extensive experiments on five benchmark\ndatasets show the effectiveness of our method. For instance, we achieve Rank-1\naccuracy of 43.3% and 83.2% on CAVIAR and MLR-CUHK03, outperforming the\nstate-of-the-art.\n",
		"date": [
			"2021-01-12",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.04544",
		"pdf_url": "http://arxiv.org/pdf/2101.04544.pdf"
	},
	"613": {
		"title": "The audiovisual resource as a pedagogical tools in times of covid 19. An\n  empirical analysis of its efficiency",
		"creator": [
			"Basignana, Juan Rodriguez",
			"Asuaga, Carolina"
		],
		"subject": "Computer Science - Computers and Society",
		"description": [
			"  The global pandemic caused by the COVID virus led universities to a change in\nthe way they teach classes, moving to a distance mode. The subject \"Modelos y\nSistemas de Costos \" of the CPA career of the Faculty of Economic Sciences and\nAdministration of the Universidad de la Rep\\'ublica (Uruguay) incorporated\naudiovisual material as a pedagogical resource consisting of videos recorded by\na group of well experienced and highest ranked teachers. The objective of this\nresearch is to analyze the efficiency of the audiovisual resources used in the\ncourse, seeking to answer whether the visualizations of said materials follow\ncertain patterns of behavior. 13 videos were analyzed, which had 16,340 views,\ncoming from at least 1,486 viewers. It was obtained that the visualizations\ndepend on the proximity to the test dates and that although the visualization\ntime has a curve that accompanies the duration of the videos, it is limited and\nthe average number of visualizations is 10 minutes and 4 seconds. It is also\nconcluded that the efficiency in viewing time increases in short videos.\n",
			"Comment: in Spanish, Journal of Internacional Institute of Cost 2020"
		],
		"date": "2021-01-10",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.04569",
			"issus 38 2020 100:118"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.04569.pdf",
		"language": "es"
	},
	"614": {
		"title": "Directed Hybrid Random Networks Mixing Preferential Attachment with\n  Uniform Attachment Mechanisms",
		"creator": [
			"Wang, Tiandong",
			"Zhang, Panpan"
		],
		"subject": [
			"Computer Science - Social and Information Networks",
			"Mathematics - Probability",
			"Statistics - Other Statistics",
			"05C80, 62G32, 05C07"
		],
		"description": "  Motivated by the complexity of network data, we propose a directed hybrid\nrandom network that mixes preferential attachment (PA) rules with uniform\nattachment (UA) rules. When a new edge is created, with probability $p\\in\n[0,1]$, it follows the PA rule. Otherwise, this new edge is added between two\nuniformly chosen nodes. Such mixture makes the in- and out-degrees of a fixed\nnode grow at a slower rate, compared to the pure PA case, thus leading to\nlighter distributional tails. Useful inference methods for the proposed hybrid\nmodel are then provided and applied to both synthetic and real datasets. We see\nthat with extra flexibility given by the parameter $p$, the hybrid random\nnetwork provides a better fit to real-world scenarios, where lighter tails from\nin- and out-degrees are observed.\n",
		"date": [
			"2021-01-06",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.04611",
		"pdf_url": "http://arxiv.org/pdf/2101.04611.pdf"
	},
	"615": {
		"title": "Forecasting blood sugar levels in Diabetes with univariate algorithms",
		"creator": "Rodriguez, Ignacio",
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  AI procedures joined with wearable gadgets can convey exact transient blood\nglucose level forecast models. Also, such models can learn customized\nglucose-insulin elements dependent on the sensor information gathered by\nobserving a few parts of the physiological condition and every day movement of\na person. Up to this point, the predominant methodology for creating\ninformation driven forecast models was to gather \"however much information as\ncould be expected\" to help doctors and patients ideally change treatment. The\ngoal of this work was to examine the base information assortment, volume, and\nspeed needed to accomplish exact individual driven diminutive term expectation\nmodels. We built up a progression of these models utilizing distinctive AI time\narrangement guaging strategies that are appropriate for execution inside a\nwearable processor. We completed a broad aloof patient checking concentrate in\ngenuine conditions to fabricate a strong informational collection. The\nexamination included a subset of type-1 diabetic subjects wearing a glimmer\nglucose checking framework. We directed a relative quantitative assessment of\nthe presentation of the created information driven expectation models and\ncomparing AI methods. Our outcomes show that precise momentary forecast can be\naccomplished by just checking interstitial glucose information over a brief\ntimeframe and utilizing a low examining recurrence. The models created can\nanticipate glucose levels inside a 15-minute skyline with a normal mistake as\nlow as 15.43 mg/dL utilizing just 24 memorable qualities gathered inside a time\nof 6 hours, and by expanding the inspecting recurrence to incorporate 72\nqualities, the normal blunder is limited to 10.15 mg/dL. Our forecast models\nare reasonable for execution inside a wearable gadget, requiring the base\nequipment necessities while simultaneously accomplishing high expectation\nprecision.\n",
			"Comment: 8 pages, 1 figure"
		],
		"date": [
			"2021-01-12",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.04770",
		"pdf_url": "http://arxiv.org/pdf/2101.04770.pdf"
	},
	"616": {
		"title": "A reusable pipeline for large-scale fiber segmentation on unidirectional\n  fiber beds using fully convolutional neural networks",
		"creator": [
			"de Siqueira, Alexandre Fioravante",
			"Ushizima, Daniela Mayumi",
			"van der Walt, Stéfan"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  Fiber-reinforced ceramic-matrix composites are advanced materials resistant\nto high temperatures, with application to aerospace engineering. Their analysis\ndepends on the detection of embedded fibers, with semi-supervised techniques\nusually employed to separate fibers within the fiber beds. Here we present an\nopen computational pipeline to detect fibers in ex-situ X-ray computed\ntomography fiber beds. To separate the fibers in these samples, we tested four\ndifferent architectures of fully convolutional neural networks. When comparing\nour neural network approach to a semi-supervised one, we obtained Dice and\nMatthews coefficients greater than $92.28 \\pm 9.65\\%$, reaching up to $98.42\n\\pm 0.03 \\%$, showing that the network results are close to the\nhuman-supervised ones in these fiber beds, in some cases separating fibers that\nhuman-curated algorithms could not find. The software we generated in this\nproject is open source, released under a permissive license, and can be freely\nadapted and re-used in other domains. All data and instructions on how to\ndownload and use it are also available.\n",
			"Comment: 26 pages, 9 figures"
		],
		"date": [
			"2021-01-12",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.04823",
		"pdf_url": "http://arxiv.org/pdf/2101.04823.pdf"
	},
	"617": {
		"title": "A Recurrent Neural Network Approach to Roll Estimation for Needle\n  Steering",
		"creator": [
			"Emerson, Maxwell",
			"Ferguson, James M.",
			"Ertop, Tayfun Efe",
			"Rox, Margaret",
			"Granna, Josephine",
			"Lester, Michael",
			"Maldonado, Fabien",
			"Gillaspie, Erin A.",
			"Alterovitz, Ron",
			"III., Robert J. Webster",
			"Kuntz, Alan"
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Signal Processing",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": "  Steerable needles are a promising technology for delivering targeted\ntherapies in the body in a minimally-invasive fashion, as they can curve around\nanatomical obstacles and hone in on anatomical targets. In order to accurately\nsteer them, controllers must have full knowledge of the needle tip's\norientation. However, current sensors either do not provide full orientation\ninformation or interfere with the needle's ability to deliver therapy. Further,\ntorsional dynamics can vary and depend on many parameters making steerable\nneedles difficult to accurately model, limiting the effectiveness of\ntraditional observer methods. To overcome these limitations, we propose a\nmodel-free, learned-method that leverages LSTM neural networks to estimate the\nneedle tip's orientation online. We validate our method by integrating it into\na sliding-mode controller and steering the needle to targets in gelatin and ex\nvivo ovine brain tissue. We compare our method's performance against an\nExtended Kalman Filter, a model-based observer, achieving significantly lower\ntargeting errors.\n",
		"date": "2021-01-12",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.04856",
		"pdf_url": "http://arxiv.org/pdf/2101.04856.pdf"
	},
	"618": {
		"title": "Crooked Indifferentiability Revisited",
		"creator": [
			"Bhattacharyya, Rishiraj",
			"Nandi, Mridul",
			"Raychaudhuri, Anik"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": "  In CRYPTO 2018, Russell et al introduced the notion of crooked\nindifferentiability to analyze the security of a hash function when the\nunderlying primitive is subverted. They showed that the $n$-bit to $n$-bit\nfunction implemented using enveloped XOR construction (\\textsf{EXor}) with\n$3n+1$ many $n$-bit functions and $3n^2$-bit random initial vectors (iv) can be\nproven secure asymptotically in the crooked indifferentiability setting.\n  -We identify several major issues and gaps in the proof by Russel et al, We\nshow that their proof can achieve security only when the adversary is\nrestricted to make queries related to a single message.\n  - We formalize new technique to prove crooked indifferentiability without\nsuch restrictions. Our technique can handle function dependent subversion. We\napply our technique to provide a revised proof for the \\textsf{EXor}\nconstruction.\n  - We analyze crooked indifferentiability of the classical sponge\nconstruction. We show, using a simple proof idea, the sponge construction is a\ncrooked-indifferentiable hash function using only $n$-bit random iv. This is a\nquadratic improvement over the {\\sf EXor} construction and solves the main open\nproblem of Russel et al.\n",
		"date": [
			"2021-01-13",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.04888",
		"pdf_url": "http://arxiv.org/pdf/2101.04888.pdf"
	},
	"619": {
		"title": "A quasi-conservative DG-ALE method for multi-component flows using the\n  non-oscillatory kinetic flux",
		"creator": [
			"Luo, Dongmi",
			"Li, Shiyi",
			"Huang, Weizhang",
			"Qiu, Jianxian",
			"Chen, Yibing"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"Computer Science - Computational Engineering, Finance, and Science"
		],
		"description": [
			"  A high-order quasi-conservative discontinuous Galerkin (DG) method is\nproposed for the numerical simulation of compressible multi-component flows. A\ndistinct feature of the method is a predictor-corrector strategy to define the\ngrid velocity. A Lagrangian mesh is first computed based on the flow velocity\nand then used as an initial mesh in a moving mesh method (the moving mesh\npartial differential equation or MMPDE method ) to improve its quality. The\nfluid dynamic equations are discretized in the direct arbitrary\nLagrangian-Eulerian framework using DG elements and the non-oscillatory kinetic\nflux while the species equation is discretized using a quasi-conservative DG\nscheme to avoid numerical oscillations near material interfaces. A selection of\none- and two-dimensional examples are presented to verify the convergence order\nand the constant-pressure-velocity preservation property of the method. They\nalso demonstrate that the incorporation of the Lagrangian meshing with the\nMMPDE moving mesh method works well to concentrate mesh points in regions of\nshocks and material interfaces.\n",
			"Comment: 44 pages, 71 figures"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.04897",
		"pdf_url": "http://arxiv.org/pdf/2101.04897.pdf"
	},
	"620": {
		"title": "Learning to Anticipate Egocentric Actions by Imagination",
		"creator": [
			"Wu, Yu",
			"Zhu, Linchao",
			"Wang, Xiaohan",
			"Yang, Yi",
			"Wu, Fei"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Anticipating actions before they are executed is crucial for a wide range of\npractical applications, including autonomous driving and robotics. In this\npaper, we study the egocentric action anticipation task, which predicts future\naction seconds before it is performed for egocentric videos. Previous\napproaches focus on summarizing the observed content and directly predicting\nfuture action based on past observations. We believe it would benefit the\naction anticipation if we could mine some cues to compensate for the missing\ninformation of the unobserved frames. We then propose to decompose the action\nanticipation into a series of future feature predictions. We imagine how the\nvisual feature changes in the near future and then predicts future action\nlabels based on these imagined representations. Differently, our ImagineRNN is\noptimized in a contrastive learning way instead of feature regression. We\nutilize a proxy task to train the ImagineRNN, i.e., selecting the correct\nfuture states from distractors. We further improve ImagineRNN by residual\nanticipation, i.e., changing its target to predicting the feature difference of\nadjacent frames instead of the frame content. This promotes the network to\nfocus on our target, i.e., the future action, as the difference between\nadjacent frame features is more important for forecasting the future. Extensive\nexperiments on two large-scale egocentric action datasets validate the\neffectiveness of our method. Our method significantly outperforms previous\nmethods on both the seen test set and the unseen test set of the EPIC Kitchens\nAction Anticipation Challenge.\n",
			"Comment: Accepted to IEEE Transactions on Image Processing (TIP)"
		],
		"date": [
			"2021-01-13",
			"2021-01-19"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.04924",
			"IEEE Transactions on Image Processing, vol. 30, pp. 1143-1152,\n  2021",
			"doi:10.1109/TIP.2020.3040521"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.04924.pdf"
	},
	"621": {
		"title": "Proposal for Adding Useful Features to Petri-Net Model Checkers",
		"creator": "Garavel, Hubert",
		"subject": "Computer Science - Logic in Computer Science",
		"description": "  Solutions proposed for the longstanding problem of automatic decomposition of\nPetri nets into concurrent processes, as well as methods developed in Grenoble\nfor the automatic conversion of safe Petri nets to NUPNs (Nested-Unit Petri\nNets), require certain properties to be computed on Petri nets. We notice that,\nalthough these properties are theoretically interesting and practically useful,\nthey are not currently implemented in mainstream Petri net tools. Taking into\naccount such properties would open fruitful research directions for tool\ndevelopers, and new perspectives for the Model Checking Contest as well.\n",
		"date": [
			"2021-01-13",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05024",
		"pdf_url": "http://arxiv.org/pdf/2101.05024.pdf"
	},
	"622": {
		"title": "Round-Competitive Algorithms for Uncertainty Problems with Parallel\n  Queries",
		"creator": [
			"Erlebach, Thomas",
			"Hoffmann, Michael",
			"de Lima, Murilo S."
		],
		"subject": "Computer Science - Data Structures and Algorithms",
		"description": [
			"  The area of computing with uncertainty considers problems where some\ninformation about the input elements is uncertain, but can be obtained using\nqueries. For example, instead of the weight of an element, we may be given an\ninterval that is guaranteed to contain the weight, and a query can be performed\nto reveal the weight. While previous work has considered models where queries\nare asked either sequentially (adaptive model) or all at once (non-adaptive\nmodel), and the goal is to minimize the number of queries that are needed to\nsolve the given problem, we propose and study a new model where $k$ queries can\nbe made in parallel in each round, and the goal is to minimize the number of\nquery rounds. We use competitive analysis and present upper and lower bounds on\nthe number of query rounds required by any algorithm in comparison with the\noptimal number of query rounds. Given a set of uncertain elements and a family\nof $m$ subsets of that set, we present an algorithm for determining the value\nof the minimum of each of the subsets that requires at most $(2+\\varepsilon)\n\\cdot \\mathrm{opt}_k+\\mathrm{O}\\left(\\frac{1}{\\varepsilon} \\cdot \\lg m\\right)$\nrounds for every $0<\\varepsilon<1$, where $\\mathrm{opt}_k$ is the optimal\nnumber of rounds, as well as nearly matching lower bounds. For the problem of\ndetermining the $i$-th smallest value and identifying all elements with that\nvalue in a set of uncertain elements, we give a $2$-round-competitive\nalgorithm. We also show that the problem of sorting a family of sets of\nuncertain elements admits a $2$-round-competitive algorithm and this is the\nbest possible.\n",
			"Comment: An extended abstract is to appear in the proceedings of the 38th\n  International Symposium on Theoretical Aspects of Computer Science (STACS\n  2021); [v2] minor fixes and typesetting"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05032",
		"pdf_url": "http://arxiv.org/pdf/2101.05032.pdf"
	},
	"623": {
		"title": "Publishing patterns reflect political polarization in news media",
		"creator": [
			"Hagar, Nick",
			"Wachs, Johannes",
			"Horvát, Emőke-Ágnes"
		],
		"subject": [
			"Computer Science - Social and Information Networks",
			"Computer Science - Computers and Society"
		],
		"description": "  Digital news outlets rely on a variety of outside contributors, from\nfreelance journalists, to political commentators, to executives and\npoliticians. These external dependencies create a network among news outlets,\ntraced along the contributors they share. Using connections between outlets, we\ndemonstrate how contributors' publishing trajectories tend to align with outlet\npolitical leanings. We also show how polarized clustering of outlets translates\nto differences in the topics of news covered and the style and tone of articles\npublished. In addition, we demonstrate how contributors who cross partisan\ndivides tend to focus on less explicitly political topics. This work addresses\nan important gap in the media polarization literature, by highlighting how\nstructural factors on the production side of news media create an ecosystem\nshaped by political leanings, independent of the priorities of any one person\nor organization.\n",
		"date": [
			"2021-01-13",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05044",
		"pdf_url": "http://arxiv.org/pdf/2101.05044.pdf"
	},
	"624": {
		"title": "A novel approach to fluid-structure interaction simulations involving\n  large translation and contact",
		"creator": [
			"Hilger, Daniel",
			"Hosters, Norbert",
			"Key, Fabian",
			"Elgeti, Stefanie",
			"Behr, Marek"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"Computer Science - Computational Engineering, Finance, and Science"
		],
		"description": "  In this work, we present a novel method for the mesh update in flow problems\nwith moving boundaries, the phantom domain deformation mesh update method\n(PD-DMUM). The PD-DMUM is designed to avoid remeshing; even in the event of\nlarge, unidirectional displacements of boundaries. The method combines the\nconcept of two mesh adaptation approaches: (1) The virtual ring shear-slip mesh\nupdatemethod (VR-SSMUM); and (2) the elastic mesh update method (EMUM). As in\nthe VR-SSMUM, the PD-DMUMextends the fluid domain by a phantom domain; the\nPD-DMUM can thus locally adapt the element density. Combined with the EMUM, the\nPD-DMUMallows the consideration of arbitrary boundary movements. In this work,\nwe apply the PD-DMUM in two test cases. Within the first test case, we validate\nthe PD-DMUM in a 2D Poiseuille flow on a moving background mesh. Subsequently\nthe fluid-structure interaction (FSI) problem in the second test case serves as\na proof of concept. More, we stress the advantages of the novel method with\nregard to conventional mesh update approaches.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05090",
		"pdf_url": "http://arxiv.org/pdf/2101.05090.pdf"
	},
	"625": {
		"title": "MRI Images, Brain Lesions and Deep Learning",
		"creator": [
			"Castillo, Darwin",
			"Lakshminarayanan, Vasudevan",
			"Rodriguez-Alvarez, Maria J."
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"Quantitative Biology - Neurons and Cognition",
			"A.1",
			"I.2",
			"I.4",
			"I.3",
			"H.m",
			"E.m"
		],
		"description": [
			"  Medical brain image analysis is a necessary step in Computer Assisted /Aided\nDiagnosis (CAD) systems. Advancements in both hardware and software in the past\nfew years have led to improved segmentation and classification of various\ndiseases. In the present work, we review the published literature on systems\nand algorithms that allow for classification, identification, and detection of\nWhite Matter Hyperintensities (WMHs) of brain MRI images specifically in cases\nof ischemic stroke and demyelinating diseases. For the selection criteria, we\nused the bibliometric networks. Out of a total of 140 documents we selected 38\narticles that deal with the main objectives of this study. Based on the\nanalysis and discussion of the revised documents, there is constant growth in\nthe research and proposal of new models of deep learning to achieve the highest\naccuracy and reliability of the segmentation of ischemic and demyelinating\nlesions. Models with indicators (Dice Score, DSC: 0.99) were found, however\nwith little practical application due to the uses of small datasets and lack of\nreproducibility. Therefore, the main conclusion is to establish\nmultidisciplinary research groups to overcome the gap between CAD developments\nand their complete utilization in the clinical environment.\n",
			"Comment: Submitted to: Computer Programs and Methods in Biomedicine update\n  (2021)"
		],
		"date": [
			"2021-01-13",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05091",
		"pdf_url": "http://arxiv.org/pdf/2101.05091.pdf"
	},
	"626": {
		"title": "High-resolution agent-based modeling of COVID-19 spreading in a small\n  town",
		"creator": [
			"Truszkowska, Agnieszka",
			"Behring, Brandon",
			"Hasanyan, Jalil",
			"Zino, Lorenzo",
			"Butail, Sachit",
			"Caroppo, Emanuele",
			"Jiang, Zhong-Ping",
			"Rizzo, Alessandro",
			"Porfiri, Maurizio"
		],
		"subject": [
			"Quantitative Biology - Populations and Evolution",
			"Electrical Engineering and Systems Science - Systems and Control",
			"Quantitative Biology - Quantitative Methods"
		],
		"description": [
			"  Amid the ongoing COVID-19 pandemic, public health authorities and the general\npopulation are striving to achieve a balance between safety and normalcy. Ever\nchanging conditions call for the development of theory and simulation tools to\nfinely describe multiple strata of society while supporting the evaluation of\n\"what-if\" scenarios. Particularly important is to assess the effectiveness of\npotential testing approaches and vaccination strategies. Here, an agent-based\nmodeling platform is proposed to simulate the spreading of COVID-19 in small\ntowns and cities, with a single-individual resolution. The platform is\nvalidated on real data from New Rochelle, NY -- one of the first outbreaks\nregistered in the United States. Supported by expert knowledge and informed by\nreported data, the model incorporates detailed elements of the spreading within\na statistically realistic population. Along with pertinent functionality such\nas testing, treatment, and vaccination options, the model accounts for the\nburden of other illnesses with symptoms similar to COVID-19. Unique to the\nmodel is the possibility to explore different testing approaches -- in\nhospitals or drive-through facilities -- and vaccination strategies that could\nprioritize vulnerable groups. Decision making by public authorities could\nbenefit from the model, for its fine-grain resolution, open-source nature, and\nwide range of features.\n",
			"Comment: 44 pages (including 16 of Supplementary Information). Published\n  online in Advanced Theory and Simulations"
		],
		"date": [
			"2021-01-13",
			"2021-01-19"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05171",
			"doi:10.1002/adts.202000277"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05171.pdf"
	},
	"627": {
		"title": "Neural Volume Rendering: NeRF And Beyond",
		"creator": [
			"Dellaert, Frank",
			"Yen-Chen, Lin"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Graphics"
		],
		"description": [
			"  Besides the COVID-19 pandemic and political upheaval in the US, 2020 was also\nthe year in which neural volume rendering exploded onto the scene, triggered by\nthe impressive NeRF paper by Mildenhall et al. (2020). Both of us have tried to\ncapture this excitement, Frank on a blog post (Dellaert, 2020) and Yen-Chen in\na Github collection (Yen-Chen, 2020). This note is an annotated bibliography of\nthe relevant papers, and we posted the associated bibtex file on the\nrepository.\n",
			"Comment: Blog: https://dellaert.github.io/NeRF/ Bibtex:\n  https://github.com/yenchenlin/awesome-NeRF"
		],
		"date": [
			"2020-12-17",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05204",
		"pdf_url": "http://arxiv.org/pdf/2101.05204.pdf"
	},
	"628": {
		"title": "Similarity-based prediction for channel mapping and user positioning",
		"creator": "Magoarou, Luc Le",
		"subject": [
			"Electrical Engineering and Systems Science - Signal Processing",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  In a wireless network, gathering information at the base station about mobile\nusers based only on uplink channel measurements is an interesting challenge.\nIndeed, accessing the users locations and predicting their downlink channels\nwould be particularly useful in order to optimize the network efficiency. In\nthis paper, a supervised machine learning approach addressing these tasks in an\nunified way is proposed. It relies on a labeled database that can be acquired\nin a simple way by the base station while operating. The proposed regression\nmethod can be seen as a computationally efficient two layers neural network\ninitialized with a non-parametric estimator. It is illustrated on realistic\nchannel data, both for the positioning and channel mapping tasks, achieving\nbetter results than previously proposed approaches, at a lower cost.\n",
			"Comment: IEEE Communications Letters, Institute of Electrical and Electronics\n  Engineers, In press"
		],
		"date": [
			"2020-12-02",
			"2021-01-14"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05217",
		"pdf_url": "http://arxiv.org/pdf/2101.05217.pdf"
	},
	"629": {
		"title": "Real or Virtual? Using Brain Activity Patterns to differentiate Attended\n  Targets during Augmented Reality Scenarios",
		"creator": [
			"Vortmann, Lisa-Marie",
			"Schwenke, Leonid",
			"Putze, Felix"
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Machine Learning"
		],
		"description": "  Augmented Reality is the fusion of virtual components and our real\nsurroundings. The simultaneous visibility of generated and natural objects\noften requires users to direct their selective attention to a specific target\nthat is either real or virtual. In this study, we investigated whether this\ntarget is real or virtual by using machine learning techniques to classify\nelectroencephalographic (EEG) data collected in Augmented Reality scenarios. A\nshallow convolutional neural net classified 3 second data windows from 20\nparticipants in a person-dependent manner with an average accuracy above 70\\%\nif the testing data and training data came from different trials.\nPerson-independent classification was possible above chance level for 6 out of\n20 participants. Thus, the reliability of such a Brain-Computer Interface is\nhigh enough for it to be treated as a useful input mechanism for Augmented\nReality applications.\n",
		"date": "2021-01-12",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05272",
		"pdf_url": "http://arxiv.org/pdf/2101.05272.pdf"
	},
	"630": {
		"title": "AutoDS: Towards Human-Centered Automation of Data Science",
		"creator": [
			"Wang, Dakuo",
			"Andres, Josh",
			"Weisz, Justin",
			"Oduor, Erick",
			"Dugan, Casey"
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Machine Learning"
		],
		"description": "  Data science (DS) projects often follow a lifecycle that consists of\nlaborious tasks for data scientists and domain experts (e.g., data exploration,\nmodel training, etc.). Only till recently, machine learning(ML) researchers\nhave developed promising automation techniques to aid data workers in these\ntasks. This paper introduces AutoDS, an automated machine learning (AutoML)\nsystem that aims to leverage the latest ML automation techniques to support\ndata science projects. Data workers only need to upload their dataset, then the\nsystem can automatically suggest ML configurations, preprocess data, select\nalgorithm, and train the model. These suggestions are presented to the user via\na web-based graphical user interface and a notebook-based programming user\ninterface.\n  We studied AutoDS with 30 professional data scientists, where one group used\nAutoDS, and the other did not, to complete a data science project. As expected,\nAutoDS improves productivity; Yet surprisingly, we find that the models\nproduced by the AutoDS group have higher quality and less errors, but lower\nhuman confidence scores. We reflect on the findings by presenting design\nimplications for incorporating automation techniques into human work in the\ndata science lifecycle.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05273",
			"doi:10.1145/3411764.3445526"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05273.pdf"
	},
	"631": {
		"title": "Proxemics and Social Interactions in an Instrumented Virtual Reality\n  Workshop",
		"creator": [
			"Williamson, Julie",
			"Li, Jie",
			"Vinayagamoorthy, Vinoba",
			"Shamma, David A.",
			"Cesar, Pablo"
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"H.5.m",
			"J.4"
		],
		"description": [
			"  Virtual environments (VEs) can create collaborative and social spaces, which\nare increasingly important in the face of remote work and travel reduction.\nRecent advances, such as more open and widely available platforms, create new\npossibilities to observe and analyse interaction in VEs. Using a custom\ninstrumented build of Mozilla Hubs to measure position and orientation, we\nconducted an academic workshop to facilitate a range of typical workshop\nactivities. We analysed social interactions during a keynote, small group\nbreakouts, and informal networking/hallway conversations. Our mixed-methods\napproach combined environment logging, observations, and semi-structured\ninterviews. The results demonstrate how small and large spaces influenced group\nformation, shared attention, and personal space, where smaller rooms\nfacilitated more cohesive groups while larger rooms made small group formation\nchallenging but personal space more flexible. Beyond our findings, we show how\nthe combination of data and insights can fuel collaborative spaces' design and\ndeliver more effective virtual workshops.\n",
			"Comment: 20 pages, 9 figures, ACM CHI 2021"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05300",
			"doi:10.1145/3411764.3445729"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05300.pdf"
	},
	"632": {
		"title": "Spatial-Temporal Convolutional Network for Spread Prediction of COVID-19",
		"creator": [
			"Shwartz-Ziv, Ravid",
			"Ari, Itamar Ben",
			"Armon, Amitai"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  In this work we present a spatial-temporal convolutional neural network for\npredicting future COVID-19 related symptoms severity among a population, per\nregion, given its past reported symptoms. This can help approximate the number\nof future Covid-19 patients in each region, thus enabling a faster response,\ne.g., preparing the local hospital or declaring a local lockdown where\nnecessary. Our model is based on a national symptom survey distributed in\nIsrael and can predict symptoms severity for different regions daily. The model\nincludes two main parts - (1) learned region-based survey responders profiles\nused for aggregating questionnaires data into features (2) Spatial-Temporal 3D\nconvolutional neural network which uses the above features to predict symptoms\nprogression.\n",
			"Comment: IEEE BigData 2020"
		],
		"date": "2020-12-27",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05304",
		"pdf_url": "http://arxiv.org/pdf/2101.05304.pdf"
	},
	"633": {
		"title": "Toward Data Cleaning with a Target Accuracy: A Case Study for Value\n  Normalization",
		"creator": [
			"Ardalan, Adel",
			"Paulsen, Derek",
			"Saini, Amanpreet Singh",
			"Cai, Walter",
			"Doan, AnHai"
		],
		"subject": "Computer Science - Databases",
		"description": "  Many applications need to clean data with a target accuracy. As far as we\nknow, this problem has not been studied in depth. In this paper we take the\nfirst step toward solving it. We focus on value normalization (VN), the problem\nof replacing all string that refer to the same entity with a unique string. VN\nis ubiquitous, and we often want to do VN with 100% accuracy. This is typically\ndone today in industry by automatically clustering the strings then asking a\nuser to verify and clean the clusters, until reaching 100% accuracy. This\nsolution has significant limitations. It does not tell the users how to verify\nand clean the clusters. This part also often takes a lot of time, e.g., days.\nFurther, there is no effective way for multiple users to collaboratively verify\nand clean. In this paper we address these challenges. Overall, our work\nadvances the state of the art in data cleaning by introducing a novel cleaning\nproblem and describing a promising solution template.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05308",
		"pdf_url": "http://arxiv.org/pdf/2101.05308.pdf"
	},
	"634": {
		"title": "Whispered and Lombard Neural Speech Synthesis",
		"creator": [
			"Hu, Qiong",
			"Bleisch, Tobias",
			"Petkov, Petko",
			"Raitio, Tuomo",
			"Marchi, Erik",
			"Lakshminarasimhan, Varun"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Audio and Speech Processing",
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning",
			"Computer Science - Sound"
		],
		"description": [
			"  It is desirable for a text-to-speech system to take into account the\nenvironment where synthetic speech is presented, and provide appropriate\ncontext-dependent output to the user. In this paper, we present and compare\nvarious approaches for generating different speaking styles, namely, normal,\nLombard, and whisper speech, using only limited data. The following systems are\nproposed and assessed: 1) Pre-training and fine-tuning a model for each style.\n2) Lombard and whisper speech conversion through a signal processing based\napproach. 3) Multi-style generation using a single model based on a speaker\nverification model. Our mean opinion score and AB preference listening tests\nshow that 1) we can generate high quality speech through the\npre-training/fine-tuning approach for all speaking styles. 2) Although our\nspeaker verification (SV) model is not explicitly trained to discriminate\ndifferent speaking styles, and no Lombard and whisper voice is used for\npre-training this system, the SV model can be used as a style encoder for\ngenerating different style embeddings as input for the Tacotron system. We also\nshow that the resulting synthetic Lombard speech has a significant positive\nimpact on intelligibility gain.\n",
			"Comment: To appear in SLT 2021"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05313",
		"pdf_url": "http://arxiv.org/pdf/2101.05313.pdf"
	},
	"635": {
		"title": "EXMA: A Genomics Accelerator for Exact-Matching",
		"creator": [
			"Jiang, Lei",
			"Zokaee, Farzaneh"
		],
		"subject": "Computer Science - Hardware Architecture",
		"description": [
			"  Genomics is the foundation of precision medicine, global food security and\nvirus surveillance. Exact-match is one of the most essential operations widely\nused in almost every step of genomics such as alignment, assembly, annotation,\nand compression. Modern genomics adopts Ferragina-Manzini Index (FM-Index)\naugmenting space-efficient Burrows-Wheeler transform (BWT) with additional data\nstructures to permit ultra-fast exact-match operations. However, FM-Index is\nnotorious for its poor spatial locality and random memory access pattern. Prior\nworks create GPU-, FPGA-, ASIC- and even process-in-memory (PIM)-based\naccelerators to boost FM-Index search throughput. Though they achieve the\nstate-of-the-art FM-Index search throughput, the same as all prior conventional\naccelerators, FM-Index PIMs process only one DNA symbol after each DRAM row\nactivation, thereby suffering from poor memory bandwidth utilization.\n  In this paper, we propose a hardware accelerator, EXMA, to enhance FM-Index\nsearch throughput. We first create a novel EXMA table with a\nmulti-task-learning (MTL)-based index to process multiple DNA symbols with each\nDRAM row activation. We then build an accelerator to search over an EXMA table.\nWe propose 2-stage scheduling to increase the cache hit rate of our\naccelerator. We introduce dynamic page policy to improve the row buffer hit\nrate of DRAM main memory. We also present CHAIN compression to reduce the data\nstructure size of EXMA tables. Compared to state-of-the-art FM-Index PIMs, EXMA\nimproves search throughput by $4.9\\times$, and enhances search throughput per\nWatt by $4.8\\times$.\n",
			"Comment: IEEE International Symposium on High-Performance Computer\n  Architecture, 2021"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05314",
		"pdf_url": "http://arxiv.org/pdf/2101.05314.pdf"
	},
	"636": {
		"title": "ZipLine: In-Network Compression at Line Speed",
		"creator": [
			"Vaucher, Sébastien",
			"Yazdani, Niloofar",
			"Felber, Pascal",
			"Lucani, Daniel E.",
			"Schiavoni, Valerio"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Computer Science - Performance"
		],
		"description": "  Network appliances continue to offer novel opportunities to offload\nprocessing from computing nodes directly into the data plane. One popular\nconcern of network operators and their customers is to move data increasingly\nfaster. A common technique to increase data throughput is to compress it before\nits transmission. However, this requires compression of the data -- a time and\nenergy demanding pre-processing phase -- and decompression upon reception -- a\nsimilarly resource consuming operation. Moreover, if multiple nodes transfer\nsimilar data chunks across the network hop (e.g., a given pair of switches),\neach node effectively wastes resources by executing similar steps. This paper\nproposes ZipLine, an approach to design and implement (de)compression at line\nspeed leveraging the Tofino hardware platform which is programmable using the\nP4_16 language. We report on lessons learned while building the system and show\nthroughput, latency and compression measurements on synthetic and real-world\ntraces, showcasing the benefits and trade-offs of our design.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05323",
			"2020. Proceedings of the 16th International Conference on emerging\n  Networking EXperiments and Technologies. Association for Computing Machinery,\n  New York, NY, USA, 399-405",
			"doi:10.1145/3386367.3431302"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05323.pdf"
	},
	"637": {
		"title": "Advancing Eosinophilic Esophagitis Diagnosis and Phenotype Assessment\n  with Deep Learning Computer Vision",
		"creator": [
			"Adorno III, William",
			"Catalano, Alexis",
			"Ehsan, Lubaina",
			"von Eckstaedt, Hans Vitzhum",
			"Barnes, Barrett",
			"McGowan, Emily",
			"Syed, Sana",
			"Brown, Donald E."
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  Eosinophilic Esophagitis (EoE) is an inflammatory esophageal disease which is\nincreasing in prevalence. The diagnostic gold-standard involves manual review\nof a patient's biopsy tissue sample by a clinical pathologist for the presence\nof 15 or greater eosinophils within a single high-power field (400x\nmagnification). Diagnosing EoE can be a cumbersome process with added\ndifficulty for assessing the severity and progression of disease. We propose an\nautomated approach for quantifying eosinophils using deep image segmentation. A\nU-Net model and post-processing system are applied to generate eosinophil-based\nstatistics that can diagnose EoE as well as describe disease severity and\nprogression. These statistics are captured in biopsies at the initial EoE\ndiagnosis and are then compared with patient metadata: clinical and treatment\nphenotypes. The goal is to find linkages that could potentially guide treatment\nplans for new patients at their initial disease diagnosis. A deep image\nclassification model is further applied to discover features other than\neosinophils that can be used to diagnose EoE. This is the first study to\nutilize a deep learning computer vision approach for EoE diagnosis and to\nprovide an automated process for tracking disease severity and progression.\n",
			"Comment: This paper contains 12 pages, 9 figures, and 7 tables"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05326",
		"pdf_url": "http://arxiv.org/pdf/2101.05326.pdf"
	},
	"638": {
		"title": "Uniform Error and Posterior Variance Bounds for Gaussian Process\n  Regression with Application to Safe Control",
		"creator": [
			"Lederer, Armin",
			"Umlauft, Jonas",
			"Hirche, Sandra"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Systems and Control",
			"Statistics - Machine Learning"
		],
		"description": "  In application areas where data generation is expensive, Gaussian processes\nare a preferred supervised learning model due to their high data-efficiency.\nParticularly in model-based control, Gaussian processes allow the derivation of\nperformance guarantees using probabilistic model error bounds. To make these\napproaches applicable in practice, two open challenges must be solved i)\nExisting error bounds rely on prior knowledge, which might not be available for\nmany real-world tasks. (ii) The relationship between training data and the\nposterior variance, which mainly drives the error bound, is not well understood\nand prevents the asymptotic analysis. This article addresses these issues by\npresenting a novel uniform error bound using Lipschitz continuity and an\nanalysis of the posterior variance function for a large class of kernels.\nAdditionally, we show how these results can be used to guarantee safe control\nof an unknown dynamical system and provide numerical illustration examples.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05328",
		"pdf_url": "http://arxiv.org/pdf/2101.05328.pdf"
	},
	"639": {
		"title": "A Survey on Simulators for Testing Self-Driving Cars",
		"creator": [
			"Kaur, Prabhjot",
			"Taghavi, Samira",
			"Tian, Zhaofeng",
			"Shi, Weisong"
		],
		"subject": "Computer Science - Robotics",
		"description": "  A rigorous and comprehensive testing plays a key role in training\nself-driving cars to handle variety of situations that they are expected to see\non public roads.\n  The physical testing on public roads is unsafe, costly, and not always\nreproducible. This is where testing in simulation helps fill the gap, however,\nthe problem with simulation testing is that it is only as good as the simulator\nused for testing and how representative the simulated scenarios are of the real\nenvironment. In this paper, we identify key requirements that a good simulator\nmust have. Further, we provide a comparison of commonly used simulators. Our\nanalysis shows that CARLA and LGSVL simulators are the current state-of-the-art\nsimulators for end to end testing of self-driving cars for the reasons\nmentioned in this paper. Finally, we also present current challenges that\nsimulation testing continues to face as we march towards building fully\nautonomous cars.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05337",
		"pdf_url": "http://arxiv.org/pdf/2101.05337.pdf"
	},
	"640": {
		"title": "X-CAL: Explicit Calibration for Survival Analysis",
		"creator": [
			"Goldstein, Mark",
			"Han, Xintian",
			"Puli, Aahlad",
			"Perotte, Adler J.",
			"Ranganath, Rajesh"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  Survival analysis models the distribution of time until an event of interest,\nsuch as discharge from the hospital or admission to the ICU. When a model's\npredicted number of events within any time interval is similar to the observed\nnumber, it is called well-calibrated. A survival model's calibration can be\nmeasured using, for instance, distributional calibration (D-CALIBRATION)\n[Haider et al., 2020] which computes the squared difference between the\nobserved and predicted number of events within different time intervals.\nClassically, calibration is addressed in post-training analysis. We develop\nexplicit calibration (X-CAL), which turns D-CALIBRATION into a differentiable\nobjective that can be used in survival modeling alongside maximum likelihood\nestimation and other objectives. X-CAL allows practitioners to directly\noptimize calibration and strike a desired balance between predictive power and\ncalibration. In our experiments, we fit a variety of shallow and deep models on\nsimulated data, a survival dataset based on MNIST, on length-of-stay prediction\nusing MIMIC-III data, and on brain cancer data from The Cancer Genome Atlas. We\nshow that the models we study can be miscalibrated. We give experimental\nevidence on these datasets that X-CAL improves D-CALIBRATION without a large\ndecrease in concordance or likelihood.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05346",
		"pdf_url": "http://arxiv.org/pdf/2101.05346.pdf"
	},
	"641": {
		"title": "Gaussian Mixture Graphical Lasso with Application to Edge Detection in\n  Brain Networks",
		"creator": [
			"Yin, Hang",
			"Liu, Xinyue",
			"Kong, Xiangnan"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Sparse inverse covariance estimation (i.e., edge de-tection) is an important\nresearch problem in recent years, wherethe goal is to discover the direct\nconnections between a set ofnodes in a networked system based upon the observed\nnodeactivities. Existing works mainly focus on unimodal distributions,where it\nis usually assumed that the observed activities aregenerated from\nasingleGaussian distribution (i.e., one graph).However, this assumption is too\nstrong for many real-worldapplications. In many real-world applications (e.g.,\nbrain net-works), the node activities usually exhibit much more complexpatterns\nthat are difficult to be captured by one single Gaussiandistribution. In this\nwork, we are inspired by Latent DirichletAllocation (LDA) [4] and consider\nmodeling the edge detectionproblem as estimating a mixture ofmultipleGaussian\ndistribu-tions, where each corresponds to a separate sub-network. Toaddress\nthis problem, we propose a novel model called GaussianMixture Graphical Lasso\n(MGL). It learns the proportionsof signals generated by each mixture component\nand theirparameters iteratively via an EM framework. To obtain\nmoreinterpretable networks, MGL imposes a special regularization,called Mutual\nExclusivity Regularization (MER), to minimize theoverlap between different\nsub-networks. MER also addresses thecommon issues in read-world data sets,i.e.,\nnoisy observationsand small sample size. Through the extensive experiments\nonsynthetic and real brain data sets, the results demonstrate thatMGL can\neffectively discover multiple connectivity structuresfrom the observed node\nactivities\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05348",
		"pdf_url": "http://arxiv.org/pdf/2101.05348.pdf"
	},
	"642": {
		"title": "On the Identification of Electrical Equivalent Circuit Models Based on\n  Noisy Measurements",
		"creator": [
			"Balasingam, Balakumar",
			"Pattipati, Krishna"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": "  Real-time identification of electrical equivalent circuit models is a\ncritical requirement in many practical systems, such as batteries and electric\nmotors. Significant work has been done in the past developing different types\nof algorithms for system identification using reduced equivalent circuit\nmodels. However, little work was done in analyzing the theoretical performance\nbounds of these approaches. Proper understanding of theoretical bounds will\nhelp in designing a system that is economical in cost and robust in\nperformance. In this paper, we analyze the performance of a linear recursive\nleast squares approach to equivalent circuit model identification and show that\nthe least squares approach is both unbiased and efficient when the\nsignal-to-noise ratio is high enough. However, we show that, when the\nsignal-to-noise ratio is low - resembling the case in many practical\napplications - the least squares estimator becomes significantly biased.\nConsequently, we develop a parameter estimation approach based on total least\nsquares method and show it to be asymptotically unbiased and efficient at\npractically low signal-to-noise ratio regions. Further, we develop a recursive\nimplementation of the total least square algorithm and find it to be slow to\nconverge; for this, we employ a Kalman filter to improve the convergence speed\nof the total least squares method. The resulting total Kalman filter is shown\nto be both unbiased and efficient in equivalent circuit model parameter\nidentification. The performance of this filter is analyzed using real-world\ncurrent profile under fluctuating signal-to-noise ratios. Finally, the\napplicability of the algorithms and analysis in this paper in identifying\nhigher order electrical equivalent circuit models is explained.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05349",
		"pdf_url": "http://arxiv.org/pdf/2101.05349.pdf"
	},
	"643": {
		"title": "Practical Face Reconstruction via Differentiable Ray Tracing",
		"creator": [
			"Dib, Abdallah",
			"Bharaj, Gaurav",
			"Ahn, Junghyun",
			"Thébault, Cédric",
			"Gosselin, Philippe-Henri",
			"Romeo, Marco",
			"Chevallier, Louis"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Graphics",
			"65D19, 68U05",
			"I.4.5",
			"I.4.8",
			"I.3.7"
		],
		"description": [
			"  We present a differentiable ray-tracing based novel face reconstruction\napproach where scene attributes - 3D geometry, reflectance (diffuse, specular\nand roughness), pose, camera parameters, and scene illumination - are estimated\nfrom unconstrained monocular images. The proposed method models scene\nillumination via a novel, parameterized virtual light stage, which\nin-conjunction with differentiable ray-tracing, introduces a coarse-to-fine\noptimization formulation for face reconstruction. Our method can not only\nhandle unconstrained illumination and self-shadows conditions, but also\nestimates diffuse and specular albedos. To estimate the face attributes\nconsistently and with practical semantics, a two-stage optimization strategy\nsystematically uses a subset of parametric attributes, where subsequent\nattribute estimations factor those previously estimated. For example,\nself-shadows estimated during the first stage, later prevent its baking into\nthe personalized diffuse and specular albedos in the second stage. We show the\nefficacy of our approach in several real-world scenarios, where face attributes\ncan be estimated even under extreme illumination conditions. Ablation studies,\nanalyses and comparisons against several recent state-of-the-art methods show\nimproved accuracy and versatility of our approach. With consistent face\nattributes reconstruction, our method leads to several style -- illumination,\nalbedo, self-shadow -- edit and transfer applications, as discussed in the\npaper.\n",
			"Comment: 16 pages, 14 figures"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05356",
		"pdf_url": "http://arxiv.org/pdf/2101.05356.pdf"
	},
	"644": {
		"title": "Towards Creating a Deployable Grasp Type Probability Estimator for a\n  Prosthetic Hand",
		"creator": [
			"Zandigohar, Mehrshad",
			"Han, Mo",
			"Erdogmus, Deniz",
			"Schirner, Gunar"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Hardware Architecture"
		],
		"description": "  For lower arm amputees, prosthetic hands promise to restore most of physical\ninteraction capabilities. This requires to accurately predict hand gestures\ncapable of grabbing varying objects and execute them timely as intended by the\nuser. Current approaches often rely on physiological signal inputs such as\nElectromyography (EMG) signal from residual limb muscles to infer the intended\nmotion. However, limited signal quality, user diversity and high variability\nadversely affect the system robustness. Instead of solely relying on EMG\nsignals, our work enables augmenting EMG intent inference with physical state\nprobability through machine learning and computer vision method. To this end,\nwe: (1) study state-of-the-art deep neural network architectures to select a\nperformant source of knowledge transfer for the prosthetic hand, (2) use a\ndataset containing object images and probability distribution of grasp types as\na new form of labeling where instead of using absolute values of zero and one\nas the conventional classification labels, our labels are a set of\nprobabilities whose sum is 1. The proposed method generates probabilistic\npredictions which could be fused with EMG prediction of probabilities over\ngrasps by using the visual information from the palm camera of a prosthetic\nhand. Our results demonstrate that InceptionV3 achieves highest accuracy with\n0.95 angular similarity followed by 1.4 MobileNetV2 with 0.93 at ~20% the\namount of operations.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05357",
			"CyPhy 2019, WESE 2019. Lecture Notes in Computer Science, vol\n  11971. Springer, Cham",
			"doi:10.1007/978-3-030-41131-2_3"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05357.pdf"
	},
	"645": {
		"title": "Preferential Mixture-of-Experts: Interpretable Models that Rely on Human\n  Expertise as much as Possible",
		"creator": [
			"Pradier, Melanie F.",
			"Zazo, Javier",
			"Parbhoo, Sonali",
			"Perlis, Roy H.",
			"Zazzi, Maurizio",
			"Doshi-Velez, Finale"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  We propose Preferential MoE, a novel human-ML mixture-of-experts model that\naugments human expertise in decision making with a data-based classifier only\nwhen necessary for predictive performance. Our model exhibits an interpretable\ngating function that provides information on when human rules should be\nfollowed or avoided. The gating function is maximized for using human-based\nrules, and classification errors are minimized. We propose solving a coupled\nmulti-objective problem with convex subproblems. We develop approximate\nalgorithms and study their performance and convergence. Finally, we demonstrate\nthe utility of Preferential MoE on two clinical applications for the treatment\nof Human Immunodeficiency Virus (HIV) and management of Major Depressive\nDisorder (MDD).\n",
			"Comment: 10 pages, 5 figures, 4 tables, AMIA 2021 Virtual Informatics Summit"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05360",
		"pdf_url": "http://arxiv.org/pdf/2101.05360.pdf"
	},
	"646": {
		"title": "Random Shadows and Highlights: A new data augmentation method for\n  extreme lighting conditions",
		"creator": [
			"Mazhar, Osama",
			"Kober, Jens"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  In this paper, we propose a new data augmentation method, Random Shadows and\nHighlights (RSH) to acquire robustness against lighting perturbations. Our\nmethod creates random shadows and highlights on images, thus challenging the\nneural network during the learning process such that it acquires immunity\nagainst such input corruptions in real world applications. It is a\nparameter-learning free method which can be integrated into most vision related\nlearning applications effortlessly. With extensive experimentation, we\ndemonstrate that RSH not only increases the robustness of the models against\nlighting perturbations, but also reduces over-fitting significantly. Thus RSH\nshould be considered essential for all vision related learning systems. Code is\navailable at: https://github.com/OsamaMazhar/Random-Shadows-Highlights.\n",
		"date": [
			"2021-01-13",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05361",
		"pdf_url": "http://arxiv.org/pdf/2101.05361.pdf"
	},
	"647": {
		"title": "White-Box Analysis over Machine Learning: Modeling Performance of\n  Configurable Systems",
		"creator": [
			"Velez, Miguel",
			"Jamshidi, Pooyan",
			"Siegmund, Norbert",
			"Apel, Sven",
			"Kästner, Christian"
		],
		"subject": "Computer Science - Software Engineering",
		"description": [
			"  Performance-influence models can help stakeholders understand how and where\nconfiguration options and their interactions influence the performance of a\nsystem. With this understanding, stakeholders can debug performance behavior\nand make deliberate configuration decisions. Current black-box techniques to\nbuild such models combine various sampling and learning strategies, resulting\nin tradeoffs between measurement effort, accuracy, and interpretability. We\npresent Comprex, a white-box approach to build performance-influence models for\nconfigurable systems, combining insights of local measurements, dynamic taint\nanalysis to track options in the implementation, compositionality, and\ncompression of the configuration space, without relying on machine learning to\nextrapolate incomplete samples. Our evaluation on 4 widely-used, open-source\nprojects demonstrates that Comprex builds similarly accurate\nperformance-influence models to the most accurate and expensive black-box\napproach, but at a reduced cost and with additional benefits from interpretable\nand local models.\n",
			"Comment: Accepted for publication at ICSE'21"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05362",
		"pdf_url": "http://arxiv.org/pdf/2101.05362.pdf"
	},
	"648": {
		"title": "Scared into Action: How Partisanship and Fear are Associated with\n  Reactions to Public Health Directives",
		"creator": [
			"Lindow, Mike",
			"DeFranza, David",
			"Mishra, Arul",
			"Mishra, Himanshu"
		],
		"subject": [
			"Economics - General Economics",
			"Computer Science - Computation and Language",
			"Statistics - Computation"
		],
		"description": [
			"  Differences in political ideology are increasingly appearing as an impediment\nto successful bipartisan communication from local leadership. For example,\nrecent empirical findings have shown that conservatives are less likely to\nadhere to COVID-19 health directives. This behavior is in direct contradiction\nto past research which indicates that conservatives are more rule abiding,\nprefer to avoid loss, and are more prevention-motivated than liberals. We\nreconcile this disconnect between recent empirical findings and past research\nby using insights gathered from press releases, millions of tweets, and\nmobility data capturing local movement in retail, grocery, workplace, parks,\nand transit domains during COVID-19 shelter-in-place orders. We find that\nconservatives adhere to health directives when they express more fear of the\nvirus. In order to better understand this phenomenon, we analyze both official\nand citizen communications and find that press releases from local and federal\ngovernment, along with the number of confirmed COVID-19 cases, lead to an\nincrease in expressions of fear on Twitter.\n",
			"Comment: 54 pages, 11 figures"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05365",
			"doi:10.31234/osf.io/8me7q"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05365.pdf"
	},
	"649": {
		"title": "Anomaly Detection Support Using Process Classification",
		"creator": [
			"Eresheim, Sebastian",
			"Klausner, Lukas Daniel",
			"Kochberger, Patrick"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Cryptography and Security"
		],
		"description": [
			"  Anomaly detection systems need to consider a lot of information when scanning\nfor anomalies. One example is the context of the process in which an anomaly\nmight occur, because anomalies for one process might not be anomalies for a\ndifferent one. Therefore data -- such as system events -- need to be assigned\nto the program they originate from. This paper investigates whether it is\npossible to infer from a list of system events the program whose behavior\ncaused the occurrence of these system events. To that end, we model transition\nprobabilities between non-equivalent events and apply the $k$-nearest neighbors\nalgorithm. This system is evaluated on non-malicious, real-world data using\nfour different evaluation scores. Our results suggest that the approach\nproposed in this paper is capable of correctly inferring program names from\nsystem events.\n",
			"Comment: 14 pages, 6 figures"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05371",
			"Proceedings of the 5th International Conference on Software\n  Security and Assurance (ICSSA 2019), 2019, 27-40",
			"doi:10.1109/ICSSA48308.2019.00011"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05371.pdf"
	},
	"650": {
		"title": "A Work-Centered Approach for Cyber-Physical-Social System Design:\n  Applications in Aerospace Industrial Inspection",
		"creator": [
			"Cabour, Garrick",
			"Ledoux, Élise",
			"Bassetto, Samuel"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": "  Industrial inspection automation in aerospace presents numerous challenges\ndue to the dynamic, information-rich and regulated aspects of the domain. To\ndiagnose the condition of an aircraft component, expert inspectors rely on a\nsignificant amount of procedural and tacit knowledge (know-how). As systems\ncapabilities do not match high level human cognitive functions, the role of\nhumans in future automated work systems will remain important. A\nCyber-Physical-Social System (CPSS) is a suitable solution that envisions\nhumans and agents in a joint activity to enhance cognitive/computational\ncapabilities and produce better outcomes. This paper investigates how a\nwork-centred approach can support and guide the engineering process of a CPSS\nwith an industrial use case. We present a robust methodology that combines\nfieldwork inquiries and model-based engineering to elicit and formalize rich\nmental models into exploitable design patterns. Our results exhibit how\ninspectors process and apply knowledge to diagnose the component`s condition,\nhow they deal with the institution`s rules and operational constraints (norms,\nsafety policies, standard operating procedures). We suggest how these patterns\ncan be incorporated in software modules or can conceptualize Human-Agent\nTeaming requirements. We argue that this framework can corroborate the right\nfit between a system`s technical and ecological validity (system fit with\noperating context) that enhances data reliability, productivity-related factors\nand system acceptance by end-users.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05385",
		"pdf_url": "http://arxiv.org/pdf/2101.05385.pdf"
	},
	"651": {
		"title": "Evaluating Soccer Player: from Live Camera to Deep Reinforcement\n  Learning",
		"creator": [
			"Garnier, Paul",
			"Gregoir, Théophane"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Science and Game Theory"
		],
		"description": "  Scientifically evaluating soccer players represents a challenging Machine\nLearning problem. Unfortunately, most existing answers have very opaque\nalgorithm training procedures; relevant data are scarcely accessible and almost\nimpossible to generate. In this paper, we will introduce a two-part solution:\nan open-source Player Tracking model and a new approach to evaluate these\nplayers based solely on Deep Reinforcement Learning, without human data\ntraining nor guidance. Our tracking model was trained in a supervised fashion\non datasets we will also release, and our Evaluation Model relies only on\nsimulations of virtual soccer games. Combining those two architectures allows\none to evaluate Soccer Players directly from a live camera without large\ndatasets constraints. We term our new approach Expected Discounted Goal (EDG),\nas it represents the number of goals a team can score or concede from a\nparticular state. This approach leads to more meaningful results than the\nexisting ones that are based on real-world data, and could easily be extended\nto other sports.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05388",
		"pdf_url": "http://arxiv.org/pdf/2101.05388.pdf"
	},
	"652": {
		"title": "Should Ensemble Members Be Calibrated?",
		"creator": [
			"Wu, Xixin",
			"Gales, Mark"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  Underlying the use of statistical approaches for a wide range of applications\nis the assumption that the probabilities obtained from a statistical model are\nrepresentative of the \"true\" probability that event, or outcome, will occur.\nUnfortunately, for modern deep neural networks this is not the case, they are\noften observed to be poorly calibrated. Additionally, these deep learning\napproaches make use of large numbers of model parameters, motivating the use of\nBayesian, or ensemble approximation, approaches to handle issues with parameter\nestimation. This paper explores the application of calibration schemes to deep\nensembles from both a theoretical perspective and empirically on a standard\nimage classification task, CIFAR-100. The underlying theoretical requirements\nfor calibration, and associated calibration criteria, are first described. It\nis shown that well calibrated ensemble members will not necessarily yield a\nwell calibrated ensemble prediction, and if the ensemble prediction is well\ncalibrated its performance cannot exceed that of the average performance of the\ncalibrated ensemble members. On CIFAR-100 the impact of calibration for\nensemble prediction, and associated calibration is evaluated. Additionally the\nsituation where multiple different topologies are combined together is\ndiscussed.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05397",
		"pdf_url": "http://arxiv.org/pdf/2101.05397.pdf"
	},
	"653": {
		"title": "Act to Reason: A Dynamic Game Theoretical Model of Driving",
		"creator": [
			"Köprülü, Cevahir",
			"Yıldız, Yıldıray"
		],
		"subject": [
			"Computer Science - Multiagent Systems",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": [
			"  The focus of this paper is to propose a driver model that incorporates human\nreasoning levels as actions during interactions with other drivers. Different\nfrom earlier work using game theoretical human reasoning levels, we propose a\ndynamic approach, where the actions are the levels themselves, instead of\nconventional driving actions such as accelerating or braking. This results in a\ndynamic behavior, where the agent adapts to its environment by exploiting\ndifferent behavior models as available moves to choose from, depending on the\nrequirements of the traffic situation. The bounded rationality assumption is\npreserved since the selectable strategies are designed by adhering to the fact\nthat humans are cognitively limited in their understanding and decision making.\nUsing a highway merging scenario, it is demonstrated that the proposed dynamic\napproach produces more realistic outcomes compared to the conventional method\nthat employs fixed human reasoning levels.\n",
			"Comment: 17 pages, 10 figures"
		],
		"date": [
			"2021-01-13",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05399",
		"pdf_url": "http://arxiv.org/pdf/2101.05399.pdf"
	},
	"654": {
		"title": "Optimal Clustering in Anisotropic Gaussian Mixture Models",
		"creator": [
			"Chen, Xin",
			"Zhang, Anderson Y."
		],
		"subject": [
			"Mathematics - Statistics Theory",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  We study the clustering task under anisotropic Gaussian Mixture Models where\nthe covariance matrices from different clusters are unknown and are not\nnecessarily the identical matrix. We characterize the dependence of\nsignal-to-noise ratios on the cluster centers and covariance matrices and\nobtain the minimax lower bound for the clustering problem. In addition, we\npropose a computationally feasible procedure and prove it achieves the optimal\nrate within a few iterations. The proposed procedure is a hard EM type\nalgorithm, and it can also be seen as a variant of the Lloyd's algorithm that\nis adjusted to the anisotropic covariance matrices.\n",
		"date": [
			"2021-01-13",
			"2021-01-17"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05402",
		"pdf_url": "http://arxiv.org/pdf/2101.05402.pdf"
	},
	"655": {
		"title": "Image deblurring based on lightweight multi-information fusion network",
		"creator": [
			"Zhang, Yanni",
			"Liu, Yiming",
			"Li, Qiang",
			"Qi, Miao",
			"Xu, Dahong",
			"Kong, Jun",
			"Wang, Jianzhong"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  Recently, deep learning based image deblurring has been well developed.\nHowever, exploiting the detailed image features in a deep learning framework\nalways requires a mass of parameters, which inevitably makes the network suffer\nfrom high computational burden. To solve this problem, we propose a lightweight\nmultiinformation fusion network (LMFN) for image deblurring. The proposed LMFN\nis designed as an encoder-decoder architecture. In the encoding stage, the\nimage feature is reduced to various smallscale spaces for multi-scale\ninformation extraction and fusion without a large amount of information loss.\nThen, a distillation network is used in the decoding stage, which allows the\nnetwork benefit the most from residual learning while remaining sufficiently\nlightweight. Meanwhile, an information fusion strategy between distillation\nmodules and feature channels is also carried out by attention mechanism.\nThrough fusing different information in the proposed approach, our network can\nachieve state-of-the-art image deblurring result with smaller number of\nparameters and outperforms existing methods in model complexity.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05403",
		"pdf_url": "http://arxiv.org/pdf/2101.05403.pdf"
	},
	"656": {
		"title": "A Multi-Stage Attentive Transfer Learning Framework for Improving\n  COVID-19 Diagnosis",
		"creator": [
			"Liu, Yi",
			"Ji, Shuiwang"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  Computed tomography (CT) imaging is a promising approach to diagnosing the\nCOVID-19. Machine learning methods can be employed to train models from labeled\nCT images and predict whether a case is positive or negative. However, there\nexists no publicly-available and large-scale CT data to train accurate models.\nIn this work, we propose a multi-stage attentive transfer learning framework\nfor improving COVID-19 diagnosis. Our proposed framework consists of three\nstages to train accurate diagnosis models through learning knowledge from\nmultiple source tasks and data of different domains. Importantly, we propose a\nnovel self-supervised learning method to learn multi-scale representations for\nlung CT images. Our method captures semantic information from the whole lung\nand highlights the functionality of each lung region for better representation\nlearning. The method is then integrated to the last stage of the proposed\ntransfer learning framework to reuse the complex patterns learned from the same\nCT images. We use a base model integrating self-attention (ATTNs) and\nconvolutional operations. Experimental results show that networks with ATTNs\ninduce greater performance improvement through transfer learning than networks\nwithout ATTNs. This indicates attention exhibits higher transferability than\nconvolution. Our results also show that the proposed self-supervised learning\nmethod outperforms several baseline methods.\n",
			"Comment: 12 pages, 4 figures, 6 tables"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05410",
		"pdf_url": "http://arxiv.org/pdf/2101.05410.pdf"
	},
	"657": {
		"title": "Interval centred form for proving stability of non-linear discrete-time\n  systems",
		"creator": [
			"Bourgois, Auguste",
			"Jaulin, Luc"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  In this paper, we propose a new approach to prove stability of non-linear\ndiscrete-time systems. After introducing the new concept of stability\ncontractor, we show that the interval centred form plays a fundamental role in\nthis context and makes it possible to easily prove asymptotic stability of a\ndiscrete system. Then, we illustrate the principle of our approach through\ntheoretical examples. Finally, we provide two practical examples using our\nmethod : proving stability of a localisation system and that of the trajectory\nof a robot.\n",
			"Comment: In Proceedings SNR 2020, arXiv:2101.05256"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05412",
			"EPTCS 331, 2021, pp. 1-17",
			"doi:10.4204/EPTCS.331.1"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05412.pdf"
	},
	"658": {
		"title": "Verification and Reachability Analysis of Fractional-Order Differential\n  Equations Using Interval Analysis",
		"creator": [
			"Rauh, Andreas",
			"Kersten, Julia"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"B.2.2",
			"G.1.0",
			"G.1.7",
			"G.1.10"
		],
		"description": [
			"  Interval approaches for the reachability analysis of initial value problems\nfor sets of classical ordinary differential equations have been investigated\nand implemented by many researchers during the last decades. However, there\nexist numerous applications in computational science and engineering, where\ncontinuous-time system dynamics cannot be described adequately by integer-order\ndifferential equations. Especially in cases in which long-term memory effects\nare observed, fractional-order system representations are promising to describe\nthe dynamics, on the one hand, with sufficient accuracy and, on the other hand,\nto limit the number of required state variables and parameters to a reasonable\namount. Real-life applications for such fractional-order models can, among\nothers, be found in the field of electrochemistry, where methods for impedance\nspectroscopy are typically used to identify fractional-order models for the\ncharging/discharging behavior of batteries or for the dynamic relation between\nvoltage and current in fuel cell systems if operated in a non-stationary state.\nThis paper aims at presenting an iterative method for reachability analysis of\nfractional-order systems that is based on an interval arithmetic extension of\nMittag-Leffler functions. An illustrating example, inspired by a low-order\nmodel of battery systems concludes this contribution.\n",
			"Comment: In Proceedings SNR 2020, arXiv:2101.05256"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05414",
			"EPTCS 331, 2021, pp. 18-32",
			"doi:10.4204/EPTCS.331.2"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05414.pdf"
	},
	"659": {
		"title": "Analysis of E-commerce Ranking Signals via Signal Temporal Logic",
		"creator": [
			"Dreossi, Tommaso",
			"Ballardin, Giorgio",
			"Gupta, Parth",
			"Bakus, Jan",
			"Lin, Yu-Hsiang",
			"Salaka, Vamsi"
		],
		"subject": [
			"Computer Science - Logic in Computer Science",
			"Computer Science - Formal Languages and Automata Theory",
			"Computer Science - Information Retrieval",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  The timed position of documents retrieved by learning to rank models can be\nseen as signals. Signals carry useful information such as drop or rise of\ndocuments over time or user behaviors. In this work, we propose to use the\nlogic formalism called Signal Temporal Logic (STL) to characterize document\nbehaviors in ranking accordingly to the specified formulas. Our analysis shows\nthat interesting document behaviors can be easily formalized and detected\nthanks to STL formulas. We validate our idea on a dataset of 100K product\nsignals. Through the presented framework, we uncover interesting patterns, such\nas cold start, warm start, spikes, and inspect how they affect our learning to\nranks models.\n",
			"Comment: In Proceedings SNR 2020, arXiv:2101.05256"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05415",
			"EPTCS 331, 2021, pp. 33-42",
			"doi:10.4204/EPTCS.331.3"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05415.pdf"
	},
	"660": {
		"title": "Enclosing the Sliding Surfaces of a Controlled Swing",
		"creator": [
			"Jaulin, Luc",
			"Desrochers, Benoît"
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Logic in Computer Science",
			"G.1.0",
			"G.1.7"
		],
		"description": [
			"  When implementing a non-continuous controller for a cyber-physical system, it\nmay happen that the evolution of the closed-loop system is not anymore\npiecewise differentiable along the trajectory, mainly due to conditional\nstatements inside the controller. This may lead to some unwanted chattering\neffects than may damage the system. This behavior is difficult to observe even\nin simulation. In this paper, we propose an interval approach to characterize\nthe sliding surface which corresponds to the set of all states such that the\nstate trajectory may jump indefinitely between two distinct behaviors. We show\nthat the recent notion of thick sets will allows us to compute efficiently an\nouter approximation of the sliding surface of a given class of hybrid system\ntaking into account all set-membership uncertainties. An application to the\nverification of the controller of a child swing is considered to illustrate the\nprinciple of the approach.\n",
			"Comment: In Proceedings SNR 2020, arXiv:2101.05256"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05418",
			"EPTCS 331, 2021, pp. 43-55",
			"doi:10.4204/EPTCS.331.4"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05418.pdf"
	},
	"661": {
		"title": "DAIL: Dataset-Aware and Invariant Learning for Face Recognition",
		"creator": [
			"Wang, Gaoang",
			"Chen, Lin",
			"Liu, Tianqiang",
			"He, Mingwei",
			"Luo, Jiebo"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  To achieve good performance in face recognition, a large scale training\ndataset is usually required. A simple yet effective way to improve recognition\nperformance is to use a dataset as large as possible by combining multiple\ndatasets in the training. However, it is problematic and troublesome to naively\ncombine different datasets due to two major issues. First, the same person can\npossibly appear in different datasets, leading to an identity overlapping issue\nbetween different datasets. Naively treating the same person as different\nclasses in different datasets during training will affect back-propagation and\ngenerate non-representative embeddings. On the other hand, manually cleaning\nlabels may take formidable human efforts, especially when there are millions of\nimages and thousands of identities. Second, different datasets are collected in\ndifferent situations and thus will lead to different domain distributions.\nNaively combining datasets will make it difficult to learn domain invariant\nembeddings across different datasets. In this paper, we propose DAIL:\nDataset-Aware and Invariant Learning to resolve the above-mentioned issues. To\nsolve the first issue of identity overlapping, we propose a dataset-aware loss\nfor multi-dataset training by reducing the penalty when the same person appears\nin multiple datasets. This can be readily achieved with a modified softmax loss\nwith a dataset-aware term. To solve the second issue, domain adaptation with\ngradient reversal layers is employed for dataset invariant learning. The\nproposed approach not only achieves state-of-the-art results on several\ncommonly used face recognition validation sets, including LFW, CFP-FP, and\nAgeDB-30, but also shows great benefit for practical use.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05419",
		"pdf_url": "http://arxiv.org/pdf/2101.05419.pdf"
	},
	"662": {
		"title": "Asynchronous Gathering in a Torus",
		"creator": [
			"Kamei, Sayaka",
			"Lamani, Anissa",
			"Ooshita, Fukuhito",
			"Tixeuil, Sebastien",
			"Wada, Koichi"
		],
		"subject": "Computer Science - Distributed, Parallel, and Cluster Computing",
		"description": [
			"  We consider the gathering problem for asynchronous and oblivious robots that\ncannot communicate explicitly with each other, but are endowed with visibility\nsensors that allow them to see the positions of the other robots. Most of the\ninvestigations on the gathering problem on the discrete universe are done on\nring shaped networks due to the number of symmetric configuration. We extend in\nthis paper the study of the gathering problem on torus shaped networks assuming\nrobots endowed with local weak multiplicity detection. That is, robots cannot\nmake the difference between nodes occupied by only one robot from those\noccupied by more than one robots unless it is their current node. As a\nconsequence, solutions based on creating a single multiplicity node as a\nlandmark for the gathering cannot be used. We present in this paper a\ndeterministic algorithm that solves the gathering problem starting from any\nrigid configuration on an asymmetric unoriented torus shaped network.\n",
			"Comment: 41 pages"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05421",
		"pdf_url": "http://arxiv.org/pdf/2101.05421.pdf"
	},
	"663": {
		"title": "A Perspective-Based Understanding of Project Success",
		"creator": [
			"McLeod, Laurie",
			"Doolin, Bill",
			"MacDonell, Stephen G."
		],
		"subject": "Computer Science - Software Engineering",
		"description": [
			"  Answering the call for alternative approaches to researching project\nmanagement, we explore the evaluation of project success from a subjectivist\nperspective. An in-depth, longitudinal case study of information systems\ndevelopment in a large manufacturing company was used to investigate how\nvarious project stakeholders subjectively perceived the project outcome and\nwhat evaluation criteria they drew on in doing so. A conceptual framework is\ndeveloped for understanding and analyzing evaluations of project success, both\nformal and informal. The framework highlights how different stakeholder\nperspectives influence the perceived outcome(s) of a project, and how project\nevaluations may differ between stakeholders and across time.\n",
			"Comment: Journal, 18 pages, 2 figures, 3 tables"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05425",
			"Project Management Journal 43 (5) (2012), pp. 68-86",
			"doi:10.1002/pmj.21290"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05425.pdf"
	},
	"664": {
		"title": "Evaluating prediction systems in software project estimation",
		"creator": [
			"Shepperd, Martin",
			"MacDonell, Stephen G."
		],
		"subject": "Computer Science - Software Engineering",
		"description": [
			"  Context: Software engineering has a problem in that when we empirically\nevaluate competing prediction systems we obtain conflicting results. Objective:\nTo reduce the inconsistency amongst validation study results and provide a more\nformal foundation to interpret results with a particular focus on continuous\nprediction systems. Method: A new framework is proposed for evaluating\ncompeting prediction systems based upon (1) an unbiased statistic, Standardised\nAccuracy, (2) testing the result likelihood relative to the baseline technique\nof random 'predictions', that is guessing, and (3) calculation of effect sizes.\nResults: Previously published empirical evaluations of prediction systems are\nre-examined and the original conclusions shown to be unsafe. Additionally, even\nthe strongest results are shown to have no more than a medium effect size\nrelative to random guessing. Conclusions: Biased accuracy statistics such as\nMMRE are deprecated. By contrast this new empirical validation framework leads\nto meaningful results. Such steps will assist in performing future\nmeta-analyses and in providing more robust and usable recommendations to\npractitioners.\n",
			"Comment: Journal, 10 pages, 3 figures, 6 tables"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05426",
			"Information and Software Technology 54(8) (2012), pp.820-827",
			"doi:10.1016/j.infsof.2011.12.008"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05426.pdf"
	},
	"665": {
		"title": "Federated Learning: Opportunities and Challenges",
		"creator": "Mammen, Priyanka Mary",
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Distributed, Parallel, and Cluster Computing"
		],
		"description": "  Federated Learning (FL) is a concept first introduced by Google in 2016, in\nwhich multiple devices collaboratively learn a machine learning model without\nsharing their private data under the supervision of a central server. This\noffers ample opportunities in critical domains such as healthcare, finance etc,\nwhere it is risky to share private user information to other organisations or\ndevices. While FL appears to be a promising Machine Learning (ML) technique to\nkeep the local data private, it is also vulnerable to attacks like other ML\nmodels. Given the growing interest in the FL domain, this report discusses the\nopportunities and challenges in federated learning.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05428",
		"pdf_url": "http://arxiv.org/pdf/2101.05428.pdf"
	},
	"666": {
		"title": "A Critical Look at Coulomb Counting Towards Improving the Kalman Filter\n  Based State of Charge Tracking Algorithms in Rechargeable Batteries",
		"creator": [
			"Movassagh, Kiarash",
			"Raihan, Sheikh Arif",
			"Balasingam, Balakumar",
			"Pattipati, Krishna"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": "  In this paper, we consider the problem of state of charge estimation for\nrechargeable batteries. Coulomb counting is one of the traditional approaches\nto state of charge estimation and it is considered reliable as long as the\nbattery capacity and initial state of charge are known. However, the Coulomb\ncounting method is susceptible to errors from several sources and the extent of\nthese errors are not studied in the literature. In this paper, we formally\nderive and quantify the state of charge estimation error during Coulomb\ncounting due to the following four types of error sources: (i) current\nmeasurement error; (ii) current integration approximation error; (iii) battery\ncapacity uncertainty; and (iv) the timing oscillator error/drift. It is shown\nthat the resulting state of charge error can either be of the time-cumulative\nor of state-of-charge-proportional type. Time-cumulative errors increase with\ntime and has the potential to completely invalidate the state of charge\nestimation in the long run. State-of-charge-proportional errors increase with\nthe accumulated state of charge and reach its worst value within one\ncharge/discharge cycle. Simulation analyses are presented to demonstrate the\nextent of these errors under several realistic scenarios and the paper\ndiscusses approaches to reduce the time-cumulative and state of\ncharge-proportional errors.\n",
		"date": [
			"2021-01-13",
			"2021-01-15"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05435",
		"pdf_url": "http://arxiv.org/pdf/2101.05435.pdf"
	},
	"667": {
		"title": "Unsupervised heart abnormality detection based on phonocardiogram\n  analysis with Beta Variational Auto-Encoders",
		"creator": [
			"Li, Shengchen",
			"Tian, Ke",
			"Wang, Rui"
		],
		"subject": [
			"Computer Science - Sound",
			"Electrical Engineering and Systems Science - Audio and Speech Processing"
		],
		"description": "  Heart Sound (also known as phonocardiogram (PCG)) analysis is a popular way\nthat detects cardiovascular diseases (CVDs). Most PCG analysis uses supervised\nway, which demands both normal and abnormal samples. This paper proposes a\nmethod of unsupervised PCG analysis that uses beta variational auto-encoder\n($\\beta-\\text{VAE}$) to model the normal PCG signals. The best performed model\nreaches an AUC (Area Under Curve) value of 0.91 in ROC (Receiver Operating\nCharacteristic) test for PCG signals collected from the same source. Unlike\nmajority of $\\beta-\\text{VAE}$s that are used as generative models, the\nbest-performed $\\beta-\\text{VAE}$ has a $\\beta$ value smaller than 1. Further\nexperiments then find that the introduction of a light weighted KL divergence\nbetween distribution of latent space and normal distribution improves the\nperformance of anomaly PCG detection based on anomaly scores resulted by\nreconstruction loss. The fact suggests that anomaly score based on\nreconstruction loss may be better than anomaly scores based on latent vectors\nof samples\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05443",
		"pdf_url": "http://arxiv.org/pdf/2101.05443.pdf"
	},
	"668": {
		"title": "Application of Failure Modes and Effects Analysis in the Engineering\n  Design Process",
		"creator": "Fakhravar, Hengameh",
		"subject": "Computer Science - Software Engineering",
		"description": "  Failure modes and effects analysis (FMEA) is one of the most practical design\ntools implemented in the product design to analyze the possible failures and to\nimprove the design. The use of FMEA is diversified, and different approaches\nare proposed by various organizations and researchers from one application to\nanother. The question is how to use the features of FMEA along with the design\nprocess. This research focuses on different types of FMEA in the design\nprocess, which is considered as the mapping between customer requirements,\ndesign components, and product functions. These three elements of design are\nthe foundation of the integration model proposed in this research. The\nobjective of this research is to understand an integrated approach of FMEA in\nthe design process. Significantly, an integration framework is developed to\nintegrate the design process and FMEA. Then, a step-by-step FMEA-facilitated\ndesign process is proposed to apply FMEA along with the design process.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05444",
		"pdf_url": "http://arxiv.org/pdf/2101.05444.pdf"
	},
	"669": {
		"title": "Data Engagement Reconsidered: A Study of Automatic Stress Tracking\n  Technology in Use",
		"creator": [
			"Ding, Xianghua",
			"Wei, Shuhan",
			"Gui, Xinning",
			"Gu, Ning",
			"Zhang, Peng"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": [
			"  In today's fast-paced world, stress has become a growing health concern.\nWhile more automatic stress tracking technologies have recently become\navailable on wearable or mobile devices, there is still a limited understanding\nof how they are actually used in everyday life. This paper presents an\nempirical study of automatic stress-tracking technologies in use in China,\nbased on semi-structured interviews with 17 users. The study highlights three\nchallenges of stress-tracking data engagement that prevent effective technology\nusage: the lack of immediate awareness, the lack of pre-required knowledge, and\nthe lack of corresponding communal support. Drawing on the stress-tracking\npractices uncovered in the study, we bring these issues to the fore, and unpack\nassumptions embedded in related works on self-tracking and how data engagement\nis approached. We end by calling for a reconsideration of data engagement as\npart of self-tracking practices with technologies rather than simply looking at\nthe user interface.\n",
			"Comment: 13 pages, 2 figures, 1 table, Accepted at ACM 2021 CHI Conference on\n  Human Factors in Computing Systems (CHI 2021)"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05450",
		"pdf_url": "http://arxiv.org/pdf/2101.05450.pdf"
	},
	"670": {
		"title": "Finding faults: A scoping study of fault diagnostics for Industrial\n  Cyber-Physical Systems",
		"creator": [
			"Dowdeswell, Barry",
			"Sinha, Roopak",
			"MacDonell, Stephen G."
		],
		"subject": "Computer Science - Software Engineering",
		"description": [
			"  Context: As Industrial Cyber-Physical Systems (ICPS) become more connected\nand widely-distributed, often operating in safety-critical environments, we\nrequire innovative approaches to detect and diagnose the faults that occur in\nthem. Objective: We profile fault identification and diagnosis techniques\nemployed in the aerospace, automotive, and industrial control domains. By\nexamining both theoretical presentations as well as case studies from\nproduction environments, we present a profile of the current approaches being\nemployed and identify gaps. Methodology: A scoping study was used to identify\nand compare fault detection and diagnosis methodologies that are presented in\nthe current literature. Results: Fault identification and analysis studies from\n127 papers published from 2004 to 2019 reveal a wide diversity of promising\ntechniques, both emerging and in-use. These range from traditional\nPhysics-based Models to Data-Driven Artificial Intelligence (AI) and\nKnowledge-Based approaches. Predictive diagnostics or prognostics featured\nprominently across all sectors, along with discussions of techniques including\nFault trees, Petri nets and Markov approaches. We also profile some of the\ntechniques that have reached the highest Technology Readiness Levels, showing\nhow those methods are being applied in real-world environments beyond the\nlaboratory. Conclusions: Our results suggest that the continuing wide use of\nboth Model-Based and Data-Driven AI techniques across all domains, especially\nwhen they are used together in hybrid configuration, reflects the complexity of\nthe current ICPS application space. While creating sufficiently-complete models\nis labor intensive, Model-free AI techniques were evidenced as a viable way of\naddressing aspects of this challenge, demonstrating the increasing\nsophistication of current machine learning systems.(Abridged)\n",
			"Comment: Journal, 19 pages, 7 figures, 6 tables"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05451",
			"10.1016/j.jss.2020.110638"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05451.pdf"
	},
	"671": {
		"title": "Interpreting and Predicting Tactile Signals for the SynTouch BioTac",
		"creator": [
			"Narang, Yashraj S.",
			"Sundaralingam, Balakumar",
			"Van Wyk, Karl",
			"Mousavian, Arsalan",
			"Fox, Dieter"
		],
		"subject": "Computer Science - Robotics",
		"description": [
			"  In the human hand, high-density contact information provided by afferent\nneurons is essential for many human grasping and manipulation capabilities. In\ncontrast, robotic tactile sensors, including the state-of-the-art SynTouch\nBioTac, are typically used to provide low-density contact information, such as\ncontact location, center of pressure, and net force. Although useful, these\ndata do not convey or leverage the rich information content that some tactile\nsensors naturally measure. This research extends robotic tactile sensing beyond\nreduced-order models through 1) the automated creation of a precise\nexperimental tactile dataset for the BioTac over a diverse range of physical\ninteractions, 2) a 3D finite element (FE) model of the BioTac, which\ncomplements the experimental dataset with high-density, distributed contact\ndata, 3) neural-network-based mappings from raw BioTac signals to not only\nlow-dimensional experimental data, but also high-density FE deformation fields,\nand 4) mappings from the FE deformation fields to the raw signals themselves.\nThe high-density data streams can provide a far greater quantity of\ninterpretable information for grasping and manipulation algorithms than\npreviously accessible.\n",
			"Comment: Submitted to International Journal of Robotics Research (IJRR)"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05452",
		"pdf_url": "http://arxiv.org/pdf/2101.05452.pdf"
	},
	"672": {
		"title": "On the quantization of recurrent neural networks",
		"creator": [
			"Li, Jian",
			"Alvarez, Raziel"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Integer quantization of neural networks can be defined as the approximation\nof the high precision computation of the canonical neural network formulation,\nusing reduced integer precision. It plays a significant role in the efficient\ndeployment and execution of machine learning (ML) systems, reducing memory\nconsumption and leveraging typically faster computations. In this work, we\npresent an integer-only quantization strategy for Long Short-Term Memory (LSTM)\nneural network topologies, which themselves are the foundation of many\nproduction ML systems. Our quantization strategy is accurate (e.g. works well\nwith quantization post-training), efficient and fast to execute (utilizing 8\nbit integer weights and mostly 8 bit activations), and is able to target a\nvariety of hardware (by leveraging instructions sets available in common CPU\narchitectures, as well as available neural accelerators).\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05453",
		"pdf_url": "http://arxiv.org/pdf/2101.05453.pdf"
	},
	"673": {
		"title": "Self-Supervised Learning for Segmentation",
		"creator": [
			"Dhere, Abhinav",
			"Sivaswamy, Jayanthi"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Self-supervised learning is emerging as an effective substitute for transfer\nlearning from large datasets. In this work, we use kidney segmentation to\nexplore this idea. The anatomical asymmetry of kidneys is leveraged to define\nan effective proxy task for kidney segmentation via self-supervised learning. A\nsiamese convolutional neural network (CNN) is used to classify a given pair of\nkidney sections from CT volumes as being kidneys of the same or different\nsides. This knowledge is then transferred for the segmentation of kidneys using\nanother deep CNN using one branch of the siamese CNN as the encoder for the\nsegmentation network. Evaluation results on a publicly available dataset\ncontaining computed tomography (CT) scans of the abdominal region shows that a\nboost in performance and fast convergence can be had relative to a network\ntrained conventionally from scratch. This is notable given that no additional\ndata/expensive annotations or augmentation were used in training.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05456",
		"pdf_url": "http://arxiv.org/pdf/2101.05456.pdf"
	},
	"674": {
		"title": "Noise Is Useful: Exploiting Data Diversity for Edge Intelligence",
		"creator": [
			"Zeng, Zhi",
			"Liu, Yuan",
			"Tang, Weijun",
			"Chen, Fangjiong"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  Edge intelligence requires to fast access distributed data samples generated\nby edge devices. The challenge is using limited radio resource to acquire\nmassive data samples for training machine learning models at edge server. In\nthis article, we propose a new communication-efficient edge intelligence scheme\nwhere the most useful data samples are selected to train the model. Here the\nusefulness or values of data samples is measured by data diversity which is\ndefined as the difference between data samples. We derive a close-form\nexpression of data diversity that combines data informativeness and channel\nquality. Then a joint data-and-channel diversity aware multiuser scheduling\nalgorithm is proposed. We find that noise is useful for enhancing data\ndiversity under some conditions.\n",
			"Comment: 5 pages, 6 figures, to be presented at IEEE Communications Letters"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05465",
		"pdf_url": "http://arxiv.org/pdf/2101.05465.pdf"
	},
	"675": {
		"title": "Text Augmentation in a Multi-Task View",
		"creator": [
			"Wei, Jason",
			"Huang, Chengyu",
			"Xu, Shiqi",
			"Vosoughi, Soroush"
		],
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  Traditional data augmentation aims to increase the coverage of the input\ndistribution by generating augmented examples that strongly resemble original\nsamples in an online fashion where augmented examples dominate training. In\nthis paper, we propose an alternative perspective -- a multi-task view (MTV) of\ndata augmentation -- in which the primary task trains on original examples and\nthe auxiliary task trains on augmented examples. In MTV data augmentation, both\noriginal and augmented samples are weighted substantively during training,\nrelaxing the constraint that augmented examples must resemble original data and\nthereby allowing us to apply stronger levels of augmentation. In empirical\nexperiments using four common data augmentation techniques on three benchmark\ntext classification datasets, we find that the MTV leads to higher and more\nrobust performance improvements than traditional augmentation.\n",
			"Comment: Accepted to EACL 2021"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05469",
		"pdf_url": "http://arxiv.org/pdf/2101.05469.pdf"
	},
	"676": {
		"title": "OrigamiSet1.0: Two New Datasets for Origami Classification and\n  Difficulty Estimation",
		"creator": [
			"Ma, Daniel",
			"Friedland, Gerald",
			"Krell, Mario Michael"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"I.4.9"
		],
		"description": [
			"  Origami is becoming more and more relevant to research. However, there is no\npublic dataset yet available and there hasn't been any research on this topic\nin machine learning. We constructed an origami dataset using images from the\nmultimedia commons and other databases. It consists of two subsets: one for\nclassification of origami images and the other for difficulty estimation. We\nobtained 16000 images for classification (half origami, half other objects) and\n1509 for difficulty estimation with $3$ different categories (easy: 764,\nintermediate: 427, complex: 318). The data can be downloaded at:\nhttps://github.com/multimedia-berkeley/OriSet. Finally, we provide machine\nlearning baselines.\n",
			"Comment: In Proceedings of Origami Science Maths Education, 7OSME, Oxford UK\n  (2018)"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05470",
		"pdf_url": "http://arxiv.org/pdf/2101.05470.pdf"
	},
	"677": {
		"title": "Time-critical testing and search problems",
		"creator": [
			"Agnetis, Alessandro",
			"Hermans, Ben",
			"Leus, Roel",
			"Rostami, Salim"
		],
		"subject": "Computer Science - Discrete Mathematics",
		"description": "  This paper introduces a problem in which the state of a system needs to be\ndetermined through costly tests of its components by a limited number of\ntesting units and before a given deadline. We also consider a closely related\nsearch problem in which there are multiple searchers to find a target before a\ngiven deadline. These natural generalizations of the classical sequential\ntesting problem and search problem are applicable in a wide range of\ntime-critical operations such as machine maintenance, diagnosing a patient, and\nnew product development. We show that both problems are NP-hard, develop a\npseudo-polynomial dynamic program for the special case of two time slots, and\ndescribe a partial-order-based as well as an assignment-based mixed integer\nprogram for the general case. Based on extensive computational experiments, we\nfind that the assignment-based formulation performs better than the\npartial-order-based formulation for the testing variant, but that this is the\nother way round for the search variant. Finally, we propose a\npairwise-interchange-based local search procedure and show that, empirically,\nit performs very well in finding near-optimal solutions.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05473",
		"pdf_url": "http://arxiv.org/pdf/2101.05473.pdf"
	},
	"678": {
		"title": "EDSC: An Event-Driven Smart Contract Platform",
		"creator": [
			"Kaleem, Mudabbir",
			"Kasichainula, Keshav",
			"Karanjai, Rabimba",
			"Xu, Lei",
			"Gao, Zhimin",
			"Chen, Lin",
			"Shi, Weidong"
		],
		"subject": "Computer Science - Distributed, Parallel, and Cluster Computing",
		"description": [
			"  This paper presents EDSC, a novel smart contract platform design based on the\nevent-driven execution model as opposed to the traditionally employed\ntransaction-driven execution model. We reason that such a design is a better\nfit for many emerging smart contract applications and is better positioned to\naddress the scalability and performance challenges plaguing the smart contract\necosystem. We propose EDSC's design under the Ethereum framework, and the\ndesign can be easily adapted for other existing smart contract platforms. We\nhave conducted implementation using Ethereum client and experiments where\nperformance modeling results show on average 2.2 to 4.6 times reduced total\nlatency of event triggered smart contracts, which demonstrates its\neffectiveness for supporting contracts that demand timely execution based on\nevents. In addition, we discuss example use cases to demonstrate the design's\nutility and comment on its potential security dynamics.\n",
			"Comment: 11 pages"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05475",
		"pdf_url": "http://arxiv.org/pdf/2101.05475.pdf"
	},
	"679": {
		"title": "Optimal network online change point localisation",
		"creator": [
			"Yu, Yi",
			"Padilla, Oscar Hernan Madrid",
			"Wang, Daren",
			"Rinaldo, Alessandro"
		],
		"subject": [
			"Mathematics - Statistics Theory",
			"Computer Science - Machine Learning"
		],
		"description": "  We study the problem of online network change point detection. In this\nsetting, a collection of independent Bernoulli networks is collected\nsequentially, and the underlying distributions change when a change point\noccurs. The goal is to detect the change point as quickly as possible, if it\nexists, subject to a constraint on the number or probability of false alarms.\nIn this paper, on the detection delay, we establish a minimax lower bound and\ntwo upper bounds based on NP-hard algorithms and polynomial-time algorithms,\ni.e., \\[ \\mbox{detection delay} \\begin{cases} \\gtrsim \\log(1/\\alpha)\n\\frac{\\max\\{r^2/n, \\, 1\\}}{\\kappa_0^2 n \\rho},\\\\ \\lesssim \\log(\\Delta/\\alpha)\n\\frac{\\max\\{r^2/n, \\, \\log(r)\\}}{\\kappa_0^2 n \\rho}, & \\mbox{with NP-hard\nalgorithms},\\\\ \\lesssim \\log(\\Delta/\\alpha) \\frac{r}{\\kappa_0^2 n \\rho}, &\n\\mbox{with polynomial-time algorithms}, \\end{cases} \\] where $\\kappa_0, n,\n\\rho, r$ and $\\alpha$ are the normalised jump size, network size, entrywise\nsparsity, rank sparsity and the overall Type-I error upper bound. All the model\nparameters are allowed to vary as $\\Delta$, the location of the change point,\ndiverges. The polynomial-time algorithms are novel procedures that we propose\nin this paper, designed for quick detection under two different forms of Type-I\nerror control. The first is based on controlling the overall probability of a\nfalse alarm when there are no change points, and the second is based on\nspecifying a lower bound on the expected time of the first false alarm.\nExtensive experiments show that, under different scenarios and the\naforementioned forms of Type-I error control, our proposed approaches\noutperform state-of-the-art methods.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05477",
		"pdf_url": "http://arxiv.org/pdf/2101.05477.pdf"
	},
	"680": {
		"title": "Understanding the Role of Scene Graphs in Visual Question Answering",
		"creator": [
			"Damodaran, Vinay",
			"Chakravarthy, Sharanya",
			"Kumar, Akshay",
			"Umapathy, Anjana",
			"Mitamura, Teruko",
			"Nakashima, Yuta",
			"Garcia, Noa",
			"Chu, Chenhui"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  Visual Question Answering (VQA) is of tremendous interest to the research\ncommunity with important applications such as aiding visually impaired users\nand image-based search. In this work, we explore the use of scene graphs for\nsolving the VQA task. We conduct experiments on the GQA dataset which presents\na challenging set of questions requiring counting, compositionality and\nadvanced reasoning capability, and provides scene graphs for a large number of\nimages. We adopt image + question architectures for use with scene graphs,\nevaluate various scene graph generation techniques for unseen images, propose a\ntraining curriculum to leverage human-annotated and auto-generated scene\ngraphs, and build late fusion architectures to learn from multiple image\nrepresentations. We present a multi-faceted study into the use of scene graphs\nfor VQA, making this work the first of its kind.\n",
		"date": [
			"2021-01-14",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05479",
		"pdf_url": "http://arxiv.org/pdf/2101.05479.pdf"
	},
	"681": {
		"title": "Iterative regularization for constrained minimization formulations of\n  nonlinear inverse problems",
		"creator": [
			"Kaltenbacher, Barbara",
			"Van Huynh, Kha"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"Mathematics - Optimization and Control"
		],
		"description": "  In this paper we the formulation of inverse problems as constrained\nminimization problems and their iterative solution by gradient or Newton type.\nWe carry out a convergence analysis in the sense of regularization methods and\ndiscuss applicability to the problem of identifying the spatially varying\ndiffusivity in an elliptic PDE from different sets of observations. Among these\nis a novel hybrid imaging techology known as impedance acoustic tomography, for\nwhich we provide numerical experiments.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05482",
		"pdf_url": "http://arxiv.org/pdf/2101.05482.pdf"
	},
	"682": {
		"title": "4D Attention-based Neural Network for EEG Emotion Recognition",
		"creator": [
			"Xiao, Guowen",
			"Ye, Mengwen",
			"Xu, Bowen",
			"Chen, Zhendi",
			"Ren, Quansheng"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Electroencephalograph (EEG) emotion recognition is a significant task in the\nbrain-computer interface field. Although many deep learning methods are\nproposed recently, it is still challenging to make full use of the information\ncontained in different domains of EEG signals. In this paper, we present a\nnovel method, called four-dimensional attention-based neural network (4D-aNN)\nfor EEG emotion recognition. First, raw EEG signals are transformed into 4D\nspatial-spectral-temporal representations. Then, the proposed 4D-aNN adopts\nspectral and spatial attention mechanisms to adaptively assign the weights of\ndifferent brain regions and frequency bands, and a convolutional neural network\n(CNN) is utilized to deal with the spectral and spatial information of the 4D\nrepresentations. Moreover, a temporal attention mechanism is integrated into a\nbidirectional Long Short-Term Memory (LSTM) to explore temporal dependencies of\nthe 4D representations. Our model achieves state-of-the-art performance on the\nSEED dataset under intra-subject splitting. The experimental results have shown\nthe effectiveness of the attention mechanisms in different domains for EEG\nemotion recognition.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05484",
		"pdf_url": "http://arxiv.org/pdf/2101.05484.pdf"
	},
	"683": {
		"title": "Label Contrastive Coding based Graph Neural Network for Graph\n  Classification",
		"creator": [
			"Ren, Yuxiang",
			"Bai, Jiyang",
			"Zhang, Jiawei"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Graph classification is a critical research problem in many applications from\ndifferent domains. In order to learn a graph classification model, the most\nwidely used supervision component is an output layer together with\nclassification loss (e.g.,cross-entropy loss together with softmax or margin\nloss). In fact, the discriminative information among instances are more\nfine-grained, which can benefit graph classification tasks. In this paper, we\npropose the novel Label Contrastive Coding based Graph Neural Network (LCGNN)\nto utilize label information more effectively and comprehensively. LCGNN still\nuses the classification loss to ensure the discriminability of classes.\nMeanwhile, LCGNN leverages the proposed Label Contrastive Loss derived from\nself-supervised learning to encourage instance-level intra-class compactness\nand inter-class separability. To power the contrastive learning, LCGNN\nintroduces a dynamic label memory bank and a momentum updated encoder. Our\nextensive evaluations with eight benchmark graph datasets demonstrate that\nLCGNN can outperform state-of-the-art graph classification models. Experimental\nresults also verify that LCGNN can achieve competitive performance with less\ntraining data because LCGNN exploits label information comprehensively.\n",
			"Comment: Accept by DASFAA'21"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05486",
		"pdf_url": "http://arxiv.org/pdf/2101.05486.pdf"
	},
	"684": {
		"title": "Neural networks behave as hash encoders: An empirical study",
		"creator": [
			"He, Fengxiang",
			"Lei, Shiye",
			"Ji, Jianmin",
			"Tao, Dacheng"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Statistics - Machine Learning"
		],
		"description": "  The input space of a neural network with ReLU-like activations is partitioned\ninto multiple linear regions, each corresponding to a specific activation\npattern of the included ReLU-like activations. We demonstrate that this\npartition exhibits the following encoding properties across a variety of deep\nlearning models: (1) {\\it determinism}: almost every linear region contains at\nmost one training example. We can therefore represent almost every training\nexample by a unique activation pattern, which is parameterized by a {\\it neural\ncode}; and (2) {\\it categorization}: according to the neural code, simple\nalgorithms, such as $K$-Means, $K$-NN, and logistic regression, can achieve\nfairly good performance on both training and test data. These encoding\nproperties surprisingly suggest that {\\it normal neural networks well-trained\nfor classification behave as hash encoders without any extra efforts.} In\naddition, the encoding properties exhibit variability in different scenarios.\n{Further experiments demonstrate that {\\it model size}, {\\it training time},\n{\\it training sample size}, {\\it regularization}, and {\\it label noise}\ncontribute in shaping the encoding properties, while the impacts of the first\nthree are dominant.} We then define an {\\it activation hash phase chart} to\nrepresent the space expanded by {model size}, training time, training sample\nsize, and the encoding properties, which is divided into three canonical\nregions: {\\it under-expressive regime}, {\\it critically-expressive regime}, and\n{\\it sufficiently-expressive regime}. The source code package is available at\n\\url{https://github.com/LeavesLei/activation-code}.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05490",
		"pdf_url": "http://arxiv.org/pdf/2101.05490.pdf"
	},
	"685": {
		"title": "Hostility Detection in Hindi leveraging Pre-Trained Language Models",
		"creator": [
			"Kamal, Ojasv",
			"Kumar, Adarsh",
			"Vaidhya, Tejas"
		],
		"subject": "Computer Science - Computation and Language",
		"description": "  Hostile content on social platforms is ever increasing. This has led to the\nneed for proper detection of hostile posts so that appropriate action can be\ntaken to tackle them. Though a lot of work has been done recently in the\nEnglish Language to solve the problem of hostile content online, similar works\nin Indian Languages are quite hard to find. This paper presents a transfer\nlearning based approach to classify social media (i.e Twitter, Facebook, etc.)\nposts in Hindi Devanagari script as Hostile or Non-Hostile. Hostile posts are\nfurther analyzed to determine if they are Hateful, Fake, Defamation, and\nOffensive. This paper harnesses attention based pre-trained models fine-tuned\non Hindi data with Hostile-Non hostile task as Auxiliary and fusing its\nfeatures for further sub-tasks classification. Through this approach, we\nestablish a robust and consistent model without any ensembling or complex\npre-processing. We have presented the results from our approach in\nCONSTRAINT-2021 Shared Task on hostile post detection where our model performs\nextremely well with 3rd runner up in terms of Weighted Fine-Grained F1 Score.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05494",
		"pdf_url": "http://arxiv.org/pdf/2101.05494.pdf"
	},
	"686": {
		"title": "Selective Deletion in a Blockchain",
		"creator": [
			"Hillmann, Peter",
			"Knüpfer, Marcus",
			"Heiland, Erik",
			"Karcher, Andreas"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Computers and Society",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": "  The constantly growing size of blockchains becomes a challenge with the\nincreasing usage. Especially the storage of unwanted data in a blockchain is an\nissue, because it cannot be removed naturally. In order to counteract this\nproblem, we present the first concept for the selective deletion of single\nentries in a blockchain. For this purpose, the general consensus algorithm is\nextended by the functionality of regularly creating summary blocks. Previous\ndata of the chain are summarized and stored again in a new block, leaving out\nunwanted information. With a shifting marker of the Genesis Block, data can be\ndeleted from the beginning of a blockchain. In this way, the technology of the\nblockchain becomes fully transactional. The concept is independent of a\nspecific block structure, network structure, or consensus algorithm. Moreover,\nthis functionality can be adapted to current blockchains to solve multiple\nproblems related to scalability. This approach enables the transfer of\nblockchain technology to further fields of application, among others in the\narea of Industry 4.0 and Product Life-cycle Management.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05495",
			"International Workshop on Blockchain and Mobile Applications\n  (BlockApp 2020) during the International Conference on Distributed Computing\n  Systems (ICDCS 2020)"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05495.pdf"
	},
	"687": {
		"title": "ECOL: Early Detection of COVID Lies Using Content, Prior Knowledge and\n  Source Information",
		"creator": [
			"Baris, Ipek",
			"Boukhers, Zeyd"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Social media platforms are vulnerable to fake news dissemination, which\ncauses negative consequences such as panic and wrong medication in the\nhealthcare domain. Therefore, it is important to automatically detect fake news\nin an early stage before they get widely spread. This paper analyzes the impact\nof incorporating content information, prior knowledge, and credibility of\nsources into models for the early detection of fake news. We propose a\nframework modeling those features by using BERT language model and external\nsources, namely Simple English Wikipedia and source reliability tags. The\nconducted experiments on CONSTRAINT datasets demonstrated the benefit of\nintegrating these features for the early detection of fake news in the\nhealthcare domain.\n",
			"Comment: to be published in Constraint-2021 Workshop @ AAAI"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05499",
		"pdf_url": "http://arxiv.org/pdf/2101.05499.pdf"
	},
	"688": {
		"title": "Joint Dimensionality Reduction for Separable Embedding Estimation",
		"creator": [
			"Li, Yanjun",
			"Wen, Bihan",
			"Cheng, Hao",
			"Bresler, Yoram"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Low-dimensional embeddings for data from disparate sources play critical\nroles in multi-modal machine learning, multimedia information retrieval, and\nbioinformatics. In this paper, we propose a supervised dimensionality reduction\nmethod that learns linear embeddings jointly for two feature vectors\nrepresenting data of different modalities or data from distinct types of\nentities. We also propose an efficient feature selection method that\ncomplements, and can be applied prior to, our joint dimensionality reduction\nmethod. Assuming that there exist true linear embeddings for these features,\nour analysis of the error in the learned linear embeddings provides theoretical\nguarantees that the dimensionality reduction method accurately estimates the\ntrue embeddings when certain technical conditions are satisfied and the number\nof samples is sufficiently large. The derived sample complexity results are\nechoed by numerical experiments. We apply the proposed dimensionality reduction\nmethod to gene-disease association, and predict unknown associations using\nkernel regression on the dimension-reduced feature vectors. Our approach\ncompares favorably against other dimensionality reduction methods, and against\na state-of-the-art method of bilinear regression for predicting gene-disease\nassociations.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05500",
		"pdf_url": "http://arxiv.org/pdf/2101.05500.pdf"
	},
	"689": {
		"title": "Evaluating the Robustness of Collaborative Agents",
		"creator": [
			"Knott, Paul",
			"Carroll, Micah",
			"Devlin, Sam",
			"Ciosek, Kamil",
			"Hofmann, Katja",
			"Dragan, A. D.",
			"Shah, Rohin"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Multiagent Systems"
		],
		"description": "  In order for agents trained by deep reinforcement learning to work alongside\nhumans in realistic settings, we will need to ensure that the agents are\n\\emph{robust}. Since the real world is very diverse, and human behavior often\nchanges in response to agent deployment, the agent will likely encounter novel\nsituations that have never been seen during training. This results in an\nevaluation challenge: if we cannot rely on the average training or validation\nreward as a metric, then how can we effectively evaluate robustness? We take\ninspiration from the practice of \\emph{unit testing} in software engineering.\nSpecifically, we suggest that when designing AI agents that collaborate with\nhumans, designers should search for potential edge cases in \\emph{possible\npartner behavior} and \\emph{possible states encountered}, and write tests which\ncheck that the behavior of the agent in these edge cases is reasonable. We\napply this methodology to build a suite of unit tests for the Overcooked-AI\nenvironment, and use this test suite to evaluate three proposals for improving\nrobustness. We find that the test suite provides significant insight into the\neffects of these proposals that were generally not revealed by looking solely\nat the average validation reward.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05507",
		"pdf_url": "http://arxiv.org/pdf/2101.05507.pdf"
	},
	"690": {
		"title": "Transformer-based Language Model Fine-tuning Methods for COVID-19 Fake\n  News Detection",
		"creator": [
			"Chen, Ben",
			"Chen, Bin",
			"Gao, Dehong",
			"Chen, Qijin",
			"Huo, Chengfu",
			"Meng, Xiaonan",
			"Ren, Weijun",
			"Zhou, Yang"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  With the pandemic of COVID-19, relevant fake news is spreading all over the\nsky throughout the social media. Believing in them without discrimination can\ncause great trouble to people's life. However, universal language models may\nperform weakly in these fake news detection for lack of large-scale annotated\ndata and sufficient semantic understanding of domain-specific knowledge. While\nthe model trained on corresponding corpora is also mediocre for insufficient\nlearning. In this paper, we propose a novel transformer-based language model\nfine-tuning approach for these fake news detection. First, the token vocabulary\nof individual model is expanded for the actual semantics of professional\nphrases. Second, we adapt the heated-up softmax loss to distinguish the\nhard-mining samples, which are common for fake news because of the\ndisambiguation of short text. Then, we involve adversarial training to improve\nthe model's robustness. Last, the predicted features extracted by universal\nlanguage model RoBERTa and domain-specific model CT-BERT are fused by one\nmultiple layer perception to integrate fine-grained and high-level specific\nrepresentations. Quantitative experimental results evaluated on existing\nCOVID-19 fake news dataset show its superior performances compared to the\nstate-of-the-art methods among various evaluation metrics. Furthermore, the\nbest weighted average F1 score achieves 99.02%.\n",
			"Comment: 9 pages, 1 figures"
		],
		"date": [
			"2021-01-14",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05509",
		"pdf_url": "http://arxiv.org/pdf/2101.05509.pdf"
	},
	"691": {
		"title": "Entangled Kernels -- Beyond Separability",
		"creator": [
			"Huusari, Riikka",
			"Kadri, Hachem"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Quantum Physics",
			"Statistics - Machine Learning"
		],
		"description": "  We consider the problem of operator-valued kernel learning and investigate\nthe possibility of going beyond the well-known separable kernels. Borrowing\ntools and concepts from the field of quantum computing, such as partial trace\nand entanglement, we propose a new view on operator-valued kernels and define a\ngeneral family of kernels that encompasses previously known operator-valued\nkernels, including separable and transformable kernels. Within this framework,\nwe introduce another novel class of operator-valued kernels called entangled\nkernels that are not separable. We propose an efficient two-step algorithm for\nthis framework, where the entangled kernel is learned based on a novel\nextension of kernel alignment to operator-valued kernels. We illustrate our\nalgorithm with an application to supervised dimensionality reduction, and\ndemonstrate its effectiveness with both artificial and real data for\nmulti-output regression.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05514",
			"Journal of Machine Learning Research 22 (2021) 1-40"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05514.pdf"
	},
	"692": {
		"title": "An evaluation of word-level confidence estimation for end-to-end\n  automatic speech recognition",
		"creator": [
			"Oneata, Dan",
			"Caranica, Alexandru",
			"Stan, Adriana",
			"Cucu, Horia"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Audio and Speech Processing",
			"Computer Science - Computation and Language",
			"Computer Science - Sound"
		],
		"description": [
			"  Quantifying the confidence (or conversely the uncertainty) of a prediction is\na highly desirable trait of an automatic system, as it improves the robustness\nand usefulness in downstream tasks. In this paper we investigate confidence\nestimation for end-to-end automatic speech recognition (ASR). Previous work has\naddressed confidence measures for lattice-based ASR, while current machine\nlearning research mostly focuses on confidence measures for unstructured deep\nlearning. However, as the ASR systems are increasingly being built upon deep\nend-to-end methods, there is little work that tries to develop confidence\nmeasures in this context. We fill this gap by providing an extensive benchmark\nof popular confidence methods on four well-known speech datasets. There are two\nchallenges we overcome in adapting existing methods: working on structured data\n(sequences) and obtaining confidences at a coarser level than the predictions\n(words instead of tokens). Our results suggest that a strong baseline can be\nobtained by scaling the logits by a learnt temperature, followed by estimating\nthe confidence as the negative entropy of the predictive distribution and,\nfinally, sum pooling to aggregate at word level.\n",
			"Comment: Accepted at SLT 2021"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05525",
		"pdf_url": "http://arxiv.org/pdf/2101.05525.pdf"
	},
	"693": {
		"title": "Scaling Equilibrium Propagation to Deep ConvNets by Drastically Reducing\n  its Gradient Estimator Bias",
		"creator": [
			"Laborieux, Axel",
			"Ernoult, Maxence",
			"Scellier, Benjamin",
			"Bengio, Yoshua",
			"Grollier, Julie",
			"Querlioz, Damien"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Neural and Evolutionary Computing"
		],
		"description": [
			"  Equilibrium Propagation (EP) is a biologically-inspired counterpart of\nBackpropagation Through Time (BPTT) which, owing to its strong theoretical\nguarantees and the locality in space of its learning rule, fosters the design\nof energy-efficient hardware dedicated to learning. In practice, however, EP\ndoes not scale to visual tasks harder than MNIST. In this work, we show that a\nbias in the gradient estimate of EP, inherent in the use of finite nudging, is\nresponsible for this phenomenon and that cancelling it allows training deep\nConvNets by EP, including architectures with distinct forward and backward\nconnections. These results highlight EP as a scalable approach to compute error\ngradients in deep neural networks, thereby motivating its hardware\nimplementation.\n",
			"Comment: NeurIPS 2020 Workshop : \"Beyond Backpropagation Novel Ideas for\n  Training Neural Architectures\". arXiv admin note: substantial text overlap\n  with arXiv:2006.03824"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05536",
		"pdf_url": "http://arxiv.org/pdf/2101.05536.pdf"
	},
	"694": {
		"title": "Optimal Energy Shaping via Neural Approximators",
		"creator": [
			"Massaroli, Stefano",
			"Poli, Michael",
			"Califano, Federico",
			"Park, Jinkyoo",
			"Yamashita, Atsushi",
			"Asama, Hajime"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning",
			"Computer Science - Neural and Evolutionary Computing",
			"Mathematics - Dynamical Systems"
		],
		"description": "  We introduce optimal energy shaping as an enhancement of classical\npassivity-based control methods. A promising feature of passivity theory,\nalongside stability, has traditionally been claimed to be intuitive performance\ntuning along the execution of a given task. However, a systematic approach to\nadjust performance within a passive control framework has yet to be developed,\nas each method relies on few and problem-specific practical insights. Here, we\ncast the classic energy-shaping control design process in an optimal control\nframework; once a task-dependent performance metric is defined, an optimal\nsolution is systematically obtained through an iterative procedure relying on\nneural networks and gradient-based optimization. The proposed method is\nvalidated on state-regulation tasks.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05537",
		"pdf_url": "http://arxiv.org/pdf/2101.05537.pdf"
	},
	"695": {
		"title": "Cyber Taxi: A Taxonomy of Interactive Cyber Training and Education\n  Systems",
		"creator": [
			"Knüpfer, Marcus",
			"Bierwirth, Tore",
			"Stiemert, Lars",
			"Schopp, Matthias",
			"Seeber, Sebastian",
			"Pöhn, Daniela",
			"Hillmann, Peter"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Computers and Society",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": "  The lack of guided exercises and practical opportunities to learn about\ncybersecurity in a practical way makes it difficult for security experts to\nimprove their proficiency. Capture the Flag events and Cyber Ranges are ideal\nfor cybersecurity training. Thereby, the participants usually compete in teams\nagainst each other, or have to defend themselves in a specific scenario. As\norganizers of yearly events, we present a taxonomy for interactive cyber\ntraining and education. The proposed taxonomy includes different factors of the\ntechnical setup, audience, training environment, and training setup. By the\ncomprehensive taxonomy, different aspects of interactive training are\nconsidered. This can help trainings to improve and to be established\nsuccessfully. The provided taxonomy is extendable and can be used in further\napplication areas as research on new security technologies.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05538",
			"Model-driven Simulation and Training Environments for\n  Cybersecurity (MSTEC 2020)"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05538.pdf"
	},
	"696": {
		"title": "On the Synchronization Power of Token Smart Contracts",
		"creator": [
			"Alpos, Orestis",
			"Cachin, Christian",
			"Marson, Giorgia Azzurra",
			"Zanolini, Luca"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Cryptography and Security"
		],
		"description": "  Modern blockchains support a variety of distributed applications beyond\ncryptocurrencies, including smart contracts -- which let users execute\narbitrary code in a distributed and decentralized fashion. Regardless of their\nintended application, blockchain platforms implicitly assume consensus for the\ncorrect execution of a smart contract, thus requiring that all transactions are\ntotally ordered. It was only recently recognized that consensus is not\nnecessary to prevent double-spending in a cryptocurrency (Guerraoui et al.,\nPODC'19), contrary to common belief. This result suggests that current\nimplementations may be sacrificing efficiency and scalability because they\nsynchronize transactions much more tightly than actually needed. In this work,\nwe study the synchronization requirements of Ethereum's ERC20 token contract,\none of the most widely adopted smart contacts. Namely, we model a\nsmart-contract token as a concurrent object and analyze its consensus number as\na measure of synchronization power. We show that the richer set of methods\nsupported by ERC20 tokens, compared to standard cryptocurrencies, results in\nstrictly stronger synchronization requirements. More surprisingly, the\nsynchronization power of ERC20 tokens depends on the object's state and can\nthus be modified by method invocations. To prove this result, we develop a\ndedicated framework to express how the object's state affects the needed\nsynchronization level. Our findings indicate that ERC20 tokens, as well as\nother token standards, are more powerful and versatile than plain\ncryptocurrencies, and are subject to dynamic requirements. Developing specific\nsynchronization protocols that exploit these dynamic requirements will pave the\nway towards more robust and scalable blockchain platforms.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05543",
		"pdf_url": "http://arxiv.org/pdf/2101.05543.pdf"
	},
	"697": {
		"title": "DICE: Diversity in Deep Ensembles via Conditional Redundancy Adversarial\n  Estimation",
		"creator": [
			"Rame, Alexandre",
			"Cord, Matthieu"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Information Theory"
		],
		"description": [
			"  Deep ensembles perform better than a single network thanks to the diversity\namong their members. Recent approaches regularize predictions to increase\ndiversity; however, they also drastically decrease individual members'\nperformances. In this paper, we argue that learning strategies for deep\nensembles need to tackle the trade-off between ensemble diversity and\nindividual accuracies. Motivated by arguments from information theory and\nleveraging recent advances in neural estimation of conditional mutual\ninformation, we introduce a novel training criterion called DICE: it increases\ndiversity by reducing spurious correlations among features. The main idea is\nthat features extracted from pairs of members should only share information\nuseful for target class prediction without being conditionally redundant.\nTherefore, besides the classification loss with information bottleneck, we\nadversarially prevent features from being conditionally predictable from each\nother. We manage to reduce simultaneous errors while protecting class\ninformation. We obtain state-of-the-art accuracy results on CIFAR-10/100: for\nexample, an ensemble of 5 networks trained with DICE matches an ensemble of 7\nnetworks trained independently. We further analyze the consequences on\ncalibration, uncertainty estimation, out-of-distribution detection and online\nco-distillation.\n",
			"Comment: Published as a conference paper at ICLR 2021. 9 main pages, 13\n  figures, 12 tables"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05544",
		"pdf_url": "http://arxiv.org/pdf/2101.05544.pdf"
	},
	"698": {
		"title": "Feature reduction for machine learning on molecular features: The\n  GeneScore",
		"creator": [
			"Denker, Alexander",
			"Steshina, Anastasia",
			"Grooss, Theresa",
			"Ueckert, Frank",
			"Nürnberg, Sylvia"
		],
		"subject": [
			"Quantitative Biology - Genomics",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  We present the GeneScore, a concept of feature reduction for Machine Learning\nanalysis of biomedical data. Using expert knowledge, the GeneScore integrates\ndifferent molecular data types into a single score. We show that the GeneScore\nis superior to a binary matrix in the classification of cancer entities from\nSNV, Indel, CNV, gene fusion and gene expression data. The GeneScore is a\nstraightforward way to facilitate state-of-the-art analysis, while making use\nof the available scientific knowledge on the nature of molecular data features\nused.\n",
			"Comment: 11 pages, 9 figures, 4 tables"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05546",
		"pdf_url": "http://arxiv.org/pdf/2101.05546.pdf"
	},
	"699": {
		"title": "FabricNet: A Fiber Recognition Architecture Using Ensemble ConvNets",
		"creator": [
			"Ohi, Abu Quwsar",
			"Mridha, M. F.",
			"Hamid, Md. Abdul",
			"Monowar, Muhammad Mostafa",
			"Kateb, Faris A"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Fabric is a planar material composed of textile fibers. Textile fibers are\ngenerated from many natural sources; including plants, animals, minerals, and\neven, it can be synthetic. A particular fabric may contain different types of\nfibers that pass through a complex production process. Fiber identification is\nusually carried out through chemical tests and microscopic tests. However,\nthese testing processes are complicated as well as time-consuming. We propose\nFabricNet, a pioneering approach for the image-based textile fiber recognition\nsystem, which may have a revolutionary impact from individual to the industrial\nfiber recognition process. The FabricNet can recognize a large scale of fibers\nby only utilizing a surface image of fabric. The recognition system is\nconstructed using a distinct category of class-based ensemble convolutional\nneural network (CNN) architecture. The experiment is conducted on recognizing\n50 different types of textile fibers. This experiment includes a significantly\nlarge number of unique textile fibers than previous research endeavors to the\nbest of our knowledge. We experiment with popular CNN architectures that\ninclude Inception, ResNet, VGG, MobileNet, DenseNet, and Xception. Finally, the\nexperimental results demonstrate that FabricNet outperforms the\nstate-of-the-art popular CNN architectures by reaching an accuracy of 84% and\nF1-score of 90%.\n",
			"Comment: Accepted in IEEE Access"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05564",
			"doi:10.1109/ACCESS.2021.3051980"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05564.pdf"
	},
	"700": {
		"title": "Design of false data injection attack on distributed process estimation",
		"creator": [
			"Choraria, Moulik",
			"Chattopadhyay, Arpan",
			"Mitra, Urbashi",
			"Strom, Erik"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Computer Science - Multiagent Systems"
		],
		"description": [
			"  Herein, design of false data injection attack on a distributed cyber-physical\nsystem is considered. A stochastic process with linear dynamics and Gaussian\nnoise is measured by multiple agent nodes, each equipped with multiple sensors.\nThe agent nodes form a multi-hop network among themselves. Each agent node\ncomputes an estimate of the process by using its sensor observation and\nmessages obtained from neighboring nodes, via Kalman-consensus filtering. An\nexternal attacker, capable of arbitrarily manipulating the sensor observations\nof some or all agent nodes, injects errors into those sensor observations. The\ngoal of the attacker is to steer the estimates at the agent nodes as close as\npossible to a pre-specified value, while respecting a constraint on the attack\ndetection probability. To this end, a constrained optimization problem is\nformulated to find the optimal parameter values of a certain class of linear\nattacks. The parameters of linear attack are learnt on-line via a combination\nof stochastic approximation based update of a Lagrange multiplier, and an\noptimization technique involving either the Karush-Kuhn-Tucker (KKT) conditions\nor online stochastic gradient descent. The problem turns out to be convex for\nsome special cases. Desired convergence of the proposed algorithms are proved\nby exploiting the convexity and properties of stochastic approximation\nalgorithms. Finally, numerical results demonstrate the efficacy of the attack.\n",
			"Comment: arXiv admin note: substantial text overlap with arXiv:2002.01545"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05567",
		"pdf_url": "http://arxiv.org/pdf/2101.05567.pdf"
	},
	"701": {
		"title": "All-at-once formulation meets the Bayesian approach: A study of two\n  prototypical linear inverse problems",
		"creator": [
			"Schlintl, Anna",
			"Kaltenbacher, Barbara"
		],
		"subject": "Mathematics - Numerical Analysis",
		"description": "  In this work, the Bayesian approach to inverse problems is formulated in an\nall-at-once setting. The advantages of the all-at-once formulation are known to\ninclude the avoidance of a parameter-to-state map as well as numerical\nimprovements, especially when considering nonlinear problems. In the Bayesian\napproach, prior knowledge is taken into account with the help of a prior\ndistribution. In addition, the error in the observation equation is formulated\nby means of a distribution. This method naturally results in a whole posterior\ndistribution for the unknown target, not just point estimates. This allows for\nfurther statistical analysis including the computation of credible intervals.\nWe combine the Bayesian setting with the all-at-once formulation, resulting in\na novel approach for investigating inverse problems. With this combination we\nare able to chose a prior not only for the parameter, but also for the state\nvariable, which directly influences the parameter. Furthermore, errors not only\nin the observation equation, but additionally, in the model can be taken into\naccount. %The aim of this approach is not only to accomplish reasonable\nreconstructions of the unknown parameter but also to maximize the information\ngained from measurements through combining it with prior knowledge, obtained\neither from certain expertise or former investigation in the model. We analyze\nthis approach with the help of two linear standard examples, namely the inverse\nsource problem for the Poisson equation and the backwards heat equation, i.e. a\nstationary and a time dependent problem. Appropriate function spaces and\nderivation of adjoint operators are investigated. To assess the degree of\nill-posedness, we analyze the singular values of the corresponding all-at-once\nforward operators. %as well as the convergence of the method. Finally, joint\npriors are designed and numerically tested.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05577",
		"pdf_url": "http://arxiv.org/pdf/2101.05577.pdf"
	},
	"702": {
		"title": "DeFi-ning DeFi: Challenges & Pathway",
		"creator": [
			"Amler, Hendrik",
			"Eckey, Lisa",
			"Faust, Sebastian",
			"Kaiser, Marcel",
			"Sandner, Philipp",
			"Schlosser, Benjamin"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": "  The decentralized and trustless nature of cryptocurrencies and blockchain\ntechnology leads to a shift in the digital world. The possibility to execute\nsmall programs, called smart contracts, on cryptocurrencies like Ethereum\nopened doors to countless new applications. One particular exciting use case is\ndecentralized finance (DeFi), which aims to revolutionize traditional financial\nservices by founding them on a decentralized infrastructure. We show the\npotential of DeFi by analyzing its advantages compared to traditional finance.\nAdditionally, we survey the state-of-the-art of DeFi products and categorize\nexisting services. Since DeFi is still in its infancy, there are countless\nhurdles for mass adoption. We discuss the most prominent challenges and point\nout possible solutions. Finally, we analyze the economics behind DeFi products.\nBy carefully analyzing the state-of-the-art and discussing current challenges,\nwe give a perspective on how the DeFi space might develop in the near future.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05589",
		"pdf_url": "http://arxiv.org/pdf/2101.05589.pdf"
	},
	"703": {
		"title": "ANDROMEDA: An FPGA Based RISC-V MPSoC Exploration Framework",
		"creator": [
			"Merchant, Farhad",
			"Sisejkovic, Dominik",
			"Reimann, Lennart M.",
			"Yasotharan, Kirthihan",
			"Grass, Thomas",
			"Leupers, Rainer"
		],
		"subject": "Computer Science - Hardware Architecture",
		"description": [
			"  With the growing demands of consumer electronic products, the computational\nrequirements are increasing exponentially. Due to the applications'\ncomputational needs, the computer architects are trying to pack as many cores\nas possible on a single die for accelerated execution of the application\nprogram codes. In a multiprocessor system-on-chip (MPSoC), striking a balance\namong the number of cores, memory subsystems, and network-on-chip parameters is\nessential to attain the desired performance. In this paper, we present\nANDROMEDA, a RISC-V based framework that allows us to explore the different\nconfigurations of an MPSoC and observe the performance penalties and gains. We\nemulate the various configurations of MPSoC on the Synopsys HAPS-80D Dual FPGA\nplatform. Using STREAM, matrix multiply, and N-body simulations as benchmarks,\nwe demonstrate our framework's efficacy in quickly identifying the right\nparameters for efficient execution of these benchmarks.\n",
			"Comment: Accepted in VLSI Design 2021"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05591",
		"pdf_url": "http://arxiv.org/pdf/2101.05591.pdf"
	},
	"704": {
		"title": "On the Temporality of Priors in Entity Linking",
		"creator": "Joao, Renato Stoffalette",
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning"
		],
		"description": "  Entity linking is a fundamental task in natural language processing which\ndeals with the lexical ambiguity in texts. An important component in entity\nlinking approaches is the mention-to-entity prior probability. Even though\nthere is a large number of works in entity linking, the existing approaches do\nnot explicitly consider the time aspect, specifically the temporality of an\nentity's prior probability. We posit that this prior probability is temporal in\nnature and affects the performance of entity linking systems. In this paper we\nsystematically study the effect of the prior on the entity linking performance\nover the temporal validity of both texts and KBs.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05593",
			"2020 European Conference on Information Retrieval"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05593.pdf"
	},
	"705": {
		"title": "A Physics-Informed Machine Learning Model for Porosity Analysis in Laser\n  Powder Bed Fusion Additive Manufacturing",
		"creator": [
			"Liu, Rui",
			"Liu, Sen",
			"Zhang, Xiaoli"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  To control part quality, it is critical to analyze pore generation\nmechanisms, laying theoretical foundation for future porosity control. Current\nporosity analysis models use machine setting parameters, such as laser angle\nand part pose. However, these setting-based models are machine dependent, hence\nthey often do not transfer to analysis of porosity for a different machine. To\naddress the first problem, a physics-informed, data-driven model (PIM), which\ninstead of directly using machine setting parameters to predict porosity levels\nof printed parts, it first interprets machine settings into physical effects,\nsuch as laser energy density and laser radiation pressure. Then, these\nphysical, machine independent effects are used to predict porosity levels\naccording to pass, flag, fail categories instead of focusing on quantitative\npore size prediction. With six learning methods evaluation, PIM proved to\nachieve good performances with prediction error of 10$\\sim$26%. Finally,\npore-encouraging influence and pore-suppressing influence were analyzed for\nquality analysis.\n",
			"Comment: 14 pages"
		],
		"date": "2021-01-12",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05605",
		"pdf_url": "http://arxiv.org/pdf/2101.05605.pdf"
	},
	"706": {
		"title": "Deep Cellular Recurrent Network for Efficient Analysis of Time-Series\n  Data with Spatial Information",
		"creator": [
			"Vidyaratne, Lasitha",
			"Alam, Mahbubul",
			"Glandon, Alexander",
			"Shabalina, Anna",
			"Tennant, Christopher",
			"Iftekharuddin, Khan"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": "  Efficient processing of large-scale time series data is an intricate problem\nin machine learning. Conventional sensor signal processing pipelines with hand\nengineered feature extraction often involve huge computational cost with high\ndimensional data. Deep recurrent neural networks have shown promise in\nautomated feature learning for improved time-series processing. However,\ngeneric deep recurrent models grow in scale and depth with increased complexity\nof the data. This is particularly challenging in presence of high dimensional\ndata with temporal and spatial characteristics. Consequently, this work\nproposes a novel deep cellular recurrent neural network (DCRNN) architecture to\nefficiently process complex multi-dimensional time series data with spatial\ninformation. The cellular recurrent architecture in the proposed model allows\nfor location-aware synchronous processing of time series data from spatially\ndistributed sensor signal sources. Extensive trainable parameter sharing due to\ncellularity in the proposed architecture ensures efficiency in the use of\nrecurrent processing units with high-dimensional inputs. This study also\ninvestigates the versatility of the proposed DCRNN model for classification of\nmulti-class time series data from different application domains. Consequently,\nthe proposed DCRNN architecture is evaluated using two time-series datasets: a\nmultichannel scalp EEG dataset for seizure detection, and a machine fault\ndetection dataset obtained in-house. The results suggest that the proposed\narchitecture achieves state-of-the-art performance while utilizing\nsubstantially less trainable parameters when compared to comparable methods in\nthe literature.\n",
		"date": "2021-01-12",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05608",
		"pdf_url": "http://arxiv.org/pdf/2101.05608.pdf"
	},
	"707": {
		"title": "Review on the Security Threats of Internet of Things",
		"creator": [
			"Podder, Prajoy",
			"Mondal, M. Rubaiyat Hossain",
			"Bharati, Subrato",
			"Paul, Pinto Kumar"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": [
			"  Internet of Things (IoT) is being considered as the growth engine for\nindustrial revolution 4.0. The combination of IoT, cloud computing and\nhealthcare can contribute in ensuring well-being of people. One important\nchallenge of IoT network is maintaining privacy and to overcome security\nthreats. This paper provides a systematic review of the security aspects of\nIoT. Firstly, the application of IoT in industrial and medical service\nscenarios are described, and the security threats are discussed for the\ndifferent layers of IoT healthcare architecture. Secondly, different types of\nexisting malware including spyware, viruses, worms, keyloggers, and trojan\nhorses are described in the context of IoT. Thirdly, some of the recent malware\nattacks such as Mirai, echobot and reaper are discussed. Next, a comparative\ndiscussion is presented on the effectiveness of different machine learning\nalgorithms in mitigating the security threats. It is found that the k-nearest\nneighbor (kNN) machine learning algorithm exhibits excellent accuracy in\ndetecting malware. This paper also reviews different tools for ransomware\ndetection, classification and analysis. Finally, a discussion is presented on\nthe existing security issues, open challenges and possible future scopes in\nensuring IoT security.\n",
			"Comment: 9 Pages, 9 figures"
		],
		"date": "2021-01-12",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05614",
			"International Journal of Computer Applications (IJCA), 2020",
			"doi:10.5120/ijca2020920548"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05614.pdf"
	},
	"708": {
		"title": "FBGEMM: Enabling High-Performance Low-Precision Deep Learning Inference",
		"creator": [
			"Khudia, Daya",
			"Huang, Jianyu",
			"Basu, Protonu",
			"Deng, Summer",
			"Liu, Haixin",
			"Park, Jongsoo",
			"Smelyanskiy, Mikhail"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Performance"
		],
		"description": "  Deep learning models typically use single-precision (FP32) floating point\ndata types for representing activations and weights, but a slew of recent\nresearch work has shown that computations with reduced-precision data types\n(FP16, 16-bit integers, 8-bit integers or even 4- or 2-bit integers) are enough\nto achieve same accuracy as FP32 and are much more efficient. Therefore, we\ndesigned fbgemm, a high-performance kernel library, from ground up to perform\nhigh-performance quantized inference on current generation CPUs. fbgemm\nachieves efficiency by fusing common quantization operations with a\nhigh-performance gemm implementation and by shape- and size-specific kernel\ncode generation at runtime. The library has been deployed at Facebook, where it\ndelivers greater than 2x performance gains with respect to our current\nproduction baseline.\n",
		"date": "2021-01-12",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05615",
		"pdf_url": "http://arxiv.org/pdf/2101.05615.pdf"
	},
	"709": {
		"title": "A Framework for Assurance of Medication Safety using Machine Learning",
		"creator": [
			"Jia, Yan",
			"Lawton, Tom",
			"McDermid, John",
			"Rojas, Eric",
			"Habli, Ibrahim"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computers and Society"
		],
		"description": "  Medication errors continue to be the leading cause of avoidable patient harm\nin hospitals. This paper sets out a framework to assure medication safety that\ncombines machine learning and safety engineering methods. It uses safety\nanalysis to proactively identify potential causes of medication error, based on\nexpert opinion. As healthcare is now data rich, it is possible to augment\nsafety analysis with machine learning to discover actual causes of medication\nerror from the data, and to identify where they deviate from what was predicted\nin the safety analysis. Combining these two views has the potential to enable\nthe risk of medication errors to be managed proactively and dynamically. We\napply the framework to a case study involving thoracic surgery, e.g.\noesophagectomy, where errors in giving beta-blockers can be critical to control\natrial fibrillation. This case study combines a HAZOP-based safety analysis\nmethod known as SHARD with Bayesian network structure learning and process\nmining to produce the analysis results, showing the potential of the framework\nfor ensuring patient safety, and for transforming the way that safety is\nmanaged in complex healthcare environments.\n",
		"date": "2021-01-11",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05620",
		"pdf_url": "http://arxiv.org/pdf/2101.05620.pdf"
	},
	"710": {
		"title": "Design of borehole resistivity measurement acquisition systems using\n  deep learning",
		"creator": [
			"Shahriari, M.",
			"Hazra, A.",
			"Pardo, D."
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Signal Processing",
			"Mathematics - Numerical Analysis"
		],
		"description": "  Borehole resistivity measurements recorded with logging-while-drilling (LWD)\ninstruments are widely used for characterizing the earth's subsurface\nproperties. They facilitate the extraction of natural resources such as oil and\ngas. LWD instruments require real-time inversions of electromagnetic\nmeasurements to estimate the electrical properties of the earth's subsurface\nnear the well and possibly correct the well trajectory. Deep Neural Network\n(DNN)-based methods are suitable for the rapid inversion of borehole\nresistivity measurements as they approximate the forward and inverse problem\noffline during the training phase and they only require a fraction of a second\nfor the evaluation (aka prediction). However, the inverse problem generally\nadmits multiple solutions. DNNs with traditional loss functions based on data\nmisfit are ill-equipped for solving an inverse problem. This can be partially\novercome by adding regularization terms to a loss function specifically\ndesigned for encoder-decoder architectures. But adding regularization seriously\nlimits the number of possible solutions to a set of a priori desirable physical\nsolutions. To avoid this, we use a two-step loss function without any\nregularization. In addition, to guarantee an inverse solution, we need a\ncarefully selected measurement acquisition system with a sufficient number of\nmeasurements. In this work, we propose a DNN-based iterative algorithm for\ndesigning such a measurement acquisition system. We illustrate our DNN-based\niterative algorithm via several synthetic examples. Numerical results show that\nthe obtained measurement acquisition system is sufficient to identify and\ncharacterize both resistive and conductive layers above and below the logging\ninstrument. Numerical results are promising, although further improvements are\nrequired to make our method amenable for industrial purposes.\n",
		"date": "2021-01-12",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05623",
		"pdf_url": "http://arxiv.org/pdf/2101.05623.pdf"
	},
	"711": {
		"title": "Adversarially Robust and Explainable Model Compression with On-Device\n  Personalization for Text Classification",
		"creator": [
			"Qiang, Yao",
			"Kumar, Supriya Tumkur Suresh",
			"Brocanelli, Marco",
			"Zhu, Dongxiao"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  On-device Deep Neural Networks (DNNs) have recently gained more attention due\nto the increasing computing power of the mobile devices and the number of\napplications in Computer Vision (CV), Natural Language Processing (NLP), and\nInternet of Things (IoTs). Unfortunately, the existing efficient convolutional\nneural network (CNN) architectures designed for CV tasks are not directly\napplicable to NLP tasks and the tiny Recurrent Neural Network (RNN)\narchitectures have been designed primarily for IoT applications. In NLP\napplications, although model compression has seen initial success in on-device\ntext classification, there are at least three major challenges yet to be\naddressed: adversarial robustness, explainability, and personalization. Here we\nattempt to tackle these challenges by designing a new training scheme for model\ncompression and adversarial robustness, including the optimization of an\nexplainable feature mapping objective, a knowledge distillation objective, and\nan adversarially robustness objective. The resulting compressed model is\npersonalized using on-device private training data via fine-tuning. We perform\nextensive experiments to compare our approach with both compact RNN (e.g.,\nFastGRNN) and compressed RNN (e.g., PRADO) architectures in both natural and\nadversarial NLP test settings.\n",
			"Comment: 8 pages, 4 figures"
		],
		"date": [
			"2021-01-10",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05624",
		"pdf_url": "http://arxiv.org/pdf/2101.05624.pdf"
	},
	"712": {
		"title": "Learning Student Interest Trajectory for MOOCThread Recommendation",
		"creator": [
			"Pandey, Shalini",
			"Lan, Andrew",
			"Karypis, George",
			"Srivastava, Jaideep"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Computers and Society",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  In recent years, Massive Open Online Courses (MOOCs) have witnessed immense\ngrowth in popularity. Now, due to the recent Covid19 pandemic situation, it is\nimportant to push the limits of online education. Discussion forums are primary\nmeans of interaction among learners and instructors. However, with growing\nclass size, students face the challenge of finding useful and informative\ndiscussion forums. This problem can be solved by matching the interest of\nstudents with thread contents. The fundamental challenge is that the student\ninterests drift as they progress through the course, and forum contents evolve\nas students or instructors update them. In our paper, we propose to predict\nfuture interest trajectories of students. Our model consists of two key\noperations: 1) Update operation and 2) Projection operation. Update operation\nmodels the inter-dependency between the evolution of student and thread using\ncoupled Recurrent Neural Networks when the student posts on the thread. The\nprojection operation learns to estimate future embedding of students and\nthreads. For students, the projection operation learns the drift in their\ninterests caused by the change in the course topic they study. The projection\noperation for threads exploits how different posts induce varying interest\nlevels in a student according to the thread structure. Extensive\nexperimentation on three real-world MOOC datasets shows that our model\nsignificantly outperforms other baselines for thread recommendation.\n",
			"Comment: Accepted at IEEE ICDM Workshop on Continual Learning and Adaptation\n  for Time Evolving Data, 2020"
		],
		"date": [
			"2021-01-10",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05625",
		"pdf_url": "http://arxiv.org/pdf/2101.05625.pdf"
	},
	"713": {
		"title": "Eating Garlic Prevents COVID-19 Infection: Detecting Misinformation on\n  the Arabic Content of Twitter",
		"creator": [
			"Alqurashi, Sarah",
			"Hamoui, Btool",
			"Alashaikh, Abdulaziz",
			"Alhindi, Ahmad",
			"Alanazi, Eisa"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Computers and Society",
			"Computer Science - Machine Learning",
			"Computer Science - Social and Information Networks"
		],
		"description": [
			"  The rapid growth of social media content during the current pandemic provides\nuseful tools for disseminating information which has also become a root for\nmisinformation. Therefore, there is an urgent need for fact-checking and\neffective techniques for detecting misinformation in social media. In this\nwork, we study the misinformation in the Arabic content of Twitter. We\nconstruct a large Arabic dataset related to COVID-19 misinformation and\ngold-annotate the tweets into two categories: misinformation or not. Then, we\napply eight different traditional and deep machine learning models, with\ndifferent features including word embeddings and word frequency. The word\nembedding models (\\textsc{FastText} and word2vec) exploit more than two million\nArabic tweets related to COVID-19. Experiments show that optimizing the area\nunder the curve (AUC) improves the models' performance and the Extreme Gradient\nBoosting (XGBoost) presents the highest accuracy in detecting COVID-19\nmisinformation online.\n",
			"Comment: 18 pages, 4 figures"
		],
		"date": "2021-01-09",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05626",
		"pdf_url": "http://arxiv.org/pdf/2101.05626.pdf"
	},
	"714": {
		"title": "Game-based Pricing and Task Offloading in Mobile Edge Computing Enabled\n  Edge-Cloud Systems",
		"creator": [
			"Su, Yi",
			"Fan, Wenhao",
			"Liu, Yuan'an",
			"Wu, Fan"
		],
		"subject": "Computer Science - Computer Science and Game Theory",
		"description": [
			"  As a momentous enabling of the Internet of things (IoT), mobile edge\ncomputing (MEC) provides IoT mobile devices (MD) with powerful external\ncomputing and storage resources. However, a mechanism addressing distributed\ntask offloading and price competition for the open exchange marketplace has not\nbeen established properly, which has become a huge obstacle to MEC's\napplication in the IoT market. In this paper, we formulate a distributed\nmechanism to analyze the interaction between OSPs and IoT MDs in the MEC\nenabled edge-cloud system by appling multi-leader multi-follower two-tier\nStackelberg game theory. We first prove the existence of the Stackelberg\nequilibrium, and then we propose two distributed algorithms, namely iterative\nproximal offloading algorithm (IPOA) and iterative Stackelberg game pricing\nalgorithm (ISPA). The IPOA solves the follower non-cooperative game among IoT\nMDs and ISPA uses backward induction to deal with the price competition among\nOSPs. Experimental results show that IPOA can markedly reduce the disutility of\nIoT MDs compared with other traditional task offloading schemes and the price\nof anarchy is always less than 150\\%. Besides, results also demonstrate that\nISPA is reliable in boosting the revenue of OSPs.\n",
			"Comment: 12 pages, 9 figures"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05628",
		"pdf_url": "http://arxiv.org/pdf/2101.05628.pdf"
	},
	"715": {
		"title": "Off-grid Channel Estimation with Sparse Bayesian Learning for OTFS\n  Systems",
		"creator": [
			"Wei, Zhiqiang",
			"Yuan, Weijie",
			"Li, Shuangyang",
			"Yuan, Jinhong",
			"Ng, Derrick Wing Kwan"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  This paper proposes an off-grid channel estimation scheme for orthogonal\ntime-frequency space (OTFS) systems adopting the sparse Bayesian learning (SBL)\nframework. To avoid channel spreading caused by the fractional delay and\nDoppler shifts and to fully exploit the channel sparsity in the delay-Doppler\n(DD) domain, we estimate the original DD domain channel response rather than\nthe effective DD domain channel response as commonly adopted in the literature.\nOTFS channel estimation is first formulated as a one-dimensional (1D) off-grid\nsparse signal recovery (SSR) problem based on a virtual sampling grid defined\nin the DD space, where the on-grid and off-grid components of the delay and\nDoppler shifts are separated for estimation. In particular, the on-grid\ncomponents of the delay and Doppler shifts are jointly determined by the entry\nindices with significant values in the recovered sparse vector. Then, the\ncorresponding off-grid components are modeled as hyper-parameters in the\nproposed SBL framework, which can be estimated via the expectation-maximization\nmethod. To strike a balance between channel estimation performance and\ncomputational complexity, we further propose a two-dimensional (2D) off-grid\nSSR problem via decoupling the delay and Doppler shift estimations. In our\ndeveloped 1D and 2D off-grid SBL-based channel estimation algorithms, the\nhyper-parameters are updated alternatively for computing the conditional\nposterior distribution of channels, which can be exploited to reconstruct the\neffective DD domain channel. Compared with the 1D method, the proposed 2D\nmethod enjoys a much lower computational complexity while only suffers slight\nperformance degradation. Simulation results verify the superior performance of\nthe proposed channel estimation schemes over state-of-the-art schemes.\n",
			"Comment: 30 pages, 9 figures, submitted to IEEE Transactions on Wireless\n  Communications"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05629",
		"pdf_url": "http://arxiv.org/pdf/2101.05629.pdf"
	},
	"716": {
		"title": "Parkinson's Disease Diagnosis Using Deep Learning",
		"creator": "Alissa, Mohamad",
		"subject": [
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": [
			"  Parkinson's Disease (PD) is a chronic, degenerative disorder which leads to a\nrange of motor and cognitive symptoms. PD diagnosis is a challenging task since\nits symptoms are very similar to other diseases such as normal ageing and\nessential tremor. Much research has been applied to diagnosing this disease.\nThis project aims to automate the PD diagnosis process using deep learning,\nRecursive Neural Networks (RNN) and Convolutional Neural Networks (CNN), to\ndifferentiate between healthy and PD patients. Besides that, since different\ndatasets may capture different aspects of this disease, this project aims to\nexplore which PD test is more effective in the discrimination process by\nanalysing different imaging and movement datasets (notably cube and spiral\npentagon datasets). In addition, this project evaluates which dataset type,\nimaging or time series, is more effective in diagnosing PD.\n",
			"Comment: Master Research Project"
		],
		"date": "2021-01-03",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05631",
		"pdf_url": "http://arxiv.org/pdf/2101.05631.pdf"
	},
	"717": {
		"title": "Enhanced Audit Techniques Empowered by the Reinforcement Learning\n  Pertaining to IFRS 16 Lease",
		"creator": "Choi, Byungryul",
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"68T05 (Primary) 68Q32, 68T42 (secondary)",
			"I.2.6",
			"J.1"
		],
		"description": [
			"  The purpose of accounting audit is to have clear understanding on the\nfinancial activities of a company, which can be enhanced by machine learning or\nreinforcement learning as numeric analysis better than manual analysis can be\nmade. For the purpose of assessment on the relevance, completeness and accuracy\nof the information produced by entity pertaining to the newly implemented\nInternational Financial Reporting Standard 16 Lease (IFRS 16) is one of such\ncandidates as its characteristic of requiring the understanding on the nature\nof contracts and its complete analysis from listing up without omission, which\ncan be enhanced by the digitalization of contracts for the purpose of creating\nthe lists, still leaving the need of auditing cash flows of companies for the\npossible omission due to the potential error at the stage of data collection,\nespecially for entities with various short or middle term business sites and\nrelated leases, such as construction entities.\n  The implementation of the reinforcement learning and its well-known code is\nto be made for the purpose of drawing the possibility and utilizability of\ninterpreters from domain knowledge to numerical system, also can be called\n'gamification interpreter' or 'numericalization interpreter' which can be\nreferred or compared to the extrapolation with nondimensional numbers, such as\nFroude Number, in physics, which was a source of inspiration at this study.\nStudies on the interpreters can be able to empower the utilizability of\nartificial general intelligence in domain and commercial area.\n",
			"Comment: for codes, please refer to\n  https://github.com/BryanBYChoi/Reinforcement_Learning_IFRS16_Lease"
		],
		"date": "2021-01-05",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05633",
		"pdf_url": "http://arxiv.org/pdf/2101.05633.pdf"
	},
	"718": {
		"title": "Better Together -- An Ensemble Learner for Combining the Results of\n  Ready-made Entity Linking Systems",
		"creator": [
			"João, Renato Stoffalette",
			"Fafalios, Pavlos",
			"Dietze, Stefan"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Entity linking (EL) is the task of automatically identifying entity mentions\nin text and resolving them to a corresponding entity in a reference knowledge\nbase like Wikipedia. Throughout the past decade, a plethora of EL systems and\npipelines have become available, where performance of individual systems varies\nheavily across corpora, languages or domains. Linking performance varies even\nbetween different mentions in the same text corpus, where, for instance, some\nEL approaches are better able to deal with short surface forms while others may\nperform better when more context information is available. To this end, we\nargue that performance may be optimised by exploiting results from distinct EL\nsystems on the same corpus, thereby leveraging their individual strengths on a\nper-mention basis. In this paper, we introduce a supervised approach which\nexploits the output of multiple ready-made EL systems by predicting the correct\nlink on a per-mention basis. Experimental results obtained on existing ground\ntruth datasets and exploiting three state-of-the-art EL systems show the\neffectiveness of our approach and its capacity to significantly outperform the\nindividual EL systems as well as a set of baseline methods.\n",
			"Comment: SAC '20: Proceedings of the 35th Annual ACM Symposium on Applied\n  Computing"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05634",
			"doi:10.1145/3341105.3373883"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05634.pdf"
	},
	"719": {
		"title": "To what extent is researchers' data-sharing motivated by formal\n  mechanisms of recognition and credit?",
		"creator": [
			"Dorta-González, Pablo",
			"González-Betancor, Sara M.",
			"Dorta-González, María Isabel"
		],
		"subject": [
			"Computer Science - Digital Libraries",
			"Statistics - Applications",
			"62P25"
		],
		"description": [
			"  Data sharing by researchers is a centerpiece of Open Science principles and\nscientific progress. For a sample of 6019 researchers, we analyze the\nextent/frequency of their data sharing. Specifically, the relationship with the\nfollowing four variables: how much they value data citations, the extent to\nwhich their data-sharing activities are formally recognized, their perceptions\nof whether sufficient credit is awarded for data sharing, and the reported\nextent to which data citations motivate their data sharing. In addition, we\nanalyze the extent to which researchers have reused openly accessible data, as\nwell as how data sharing varies by professional age-cohort, and its\nrelationship to the value they place on data citations. Furthermore, we\nconsider most of the explanatory variables simultaneously by estimating a\nmultiple linear regression that predicts the extent/frequency of their data\nsharing. We use the dataset of the State of Open Data Survey 2019 by Springer\nNature and Digital Science. Results do allow us to conclude that a desire for\nrecognition/credit is a major incentive for data sharing. Thus, the possibility\nof receiving data citations is highly valued when sharing data, especially\namong younger researchers, irrespective of the frequency with which it is\npracticed. Finally, the practice of data sharing was found to be more prevalent\nat late research career stages, despite this being when citations are less\nvalued and have a lower motivational impact. This could be due to the fact that\nlater-career researchers may benefit less from keeping their data private.\n",
			"Comment: 26 pages, 4 figures, 7 tables"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05636",
		"pdf_url": "http://arxiv.org/pdf/2101.05636.pdf"
	},
	"720": {
		"title": "Untargeted, Targeted and Universal Adversarial Attacks and Defenses on\n  Time Series",
		"creator": [
			"Rathore, Pradeep",
			"Basak, Arghya",
			"Nistala, Sri Harsha",
			"Runkana, Venkataramana"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  Deep learning based models are vulnerable to adversarial attacks. These\nattacks can be much more harmful in case of targeted attacks, where an attacker\ntries not only to fool the deep learning model, but also to misguide the model\nto predict a specific class. Such targeted and untargeted attacks are\nspecifically tailored for an individual sample and require addition of an\nimperceptible noise to the sample. In contrast, universal adversarial attack\ncalculates a special imperceptible noise which can be added to any sample of\nthe given dataset so that, the deep learning model is forced to predict a wrong\nclass. To the best of our knowledge these targeted and universal attacks on\ntime series data have not been studied in any of the previous works. In this\nwork, we have performed untargeted, targeted and universal adversarial attacks\non UCR time series datasets. Our results show that deep learning based time\nseries classification models are vulnerable to these attacks. We also show that\nuniversal adversarial attacks have good generalization property as it need only\na fraction of the training data. We have also performed adversarial training\nbased adversarial defense. Our results show that models trained adversarially\nusing Fast gradient sign method (FGSM), a single step attack, are able to\ndefend against FGSM as well as Basic iterative method (BIM), a popular\niterative attack.\n",
			"Comment: Published at IJCNN 2020"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05639",
			"doi:10.1109/IJCNN48605.2020.9207272"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05639.pdf"
	},
	"721": {
		"title": "$C^3DRec$: Cloud-Client Cooperative Deep Learning for Temporal\n  Recommendation in the Post-GDPR Era",
		"creator": [
			"Han, Jialiang",
			"Ma, Yun"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Cryptography and Security",
			"Computer Science - Machine Learning"
		],
		"description": "  Mobile devices enable users to retrieve information at any time and any\nplace. Considering the occasional requirements and fragmentation usage pattern\nof mobile users, temporal recommendation techniques are proposed to improve the\nefficiency of information retrieval on mobile devices by means of accurately\nrecommending items via learning temporal interests with short-term user\ninteraction behaviors. However, the enforcement of privacy-preserving laws and\nregulations, such as GDPR, may overshadow the successful practice of temporal\nrecommendation. The reason is that state-of-the-art recommendation systems\nrequire to gather and process the user data in centralized servers but the\ninteraction behaviors data used for temporal recommendation are usually\nnon-transactional data that are not allowed to gather without the explicit\npermission of users according to GDPR. As a result, if users do not permit\nservices to gather their interaction behaviors data, the temporal\nrecommendation fails to work. To realize the temporal recommendation in the\npost-GDPR era, this paper proposes $C^3DRec$, a cloud-client cooperative deep\nlearning framework of mining interaction behaviors for recommendation while\npreserving user privacy. $C^3DRec$ constructs a global recommendation model on\ncentralized servers using data collected before GDPR and fine-tunes the model\ndirectly on individual local devices using data collected after GDPR. We design\ntwo modes to accomplish the recommendation, i.e. pull mode where candidate\nitems are pulled down onto the devices and fed into the local model to get\nrecommended items, and push mode where the output of the local model is pushed\nonto the server and combined with candidate items to get recommended ones.\nEvaluation results show that $C^3DRec$ achieves comparable recommendation\naccuracy to the centralized approaches, with minimal privacy concern.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05641",
		"pdf_url": "http://arxiv.org/pdf/2101.05641.pdf"
	},
	"722": {
		"title": "Ensemble of LSTMs and feature selection for human action prediction",
		"creator": [
			"Petković, Tomislav",
			"Petrović, Luka",
			"Marković, Ivan",
			"Petrović, Ivan"
		],
		"subject": "Computer Science - Robotics",
		"description": "  As robots are becoming more and more ubiquitous in human environments, it\nwill be necessary for robotic systems to better understand and predict human\nactions. However, this is not an easy task, at times not even for us humans,\nbut based on a relatively structured set of possible actions, appropriate cues,\nand the right model, this problem can be computationally tackled. In this\npaper, we propose to use an ensemble of long-short term memory (LSTM) networks\nfor human action prediction. To train and evaluate models, we used the MoGaze\ndataset - currently the most comprehensive dataset capturing poses of human\njoints and the human gaze. We have thoroughly analyzed the MoGaze dataset and\nselected a reduced set of cues for this task. Our model can predict (i) which\nof the labeled objects the human is going to grasp, and (ii) which of the macro\nlocations the human is going to visit (such as table or shelf). We have\nexhaustively evaluated the proposed method and compared it to individual cue\nbaselines. The results suggest that our LSTM model slightly outperforms the\ngaze baseline in single object picking accuracy, but achieves better accuracy\nin macro object prediction. Furthermore, we have also analyzed the prediction\naccuracy when the gaze is not used, and in this case, the LSTM model\nconsiderably outperformed the best single cue baseline\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05645",
		"pdf_url": "http://arxiv.org/pdf/2101.05645.pdf"
	},
	"723": {
		"title": "Malicious Code Detection: Run Trace Output Analysis by LSTM",
		"creator": [
			"Acarturk, Cengiz",
			"Sirlanci, Melih",
			"Balikcioglu, Pinar Gurkan",
			"Demirci, Deniz",
			"Sahin, Nazenin",
			"Kucuk, Ozge Acar"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning",
			"D.2.5",
			"I.2.7",
			"K.3.2"
		],
		"description": [
			"  Malicious software threats and their detection have been gaining importance\nas a subdomain of information security due to the expansion of ICT applications\nin daily settings. A major challenge in designing and developing anti-malware\nsystems is the coverage of the detection, particularly the development of\ndynamic analysis methods that can detect polymorphic and metamorphic malware\nefficiently. In the present study, we propose a methodological framework for\ndetecting malicious code by analyzing run trace outputs by Long Short-Term\nMemory (LSTM). We developed models of run traces of malicious and benign\nPortable Executable (PE) files. We created our dataset from run trace outputs\nobtained from dynamic analysis of PE files. The obtained dataset was in the\ninstruction format as a sequence and was called Instruction as a Sequence Model\n(ISM). By splitting the first dataset into basic blocks, we obtained the second\none called Basic Block as a Sequence Model (BSM). The experiments showed that\nthe ISM achieved an accuracy of 87.51% and a false positive rate of 18.34%,\nwhile BSM achieved an accuracy of 99.26% and a false positive rate of 2.62%.\n",
			"Comment: 11 pages, 5 figures, 5 tables, accepted to IEEE Access"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05646",
			"doi:10.1109/ACCESS.2021.3049200"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05646.pdf"
	},
	"724": {
		"title": "A Nature-Inspired Feature Selection Approach based on Hypercomplex\n  Information",
		"creator": [
			"de Rosa, Gustavo H.",
			"Papa, João Paulo",
			"Yang, Xin-She"
		],
		"subject": [
			"Computer Science - Neural and Evolutionary Computing",
			"Computer Science - Machine Learning",
			"I.2.0"
		],
		"description": [
			"  Feature selection for a given model can be transformed into an optimization\ntask. The essential idea behind it is to find the most suitable subset of\nfeatures according to some criterion. Nature-inspired optimization can mitigate\nthis problem by producing compelling yet straightforward solutions when dealing\nwith complicated fitness functions. Additionally, new mathematical\nrepresentations, such as quaternions and octonions, are being used to handle\nhigher-dimensional spaces. In this context, we are introducing a meta-heuristic\noptimization framework in a hypercomplex-based feature selection, where\nhypercomplex numbers are mapped to real-valued solutions and then transferred\nonto a boolean hypercube by a sigmoid function. The intended hypercomplex\nfeature selection is tested for several meta-heuristic algorithms and\nhypercomplex representations, achieving results comparable to some\nstate-of-the-art approaches. The good results achieved by the proposed approach\nmake it a promising tool amongst feature selection research.\n",
			"Comment: 17 pages, 7 figures"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05652",
			"APPLIED SOFT COMPUTING; v. 94, SEP 2020",
			"doi:10.1016/j.asoc.2020.106453"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05652.pdf"
	},
	"725": {
		"title": "On Informative Tweet Identification For Tracking Mass Events",
		"creator": "João, Renato Stoffalette",
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning"
		],
		"description": "  Twitter has been heavily used as an important channel for communicating and\ndiscussing about events in real-time. In such major events, many uninformative\ntweets are also published rapidly by many users, making it hard to follow the\nevents. In this paper, we address this problem by investigating machine\nlearning methods for automatically identifying informative tweets among those\nthat are relevant to a target event. We examine both traditional approaches\nwith a rich set of handcrafted features and state of the art approaches with\nautomatically learned features. We further propose a hybrid model that\nleverages both the handcrafted features and the automatically learned ones. Our\nexperiments on several large datasets of real-world events show that the latter\napproaches significantly outperform the former and our proposed model performs\nthe best, suggesting highly effective mechanisms for tracking mass events.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05656",
		"pdf_url": "http://arxiv.org/pdf/2101.05656.pdf"
	},
	"726": {
		"title": "No-go Theorem for Acceleration in the Hyperbolic Plane",
		"creator": [
			"Hamilton, Linus",
			"Moitra, Ankur"
		],
		"subject": [
			"Mathematics - Optimization and Control",
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  In recent years there has been significant effort to adapt the key tools and\nideas in convex optimization to the Riemannian setting. One key challenge has\nremained: Is there a Nesterov-like accelerated gradient method for geodesically\nconvex functions on a Riemannian manifold? Recent work has given partial\nanswers and the hope was that this ought to be possible.\n  Here we dash these hopes. We prove that in a noisy setting, there is no\nanalogue of accelerated gradient descent for geodesically convex functions on\nthe hyperbolic plane. Our results apply even when the noise is exponentially\nsmall. The key intuition behind our proof is short and simple: In negatively\ncurved spaces, the volume of a ball grows so fast that information about the\npast gradients is not useful in the future.\n",
			"Comment: 12 pages"
		],
		"date": [
			"2021-01-14",
			"2021-01-16"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05657",
		"pdf_url": "http://arxiv.org/pdf/2101.05657.pdf"
	},
	"727": {
		"title": "A Pipeline for Vision-Based On-Orbit Proximity Operations Using Deep\n  Learning and Synthetic Imagery",
		"creator": [
			"Schubert, Carson",
			"Black, Kevin",
			"Fonseka, Daniel",
			"Dhir, Abhimanyu",
			"Deutsch, Jacob",
			"Dhamani, Nihal",
			"Martin, Gavin",
			"Akella, Maruthi"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Software Engineering"
		],
		"description": [
			"  Deep learning has become the gold standard for image processing over the past\ndecade. Simultaneously, we have seen growing interest in orbital activities\nsuch as satellite servicing and debris removal that depend on proximity\noperations between spacecraft. However, two key challenges currently pose a\nmajor barrier to the use of deep learning for vision-based on-orbit proximity\noperations. Firstly, efficient implementation of these techniques relies on an\neffective system for model development that streamlines data curation,\ntraining, and evaluation. Secondly, a scarcity of labeled training data (images\nof a target spacecraft) hinders creation of robust deep learning models. This\npaper presents an open-source deep learning pipeline, developed specifically\nfor on-orbit visual navigation applications, that addresses these challenges.\nThe core of our work consists of two custom software tools built on top of a\ncloud architecture that interconnects all stages of the model development\nprocess. The first tool leverages Blender, an open-source 3D graphics toolset,\nto generate labeled synthetic training data with configurable model poses\n(positions and orientations), lighting conditions, backgrounds, and commonly\nobserved in-space image aberrations. The second tool is a plugin-based\nframework for effective dataset curation and model training; it provides common\nfunctionality like metadata generation and remote storage access to all\nprojects while giving complete independence to project-specific code.\nTime-consuming, graphics-intensive processes such as synthetic image generation\nand model training run on cloud-based computational resources which scale to\nany scope and budget and allow development of even the largest datasets and\nmodels from any machine. The presented system has been used in the Texas\nSpacecraft Laboratory with marked benefits in development speed and quality.\n",
			"Comment: Accepted to IEEE Aerospace Conference 2021. 14 pages, 11 figures"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05661",
		"pdf_url": "http://arxiv.org/pdf/2101.05661.pdf"
	},
	"728": {
		"title": "Exploring the socio-technical interplay of Industry 4.0: a single case\n  study of an Italian manufacturing organisation",
		"creator": [
			"Margherita, Emanuele Gabriel",
			"Braccini, Alessio Maria"
		],
		"subject": "Computer Science - Computers and Society",
		"description": [
			"  In this position paper, we explore the socio-technical interplay of Industry\n4.0. Industry 4.0 is an industrial plan that aims at automating the production\nprocess by the adoption of advanced leading-edge technologies down the assembly\nline. Most of the studies employ a technical perspective that is focused on\nstudying how to integrate various technologies and the resulting benefits for\norganisations. In contrast, few studies use a socio-technical perspective of\nIndustry 4.0. We close this gap employs the socio-technical lens on an in-depth\nsingle case study of a manufacturing organisation that effectively adopted\nIndustry 4.0 technologies. The findings of our studies shed light both on the\nsocio-technical interplay between workers and technologies and the novel role\nof workers. We conclude proposing a socio-technical framework for an Industry\n4.0 context.\n",
			"Comment: Proceedings of the 6th International Workshop on Socio-Technical\n  Perspective in IS Development (STPIS 2020), June 8-9, 2020\n  http://ceur-ws.org/Vol-2789/paper16.pdf"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05665",
			"CEUR Workshop Proceedings, Vol-2789,pages 121-126, 2020"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05665.pdf"
	},
	"729": {
		"title": "The Expando-Mono-Duo Design Pattern for Text Ranking with Pretrained\n  Sequence-to-Sequence Models",
		"creator": [
			"Pradeep, Ronak",
			"Nogueira, Rodrigo",
			"Lin, Jimmy"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Computation and Language"
		],
		"description": "  We propose a design pattern for tackling text ranking problems, dubbed\n\"Expando-Mono-Duo\", that has been empirically validated for a number of ad hoc\nretrieval tasks in different domains. At the core, our design relies on\npretrained sequence-to-sequence models within a standard multi-stage ranking\narchitecture. \"Expando\" refers to the use of document expansion techniques to\nenrich keyword representations of texts prior to inverted indexing. \"Mono\" and\n\"Duo\" refer to components in a reranking pipeline based on a pointwise model\nand a pairwise model that rerank initial candidates retrieved using keyword\nsearch. We present experimental results from the MS MARCO passage and document\nranking tasks, the TREC 2020 Deep Learning Track, and the TREC-COVID challenge\nthat validate our design. In all these tasks, we achieve effectiveness that is\nat or near the state of the art, in some cases using a zero-shot approach that\ndoes not exploit any training data from the target task. To support\nreplicability, implementations of our design pattern are open-sourced in the\nPyserini IR toolkit and PyGaggle neural reranking library.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05667",
		"pdf_url": "http://arxiv.org/pdf/2101.05667.pdf"
	},
	"730": {
		"title": "Exploring the Smart City Adoption Process: Evidence from the Belgian\n  urban context",
		"creator": [
			"Margherita, Emanuele Gabriel",
			"Esposito, Giovanni",
			"Escobar, Stefania Denise",
			"Crutzen, Nathalie"
		],
		"subject": "Computer Science - Computers and Society",
		"description": [
			"  In this position paper, we explore the adoption of a Smart City with a\nsocio-technical perspective. A Smart city is a transformational technological\nprocess leading to profound modifications of existing urban regimes and\ninfrastructure components. In this study, we consider a Smart City as a\nsocio-technical system where the interplay between technologies and users\nensures the sustainable development of smart city initiatives that improve the\nquality of life and solve important socio-economic problems. The adoption of a\nSmart City required a participative approach where users are involved during\nthe adoption process to joint optimise both systems. Thus, we contribute to\nsocio-technical research showing how a participative approach based on press\nrelationships to facilitate information exchange between municipal actors and\ncitizens worked as a success factor for the smart city adoption. We also\ndiscuss the limitations of this approach.\n",
			"Comment: Proceedings of the 6th International Workshop on Socio-Technical\n  Perspective in IS Development (STPIS 2020), June 8-9, 2020\n  http://ceur-ws.org/Vol-2789/paper1.pdf"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05670",
			"CEUR Workshop Proceedings, Vol-2789, pages 1-7, 2020"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05670.pdf"
	},
	"731": {
		"title": "Analysis of hidden feedback loops in continuous machine learning systems",
		"creator": "Khritankov, Anton",
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Software Engineering"
		],
		"description": [
			"  In this concept paper, we discuss intricacies of specifying and verifying the\nquality of continuous and lifelong learning artificial intelligence systems as\nthey interact with and influence their environment causing a so-called concept\ndrift. We signify a problem of implicit feedback loops, demonstrate how they\nintervene with user behavior on an exemplary housing prices prediction system.\nBased on a preliminary model, we highlight conditions when such feedback loops\narise and discuss possible solution approaches.\n",
			"Comment: 7 pages, 9 figures; added more experiments, minor stylistic fixes and\n  typos"
		],
		"date": [
			"2021-01-14",
			"2021-01-17"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05673",
			"Soft. Qual.: Fut. Persp. on Soft. Eng. Q. SWQD 2021. LNBIP, V. 404",
			"doi:10.1007/978-3-030-65854-0_5"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05673.pdf"
	},
	"732": {
		"title": "Improving non-deterministic uncertainty modelling in Industry 4.0\n  scheduling",
		"creator": [
			"Misra, Ashwin",
			"Mittal, Ankit",
			"Misra, Vihaan",
			"Pandey, Deepanshu"
		],
		"subject": [
			"Statistics - Other Statistics",
			"Computer Science - Artificial Intelligence",
			"Statistics - Applications"
		],
		"description": "  The latest Industrial revolution has helped industries in achieving very high\nrates of productivity and efficiency. It has introduced data aggregation and\ncyber-physical systems to optimize planning and scheduling. Although,\nuncertainty in the environment and the imprecise nature of human operators are\nnot accurately considered for into the decision making process. This leads to\ndelays in consignments and imprecise budget estimations. This widespread\npractice in the industrial models is flawed and requires rectification. Various\nother articles have approached to solve this problem through stochastic or\nfuzzy set model methods. This paper presents a comprehensive method to\nlogically and realistically quantify the non-deterministic uncertainty through\nprobabilistic uncertainty modelling. This method is applicable on virtually all\nIndustrial data sets, as the model is self adjusting and uses\nepsilon-contamination to cater to limited or incomplete data sets. The results\nare numerically validated through an Industrial data set in Flanders, Belgium.\nThe data driven results achieved through this robust scheduling method\nillustrate the improvement in performance.\n",
		"date": "2021-01-08",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05677",
		"pdf_url": "http://arxiv.org/pdf/2101.05677.pdf"
	},
	"733": {
		"title": "Convex Smoothed Autoencoder-Optimal Transport model",
		"creator": "Mustafi, Aratrika",
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Generative modelling is a key tool in unsupervised machine learning which has\nachieved stellar success in recent years. Despite this huge success, even the\nbest generative models such as Generative Adversarial Networks (GANs) and\nVariational Autoencoders (VAEs) come with their own shortcomings, mode collapse\nand mode mixture being the two most prominent problems. In this paper we\ndevelop a new generative model capable of generating samples which resemble the\nobserved data, and is free from mode collapse and mode mixture. Our model is\ninspired by the recently proposed Autoencoder-Optimal Transport (AE-OT) model\nand tries to improve on it by addressing the problems faced by the AE-OT model\nitself, specifically with respect to the sample generation algorithm.\nTheoretical results concerning the bound on the error in approximating the\nnon-smooth Brenier potential by its smoothed estimate, and approximating the\ndiscontinuous optimal transport map by a smoothed optimal transport map\nestimate have also been established in this paper.\n",
			"Comment: 26 pages"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05679",
		"pdf_url": "http://arxiv.org/pdf/2101.05679.pdf"
	},
	"734": {
		"title": "Adaptive Private Distributed Matrix Multiplication",
		"creator": [
			"Bitar, Rawad",
			"Xhemrishi, Marvin",
			"Wachter-Zeh, Antonia"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  We consider the problem of designing codes with flexible rate (referred to as\nrateless codes), for private distributed matrix-matrix multiplication. A master\nserver owns two private matrices $\\mathbf{A}$ and $\\mathbf{B}$ and hires worker\nnodes to help computing their multiplication. The matrices should remain\ninformation-theoretically private from the workers. Codes with fixed rate\nrequire the master to assign tasks to the workers and then wait for a\npredetermined number of workers to finish their assigned tasks. The size of the\ntasks, hence the rate of the scheme, depends on the number of workers that the\nmaster waits for. We design a rateless private matrix-matrix multiplication\nscheme, called RPM3. In contrast to fixed-rate schemes, our scheme fixes the\nsize of the tasks and allows the master to send multiple tasks to the workers.\nThe master keeps sending tasks and receiving results until it can decode the\nmultiplication; rendering the scheme flexible and adaptive to heterogeneous\nenvironments. Despite resulting in a smaller rate than known straggler-tolerant\nschemes, RPM3 provides a smaller mean waiting time of the master by leveraging\nthe heterogeneity of the workers. The waiting time is studied under two\ndifferent models for the workers' service time. We provide upper bounds for the\nmean waiting time under both models. In addition, we provide lower bounds on\nthe mean waiting time under the worker-dependent fixed service time model.\n",
			"Comment: arXiv admin note: text overlap with arXiv:2004.12925"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05681",
		"pdf_url": "http://arxiv.org/pdf/2101.05681.pdf"
	},
	"735": {
		"title": "AVGCN: Trajectory Prediction using Graph Convolutional Networks Guided\n  by Human Attention",
		"creator": [
			"Liu, Congcong",
			"Chen, Yuying",
			"Liu, Ming",
			"Shi, Bertram E."
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Robotics"
		],
		"description": [
			"  Pedestrian trajectory prediction is a critical yet challenging task,\nespecially for crowded scenes. We suggest that introducing an attention\nmechanism to infer the importance of different neighbors is critical for\naccurate trajectory prediction in scenes with varying crowd size. In this work,\nwe propose a novel method, AVGCN, for trajectory prediction utilizing graph\nconvolutional networks (GCN) based on human attention (A denotes attention, V\ndenotes visual field constraints). First, we train an attention network that\nestimates the importance of neighboring pedestrians, using gaze data collected\nas subjects perform a bird's eye view crowd navigation task. Then, we\nincorporate the learned attention weights modulated by constraints on the\npedestrian's visual field into a trajectory prediction network that uses a GCN\nto aggregate information from neighbors efficiently. AVGCN also considers the\nstochastic nature of pedestrian trajectories by taking advantage of variational\ntrajectory prediction. Our approach achieves state-of-the-art performance on\nseveral trajectory prediction benchmarks, and the lowest average prediction\nerror over all considered benchmarks.\n",
			"Comment: 7 pages, 4 figures"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05682",
		"pdf_url": "http://arxiv.org/pdf/2101.05682.pdf"
	},
	"736": {
		"title": "Generating coherent spontaneous speech and gesture from text",
		"creator": [
			"Alexanderson, Simon",
			"Székely, Éva",
			"Henter, Gustav Eje",
			"Kucherenko, Taras",
			"Beskow, Jonas"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Graphics",
			"Computer Science - Sound",
			"Electrical Engineering and Systems Science - Audio and Speech Processing",
			"68T07",
			"I.2.6",
			"J.4",
			"I.3.7",
			"I.2.9"
		],
		"description": [
			"  Embodied human communication encompasses both verbal (speech) and non-verbal\ninformation (e.g., gesture and head movements). Recent advances in machine\nlearning have substantially improved the technologies for generating synthetic\nversions of both of these types of data: On the speech side, text-to-speech\nsystems are now able to generate highly convincing, spontaneous-sounding speech\nusing unscripted speech audio as the source material. On the motion side,\nprobabilistic motion-generation methods can now synthesise vivid and lifelike\nspeech-driven 3D gesticulation. In this paper, we put these two\nstate-of-the-art technologies together in a coherent fashion for the first\ntime. Concretely, we demonstrate a proof-of-concept system trained on a\nsingle-speaker audio and motion-capture dataset, that is able to generate both\nspeech and full-body gestures together from text input. In contrast to previous\napproaches for joint speech-and-gesture generation, we generate full-body\ngestures from speech synthesis trained on recordings of spontaneous speech from\nthe same person as the motion-capture data. We illustrate our results by\nvisualising gesture spaces and text-speech-gesture alignments, and through a\ndemonstration video at https://simonalexanderson.github.io/IVA2020 .\n",
			"Comment: 3 pages, 2 figures, published at the ACM International Conference on\n  Intelligent Virtual Agents (IVA) 2020"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05684",
			"Proceedings of the 20th ACM International Conference on\n  Intelligent Virtual Agents (IVA '20), 2020, 3 pages",
			"doi:10.1145/3383652.3423874"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05684.pdf"
	},
	"737": {
		"title": "EmoCat: Language-agnostic Emotional Voice Conversion",
		"creator": [
			"Schnell, Bastian",
			"Huybrechts, Goeric",
			"Perz, Bartek",
			"Drugman, Thomas",
			"Lorenzo-Trueba, Jaime"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Audio and Speech Processing",
			"Computer Science - Sound"
		],
		"description": [
			"  Emotional voice conversion models adapt the emotion in speech without\nchanging the speaker identity or linguistic content. They are less data hungry\nthan text-to-speech models and allow to generate large amounts of emotional\ndata for downstream tasks. In this work we propose EmoCat, a language-agnostic\nemotional voice conversion model. It achieves high-quality emotion conversion\nin German with less than 45 minutes of German emotional recordings by\nexploiting large amounts of emotional data in US English. EmoCat is an\nencoder-decoder model based on CopyCat, a voice conversion system which\ntransfers prosody. We use adversarial training to remove emotion leakage from\nthe encoder to the decoder. The adversarial training is improved by a novel\ncontribution to gradient reversal to truly reverse gradients. This allows to\nremove only the leaking information and to converge to better optima with\nhigher conversion performance. Evaluations show that Emocat can convert to\ndifferent emotions but misses on emotion intensity compared to the recordings,\nespecially for very expressive emotions. EmoCat is able to achieve audio\nquality on par with the recordings for five out of six tested emotion\nintensities.\n",
			"Comment: Submitted to IEEE ICASSP 2021"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05695",
		"pdf_url": "http://arxiv.org/pdf/2101.05695.pdf"
	},
	"738": {
		"title": "Multi-Fidelity Digital Twins: a Means for Better Cyber-Physical Systems\n  Testing?",
		"creator": "Arrieta, Aitor",
		"subject": "Computer Science - Software Engineering",
		"description": "  Cyber-Physical Systems (CPSs) combine software and physical components. These\nsystems are widely applied in society within many domains, including the\nautomotive, aerospace, railway, etc. Testing these systems is extremely\nchallenging, therefore, it has attracted significant attention from the\nresearch community. A driving CPS testing technique in industry is\nsimulation-based testing. However, this poses significant challenges. In this\nnew-idea paper we present a novel approach to enhance the testing processes of\nCPSs. This novel approach is motivated with examples and open questions.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05697",
		"pdf_url": "http://arxiv.org/pdf/2101.05697.pdf"
	},
	"739": {
		"title": "TUDublin team at Constraint@AAAI2021 -- COVID19 Fake News Detection",
		"creator": [
			"Shushkevich, Elena",
			"Cardiff, John"
		],
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  The paper is devoted to the participation of the TUDublin team in\nConstraint@AAAI2021 - COVID19 Fake News Detection Challenge. Today, the problem\nof fake news detection is more acute than ever in connection with the pandemic.\nThe number of fake news is increasing rapidly and it is necessary to create AI\ntools that allow us to identify and prevent the spread of false information\nabout COVID-19 urgently. The main goal of the work was to create a model that\nwould carry out a binary classification of messages from social media as real\nor fake news in the context of COVID-19. Our team constructed the ensemble\nconsisting of Bidirectional Long Short Term Memory, Support Vector Machine,\nLogistic Regression, Naive Bayes and a combination of Logistic Regression and\nNaive Bayes. The model allowed us to achieve 0.94 F1-score, which is within 5\\%\nof the best result.\n",
			"Comment: 8 pages"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05701",
		"pdf_url": "http://arxiv.org/pdf/2101.05701.pdf"
	},
	"740": {
		"title": "Structural Analysis of Multimode DAE Systems: summary of results",
		"creator": [
			"Benveniste, Albert",
			"Caillaud, Benoît",
			"Malandain, Mathias"
		],
		"subject": "Computer Science - Programming Languages",
		"description": [
			"  Modern modeling languages for general physical systems, such as Modelica,\nAmesim, or Simscape, rely on Differential Algebraic Equations (DAEs), i.e.,\nconstraints of the form f(\\dot{x},x,u)=0. This drastically facilitates modeling\nfrom first principles of the physics, as well as model reuse. In recent works\n[RR-9334], we presented the mathematical theory needed to establish the\ndevelopment of compilers and tools for DAE-based physical modeling languages on\nsolid mathematical grounds.At the core of this analysis sits the so-called\n*structural analysis*, whose purpose, at compile time, is to either identify\nunder- and over-specified subsystems (if any), or to rewrite the model in a\nform amenable of existing DAE solvers, including the handling of mode change\nevents. The notion of \"structure\" collects, for each mode and mode change\nevent, the variables and equations involved, as well as the *latent equations*\n(additional equations redundant with the system), needed to prepare the code\nsubmitted to the solver. The notion of DAE *index* (the minimal number of times\nany equation has to be possibly differentiated) is part of this structural\nanalysis. This report complements [RR-9334] by collecting all the needed\nbackground on structural analysis. The body of knowledge on structural analysis\nis large and scattered, which also motivated us to collect it in a single\nreport.We first explain the primary meaning of structural analysis of systems\nof equations, namely the study of their regularity or singularity in some\ngeneric sense. We then briefly review the body of graph theory used in this\ncontext. We develop some extensions, for which we are not aware of any\nreference, namely the structural analysis of systems of equations with\nexistential quantifiers. For the structural analysis of DAE systems, we focus\non John Pryce's Sigma-method, that we both summarize and extend to non-square\nsystems. The uses of these tools and methods in [RR9334] are highlighted in\nthis report.\n",
			"Comment: arXiv admin note: substantial text overlap with arXiv:2008.05166"
		],
		"date": [
			"2021-01-14",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05702",
		"pdf_url": "http://arxiv.org/pdf/2101.05702.pdf"
	},
	"741": {
		"title": "Exploring Asymmetric Roles in Mixed-Ability Gaming",
		"creator": [
			"Gonçalves, David",
			"Rodrigues, André",
			"Richardson, Mike L.",
			"de Sousa, Alexandra A.",
			"Proulx, Michael J.",
			"Guerreiro, Tiago"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": [
			"  The landscape of digital games is segregated by player ability. For example,\nsighted players have a multitude of highly visual games at their disposal,\nwhile blind players may choose from a variety of audio games. Attempts at\nimproving cross-ability access to any of those are often limited in the\nexperience they provide, or disregard multiplayer experiences. We explore\nability-based asymmetric roles as a design approach to create engaging and\nchallenging mixed-ability play. Our team designed and developed two\ncollaborative testbed games exploring asymmetric interdependent roles. In a\nremote study with 13 mixed-visual-ability pairs we assessed how roles affected\nperceptions of engagement, competence, and autonomy, using a mixed-methods\napproach. The games provided an engaging and challenging experience, in which\ndifferences in visual ability were not limiting. Our results underline how\nexperiences unequal by design can give rise to an equitable joint experience.\n",
			"Comment: 21 pages, 1 figure. Manuscript submitted to ACM Conference on Human\n  Factors in Computing Systems (CHI 21)"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05703",
		"pdf_url": "http://arxiv.org/pdf/2101.05703.pdf"
	},
	"742": {
		"title": "Environmental Variable Monitoring with IoT Technology",
		"creator": [
			"Pinilla, Harold",
			"Macias, Jose",
			"Lescano, Emmanuel",
			"Alvarado, Jose David",
			"Castellanos, Wilder"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"68N01 (Primary), 68N99 (Secondary)"
		],
		"description": [
			"  This article describes the design of a flexible and low-cost platform for\nmonitoring environmental variables applied to agriculture. For the construction\nof this platform, technologies based on the communication protocol, Wi-Fi,\nBluetooth, and Zigbee were used, using the embedded Raspberry pi 3 b + system\nand sensors to quantify different environmental variables, using different open\nsource hardware and software tools. The network is made up of a central node\n(gateway), implemented on Samsung's Artik 1020 card, and two nodes where the\nsensors for reading environmental variables are connected. Finally, the data is\ncollected by the gateway, which will be in charge of processing and storing it\nin a database so that the user in the future can access the information in real\ntime from anywhere.\n",
			"Comment: 14 pages, in Spanish. 12 figures. Work presented in TechFest 2019\n  Conference. organized by Universidad de San Buenaventura. Bogota. Colombia.\n  https://www.usbbog.edu.co/images/pdf/educontinua/tech_fest_agenda.pdf\n  Proceedings in press"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05706",
		"pdf_url": "http://arxiv.org/pdf/2101.05706.pdf",
		"language": "es"
	},
	"743": {
		"title": "Rule-based Optimal Control for Autonomous Driving",
		"creator": [
			"Xiao, Wei",
			"Mehdipour, Noushin",
			"Collin, Anne",
			"Bin-Nun, Amitai",
			"Frazzoli, Emilio",
			"Tebbens, Radboud Duintjer",
			"Belta, Calin"
		],
		"subject": [
			"Computer Science - Robotics",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": [
			"  We develop optimal control strategies for Autonomous Vehicles (AVs) that are\nrequired to meet complex specifications imposed by traffic laws and cultural\nexpectations of reasonable driving behavior. We formulate these specifications\nas rules, and specify their priorities by constructing a priority structure. We\npropose a recursive framework, in which the satisfaction of the rules in the\npriority structure are iteratively relaxed based on their priorities. Central\nto this framework is an optimal control problem, where convergence to desired\nstates is achieved using Control Lyapunov Functions (CLFs), and safety is\nenforced through Control Barrier Functions (CBFs). We also show how the\nproposed framework can be used for after-the-fact, pass / fail evaluation of\ntrajectories - a given trajectory is rejected if we can find a controller\nproducing a trajectory that leads to less violation of the rule priority\nstructure. We present case studies with multiple driving scenarios to\ndemonstrate the effectiveness of the proposed framework.\n",
			"Comment: accepted in ICCPS2021"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05709",
		"pdf_url": "http://arxiv.org/pdf/2101.05709.pdf"
	},
	"744": {
		"title": "SICKNL: A Dataset for Dutch Natural Language Inference",
		"creator": [
			"Wijnholds, Gijs",
			"Moortgat, Michael"
		],
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  We present SICK-NL (read: signal), a dataset targeting Natural Language\nInference in Dutch. SICK-NL is obtained by translating the SICK dataset of\nMarelli et al. (2014)from English into Dutch. Having a parallel inference\ndataset allows us to compare both monolingual and multilingual NLP models for\nEnglish and Dutch on the two tasks. In the paper, we motivate and detail the\ntranslation process, perform a baseline evaluation on both the original SICK\ndataset and its Dutch incarnation SICK-NL, taking inspiration from Dutch\nskipgram embeddings and contextualised embedding models. In addition, we\nencapsulate two phenomena encountered in the translation to formulate stress\ntests and verify how well the Dutch models capture syntactic restructurings\nthat do not affect semantics. Our main finding is all models perform worse on\nSICK-NL than on SICK, indicating that the Dutch dataset is more challenging\nthan the English original. Results on the stress tests show that models don't\nfully capture word order freedom in Dutch, warranting future systematic\nstudies.\n",
			"Comment: To appear at EACL 2021"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05716",
		"pdf_url": "http://arxiv.org/pdf/2101.05716.pdf"
	},
	"745": {
		"title": "Adaptive Frequency Response Reserve based on Real-time System Inertia",
		"creator": "You, Shutang",
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  To ensure adequate and economic reserve for primary frequency response in the\ncurrent and future power system, this paper proposes real-time frequency\nresponse reserve (FRR) requirement based on system inertia. This minimum FRR\nwill help power system operators adjust the current frequency response\nrequirement and accommodate more renewable generations while achieving a saving\nof both energy and facility costs. Most importantly, the ability to adaptively\nvary the FRR will provide the additional agility, resiliency, and reliability\nto the grid.\n",
			"Comment: 6 pages, 17 figures, 3 tables"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05717",
		"pdf_url": "http://arxiv.org/pdf/2101.05717.pdf"
	},
	"746": {
		"title": "Stereo camera system calibration: the need of two sets of parameters",
		"creator": [
			"Beschi, Riccardo",
			"Feng, Xiao",
			"Melillo, Stefania",
			"Parisi, Leonardo",
			"Postiglione, Lorena"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  The reconstruction of a scene via a stereo-camera system is a two-steps\nprocess, where at first images from different cameras are matched to identify\nthe set of point-to-point correspondences that then will actually be\nreconstructed in the three dimensional real world. The performance of the\nsystem strongly relies of the calibration procedure, which has to be carefully\ndesigned to guarantee optimal results. We implemented three different\ncalibration methods and we compared their performance over 19 datasets. We\npresent the experimental evidence that, due to the image noise, a single set of\nparameters is not sufficient to achieve high accuracy in the identification of\nthe correspondences and in the 3D reconstruction at the same time. We propose\nto calibrate the system twice to estimate two different sets of parameters: the\none obtained by minimizing the reprojection error that will be used when\ndealing with quantities defined in the 2D space of the cameras, and the one\nobtained by minimizing the reconstruction error that will be used when dealing\nwith quantities defined in the real 3D world.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05725",
		"pdf_url": "http://arxiv.org/pdf/2101.05725.pdf"
	},
	"747": {
		"title": "A degenerate elliptic-parabolic system arising in competitive\n  contaminant transport",
		"creator": [
			"Baía, Margarida",
			"Bozorgnia, Farid",
			"Monsaingeon, Léonard",
			"Videman, Juha"
		],
		"subject": [
			"Mathematics - Analysis of PDEs",
			"Mathematics - Numerical Analysis"
		],
		"description": [
			"  In this work we investigate a coupled system of degenerate and nonlinear\npartial differential equations governing the transport of reactive solutes in\ngroundwater. We show that the system admits a unique weak solution provided the\nnonlinear adsorption isotherm associated with the reaction process satisfies\ncertain physically reasonable structural conditions. We conclude, moreover,\nthat the solute concentrations stay non-negative if the source term is\ncomponentwise non-negative and investigate numerically the finite speed of\npropagation of compactly supported initial concentrations, in a two-component\ntest case.\n",
			"Comment: old paper accepted in 2017 but not uploaded to arxiv"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05726",
			"Journal of Mathematical Analysis and Applications, 457 (2018), pp.\n  77-103",
			"doi:10.1016/j.jmaa.2017.07.061"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05726.pdf"
	},
	"748": {
		"title": "Towards Understanding and Evaluating Structural Node Embeddings",
		"creator": [
			"Jin, Junchen",
			"Heimann, Mark",
			"Jin, Di",
			"Koutra, Danai"
		],
		"subject": "Computer Science - Social and Information Networks",
		"description": [
			"  While most network embedding techniques model the proximity between nodes in\na network, recently there has been significant interest in structural\nembeddings that are based on node equivalences, a notion rooted in sociology:\nequivalences or positions are collections of nodes that have similar\nroles--i.e., similar functions, ties or interactions with nodes in other\npositions--irrespective of their distance or reachability in the network.\nUnlike the proximity-based methods that are rigorously evaluated in the\nliterature, the evaluation of structural embeddings is less mature. It relies\non small synthetic or real networks with labels that are not perfectly defined,\nand its connection to sociological equivalences has hitherto been vague and\ntenuous. With new node embedding methods being developed at a breakneck pace,\nproper evaluation and systematic characterization of existing approaches will\nbe essential to progress. To fill in this gap, we set out to understand what\ntypes of equivalences structural embeddings capture. We are the first to\ncontribute rigorous intrinsic and extrinsic evaluation methodology for\nstructural embeddings, along with carefully-designed, diverse datasets of\nvarying sizes. We observe a number of different evaluation variables that can\nlead to different results (e.g., choice of similarity measure, classifier,\nlabel definitions). We find that degree distributions within nodes' local\nneighborhoods can lead to simple yet effective baselines in their own right and\nguide the future development of structural embedding. We hope that our findings\ncan influence the design of further node embedding methods and also pave the\nway for more comprehensive and fair evaluation of structural embedding methods.\n",
			"Comment: A shorter version of this paper was presented in the Mining and\n  Learning with Graphs workshop at KDD 2020"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05730",
		"pdf_url": "http://arxiv.org/pdf/2101.05730.pdf"
	},
	"749": {
		"title": "Phase-bounded finite element method for two-fluid incompressible flow\n  systems",
		"creator": [
			"Treeratanaphitak, Tanyakarn",
			"Abukhdeir, Nasser Mohieddin"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"Computer Science - Software Engineering",
			"Physics - Fluid Dynamics"
		],
		"description": "  An understanding of the hydrodynamics of multiphase processes is essential\nfor their design and operation. Multiphase computational fluid dynamics (CFD)\nsimulations enable researchers to gain insight which is inaccessible\nexperimentally. The model frequently used to simulate these processes is the\ntwo-fluid (Euler-Euler) model where fluids are treated as inter-penetrating\ncontinua. It is formulated for the multiphase flow regime where one phase is\ndispersed within another and enables simulation on experimentally relevant\nscales. Phase fractions are used to describe the composition of the mixture and\nare bounded quantities. Consequently, numerical solution methods used in\nsimulations must preserve boundedness for accuracy and physical fidelity. In\nthis work, a numerical method for the two-fluid model is developed in which\nphase fraction constraints are imposed through the use of an nonlinear\nvariational inequality solver which implicitly imposes inequality constraints.\nThe numerical method is verified and compared to an established explicit\nnumerical method.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05734",
			"International Journal of Multiphase Flow 117 (2019) 1-13",
			"doi:10.1016/j.ijmultiphaseflow.2019.04.024"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05734.pdf"
	},
	"750": {
		"title": "The Good, the Bad and the Ugly: Pitfalls and Best Practices in Automated\n  Sound Static Analysis of Ethereum Smart Contracts",
		"creator": [
			"Schneidewind, Clara",
			"Scherer, Markus",
			"Maffei, Matteo"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": "  Ethereum smart contracts are distributed programs running on top of the\nEthereum blockchain. Since program flaws can cause significant monetary losses\nand can hardly be fixed due to the immutable nature of the blockchain, there is\na strong need of automated analysis tools which provide formal security\nguarantees. Designing such analyzers, however, proved to be challenging and\nerror-prone. We review the existing approaches to automated, sound, static\nanalysis of Ethereum smart contracts and highlight prevalent issues in the\nstate of the art. Finally, we overview eThor, a recent static analysis tool\nthat we developed following a principled design and implementation approach\nbased on rigorous semantic foundations to overcome the problems of past works.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05735",
			"doi:10.1007/978-3-030-61467-6_14"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05735.pdf"
	},
	"751": {
		"title": "A Pragmatic Approach for Hyper-Parameter Tuning in Search-based Test\n  Case Generation",
		"creator": [
			"Zamani, Shayan",
			"Hemmati, Hadi"
		],
		"subject": "Computer Science - Software Engineering",
		"description": "  Search-based test case generation, which is the application of meta-heuristic\nsearch for generating test cases, has been studied a lot in the literature,\nlately. Since, in theory, the performance of meta-heuristic search methods is\nhighly dependent on their hyper-parameters, there is a need to study\nhyper-parameter tuning in this domain. In this paper, we propose a new metric\n(\"Tuning Gain\"), which estimates how cost-effective tuning a particular class\nis. We then predict \"Tuning Gain\" using static features of source code classes.\nFinally, we prioritize classes for tuning, based on the estimated \"Tuning\nGains\" and spend the tuning budget only on the highly-ranked classes. To\nevaluate our approach, we exhaustively analyze 1,200 hyper-parameter\nconfigurations of a well-known search-based test generation tool (EvoSuite) for\n250 classes of 19 projects from benchmarks such as SF110 and SBST2018 tool\ncompetition. We used a tuning approach called Meta-GA and compared the tuning\nresults with and without the proposed class prioritization. The results show\nthat for a low tuning budget, prioritizing classes outperforms the alternatives\nin terms of extra covered branches (10 times more than a traditional global\ntuning). In addition, we report the impact of different features of our\napproach such as search space size, tuning budgets, tuning algorithms, and the\nnumber of classes to tune, on the final results.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05738",
		"pdf_url": "http://arxiv.org/pdf/2101.05738.pdf"
	},
	"752": {
		"title": "Ajalon: Simplifying the Authoring of Wearable Cognitive Assistants",
		"creator": [
			"Pham, Truong An",
			"Wang, Junjue",
			"Xiao, Yu",
			"Pillai, Padmanabhan",
			"Iyengar, Roger",
			"Klatzky, Roberta",
			"Satyanarayanan, Mahadev"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": "  Wearable Cognitive Assistance (WCA) amplifies human cognition in real time\nthrough a wearable device and low-latency wireless access to edge computing\ninfrastructure. It is inspired by, and broadens, the metaphor of GPS navigation\ntools that provide real-time step-by-step guidance, with prompt error detection\nand correction. WCA applications are likely to be transformative in education,\nhealth care, industrial troubleshooting, manufacturing, and many other areas.\nToday, WCA application development is difficult and slow, requiring skills in\nareas such as machine learning and computer vision that are not widespread\namong software developers. This paper describes Ajalon, an authoring toolchain\nfor WCA applications that reduces the skill and effort needed at each step of\nthe development pipeline. Our evaluation shows that Ajalon significantly\nreduces the effort needed to create new WCA applications.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05766",
		"pdf_url": "http://arxiv.org/pdf/2101.05766.pdf"
	},
	"753": {
		"title": "$\\text{O}^2$PF: Oversampling via Optimum-Path Forest for Breast Cancer\n  Detection",
		"creator": [
			"Passos, Leandro Aparecido",
			"Jodas, Danilo Samuel",
			"Ribeiro, Luiz C. F.",
			"Pinheiro, Thierry",
			"Papa, João P."
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  Breast cancer is among the most deadly diseases, distressing mostly women\nworldwide. Although traditional methods for detection have presented themselves\nas valid for the task, they still commonly present low accuracies and demand\nconsiderable time and effort from professionals. Therefore, a computer-aided\ndiagnosis (CAD) system capable of providing early detection becomes hugely\ndesirable. In the last decade, machine learning-based techniques have been of\nparamount importance in this context, since they are capable of extracting\nessential information from data and reasoning about it. However, such\napproaches still suffer from imbalanced data, specifically on medical issues,\nwhere the number of healthy people samples is, in general, considerably higher\nthan the number of patients. Therefore this paper proposes the $\\text{O}^2$PF,\na data oversampling method based on the unsupervised Optimum-Path Forest\nAlgorithm. Experiments conducted over the full oversampling scenario state the\nrobustness of the model, which is compared against three well-established\noversampling methods considering three breast cancer and three general-purpose\ntasks for medical issues datasets.\n",
			"Comment: 6 pages, 3 figures. 2020 IEEE 33rd International Symposium on\n  Computer-Based Medical Systems (CBMS)"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05775",
			"doi:10.1109/CBMS49503.2020.00100"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05775.pdf"
	},
	"754": {
		"title": "Checkpoint, Restore, and Live Migration for Science Platforms",
		"creator": [
			"Juric, Mario",
			"Stetzler, Steven",
			"Slater, Colin T."
		],
		"subject": [
			"Astrophysics - Instrumentation and Methods for Astrophysics",
			"Computer Science - Distributed, Parallel, and Cluster Computing"
		],
		"description": [
			"  We demonstrate a fully functional implementation of (per-user) checkpoint,\nrestore, and live migration capabilities for JupyterHub platforms.\nCheckpointing -- the ability to freeze and suspend to disk the running state\n(contents of memory, registers, open files, etc.) of a set of processes --\nenables the system to snapshot a user's Jupyter session to permanent storage.\nThe restore functionality brings a checkpointed session back to a running\nstate, to continue where it left off at a later time and potentially on a\ndifferent machine. Finally, live migration enables moving running Jupyter\nnotebook servers between different machines, transparent to the analysis code\nand w/o disconnecting the user. Our implementation of these capabilities works\nat the system level, with few limitations, and typical checkpoint/restore times\nof O(10s) with a pathway to O(1s) live migrations. It opens a myriad of\ninteresting use cases, especially for cloud-based deployments: from\ncheckpointing idle sessions w/o interruption of the user's work (achieving cost\nreductions of 4x or more), execution on spot instances w. transparent migration\non eviction (with additional cost reductions up to 3x), to automated migration\nof workloads to ideally suited instances (e.g. moving an analysis to a machine\nwith more or less RAM or cores based on observed resource utilization). The\ncapabilities we demonstrate can make science platforms fully elastic while\nretaining excellent user experience.\n",
			"Comment: 4 pages, 2 figures, to appear in the Proceedings of ADASS XXX"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05782",
		"pdf_url": "http://arxiv.org/pdf/2101.05782.pdf"
	},
	"755": {
		"title": "Persistent Anti-Muslim Bias in Large Language Models",
		"creator": [
			"Abid, Abubakar",
			"Farooqi, Maheen",
			"Zou, James"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning"
		],
		"description": "  It has been observed that large-scale language models capture undesirable\nsocietal biases, e.g. relating to race and gender; yet religious bias has been\nrelatively unexplored. We demonstrate that GPT-3, a state-of-the-art contextual\nlanguage model, captures persistent Muslim-violence bias. We probe GPT-3 in\nvarious ways, including prompt completion, analogical reasoning, and story\ngeneration, to understand this anti-Muslim bias, demonstrating that it appears\nconsistently and creatively in different uses of the model and that it is\nsevere even compared to biases about other religious groups. For instance,\n\"Muslim\" is analogized to \"terrorist\" in 23% of test cases, while \"Jewish\" is\nmapped to \"money\" in 5% of test cases. We quantify the positive distraction\nneeded to overcome this bias with adversarial text prompts, and find that use\nof the most positive 6 adjectives reduces violent completions for \"Muslims\"\nfrom 66% to 20%, but which is still higher than for other religious groups.\n",
		"date": [
			"2021-01-14",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05783",
		"pdf_url": "http://arxiv.org/pdf/2101.05783.pdf"
	},
	"756": {
		"title": "Quantitative View of the Structure of Institutional Scientific\n  Collaborations Using the Examples of Halle, Jena and Leipzig",
		"creator": "Akbaritabar, Aliakbar",
		"subject": [
			"Computer Science - Digital Libraries",
			"Computer Science - Social and Information Networks"
		],
		"description": [
			"  Examining effectiveness of institutional scientific coalitions can inform\nfuture policies. This is a study on the structure of scientific collaborations\nin three cities in central Germany. Since 1995, the three universities of this\nregion have formed and maintained a coalition which led to the establishment of\nan interdisciplinary center in 2012, i.e., German Center for Integrative\nBiodiversity Research (iDiv). We investigate whether the impact of the former\ncoalition is evident in the region's structure of scientific collaborations and\nthe scientific output of the new center. Using publications data from\n1996-2018, we build co-authorship networks and identify the most cohesive\ncommunities in terms of collaboration, and compare them with communities\nidentified based on publications presented as the scientific outcome of the\ncoalition and new center on their website. Our results show that despite the\nhighly cohesive structure of collaborations presented on the coalition website,\nthere is still much potential to be realized. The newly established center has\nbridged the member institutions but not to a particularly strong level. We see\nthat geographical proximity, collaboration policies, funding, and\norganizational structure alone do not ensure prosperous scientific\ncollaboration structures. When new center's scientific output is compared with\nits regional context, observed trends become less conspicuous. Nevertheless,\nthe level of success the coalition achieved could inform policy makers\nregarding other regions' scientific development plans.\n",
			"Comment: 18 pages, 5 figures, 5 tables"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05784",
		"pdf_url": "http://arxiv.org/pdf/2101.05784.pdf"
	},
	"757": {
		"title": "Persuasive Natural Language Generation -- A Literature Review",
		"creator": [
			"Duerr, Sebastian",
			"Gloor, Peter A."
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Artificial Intelligence",
			"I.2.7",
			"J.4"
		],
		"description": "  This literature review focuses on the use of Natural Language Generation\n(NLG) to automatically detect and generate persuasive texts. Extending previous\nresearch on automatic identification of persuasion in text, we concentrate on\ngenerative aspects through conceptualizing determinants of persuasion in five\nbusiness-focused categories: benevolence, linguistic appropriacy, logical\nargumentation, trustworthiness, tools and datasets. These allow NLG to increase\nan existing message's persuasiveness. Previous research illustrates key aspects\nin each of the above mentioned five categories. A research agenda to further\nstudy persuasive NLG is developed. The review includes analysis of\nseventy-seven articles, outlining the existing body of knowledge and showing\nthe steady progress in this research field.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05786",
		"pdf_url": "http://arxiv.org/pdf/2101.05786.pdf"
	},
	"758": {
		"title": "U-Noise: Learnable Noise Masks for Interpretable Image Segmentation",
		"creator": [
			"Koker, Teddy",
			"Mireshghallah, Fatemehsadat",
			"Titcombe, Tom",
			"Kaissis, Georgios"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Deep Neural Networks (DNNs) are widely used for decision making in a myriad\nof critical applications, ranging from medical to societal and even judicial.\nGiven the importance of these decisions, it is crucial for us to be able to\ninterpret these models. We introduce a new method for interpreting image\nsegmentation models by learning regions of images in which noise can be applied\nwithout hindering downstream model performance. We apply this method to\nsegmentation of the pancreas in CT scans, and qualitatively compare the quality\nof the method to existing explainability techniques, such as Grad-CAM and\nocclusion sensitivity. Additionally we show that, unlike other methods, our\ninterpretability model can be quantitatively evaluated based on the downstream\nperformance over obscured images.\n",
			"Comment: Submitted to ICIP. Revision: corrected affiliation"
		],
		"date": [
			"2021-01-14",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05791",
		"pdf_url": "http://arxiv.org/pdf/2101.05791.pdf"
	},
	"759": {
		"title": "A Metaheuristic-Driven Approach to Fine-Tune Deep Boltzmann Machines",
		"creator": [
			"Passos, Leandro Aparecido",
			"Papa, João Paulo"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  Deep learning techniques, such as Deep Boltzmann Machines (DBMs), have\nreceived considerable attention over the past years due to the outstanding\nresults concerning a variable range of domains. One of the main shortcomings of\nthese techniques involves the choice of their hyperparameters, since they have\na significant impact on the final results. This work addresses the issue of\nfine-tuning hyperparameters of Deep Boltzmann Machines using metaheuristic\noptimization techniques with different backgrounds, such as swarm intelligence,\nmemory- and evolutionary-based approaches. Experiments conducted in three\npublic datasets for binary image reconstruction showed that metaheuristic\ntechniques can obtain reasonable results.\n",
			"Comment: 30 pages, 7 figures"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05795",
			"Applied Soft Computing 97 (2020): 105717",
			"doi:10.1016/j.asoc.2019.105717"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05795.pdf"
	},
	"760": {
		"title": "Exploration of Visual Features and their weighted-additive fusion for\n  Video Captioning",
		"creator": [
			"S V, Praveen",
			"Bharadwaj, Akhilesh",
			"Raj, Harsh",
			"Dadhania, Janhavi",
			"A, Ganesh Samarth C.",
			"Pareek, Nikhil",
			"Prasanna, S R M"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Video captioning is a popular task that challenges models to describe events\nin videos using natural language. In this work, we investigate the ability of\nvarious visual feature representations derived from state-of-the-art\nconvolutional neural networks to capture high-level semantic context. We\nintroduce the Weighted Additive Fusion Transformer with Memory Augmented\nEncoders (WAFTM), a captioning model that incorporates memory in a transformer\nencoder and uses a novel method, to fuse features, that ensures due importance\nis given to more significant representations. We illustrate a gain in\nperformance realized by applying Word-Piece Tokenization and a popular\nREINFORCE algorithm. Finally, we benchmark our model on two datasets and obtain\na CIDEr of 92.4 on MSVD and a METEOR of 0.091 on the ActivityNet Captions\nDataset.\n",
			"Comment: 6 pages"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05806",
		"pdf_url": "http://arxiv.org/pdf/2101.05806.pdf"
	},
	"761": {
		"title": "Numerical procedure for optimal control of hybrid systems with sliding\n  modes, Part I",
		"creator": [
			"Pytlak, Radoslaw",
			"Suski, Damian"
		],
		"subject": [
			"Mathematics - Optimization and Control",
			"Mathematics - Numerical Analysis"
		],
		"description": "  This paper concerns the numerical procedure for solving hybrid optimal\ncontrol problems with sliding modes. The proposed procedure has several\nfeatures which distinguishes it from the other procedures for the problem.\nFirst of all a sliding mode is coped with differential-algebraic equations\n(DAEs) and that guarantees accurate tracking of the sliding motion surface. The\nsecond important feature is the calculation of cost and constraints functions\ngradients with the help of adjoint equations. The adjoint equations presented\nin the paper take into account sliding motion and exhibit jump conditions at\ntransition instants. The procedure uses the discretization of system equations\nby Radau IIA Runge--Kutta scheme and the evaluation of optimization functions\ngradients with the help of the adjoint equations stated for discretized system\nequations. In the first part of the paper we demonstrate the correspondence\nbetween the discrete adjoint equations and the discretized version of the\ncontinuous adjoint equations in the case of system equations described by ODEs.\nWe show that the discrete adjoint state trajectories converge to their\ncontinuous counterparts in the case of ODEs.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05829",
		"pdf_url": "http://arxiv.org/pdf/2101.05829.pdf"
	},
	"762": {
		"title": "Context-Aware Image Denoising with Auto-Threshold Canny Edge Detection\n  to Suppress Adversarial Perturbation",
		"creator": [
			"Wang, Li-Yun",
			"Jalalpour, Yeganeh",
			"Feng, Wu-chi"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  This paper presents a novel context-aware image denoising algorithm that\ncombines an adaptive image smoothing technique and color reduction techniques\nto remove perturbation from adversarial images. Adaptive image smoothing is\nachieved using auto-threshold canny edge detection to produce an accurate edge\nmap used to produce a blurred image that preserves more edge features. The\nproposed algorithm then uses color reduction techniques to reconstruct the\nimage using only a few representative colors. Through this technique, the\nalgorithm can reduce the effects of adversarial perturbations on images. We\nalso discuss experimental data on classification accuracy. Our results showed\nthat the proposed approach reduces adversarial perturbation in adversarial\nattacks and increases the robustness of the deep convolutional neural network\nmodels.\n",
			"Comment: 5 pages, 3 figures, 1 table"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05833",
		"pdf_url": "http://arxiv.org/pdf/2101.05833.pdf"
	},
	"763": {
		"title": "Physics-aware, probabilistic model order reduction with guaranteed\n  stability",
		"creator": [
			"Kaltenbach, Sebastian",
			"Koutsourelakis, Phaedon-Stelios"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning",
			"Physics - Computational Physics"
		],
		"description": [
			"  Given (small amounts of) time-series' data from a high-dimensional,\nfine-grained, multiscale dynamical system, we propose a generative framework\nfor learning an effective, lower-dimensional, coarse-grained dynamical model\nthat is predictive of the fine-grained system's long-term evolution but also of\nits behavior under different initial conditions. We target fine-grained models\nas they arise in physical applications (e.g. molecular dynamics, agent-based\nmodels), the dynamics of which are strongly non-stationary but their transition\nto equilibrium is governed by unknown slow processes which are largely\ninaccessible by brute-force simulations. Approaches based on domain knowledge\nheavily rely on physical insight in identifying temporally slow features and\nfail to enforce the long-term stability of the learned dynamics. On the other\nhand, purely statistical frameworks lack interpretability and rely on large\namounts of expensive simulation data (long and multiple trajectories) as they\ncannot infuse domain knowledge. The generative framework proposed achieves the\naforementioned desiderata by employing a flexible prior on the complex plane\nfor the latent, slow processes, and an intermediate layer of physics-motivated\nlatent variables that reduces reliance on data and imbues inductive bias. In\ncontrast to existing schemes, it does not require the a priori definition of\nprojection operators from the fine-grained description and addresses\nsimultaneously the tasks of dimensionality reduction and model estimation. We\ndemonstrate its efficacy and accuracy in multiscale physical systems of\nparticle dynamics where probabilistic, long-term predictions of phenomena not\ncontained in the training data are produced.\n",
			"Comment: ICLR 2021"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05834",
		"pdf_url": "http://arxiv.org/pdf/2101.05834.pdf"
	},
	"764": {
		"title": "An adaptive finite element DtN method for the elastic wave scattering\n  problem in three dimensions",
		"creator": [
			"Bao, Gang",
			"Li, Peijun",
			"Yuan, Xiaokai"
		],
		"subject": "Mathematics - Numerical Analysis",
		"description": "  Consider the elastic scattering of an incident wave by a rigid obstacle in\nthree dimensions, which is formulated as an exterior problem for the Navier\nequation. By constructing a Dirichlet-to-Neumann (DtN) operator and introducing\na transparent boundary condition, the scattering problem is reduced\nequivalently to a boundary value problem in a bounded domain. The discrete\nproblem with the truncated DtN operator is solved by using the a posteriori\nerror estimate based adaptive finite element method. The estimate takes account\nof both the finite element approximation error and the truncation error of the\nDtN operator, where the latter is shown to converge exponentially with respect\nto the truncation parameter. Moreover, the generalized Woodbury matrix identity\nis utilized to solve the resulting linear system efficiently. Numerical\nexperiments are presented to demonstrate the superior performance of the\nproposed method.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05835",
		"pdf_url": "http://arxiv.org/pdf/2101.05835.pdf"
	},
	"765": {
		"title": "A Neophyte With AutoML: Evaluating the Promises of Automatic Machine\n  Learning Tools",
		"creator": [
			"Bezrukavnikov, Oleg",
			"Linder, Rhema"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Human-Computer Interaction",
			"68U35",
			"H.5.0"
		],
		"description": [
			"  This paper discusses modern Auto Machine Learning (AutoML) tools from the\nperspective of a person with little prior experience in Machine Learning (ML).\nThere are many AutoML tools both ready-to-use and under development, which are\ncreated to simplify and democratize usage of ML technologies in everyday life.\nOur position is that ML should be easy to use and available to a greater number\nof people. Prior research has identified the need for intuitive AutoML tools.\nThis work seeks to understand how well AutoML tools have achieved that goal in\npractice. We evaluate three AutoML Tools to evaluate the end-user experience\nand system performance. We evaluate the tools by having them create models from\na competition dataset on banking data. We report on their performance and the\ndetails of our experience. This process provides a unique understanding of the\nstate of the art of AutoML tools. Finally, we use these experiences to inform a\ndiscussion on how future AutoML tools can improve the user experience for\nneophytes of Machine Learning.\n",
			"Comment: 10 pages, 3 tables, 3 figures. First author is a high school senior"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05840",
		"pdf_url": "http://arxiv.org/pdf/2101.05840.pdf"
	},
	"766": {
		"title": "A Subjective Model of Human Decision Making Based on Quantum Decision\n  Theory",
		"creator": [
			"Zhang, Chenda",
			"Kjellström, Hedvig"
		],
		"subject": "Computer Science - Artificial Intelligence",
		"description": "  Computer modeling of human decision making is of large importance for, e.g.,\nsustainable transport, urban development, and online recommendation systems. In\nthis paper we present a model for predicting the behavior of an individual\nduring a binary game under different amounts of risk, gain, and time pressure.\nThe model is based on Quantum Decision Theory (QDT), which has been shown to\nenable modeling of the irrational and subjective aspects of the decision\nmaking, not accounted for by the classical Cumulative Prospect Theory (CPT).\nExperiments on two different datasets show that our QDT-based approach\noutperforms both a CPT-based approach and data driven approaches such as\nfeed-forward neural networks and random forests.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05851",
		"pdf_url": "http://arxiv.org/pdf/2101.05851.pdf"
	},
	"767": {
		"title": "GloBug: Using Global Data in Fault Localization",
		"creator": [
			"Miryeganeh, Nima",
			"Hashtroudi, Sepehr",
			"Hemmati, Hadi"
		],
		"subject": "Computer Science - Software Engineering",
		"description": "  Fault Localization (FL) is an important first step in software debugging and\nis mostly manual in the current practice. Many methods have been proposed over\nyears to automate the FL process, including information retrieval (IR)-based\ntechniques. These methods localize the fault based on the similarity of the\nreported bug report and the source code. Newer variations of IR-based FL (IRFL)\ntechniques also look into the history of bug reports and leverage them during\nthe localization. However, all existing IRFL techniques limit themselves to the\ncurrent project's data (local data). In this study, we introduce Globug, which\nis an IRFL framework consisting of methods that use models pre-trained on the\nglobal data (extracted from open-source benchmark projects). In Globug, we\ninvestigate two heuristics: a) the effect of global data on a state-of-the-art\nIR-FL technique, namely BugLocator, and b) the application of a Word Embedding\ntechnique (Doc2Vec) together with global data. Our large scale experiment on 51\nsoftware projects shows that using global data improves BugLocator on average\n6.6% and 4.8% in terms of MRR (Mean Reciprocal Rank) and MAP (Mean Average\nPrecision), with over 14% in a majority (64% and 54% in terms of MRR and MAP,\nrespectively) of the cases. This amount of improvement is significant compared\nto the improvement rates that five other state-of-the-art IRFL tools provide\nover BugLocator. In addition, training the models globally is a one-time\noffline task with no overhead on BugLocator's run-time fault localization. Our\nstudy, however, shows that a Word Embedding-based global solution did not\nfurther improve the results.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05862",
		"pdf_url": "http://arxiv.org/pdf/2101.05862.pdf"
	},
	"768": {
		"title": "Impact of Distributed Rate Limiting on Load Distribution in a\n  Latency-sensitive Messaging Service",
		"creator": [
			"Li, Chong",
			"Liu, Jiangnan",
			"Lu, Chenyang",
			"Guerin, Roch",
			"Gill, Christopher D."
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": "  The cloud's flexibility and promise of seamless auto-scaling notwithstanding,\nits ability to meet service level objectives (SLOs) typically calls for some\nform of control in resource usage. This seemingly traditional problem gives\nrise to new challenges in a cloud setting, and in particular a subtle yet\nsignificant trade-off involving load-distribution decisions (the distribution\nof workload across available cloud resources to optimize performance), and rate\nlimiting (the capping of individual workloads to prevent global\nover-commitment). This paper investigates that trade-off through the design and\nimplementation of a real-time messaging system motivated by Internet-of-Things\n(IoT) applications, and demonstrates a solution capable of realizing an\neffective compromise. The paper's contributions are in both explicating the\nsource of this trade-off, and in demonstrating a possible solution.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05865",
		"pdf_url": "http://arxiv.org/pdf/2101.05865.pdf"
	},
	"769": {
		"title": "Comparisons of Graph Neural Networks on Cancer Classification Leveraging\n  a Joint of Phenotypic and Genetic Features",
		"creator": [
			"Oniani, David",
			"Wang, Chen",
			"Zhao, Yiqing",
			"Wen, Andrew",
			"Liu, Hongfang",
			"Shen, Feichen"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Quantitative Biology - Quantitative Methods"
		],
		"description": "  Cancer is responsible for millions of deaths worldwide every year. Although\nsignificant progress hasbeen achieved in cancer medicine, many issues remain to\nbe addressed for improving cancer therapy.Appropriate cancer patient\nstratification is the prerequisite for selecting appropriate treatment plan,\nascancer patients are of known heterogeneous genetic make-ups and phenotypic\ndifferences. In thisstudy, built upon deep phenotypic characterizations\nextractable from Mayo Clinic electronic healthrecords (EHRs) and genetic test\nreports for a collection of cancer patients, we evaluated variousgraph neural\nnetworks (GNNs) leveraging a joint of phenotypic and genetic features for\ncancer typeclassification. Models were applied and fine-tuned on the Mayo\nClinic cancer disease dataset. Theassessment was done through the reported\naccuracy, precision, recall, and F1 values as well as throughF1 scores based on\nthe disease class. Per our evaluation results, GNNs on average outperformed\nthebaseline models with mean statistics always being higher that those of the\nbaseline models (0.849 vs0.772 for accuracy, 0.858 vs 0.794 for precision,\n0.843 vs 0.759 for recall, and 0.843 vs 0.855 for F1score). Among GNNs,\nChebNet, GraphSAGE, and TAGCN showed the best performance, while GATshowed the\nworst. We applied and compared eight GNN models including AGNN, ChebNet,\nGAT,GCN, GIN, GraphSAGE, SGC, and TAGCN on the Mayo Clinic cancer disease\ndataset and assessedtheir performance as well as compared them with each other\nand with more conventional machinelearning models such as decision tree,\ngradient boosting, multi-layer perceptron, naive bayes, andrandom forest which\nwe used as the baselines.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05866",
		"pdf_url": "http://arxiv.org/pdf/2101.05866.pdf"
	},
	"770": {
		"title": "Technical Report: Rapid Reviews on Engineering of Internet of Things\n  Software Systems",
		"creator": [
			"Motta, Rebeca",
			"de Oliveira, Káthia",
			"Travassos, Guilherme"
		],
		"subject": "Computer Science - Software Engineering",
		"description": [
			"  We conducted a set of Rapid Reviews to characterize Internet of Things\nfacets. We formatted a generic meta-protocol that was instantiated for each of\nthe six facets presented (Connectivity, Things, Behavior, Smartness,\nInteractivity, and Environment)and considering the issue of Security, one of\nthe most important and frequent challenges in the context of IoT. The\nmeta-protocol is detailed and the results of each review are presented.\n",
			"Comment: The report was performed in collaboration with other researchers in\n  the context of a Ph.D. research"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05869",
		"pdf_url": "http://arxiv.org/pdf/2101.05869.pdf"
	},
	"771": {
		"title": "Enabling four-dimensional conformal hybrid meshing with cubic pyramids",
		"creator": [
			"Petrov, Miroslav S.",
			"Todorov, Todor D.",
			"Walters, Gage S.",
			"Williams, David M.",
			"Witherden, Freddie D."
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"52B11, 65N30, 65N50, 65D30, 65D32"
		],
		"description": [
			"  The main purpose of this article is to develop a novel refinement strategy\nfor four-dimensional hybrid meshes based on cubic pyramids. This optimal\nrefinement strategy subdivides a given cubic pyramid into a conforming set of\ncongruent cubic pyramids and invariant bipentatopes. The theoretical properties\nof the refinement strategy are rigorously analyzed and evaluated. In addition,\na new class of fully symmetric quadrature rules with positive weights are\ngenerated for the cubic pyramid. These rules are capable of exactly integrating\npolynomials with degrees up to 12. Their effectiveness is successfully\ndemonstrated on polynomial and transcendental functions. Broadly speaking, the\nrefinement strategy and quadrature rules in this paper open new avenues for\nfour-dimensional hybrid meshing, and space-time finite element methods.\n",
			"Comment: 30 pages, 15 figures"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05884",
		"pdf_url": "http://arxiv.org/pdf/2101.05884.pdf"
	},
	"772": {
		"title": "Cocktail Edge Caching: Ride Dynamic Trends of Content Popularity with\n  Ensemble Learning",
		"creator": [
			"Zong, Tongyu",
			"Li, Chen",
			"Lei, Yuanyuan",
			"Li, Guangyu",
			"Cao, Houwei",
			"Liu, Yong"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Edge caching will play a critical role in facilitating the emerging\ncontent-rich applications. However, it faces many new challenges, in\nparticular, the highly dynamic content popularity and the heterogeneous caching\nconfigurations. In this paper, we propose Cocktail Edge Caching, that tackles\nthe dynamic popularity and heterogeneity through ensemble learning. Instead of\ntrying to find a single dominating caching policy for all the caching\nscenarios, we employ an ensemble of constituent caching policies and adaptively\nselect the best-performing policy to control the cache. Towards this goal, we\nfirst show through formal analysis and experiments that different variations of\nthe LFU and LRU policies have complementary performance in different caching\nscenarios. We further develop a novel caching algorithm that enhances LFU/LRU\nwith deep recurrent neural network (LSTM) based time-series analysis. Finally,\nwe develop a deep reinforcement learning agent that adaptively combines base\ncaching policies according to their virtual hit ratios on parallel virtual\ncaches. Through extensive experiments driven by real content requests from two\nlarge video streaming platforms, we demonstrate that CEC not only consistently\noutperforms all single policies, but also improves the robustness of them. CEC\ncan be well generalized to different caching scenarios with low computation\noverheads for deployment.\n",
			"Comment: INFOCOM 2021"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05885",
		"pdf_url": "http://arxiv.org/pdf/2101.05885.pdf"
	},
	"773": {
		"title": "Reformulated dissipation for the free-stream preserving of the\n  conservative finite difference schemes on curvilinear grids",
		"creator": [
			"Su, Hongmin",
			"Cai, Jinsheng",
			"Pan, Shucheng",
			"Hu, Xiangyu"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"Physics - Computational Physics",
			"Physics - Fluid Dynamics"
		],
		"description": "  In this paper, we develop a new free-stream preserving (FP) method for\nhigh-order upwind conservative finite-difference (FD) schemes on the\ncurvilinear grids. This FP method is constrcuted by subtracting a reference\ncell-face flow state from each cell-center value in the local stencil of the\noriginal upwind conservative FD schemes, which effectively leads to a\nreformulated dissipation. It is convenient to implement this method, as it does\nnot require to modify the original forms of the upwind schemes. In addition,\nthe proposed method removes the constraint in the traditional FP conservative\nFD schemes that require a consistent discretization of the mesh metrics and the\nfluxes. With this, the proposed method is more flexible in simulating the\nengineering problems which usually require a low-order scheme for their\nlow-quality mesh, while the high-order schemes can be applied to approximate\nthe flow states to improve the resolution. After demonstrating the strict FP\nproperty and the order of accuracy by two simple test cases, we consider\nvarious validation cases, including the supersonic flow around the cylinder,\nthe subsonic flow past the three-element airfoil, and the transonic flow around\nthe ONERA M6 wing, etc., to show that the method is suitable for a wide range\nof fluid dynamic problems containing complex geometries. Moreover, these test\ncases also indicate that the discretization order of the metrics have no\nsignificant influences on the numerical results if the mesh resolution is not\nsufficiently large.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05886",
		"pdf_url": "http://arxiv.org/pdf/2101.05886.pdf"
	},
	"774": {
		"title": "A Deep Learning Based Ternary Task Classification System Using Gramian\n  Angular Summation Field in fNIRS Neuroimaging Data",
		"creator": [
			"Wickramaratne, Sajila D.",
			"Mahmud, Md Shaad"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  Functional near-infrared spectroscopy (fNIRS) is a non-invasive, economical\nmethod used to study its blood flow pattern. These patterns can be used to\nclassify tasks a subject is performing. Currently, most of the classification\nsystems use simple machine learning solutions for the classification of tasks.\nThese conventional machine learning methods, which are easier to implement and\ninterpret, usually suffer from low accuracy and undergo a complex preprocessing\nphase before network training. The proposed method converts the raw fNIRS time\nseries data into an image using Gramian Angular Summation Field. A Deep\nConvolutional Neural Network (CNN) based architecture is then used for task\nclassification, including mental arithmetic, motor imagery, and idle state.\nFurther, this method can eliminate the feature selection stage, which affects\nthe traditional classifiers' performance. This system obtained 87.14% average\nclassification accuracy higher than any other method for the dataset.\n",
			"Comment: 4 pages, 4 Figures"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05891",
		"pdf_url": "http://arxiv.org/pdf/2101.05891.pdf"
	},
	"775": {
		"title": "A Ternary Bi-Directional LSTM Classification for Brain Activation\n  Pattern Recognition Using fNIRS",
		"creator": [
			"Wickramaratne, Sajila D.",
			"Mahmud, MD Shaad"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  Functional near-infrared spectroscopy (fNIRS) is a non-invasive, low-cost\nmethod used to study the brain's blood flow pattern. Such patterns can enable\nus to classify performed by a subject. In recent research, most classification\nsystems use traditional machine learning algorithms for the classification of\ntasks. These methods, which are easier to implement, usually suffer from low\naccuracy. Further, a complex pre-processing phase is required for data\npreparation before implementing traditional machine learning methods. The\nproposed system uses a Bi-Directional LSTM based deep learning architecture for\ntask classification, including mental arithmetic, motor imagery, and idle state\nusing fNIRS data. Further, this system will require less pre-processing than\nthe traditional approach, saving time and computational resources while\nobtaining an accuracy of 81.48\\%, which is considerably higher than the\naccuracy obtained using conventional machine learning algorithms for the same\ndata set.\n",
			"Comment: 6 pages, 7 figures"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05892",
		"pdf_url": "http://arxiv.org/pdf/2101.05892.pdf"
	},
	"776": {
		"title": "Instance-Aware Predictive Navigation in Multi-Agent Environments",
		"creator": [
			"Cao, Jinkun",
			"Wang, Xin",
			"Darrell, Trevor",
			"Yu, Fisher"
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  In this work, we aim to achieve efficient end-to-end learning of driving\npolicies in dynamic multi-agent environments. Predicting and anticipating\nfuture events at the object level are critical for making informed driving\ndecisions. We propose an Instance-Aware Predictive Control (IPC) approach,\nwhich forecasts interactions between agents as well as future scene structures.\nWe adopt a novel multi-instance event prediction module to estimate the\npossible interaction among agents in the ego-centric view, conditioned on the\nselected action sequence of the ego-vehicle. To decide the action at each step,\nwe seek the action sequence that can lead to safe future states based on the\nprediction module outputs by repeatedly sampling likely action sequences. We\ndesign a sequential action sampling strategy to better leverage predicted\nstates on both scene-level and instance-level. Our method establishes a new\nstate of the art in the challenging CARLA multi-agent driving simulation\nenvironments without expert demonstration, giving better explainability and\nsample efficiency.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05893",
		"pdf_url": "http://arxiv.org/pdf/2101.05893.pdf"
	},
	"777": {
		"title": "Transmission-and-Distribution Frequency Dynamic Co-Simulation Framework\n  for Distributed Energy Resources Frequency Response",
		"creator": [
			"Wang, Wenbo",
			"Fang, Xin",
			"Cui, Hantao",
			"Li, Fangxing"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": "  The rapid deployment of distributed energy resources (DERs) in distribution\nnetworks has brought challenges to balance the system and stabilize frequency.\nDERs have the ability to provide frequency regulation; however, existing\ndynamic frequency simulation tools-which were developed mainly for the\ntransmission system-lack the capability to simulate distribution network\ndynamics with high penetrations of DERs. Although electromagnetic transient\n(EMT) simulation tools can simulate distribution network dynamics, the\ncomputation efficiency limits their use for large-scale\ntransmission-and-distribution (T&D) simulations. This paper presents an\nefficient T&D dynamic frequency co-simulation framework for DER frequency\nresponse based on the HELICS platform and existing off-the-shelf simulators.\nThe challenge of synchronizing frequency between the transmission network and\nDERs hosted in the distribution network is approached by detailed modeling of\nDERs in frequency dynamic models while DER phasor models are also preserved in\nthe distribution networks. Thereby, local voltage constraints can be respected\nwhen dispatching the DER power for frequency response. The DER frequency\nresponses (primary and secondary)-are simulated in case studies to validate the\nproposed framework. Lastly, fault-induced delayed voltage recovery (FIDVR)\nevent of a large system is presented to demonstrate the efficiency and\neffectiveness of the overall framework.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05894",
		"pdf_url": "http://arxiv.org/pdf/2101.05894.pdf"
	},
	"778": {
		"title": "A Ramsey Theorem for Finite Monoids",
		"creator": "Jecker, Ismaël",
		"subject": "Computer Science - Formal Languages and Automata Theory",
		"description": "  Repeated idempotent elements are commonly used to characterise iterable\nbehaviours in abstract models of computation. Therefore, given a monoid $M$, it\nis natural to ask how long a sequence of elements of $M$ needs to be to ensure\nthe presence of consecutive idempotent factors. This question is formalised\nthrough the notion of the Ramsey function $R_M$ associated to M, obtained by\nmapping every positive integer $k$ to the minimal integer $R_M(k)$ such that\nevery word $u$ in $M^*$ of length $R_M(k)$ contains $k$ consecutive non-empty\nfactors that correspond to the same idempotent element of $M$.\n  In this work, we study the behaviour of the Ramsey function $R_M$ by\ninvestigating the regular $D$-length of $M$, defined as the largest size $L(M)$\nof a submonoid of $M$ isomorphic to the set of natural numbers $\\{1,2, ...,\nL(M)\\}$ equipped with the Max operation. We show that the regular $D$-length of\n$M$ determines the degree of $R_M$, by proving that $k^{L(M)} \\leq R_M(k) \\leq\n(k|M|^4)^{L(M)}$.\n  To allow applications of this result, we provide the value of the regular\n$D$-length of diverse monoids. In particular, we prove that the full monoid of\n$n \\times n$ Boolean matrices, which is used to express transition monoids of\nnon-deterministic automata, has a regular $D$-length of $\\frac{n^2+n+2}{2}$.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05895",
		"pdf_url": "http://arxiv.org/pdf/2101.05895.pdf"
	},
	"779": {
		"title": "An EIM-degradation free reduced basis method via over collocation and\n  residual hyper reduction-based error estimation",
		"creator": [
			"Chen, Yanlai",
			"Gottlieb, Sigal",
			"Ji, Lijie",
			"Maday, Yvon"
		],
		"subject": "Mathematics - Numerical Analysis",
		"description": [
			"  The need for multiple interactive, real-time simulations using different\nparameter values has driven the design of fast numerical algorithms with\ncertifiable accuracies. The reduced basis method (RBM) presents itself as such\nan option. RBM features a mathematically rigorous error estimator which drives\nthe construction of a low-dimensional subspace. A surrogate solution is then\nsought in this low-dimensional space approximating the parameter-induced high\nfidelity solution manifold. However when the system is nonlinear or its\nparameter dependence nonaffine, this efficiency gain degrades tremendously, an\ninherent drawback of the application of the empirical interpolation method\n(EIM).\n  In this paper, we augment and extend the EIM approach as a direct solver, as\nopposed to an assistant, for solving nonlinear partial differential equations\non the reduced level. The resulting method, called Reduced Over-Collocation\nmethod (ROC), is stable and capable of avoiding the efficiency degradation. Two\ncritical ingredients of the scheme are collocation at about twice as many\nlocations as the number of basis elements for the reduced approximation space,\nand an efficient error indicator for the strategic building of the reduced\nsolution space. The latter, the main contribution of this paper, results from\nan adaptive hyper reduction of the residuals for the reduced solution.\nTogether, these two ingredients render the proposed R2-ROC scheme both offline-\nand online-efficient. A distinctive feature is that the efficiency degradation\nappearing in traditional RBM approaches that utilize EIM for nonlinear and\nnonaffine problems is circumvented, both in the offline and online stages.\nNumerical tests on different families of time-dependent and steady-state\nnonlinear problems demonstrate the high efficiency and accuracy of our R2-ROC\nand its superior stability performance.\n",
			"Comment: arXiv admin note: substantial text overlap with arXiv:2009.04812,\n  arXiv:1906.07349"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05902",
		"pdf_url": "http://arxiv.org/pdf/2101.05902.pdf"
	},
	"780": {
		"title": "Supervised Transfer Learning at Scale for Medical Imaging",
		"creator": [
			"Mustafa, Basil",
			"Loh, Aaron",
			"Freyberg, Jan",
			"MacWilliams, Patricia",
			"Wilson, Megan",
			"McKinney, Scott Mayer",
			"Sieniek, Marcin",
			"Winkens, Jim",
			"Liu, Yuan",
			"Bui, Peggy",
			"Prabhakara, Shruthi",
			"Telang, Umesh",
			"Karthikesalingam, Alan",
			"Houlsby, Neil",
			"Natarajan, Vivek"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Transfer learning is a standard technique to improve performance on tasks\nwith limited data. However, for medical imaging, the value of transfer learning\nis less clear. This is likely due to the large domain mismatch between the\nusual natural-image pre-training (e.g. ImageNet) and medical images. However,\nrecent advances in transfer learning have shown substantial improvements from\nscale. We investigate whether modern methods can change the fortune of transfer\nlearning for medical imaging. For this, we study the class of large-scale\npre-trained networks presented by Kolesnikov et al. on three diverse imaging\ntasks: chest radiography, mammography, and dermatology. We study both transfer\nperformance and critical properties for the deployment in the medical domain,\nincluding: out-of-distribution generalization, data-efficiency, sub-group\nfairness, and uncertainty estimation. Interestingly, we find that for some of\nthese properties transfer from natural to medical images is indeed extremely\neffective, but only when performed at sufficient scale.\n",
		"date": [
			"2021-01-14",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05913",
		"pdf_url": "http://arxiv.org/pdf/2101.05913.pdf"
	},
	"781": {
		"title": "Image Enhancement using Fuzzy Intensity Measure and Adaptive Clipping\n  Histogram Equalization",
		"creator": [
			"Zhu, Xiangyuan",
			"Xiao, Xiaoming",
			"Tjahjadi, Tardi",
			"Wu, Zhihu",
			"Tang, Jin"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Image enhancement aims at processing an input image so that the visual\ncontent of the output image is more pleasing or more useful for certain\napplications. Although histogram equalization is widely used in image\nenhancement due to its simplicity and effectiveness, it changes the mean\nbrightness of the enhanced image and introduces a high level of noise and\ndistortion. To address these problems, this paper proposes image enhancement\nusing fuzzy intensity measure and adaptive clipping histogram equalization\n(FIMHE). FIMHE uses fuzzy intensity measure to first segment the histogram of\nthe original image, and then clip the histogram adaptively in order to prevent\nexcessive image enhancement. Experiments on the Berkeley database and\nCVF-UGR-Image database show that FIMHE outperforms state-of-the-art histogram\nequalization based methods.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05922",
		"pdf_url": "http://arxiv.org/pdf/2101.05922.pdf"
	},
	"782": {
		"title": "Nowcasting Gentrification Using Airbnb Data",
		"creator": [
			"Jain, Shomik",
			"Proserpio, Davide",
			"Quattrone, Giovanni",
			"Quercia, Daniele"
		],
		"subject": [
			"Computer Science - Computers and Society",
			"Computer Science - Machine Learning",
			"K.4.0",
			"J.4"
		],
		"description": [
			"  There is a rumbling debate over the impact of gentrification: presumed\ngentrifiers have been the target of protests and attacks in some cities, while\nthey have been welcome as generators of new jobs and taxes in others. Census\ndata fails to measure neighborhood change in real-time since it is usually\nupdated every ten years. This work shows that Airbnb data can be used to\nquantify and track neighborhood changes. Specifically, we consider both\nstructured data (e.g. number of listings, number of reviews, listing\ninformation) and unstructured data (e.g. user-generated reviews processed with\nnatural language processing and machine learning algorithms) for three major\ncities, New York City (US), Los Angeles (US), and Greater London (UK). We find\nthat Airbnb data (especially its unstructured part) appears to nowcast\nneighborhood gentrification, measured as changes in housing affordability and\ndemographics. Overall, our results suggest that user-generated data from online\nplatforms can be used to create socioeconomic indices to complement traditional\nmeasures that are less granular, not in real-time, and more costly to obtain.\n",
			"Comment: To appear in the proceedings of the ACM Conference on\n  Computer-Supported Cooperative Work and Social Computing (CSCW 2021)"
		],
		"date": [
			"2021-01-14",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05924",
		"pdf_url": "http://arxiv.org/pdf/2101.05924.pdf"
	},
	"783": {
		"title": "KDLSQ-BERT: A Quantized Bert Combining Knowledge Distillation with\n  Learned Step Size Quantization",
		"creator": [
			"Jin, Jing",
			"Liang, Cai",
			"Wu, Tiancheng",
			"Zou, Liqin",
			"Gan, Zhiliang"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": "  Recently, transformer-based language models such as BERT have shown\ntremendous performance improvement for a range of natural language processing\ntasks. However, these language models usually are computation expensive and\nmemory intensive during inference. As a result, it is difficult to deploy them\non resource-restricted devices. To improve the inference performance, as well\nas reduce the model size while maintaining the model accuracy, we propose a\nnovel quantization method named KDLSQ-BERT that combines knowledge distillation\n(KD) with learned step size quantization (LSQ) for language model quantization.\nThe main idea of our method is that the KD technique is leveraged to transfer\nthe knowledge from a \"teacher\" model to a \"student\" model when exploiting LSQ\nto quantize that \"student\" model during the quantization training process.\nExtensive experiment results on GLUE benchmark and SQuAD demonstrate that our\nproposed KDLSQ-BERT not only performs effectively when doing different bit\n(e.g. 2-bit $\\sim$ 8-bit) quantization, but also outperforms the existing BERT\nquantization methods, and even achieves comparable performance as the\nfull-precision base-line model while obtaining 14.9x compression ratio. Our\ncode will be public available.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05938",
		"pdf_url": "http://arxiv.org/pdf/2101.05938.pdf"
	},
	"784": {
		"title": "A Risk-Sensitive Task Offloading Strategy for Edge Computing in\n  Industrial Internet of Things",
		"creator": [
			"Hao, Xiaoyu",
			"Zhao, Ruohai",
			"Yang, Tao",
			"Hu, Yulin",
			"Hu, Bo",
			"Qiu, Yuhe"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  Edge computing has become one of the key enablers for ultra-reliable and\nlow-latency communications in the industrial Internet of Things in the fifth\ngeneration communication systems, and is also a promising technology in the\nfuture sixth generation communication systems. In this work, we consider the\napplication of edge computing to smart factories for mission-critical task\noffloading through wireless links. In such scenarios, although high end-to-end\ndelays from the generation to completion of tasks happen with low probability,\nthey may incur severe casualties and property loss, and should be seriously\ntreated. Inspired by the risk management theory widely used in finance, we\nadopt the Conditional Value at Risk to capture the tail of the delay\ndistribution. An upper bound of the Conditional Value at Risk is derived\nthrough analysis of the queues both at the devices and the edge computing\nservers. We aim to find out the optimal offloading policy taking into\nconsideration both the average and the worst case delay performance of the\nsystem. Given that the formulated optimization problem is a non-convex mixed\ninteger non-linear programming problem, a decomposition into sub-problems is\nperformed and a two-stage heuristic algorithm is proposed. Simulation results\nvalidate our analysis and indicate that the proposed algorithm can reduce the\nrisk in both the queuing and end-to-end delay.\n",
			"Comment: 17 pages, has been submitted to EURASIP JWCN, major revision"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05946",
		"pdf_url": "http://arxiv.org/pdf/2101.05946.pdf"
	},
	"785": {
		"title": "Differentiable Nonparametric Belief Propagation",
		"creator": [
			"Opipari, Anthony",
			"Chen, Chao",
			"Wang, Shoutian",
			"Pavlasek, Jana",
			"Desingh, Karthik",
			"Jenkins, Odest Chadwicke"
		],
		"subject": "Computer Science - Robotics",
		"description": [
			"  We present a differentiable approach to learn the probabilistic factors used\nfor inference by a nonparametric belief propagation algorithm. Existing\nnonparametric belief propagation methods rely on domain-specific features\nencoded in the probabilistic factors of a graphical model. In this work, we\nreplace each crafted factor with a differentiable neural network enabling the\nfactors to be learned using an efficient optimization routine from labeled\ndata. By combining differentiable neural networks with an efficient belief\npropagation algorithm, our method learns to maintain a set of marginal\nposterior samples using end-to-end training. We evaluate our differentiable\nnonparametric belief propagation (DNBP) method on a set of articulated pose\ntracking tasks and compare performance with a recurrent neural network. Results\nfrom this comparison demonstrate the effectiveness of using learned factors for\ntracking and suggest the practical advantage over hand-crafted approaches. The\nproject webpage is available at: progress.eecs.umich.edu/projects/dnbp.\n",
			"Comment: 12 pages, 9 figures"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05948",
		"pdf_url": "http://arxiv.org/pdf/2101.05948.pdf"
	},
	"786": {
		"title": "Robusta: Robust AutoML for Feature Selection via Reinforcement Learning",
		"creator": [
			"Wang, Xiaoyang",
			"Li, Bo",
			"Zhang, Yibo",
			"Kailkhura, Bhavya",
			"Nahrstedt, Klara"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  Several AutoML approaches have been proposed to automate the machine learning\n(ML) process, such as searching for the ML model architectures and\nhyper-parameters. However, these AutoML pipelines only focus on improving the\nlearning accuracy of benign samples while ignoring the ML model robustness\nunder adversarial attacks. As ML systems are increasingly being used in a\nvariety of mission-critical applications, improving the robustness of ML\nsystems has become of utmost importance. In this paper, we propose the first\nrobust AutoML framework, Robusta--based on reinforcement learning (RL)--to\nperform feature selection, aiming to select features that lead to both accurate\nand robust ML systems. We show that a variation of the 0-1 robust loss can be\ndirectly optimized via an RL-based combinatorial search in the feature\nselection scenario. In addition, we employ heuristics to accelerate the search\nprocedure based on feature scoring metrics, which are mutual information\nscores, tree-based classifiers feature importance scores, F scores, and\nIntegrated Gradient (IG) scores, as well as their combinations. We conduct\nextensive experiments and show that the proposed framework is able to improve\nthe model robustness by up to 22% while maintaining competitive accuracy on\nbenign samples compared with other feature selection methods.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05950",
		"pdf_url": "http://arxiv.org/pdf/2101.05950.pdf"
	},
	"787": {
		"title": "Dynamic DNN Decomposition for Lossless Synergistic Inference",
		"creator": [
			"Zhang, Beibei",
			"Xiang, Tian",
			"Zhang, Hongxuan",
			"Li, Te",
			"Zhu, Shiqiang",
			"Gu, Jianjun"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Machine Learning",
			"Computer Science - Networking and Internet Architecture"
		],
		"description": [
			"  Deep neural networks (DNNs) sustain high performance in today's data\nprocessing applications. DNN inference is resource-intensive thus is difficult\nto fit into a mobile device. An alternative is to offload the DNN inference to\na cloud server. However, such an approach requires heavy raw data transmission\nbetween the mobile device and the cloud server, which is not suitable for\nmission-critical and privacy-sensitive applications such as autopilot. To solve\nthis problem, recent advances unleash DNN services using the edge computing\nparadigm. The existing approaches split a DNN into two parts and deploy the two\npartitions to computation nodes at two edge computing tiers. Nonetheless, these\nmethods overlook collaborative device-edge-cloud computation resources.\nBesides, previous algorithms demand the whole DNN re-partitioning to adapt to\ncomputation resource changes and network dynamics. Moreover, for\nresource-demanding convolutional layers, prior works do not give a parallel\nprocessing strategy without loss of accuracy at the edge side. To tackle these\nissues, we propose D3, a dynamic DNN decomposition system for synergistic\ninference without precision loss. The proposed system introduces a heuristic\nalgorithm named horizontal partition algorithm to split a DNN into three parts.\nThe algorithm can partially adjust the partitions at run time according to\nprocessing time and network conditions. At the edge side, a vertical separation\nmodule separates feature maps into tiles that can be independently run on\ndifferent edge nodes in parallel. Extensive quantitative evaluation of five\npopular DNNs illustrates that D3 outperforms the state-of-the-art counterparts\nup to 3.4 times in end-to-end DNN inference time and reduces backbone network\ncommunication overhead up to 3.68 times.\n",
			"Comment: 11 pages, 13 figures"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05952",
		"pdf_url": "http://arxiv.org/pdf/2101.05952.pdf"
	},
	"788": {
		"title": "Hostility Detection and Covid-19 Fake News Detection in Social Media",
		"creator": [
			"Gupta, Ayush",
			"Sukumaran, Rohan",
			"John, Kevin",
			"Teki, Sundeep"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Withtheadventofsocialmedia,therehasbeenanextremely rapid increase in the\ncontent shared online. Consequently, the propagation of fake news and hostile\nmessages on social media platforms has also skyrocketed. In this paper, we\naddress the problem of detecting hostile and fake content in the Devanagari\n(Hindi) script as a multi-class, multi-label problem. Using NLP techniques, we\nbuild a model that makes use of an abusive language detector coupled with\nfeatures extracted via Hindi BERT and Hindi FastText models and metadata. Our\nmodel achieves a 0.97 F1 score on coarse grain evaluation on Hostility\ndetection task. Additionally, we built models to identify fake news related to\nCovid-19 in English tweets. We leverage entity information extracted from the\ntweets along with textual representations learned from word embeddings and\nachieve a 0.93 F1 score on the English fake news detection task.\n",
			"Comment: 13 pages, 3 figures, 3 tables"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05953",
		"pdf_url": "http://arxiv.org/pdf/2101.05953.pdf"
	},
	"789": {
		"title": "Descriptive AI Ethics: Collecting and Understanding the Public Opinion",
		"creator": [
			"Lima, Gabriel",
			"Cha, Meeyoung"
		],
		"subject": [
			"Computer Science - Computers and Society",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  There is a growing need for data-driven research efforts on how the public\nperceives the ethical, moral, and legal issues of autonomous AI systems. The\ncurrent debate on the responsibility gap posed by these systems is one such\nexample. This work proposes a mixed AI ethics model that allows normative and\ndescriptive research to complement each other, by aiding scholarly discussion\nwith data gathered from the public. We discuss its implications on bridging the\ngap between optimistic and pessimistic views towards AI systems' deployment.\n",
			"Comment: Accepted to the Ethics in Design Workshop at ACM CSCW 2020\n  (https://ethicsindesignworkshop.wordpress.com/). 5 pages"
		],
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05957",
		"pdf_url": "http://arxiv.org/pdf/2101.05957.pdf"
	},
	"790": {
		"title": "DeepWaste: Applying Deep Learning to Waste Classification for a\n  Sustainable Planet",
		"creator": "Narayan, Yash",
		"subject": "Computer Science - Machine Learning",
		"description": "  Accurate waste disposal, at the point of disposal, is crucial to fighting\nclimate change. When materials that could be recycled or composted get diverted\ninto landfills, they cause the emission of potent greenhouse gases such as\nmethane. Current attempts to reduce erroneous waste disposal are expensive,\ninaccurate, and confusing. In this work, we propose DeepWaste, an easy-to-use\nmobile app, that utilizes highly optimized deep learning techniques to provide\nusers instantaneous waste classification into trash, recycling, and compost. We\nexperiment with several convolution neural network architectures to detect and\nclassify waste items. Our best model, a deep learning residual neural network\nwith 50 layers, achieves an average precision of 0.881 on the test set. We\ndemonstrate the performance and efficiency of our app on a set of real-world\nimages.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.05960",
			"Tackling Climate Change with Machine Learning at NeurIPS 2020"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.05960.pdf"
	},
	"791": {
		"title": "A Data Flow Analysis Framework for Data Flow Subsumption",
		"creator": [
			"Chaim, Marcos Lordello",
			"Baral, Kesina",
			"Offutt, Jeff"
		],
		"subject": "Computer Science - Software Engineering",
		"description": "  Data flow testing creates test requirements as definition-use (DU)\nassociations, where a definition is a program location that assigns a value to\na variable and a use is a location where that value is accessed. Data flow\ntesting is expensive, largely because of the number of test requirements.\nLuckily, many DU-associations are redundant in the sense that if one test\nrequirement (e.g., node, edge, DU-association) is covered, other\nDU-associations are guaranteed to also be covered. This relationship is called\nsubsumption. Thus, testers can save resources by only covering DU-associations\nthat are not subsumed by other testing requirements. In this work, we formally\ndescribe the Data Flow Subsumption Framework (DSF) conceived to tackle the data\nflow subsumption problem. We show that DFS is a distributive data flow analysis\nframework which allows efficient iterative algorithms to find the\nMeet-Over-All-Paths (MOP) solution for DSF transfer functions. The MOP solution\nimplies that the results at a point $p$ are valid for all paths that reach $p$.\nWe also present an algorithm, called Subsumption Algorithm (SA), that uses DSF\ntransfer functions and iterative algorithms to find the local\nDU-associations-node subsumption; that is, the set of DU-associations that are\ncovered whenever a node $n$ is toured by a test. A proof of SA's correctness is\npresented and its complexity is analyzed.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05962",
		"pdf_url": "http://arxiv.org/pdf/2101.05962.pdf"
	},
	"792": {
		"title": "Responsible AI Challenges in End-to-end Machine Learning",
		"creator": [
			"Whang, Steven Euijong",
			"Tae, Ki Hyun",
			"Roh, Yuji",
			"Heo, Geon"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  Responsible AI is becoming critical as AI is widely used in our everyday\nlives. Many companies that deploy AI publicly state that when training a model,\nwe not only need to improve its accuracy, but also need to guarantee that the\nmodel does not discriminate against users (fairness), is resilient to noisy or\npoisoned data (robustness), is explainable, and more. In addition, these\nobjectives are not only relevant to model training, but to all steps of\nend-to-end machine learning, which include data collection, data cleaning and\nvalidation, model training, model evaluation, and model management and serving.\nFinally, responsible AI is conceptually challenging, and supporting all the\nobjectives must be as easy as possible. We thus propose three key research\ndirections towards this vision - depth, breadth, and usability - to measure\nprogress and introduce our ongoing research. First, responsible AI must be\ndeeply supported where multiple objectives like fairness and robust must be\nhandled together. To this end, we propose FR-Train, a holistic framework for\nfair and robust model training in the presence of data bias and poisoning.\nSecond, responsible AI must be broadly supported, preferably in all steps of\nmachine learning. Currently we focus on the data pre-processing steps and\npropose Slice Tuner, a selective data acquisition framework for training fair\nand accurate models, and MLClean, a data cleaning framework that also improves\nfairness and robustness. Finally, responsible AI must be usable where the\ntechniques must be easy to deploy and actionable. We propose FairBatch, a batch\nselection approach for fairness that is effective and simple to use, and Slice\nFinder, a model evaluation tool that automatically finds problematic slices. We\nbelieve we scratched the surface of responsible AI for end-to-end machine\nlearning and suggest research challenges moving forward.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05967",
		"pdf_url": "http://arxiv.org/pdf/2101.05967.pdf"
	},
	"793": {
		"title": "Affordance-based Reinforcement Learning for Urban Driving",
		"creator": [
			"Agarwal, Tanmay",
			"Arora, Hitesh",
			"Schneider, Jeff"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Robotics"
		],
		"description": "  Traditional autonomous vehicle pipelines that follow a modular approach have\nbeen very successful in the past both in academia and industry, which has led\nto autonomy deployed on road. Though this approach provides ease of\ninterpretation, its generalizability to unseen environments is limited and\nhand-engineering of numerous parameters is required, especially in the\nprediction and planning systems. Recently, deep reinforcement learning has been\nshown to learn complex strategic games and perform challenging robotic tasks,\nwhich provides an appealing framework for learning to drive. In this work, we\npropose a deep reinforcement learning framework to learn optimal control policy\nusing waypoints and low-dimensional visual representations, also known as\naffordances. We demonstrate that our agents when trained from scratch learn the\ntasks of lane-following, driving around inter-sections as well as stopping in\nfront of other actors or traffic lights even in the dense traffic setting. We\nnote that our method achieves comparable or better performance than the\nbaseline methods on the original and NoCrash benchmarks on the CARLA simulator.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05970",
		"pdf_url": "http://arxiv.org/pdf/2101.05970.pdf"
	},
	"794": {
		"title": "\"Killing Me\" Is Not a Spoiler: Spoiler Detection Model using Graph\n  Neural Networks with Dependency Relation-Aware Attention Mechanism",
		"creator": [
			"Chang, Buru",
			"Lee, Inggeol",
			"Kim, Hyunjae",
			"Kang, Jaewoo"
		],
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  Several machine learning-based spoiler detection models have been proposed\nrecently to protect users from spoilers on review websites. Although dependency\nrelations between context words are important for detecting spoilers, current\nattention-based spoiler detection models are insufficient for utilizing\ndependency relations. To address this problem, we propose a new spoiler\ndetection model called SDGNN that is based on syntax-aware graph neural\nnetworks. In the experiments on two real-world benchmark datasets, we show that\nour SDGNN outperforms the existing spoiler detection models.\n",
			"Comment: EACL 2021"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05972",
		"pdf_url": "http://arxiv.org/pdf/2101.05972.pdf"
	},
	"795": {
		"title": "Russian Troll Account Classification with Twitter and Facebook Data",
		"creator": [
			"Lewinski, Dominic",
			"Hasan, Md Rashidul"
		],
		"subject": "Computer Science - Social and Information Networks",
		"description": [
			"  In this analysis, we work with the data set that was compiled by Darren\nLinvill and Patrick Warren, along with a representative sample of Facebook ads\nthat were released by the House Intelligence Committee Minority. The goal of\nthis analysis is to use the categories defined by Linvill and Warren in the\nTwitter data and investigate if these categories exist in Facebook ads. This\nbegin to give us insights to the tactics used between the two social media\nservices. Further, we try to replicate Linvill and Warren's original\ncategorization of the Twitter data. Lastly, we investigate what categories may\nexist in the Facebook data.\n",
			"Comment: 17 pages"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05983",
		"pdf_url": "http://arxiv.org/pdf/2101.05983.pdf"
	},
	"796": {
		"title": "Interaction-Aware Behavior Planning for Autonomous Vehicles Validated\n  with Real Traffic Data",
		"creator": [
			"Li, Jinning",
			"Sun, Liting",
			"Zhan, Wei",
			"Tomizuka, Masayoshi"
		],
		"subject": [
			"Computer Science - Robotics",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": "  Autonomous vehicles (AVs) need to interact with other traffic participants\nwho can be either cooperative or aggressive, attentive or inattentive. Such\ndifferent characteristics can lead to quite different interactive behaviors.\nHence, to achieve safe and efficient autonomous driving, AVs need to be aware\nof such uncertainties when they plan their own behaviors. In this paper, we\nformulate such a behavior planning problem as a partially observable Markov\nDecision Process (POMDP) where the cooperativeness of other traffic\nparticipants is treated as an unobservable state. Under different\ncooperativeness levels, we learn the human behavior models from real traffic\ndata via the principle of maximum likelihood. Based on that, the POMDP problem\nis solved by Monte-Carlo Tree Search. We verify the proposed algorithm in both\nsimulations and real traffic data on a lane change scenario, and the results\nshow that the proposed algorithm can successfully finish the lane changes\nwithout collisions.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05985",
		"pdf_url": "http://arxiv.org/pdf/2101.05985.pdf"
	},
	"797": {
		"title": "Quality meets Diversity: A Model-Agnostic Framework for Computerized\n  Adaptive Testing",
		"creator": [
			"Bi, Haoyang",
			"Ma, Haiping",
			"Huang, Zhenya",
			"Yin, Yu",
			"Liu, Qi",
			"Chen, Enhong",
			"Su, Yu",
			"Wang, Shijin"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computers and Society",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Computerized Adaptive Testing (CAT) is emerging as a promising testing\napplication in many scenarios, such as education, game and recruitment, which\ntargets at diagnosing the knowledge mastery levels of examinees on required\nconcepts. It shows the advantage of tailoring a personalized testing procedure\nfor each examinee, which selects questions step by step, depending on her\nperformance. While there are many efforts on developing CAT systems, existing\nsolutions generally follow an inflexible model-specific fashion. That is, they\nneed to observe a specific cognitive model which can estimate examinee's\nknowledge levels and design the selection strategy according to the model\nestimation. In this paper, we study a novel model-agnostic CAT problem, where\nwe aim to propose a flexible framework that can adapt to different cognitive\nmodels. Meanwhile, this work also figures out CAT solution with addressing the\nproblem of how to generate both high-quality and diverse questions\nsimultaneously, which can give a comprehensive knowledge diagnosis for each\nexaminee. Inspired by Active Learning, we propose a novel framework, namely\nModel-Agnostic Adaptive Testing (MAAT) for CAT solution, where we design three\nsophisticated modules including Quality Module, Diversity Module and Importance\nModule. Extensive experimental results on two real-world datasets clearly\ndemonstrate that our MAAT can support CAT with guaranteeing both quality and\ndiversity perspectives.\n",
			"Comment: Accepted by ICDM'2020"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05986",
		"pdf_url": "http://arxiv.org/pdf/2101.05986.pdf"
	},
	"798": {
		"title": "Coarse-grained decomposition and fine-grained interaction for multi-hop\n  question answering",
		"creator": [
			"Cao, Xing",
			"Liu, Yun"
		],
		"subject": "Computer Science - Computation and Language",
		"description": "  Recent advances regarding question answering and reading comprehension have\nresulted in models that surpass human performance when the answer is contained\nin a single, continuous passage of text, requiring only single-hop reasoning.\nHowever, in actual scenarios, lots of complex queries require multi-hop\nreasoning. The key to the Question Answering task is semantic feature\ninteraction between documents and questions, which is widely processed by\nBi-directional Attention Flow (Bi-DAF), but Bi-DAF generally captures only the\nsurface semantics of words in complex questions and fails to capture implied\nsemantic feature of intermediate answers. As a result, Bi-DAF partially ignores\npart of the contexts related to the question and cannot extract the most\nimportant parts of multiple documents. In this paper we propose a new model\narchitecture for multi-hop question answering, by applying two completion\nstrategies: (1) Coarse-Grain complex question Decomposition (CGDe) strategy are\nintroduced to decompose complex question into simple ones under the condition\nof without any additional annotations (2) Fine-Grained Interaction (FGIn)\nstrategy are introduced to better represent each word in the document and\nextract more comprehensive and accurate sentences related to the inference\npath. The above two strategies are combined and tested on the SQuAD and\nHotpotQA datasets, and the experimental results show that our method\noutperforms state-of-the-art baselines.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05988",
		"pdf_url": "http://arxiv.org/pdf/2101.05988.pdf"
	},
	"799": {
		"title": "Neural Network-derived perfusion maps: a Model-free approach to computed\n  tomography perfusion in patients with acute ischemic stroke",
		"creator": [
			"Gava, Umberto A.",
			"D'Agata, Federico",
			"Tartaglione, Enzo",
			"Grangetto, Marco",
			"Bertolino, Francesca",
			"Santonocito, Ambra",
			"Bennink, Edwin",
			"Bergui, Mauro"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  Purpose: In this study we investigate whether a Convolutional Neural Network\n(CNN) can generate clinically relevant parametric maps from CT perfusion data\nin a clinical setting of patients with acute ischemic stroke. Methods: Training\nof the CNN was done on a subset of 100 perfusion data, while 15 samples were\nused as validation. All the data used for the training/validation of the\nnetwork and to generate ground truth (GT) maps, using a state-of-the-art\ndeconvolution-algorithm, were previously pre-processed using a standard\npipeline. Validation was carried out through manual segmentation of infarct\ncore and penumbra on both CNN-derived maps and GT maps. Concordance among\nsegmented lesions was assessed using the Dice and the Pearson correlation\ncoefficients across lesion volumes. Results: Mean Dice scores from two\ndifferent raters and the GT maps were > 0.70 (good-matching). Inter-rater\nconcordance was also high and strong correlation was found between lesion\nvolumes of CNN maps and GT maps (0.99, 0.98). Conclusion: Our CNN-based\napproach generated clinically relevant perfusion maps that are comparable to\nstate-of-the-art perfusion analysis methods based on deconvolution of the data.\nMoreover, the proposed technique requires less information to estimate the\nischemic core and thus might allow the development of novel perfusion protocols\nwith lower radiation dose.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05992",
		"pdf_url": "http://arxiv.org/pdf/2101.05992.pdf"
	},
	"800": {
		"title": "Convolutional Neural Network with Pruning Method for Handwritten Digit\n  Recognition",
		"creator": "Chen, Mengyu",
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Neural and Evolutionary Computing"
		],
		"description": "  CNN model is a popular method for imagery analysis, so it could be utilized\nto recognize handwritten digits based on MNIST datasets. For higher recognition\naccuracy, various CNN models with different fully connected layer sizes are\nexploited to figure out the relationship between the CNN fully connected layer\nsize and the recognition accuracy. Inspired by previous pruning work, we\nperformed pruning methods of distinctiveness on CNN models and compared the\npruning performance with NN models. For better pruning performances on CNN, the\neffect of angle threshold on the pruning performance was explored. The\nevaluation results show that: for the fully connected layer size, there is a\nthreshold, so that when the layer size increases, the recognition accuracy\ngrows if the layer size smaller than the threshold, and falls if the layer size\nlarger than the threshold; the performance of pruning performed on CNN is worse\nthan on NN; as pruning angle threshold increases, the fully connected layer\nsize and the recognition accuracy decreases. This paper also shows that for CNN\nmodels trained by the MNIST dataset, they are capable of handwritten digit\nrecognition and achieve the highest recognition accuracy with fully connected\nlayer size 400. In addition, for same dataset MNIST, CNN models work better\nthan big, deep, simple NN models in a published paper.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.05996",
		"pdf_url": "http://arxiv.org/pdf/2101.05996.pdf"
	},
	"801": {
		"title": "Horizon: A Gas-Efficient, Trustless Bridge for Cross-Chain Transactions",
		"creator": [
			"Lan, Rongjian",
			"Upadhyaya, Ganesha",
			"Tse, Stephen",
			"Zamani, Mahdi"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Distributed, Parallel, and Cluster Computing"
		],
		"description": [
			"  With the rise of digital currency systems that rely on blockchain to ensure\nledger security, the ability to perform cross-chain transactions is becoming a\ncrucial interoperability requirement. Such transactions allow not only funds to\nbe transferred from one blockchain to another (as done in atomic swaps), but\nalso a blockchain to verify the inclusion of any event on another blockchain.\nCross-chain bridges are protocols that allow on-chain exchange of\ncryptocurrencies, on-chain transfer of assets to sidechains, and cross-shard\nverification of events in sharded blockchains, many of which rely on Byzantine\nfault tolerance (BFT) for scalability. Unfortunately, existing bridge protocols\nthat can transfer funds from a BFT blockchain incur significant computation\noverhead on the destination blockchain, resulting in a high gas cost for smart\ncontract verification of events. In this paper, we propose Horizon, a\ngas-efficient, cross-chain bridge protocol to transfer assets from a BFT\nblockchain to another blockchain (e.g., Ethereum) that supports basic smart\ncontract execution.\n",
			"Comment: 14 Pages"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06000",
		"pdf_url": "http://arxiv.org/pdf/2101.06000.pdf"
	},
	"802": {
		"title": "Walk in Wild: An Ensemble Approach for Hostility Detection in Hindi\n  Posts",
		"creator": [
			"Shekhar, Chander",
			"Bagla, Bhavya",
			"Maurya, Kaushal Kumar",
			"Desarkar, Maunendra Sankar"
		],
		"subject": "Computer Science - Computation and Language",
		"description": "  As the reach of the internet increases, pejorative terms started flooding\nover social media platforms. This leads to the necessity of identifying hostile\ncontent on social media platforms. Identification of hostile contents on\nlow-resource languages like Hindi poses different challenges due to its diverse\nsyntactic structure compared to English. In this paper, we develop a simple\nensemble based model on pre-trained mBERT and popular classification algorithms\nlike Artificial Neural Network (ANN) and XGBoost for hostility detection in\nHindi posts. We formulated this problem as binary classification (hostile and\nnon-hostile class) and multi-label multi-class classification problem (for more\nfine-grained hostile classes). We received third overall rank in the\ncompetition and weighted F1-scores of ~0.969 and ~0.61 on the binary and\nmulti-label multi-class classification tasks respectively.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06004",
		"pdf_url": "http://arxiv.org/pdf/2101.06004.pdf"
	},
	"803": {
		"title": "Reasoning over Vision and Language: Exploring the Benefits of\n  Supplemental Knowledge",
		"creator": [
			"Shevchenko, Violetta",
			"Teney, Damien",
			"Dick, Anthony",
			"Hengel, Anton van den"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  The limits of applicability of vision-and-language models are defined by the\ncoverage of their training data. Tasks like vision question answering (VQA)\noften require commonsense and factual information beyond what can be learned\nfrom task-specific datasets. This paper investigates the injection of knowledge\nfrom general-purpose knowledge bases (KBs) into vision-and-language\ntransformers. We use an auxiliary training objective that encourages the\nlearned representations to align with graph embeddings of matching entities in\na KB. We empirically study the relevance of various KBs to multiple tasks and\nbenchmarks. The technique brings clear benefits to knowledge-demanding question\nanswering tasks (OK-VQA, FVQA) by capturing semantic and relational knowledge\nabsent from existing models. More surprisingly, the technique also benefits\nvisual reasoning tasks (NLVR2, SNLI-VE). We perform probing experiments and\nshow that the injection of additional knowledge regularizes the space of\nembeddings, which improves the representation of lexical and semantic\nsimilarities. The technique is model-agnostic and can expand the applicability\nof any vision-and-language transformer with minimal computational overhead.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06013",
		"pdf_url": "http://arxiv.org/pdf/2101.06013.pdf"
	},
	"804": {
		"title": "Deadlock in packet switching networks",
		"creator": [
			"Stramaglia, Anna",
			"Keiren, Jeroen J. A.",
			"Zantema, Hans"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Computer Science - Logic in Computer Science"
		],
		"description": [
			"  A deadlock in a packet switching network is a state in which one or more\nmessages have not yet reached their target, yet cannot progress any further. We\nformalize three different notions of deadlock in the context of packet\nswitching networks, to which we refer as global, local and weak deadlock. We\nestablish the precise relations between these notions, and prove they\ncharacterize different sets of deadlocks. Moreover, we implement checking of\ndeadlock freedom of packet switching networks using the symbolic model checker\nnuXmv. We show experimentally that the implementation is effective at finding\nsubtle deadlock situations in packet switching networks.\n",
			"Comment: This is a version with full proofs of the preprint that was submitted\n  to FSEN 2021, and accepted for publication in that conference (to appear in\n  Springer LNCS)"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06015",
		"pdf_url": "http://arxiv.org/pdf/2101.06015.pdf"
	},
	"805": {
		"title": "Motion-Based Handwriting Recognition",
		"creator": [
			"Chen, Junshen Kevin",
			"Xie, Wanze",
			"He, Yutong"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  We attempt to overcome the restriction of requiring a writing surface for\nhandwriting recognition. In this study, we design a prototype of a stylus\nequipped with motion sensor, and utilizes gyroscopic and acceleration sensor\nreading to perform written letter classification using various deep learning\ntechniques such as CNN and RNNs. We also explore various data augmentation\ntechniques and their effects, reaching up to 86% accuracy.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06022",
		"pdf_url": "http://arxiv.org/pdf/2101.06022.pdf"
	},
	"806": {
		"title": "Motion-Based Handwriting Recognition and Word Reconstruction",
		"creator": [
			"Chen, Junshen Kevin",
			"Xie, Wanze",
			"He, Yutong"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  In this project, we leverage a trained single-letter classifier to predict\nthe written word from a continuously written word sequence, by designing a word\nreconstruction pipeline consisting of a dynamic-programming algorithm and an\nauto-correction model. We conduct experiments to optimize models in this\npipeline, then employ domain adaptation to explore using this pipeline on\nunseen data distributions.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06025",
		"pdf_url": "http://arxiv.org/pdf/2101.06025.pdf"
	},
	"807": {
		"title": "QoS-Driven Video Uplinking in NOMA-Based IoT",
		"creator": [
			"Ma, Pengfei",
			"Lu, Hancheng",
			"Zhang, Ming",
			"Liu, Jinxue",
			"Chen, Ruoyun"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": "  In recent years, with the explosive growth of visual sensors and a large\nnumber of related video applications in Internet of Things (IoT), massive video\ndata is generated by IoT devices. Since the volume of video data is far greater\nthan traditional data in IoT, it is challenging to ensure high Quality of\nService (QoS) for video uplinking in IoT. To address this challenge, we\nintegrate non-orthogonal multiple access (NOMA) and scalable video coding (SVC)\nin IoT. To improve the video quality, we formulate a power allocation problem\nto maximize the average QoS in the proposed integrated system. Due to that the\nproblem is non-convex, we transform it into a monotonic problem based on its\nhidden monotonicity. Then a power allocation algorithm based on polyblock outer\napproximation is proposed to solve the problem effectively. Finally, simulation\nresults demonstrate that the proposed algorithm outperforms existing OMA and\nNOMA based schemes for video uplinking in IoT in terms of QoS and energy\nefficiency.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06028",
		"pdf_url": "http://arxiv.org/pdf/2101.06028.pdf"
	},
	"808": {
		"title": "Directed Diversity: Leveraging Language Embedding Distances for\n  Collective Creativity in Crowd Ideation",
		"creator": [
			"Cox, Samuel Rhys",
			"Wang, Yunlong",
			"Abdul, Ashraf",
			"von der Weth, Christian",
			"Lim, Brian Y."
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": [
			"  Crowdsourcing can collect many diverse ideas by prompting ideators\nindividually, but this can generate redundant ideas. Prior methods reduce\nredundancy by presenting peers' ideas or peer-proposed prompts, but these\nrequire much human coordination. We introduce Directed Diversity, an automatic\nprompt selection approach that leverages language model embedding distances to\nmaximize diversity. Ideators can be directed towards diverse prompts and away\nfrom prior ideas, thus improving their collective creativity. Since there are\ndiverse metrics of diversity, we present a Diversity Prompting Evaluation\nFramework consolidating metrics from several research disciplines to analyze\nalong the ideation chain - prompt selection, prompt creativity, prompt-ideation\nmediation, and ideation creativity. Using this framework, we evaluated Directed\nDiversity in a series of a simulation study and four user studies for the use\ncase of crowdsourcing motivational messages to encourage physical activity. We\nshow that automated diverse prompting can variously improve collective\ncreativity across many nuanced metrics of diversity.\n",
			"Comment: CHI 2021"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06030",
			"doi:10.1145/3411764.3445782"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06030.pdf"
	},
	"809": {
		"title": "Improved Rank-Modulation Codes for DNA Storage with Shotgun Sequencing",
		"creator": [
			"Beeri, Niv",
			"Schwartz, Moshe"
		],
		"subject": [
			"Computer Science - Information Theory",
			"Mathematics - Combinatorics"
		],
		"description": "  We study permutations over the set of $\\ell$-grams, that are feasible in the\nsense that there is a sequence whose $\\ell$-gram frequency has the same ranking\nas the permutation. Codes, which are sets of feasible permutations, protect\ninformation stored in DNA molecules using the rank-modulation scheme, and read\nusing the shotgun sequencing technique. We construct systematic codes with an\nefficient encoding algorithm, and show that they are optimal in size. The\nlength of the DNA sequences that correspond to the codewords is shown to be\npolynomial in the code parameters. Non-systematic with larger size are also\nconstructed.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06033",
		"pdf_url": "http://arxiv.org/pdf/2101.06033.pdf"
	},
	"810": {
		"title": "Secure Optimization Through Opaque Observations",
		"creator": [
			"Vu, Son Tuan",
			"Cohen, Albert",
			"Heydemann, Karine",
			"de Grandmaison, Arnaud",
			"Guillon, Christophe"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Programming Languages"
		],
		"description": "  Secure applications implement software protections against side-channel and\nphysical attacks. Such protections are meaningful at machine code or\nmicro-architectural level, but they typically do not carry observable semantics\nat source level. To prevent optimizing compilers from altering the protection,\nsecurity engineers embed input/output side-effects into the protection. These\nside-effects are error-prone and compiler-dependent, and the current practice\ninvolves analyzing the generated machine code to make sure security or privacy\nproperties are still enforced. Vu et al. recently demonstrated how to automate\nthe insertion of volatile side-effects in a compiler [52], but these may be too\nexpensive in fined-grained protections such as control-flow integrity. We\nintroduce observations of the program state that are intrinsic to the correct\nexecution of security protections, along with means to specify and preserve\nobservations across the compilation flow. Such observations complement the\ntraditional input/output-preservation contract of compilers. We show how to\nguarantee their preservation without modifying compilation passes and with as\nlittle performance impact as possible. We validate our approach on a range of\nbenchmarks, expressing the secure compilation of these applications in terms of\nobservations to be made at specific program points.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06039",
		"pdf_url": "http://arxiv.org/pdf/2101.06039.pdf"
	},
	"811": {
		"title": "Towards a Computed-Aided Diagnosis System in Colonoscopy: Automatic\n  Polyp Segmentation Using Convolution Neural Networks",
		"creator": [
			"Brandao, Patrick",
			"Zisimopoulos, Odysseas",
			"Mazomenos, Evangelos",
			"Ciuti, Gastone",
			"Bernal, Jorge",
			"Visentini-Scarzanella, Marco",
			"Menciassi, Arianna",
			"Dario, Paolo",
			"Koulaouzidis, Anastasios",
			"Arezzo, Alberto",
			"Hawkes, David J",
			"Stoyanov, Danail"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Early diagnosis is essential for the successful treatment of bowel cancers\nincluding colorectal cancer (CRC) and capsule endoscopic imaging with robotic\nactuation can be a valuable diagnostic tool when combined with automated image\nanalysis. We present a deep learning rooted detection and segmentation\nframework for recognizing lesions in colonoscopy and capsule endoscopy images.\nWe restructure established convolution architectures, such as VGG and ResNets,\nby converting them into fully-connected convolution networks (FCNs), fine-tune\nthem and study their capabilities for polyp segmentation and detection. We\nadditionally use Shape from-Shading (SfS) to recover depth and provide a richer\nrepresentation of the tissue's structure in colonoscopy images. Depth is\nincorporated into our network models as an additional input channel to the RGB\ninformation and we demonstrate that the resulting network yields improved\nperformance. Our networks are tested on publicly available datasets and the\nmost accurate segmentation model achieved a mean segmentation IU of 47.78% and\n56.95% on the ETIS-Larib and CVC-Colon datasets, respectively. For polyp\ndetection, the top performing models we propose surpass the current state of\nthe art with detection recalls superior to 90% for all datasets tested. To our\nknowledge, we present the first work to use FCNs for polyp segmentation in\naddition to proposing a novel combination of SfS and RGB that boosts\nperformance\n",
			"Comment: 10 pages, 6 figures"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06040",
			"Journal of Medical Robotics Research, Volume 03, No. 02, 1840002\n  (2018) G",
			"doi:10.1142/S2424905X18400020"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06040.pdf"
	},
	"812": {
		"title": "Bulwark: Holistic and Verified Security Monitoring of Web Protocols",
		"creator": [
			"Veronese, Lorenzo",
			"Calzavara, Stefano",
			"Compagna, Luca"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": [
			"  Modern web applications often rely on third-party services to provide their\nfunctionality to users. The secure integration of these services is a\nnon-trivial task, as shown by the large number of attacks against Single Sign\nOn and Cashier-as-a-Service protocols. In this paper we present Bulwark, a new\nautomatic tool which generates formally verified security monitors from applied\npi-calculus specifications of web protocols. The security monitors generated by\nBulwark offer holistic protection, since they can be readily deployed both at\nthe client side and at the server side, thus ensuring full visibility of the\nattack surface against web protocols. We evaluate the effectiveness of Bulwark\nby testing it against a pool of vulnerable web applications that use the OAuth\n2.0 protocol or integrate the PayPal payment system.\n",
			"Comment: Full version of the paper presented at ESORICS2020 (14-18 September\n  2020)"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06043",
			"ESORICS 2020: Computer Security (2020) 23-41",
			"doi:10.1007/978-3-030-58951-6_2"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06043.pdf"
	},
	"813": {
		"title": "A Particle Filtering Framework for Integrity Risk of GNSS-Camera Sensor\n  Fusion",
		"creator": [
			"Mohanty, Adyasha",
			"Gupta, Shubh",
			"Gao, Grace Xingxin"
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Machine Learning"
		],
		"description": "  Adopting a joint approach towards state estimation and integrity monitoring\nresults in unbiased integrity monitoring unlike traditional approaches. So far,\na joint approach was used in Particle RAIM [l] for GNSS measurements only. In\nour work, we extend Particle RAIM to a GNSS-camera fused system for joint state\nestimation and integrity monitoring. To account for vision faults, we derive a\nprobability distribution over position from camera images using map-matching.\nWe formulate a Kullback-Leibler Divergence metric to assess the consistency of\nGNSS and camera measurements and mitigate faults during sensor fusion. The\nderived integrity risk upper bounds the probability of Hazardously Misleading\nInformation (HMI). Experimental validation on a real-world dataset shows that\nour algorithm produces less than 11 m position error and the integrity risk\nover bounds the probability of HMI with 0.11 failure rate for an 8 m Alert\nLimit in an urban scenario.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06044",
			"Proceedings of the 33rd International Technical Meeting of the\n  Satellite Division of The Institute of Navigation (ION GNSS+ 2020)",
			"doi:10.33012/2020.17660"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06044.pdf"
	},
	"814": {
		"title": "Counterfactual Generative Networks",
		"creator": [
			"Sauer, Axel",
			"Geiger, Andreas"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  Neural networks are prone to learning shortcuts -- they often model simple\ncorrelations, ignoring more complex ones that potentially generalize better.\nPrior works on image classification show that instead of learning a connection\nto object shape, deep classifiers tend to exploit spurious correlations with\nlow-level texture or the background for solving the classification task. In\nthis work, we take a step towards more robust and interpretable classifiers\nthat explicitly expose the task's causal structure. Building on current\nadvances in deep generative modeling, we propose to decompose the image\ngeneration process into independent causal mechanisms that we train without\ndirect supervision. By exploiting appropriate inductive biases, these\nmechanisms disentangle object shape, object texture, and background; hence,\nthey allow for generating counterfactual images. We demonstrate the ability of\nour model to generate such images on MNIST and ImageNet. Further, we show that\nthe counterfactual images can improve out-of-distribution robustness with a\nmarginal drop in performance on the original classification task, despite being\nsynthetic. Lastly, our generative model can be trained efficiently on a single\nGPU, exploiting common pre-trained models as inductive biases.\n",
			"Comment: Published at ICLR 2021"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06046",
		"pdf_url": "http://arxiv.org/pdf/2101.06046.pdf"
	},
	"815": {
		"title": "Chance constrained sets approximation: A probabilistic scaling approach\n  -- EXTENDED VERSION",
		"creator": [
			"Mammarella, Martina",
			"Mirasierra, Victor",
			"Lorenzen, Matthias",
			"Alamo, Teodoro",
			"Dabbene, Fabrizio"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Mathematics - Optimization and Control"
		],
		"description": [
			"  In this paper, a sample-based procedure for obtaining simple and computable\napproximations of chance-constrained sets is proposed. The procedure allows to\ncontrol the complexity of the approximating set, by defining families of\nsimple-approximating sets of given complexity. A probabilistic scaling\nprocedure then allows to rescale these sets to obtain the desired probabilistic\nguarantees. The proposed approach is shown to be applicable in several problem\nin systems and control, such as the design of Stochastic Model Predictive\nControl schemes or the solution of probabilistic set membership estimation\nproblems.\n",
			"Comment: 16 pages, 11 figures, submitted to Automatica"
		],
		"date": [
			"2021-01-15",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06052",
		"pdf_url": "http://arxiv.org/pdf/2101.06052.pdf"
	},
	"816": {
		"title": "Artificial Intelligence for IT Operations (AIOPS) Workshop White Paper",
		"creator": [
			"Bogatinovski, Jasmin",
			"Nedelkoski, Sasho",
			"Acker, Alexander",
			"Schmidt, Florian",
			"Wittkopp, Thorsten",
			"Becker, Soeren",
			"Cardoso, Jorge",
			"Kao, Odej"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Software Engineering"
		],
		"description": [
			"  Artificial Intelligence for IT Operations (AIOps) is an emerging\ninterdisciplinary field arising in the intersection between the research areas\nof machine learning, big data, streaming analytics, and the management of IT\noperations. AIOps, as a field, is a candidate to produce the future standard\nfor IT operation management. To that end, AIOps has several challenges. First,\nit needs to combine separate research branches from other research fields like\nsoftware reliability engineering. Second, novel modelling techniques are needed\nto understand the dynamics of different systems. Furthermore, it requires to\nlay out the basis for assessing: time horizons and uncertainty for imminent SLA\nviolations, the early detection of emerging problems, autonomous remediation,\ndecision making, support of various optimization objectives. Moreover, a good\nunderstanding and interpretability of these aiding models are important for\nbuilding trust between the employed tools and the domain experts. Finally, all\nthis will result in faster adoption of AIOps, further increase the interest in\nthis research field and contribute to bridging the gap towards fully-autonomous\noperating IT systems.\n  The main aim of the AIOPS workshop is to bring together researchers from both\nacademia and industry to present their experiences, results, and work in\nprogress in this field. The workshop aims to strengthen the community and unite\nit towards the goal of joining the efforts for solving the main challenges the\nfield is currently facing. A consensus and adoption of the principles of\nopenness and reproducibility will boost the research in this emerging area\nsignificantly.\n",
			"Comment: 8 pages, white paper for the AIOPS 2020 workshop at ICSOC 2020"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06054",
		"pdf_url": "http://arxiv.org/pdf/2101.06054.pdf"
	},
	"817": {
		"title": "EC-SAGINs: Edge Computing-enhanced Space-Air-Ground Integrated Networks\n  for Internet of Vehicles",
		"creator": [
			"Yu, Shuai",
			"Gong, Xiaowen",
			"Shi, Qian",
			"Wang, Xiaofei",
			"Chen, Xu"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Distributed, Parallel, and Cluster Computing"
		],
		"description": [
			"  Edge computing-enhanced Internet of Vehicles (EC-IoV) enables ubiquitous data\nprocessing and content sharing among vehicles and terrestrial edge computing\n(TEC) infrastructures (e.g., 5G base stations and roadside units) with little\nor no human intervention, plays a key role in the intelligent transportation\nsystems. However, EC-IoV is heavily dependent on the connections and\ninteractions between vehicles and TEC infrastructures, thus will break down in\nsome remote areas where TEC infrastructures are unavailable (e.g., desert,\nisolated islands and disaster-stricken areas). Driven by the ubiquitous\nconnections and global-area coverage, space-air-ground integrated networks\n(SAGINs) efficiently support seamless coverage and efficient resource\nmanagement, represent the next frontier for edge computing. In light of this,\nwe first review the state-of-the-art edge computing research for SAGINs in this\narticle. After discussing several existing orbital and aerial edge computing\narchitectures, we propose a framework of edge computing-enabled\nspace-air-ground integrated networks (EC-SAGINs) to support various IoV\nservices for the vehicles in remote areas. The main objective of the framework\nis to minimize the task completion time and satellite resource usage. To this\nend, a pre-classification scheme is presented to reduce the size of action\nspace, and a deep imitation learning (DIL) driven offloading and caching\nalgorithm is proposed to achieve real-time decision making. Simulation results\nshow the effectiveness of our proposed scheme. At last, we also discuss some\ntechnology challenges and future directions.\n",
			"Comment: The paper is accepted by IEEE IoTJ, Jan. 2021"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06056",
		"pdf_url": "http://arxiv.org/pdf/2101.06056.pdf"
	},
	"818": {
		"title": "The Challenge of Value Alignment: from Fairer Algorithms to AI Safety",
		"creator": [
			"Gabriel, Iason",
			"Ghazavi, Vafa"
		],
		"subject": "Computer Science - Computers and Society",
		"description": "  This paper addresses the question of how to align AI systems with human\nvalues and situates it within a wider body of thought regarding technology and\nvalue. Far from existing in a vacuum, there has long been an interest in the\nability of technology to 'lock-in' different value systems. There has also been\nconsiderable thought about how to align technologies with specific social\nvalues, including through participatory design-processes. In this paper we look\nmore closely at the question of AI value alignment and suggest that the power\nand autonomy of AI systems gives rise to opportunities and challenges in the\ndomain of value that have not been encountered before. Drawing important\ncontinuities between the work of the fairness, accountability, transparency and\nethics community, and work being done by technical AI safety researchers, we\nsuggest that more attention needs to be paid to the question of 'social value\nalignment' - that is, how to align AI systems with the plurality of values\nendorsed by groups of people, especially on the global level.\n",
		"date": [
			"2021-01-15",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06060",
		"pdf_url": "http://arxiv.org/pdf/2101.06060.pdf"
	},
	"819": {
		"title": "Heating up decision boundaries: isocapacitory saturation, adversarial\n  scenarios and generalization bounds",
		"creator": [
			"Georgiev, Bogdan",
			"Franken, Lukas",
			"Mukherjee, Mayukh"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Mathematics - Metric Geometry",
			"Mathematics - Probability",
			"Mathematics - Statistics Theory",
			"Statistics - Machine Learning"
		],
		"description": [
			"  In the present work we study classifiers' decision boundaries via Brownian\nmotion processes in ambient data space and associated probabilistic techniques.\nIntuitively, our ideas correspond to placing a heat source at the decision\nboundary and observing how effectively the sample points warm up. We are\nlargely motivated by the search for a soft measure that sheds further light on\nthe decision boundary's geometry. En route, we bridge aspects of potential\ntheory and geometric analysis (Mazya, 2011, Grigoryan-Saloff-Coste, 2002) with\nactive fields of ML research such as adversarial examples and generalization\nbounds. First, we focus on the geometric behavior of decision boundaries in the\nlight of adversarial attack/defense mechanisms. Experimentally, we observe a\ncertain capacitory trend over different adversarial defense strategies:\ndecision boundaries locally become flatter as measured by isoperimetric\ninequalities (Ford et al, 2019); however, our more sensitive heat-diffusion\nmetrics extend this analysis and further reveal that some non-trivial geometry\ninvisible to plain distance-based methods is still preserved. Intuitively, we\nprovide evidence that the decision boundaries nevertheless retain many\npersistent \"wiggly and fuzzy\" regions on a finer scale. Second, we show how\nBrownian hitting probabilities translate to soft generalization bounds which\nare in turn connected to compression and noise stability (Arora et al, 2018),\nand these bounds are significantly stronger if the decision boundary has\ncontrolled geometric features.\n",
			"Comment: Accepted as conference paper at ICLR 2021. 36 pages, 16 figures,\n  comments welcome!"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06061",
		"pdf_url": "http://arxiv.org/pdf/2101.06061.pdf"
	},
	"820": {
		"title": "Unstructured Knowledge Access in Task-oriented Dialog Modeling using\n  Language Inference, Knowledge Retrieval and Knowledge-Integrative Response\n  Generation",
		"creator": [
			"Chaudhary, Mudit",
			"Dzodzo, Borislav",
			"Huang, Sida",
			"Lo, Chun Hei",
			"Lyu, Mingzhi",
			"Nie, Lun Yiu",
			"Xing, Jinbo",
			"Zhang, Tianhua",
			"Zhang, Xiaoying",
			"Zhou, Jingyan",
			"Cheng, Hong",
			"Lam, Wai",
			"Meng, Helen"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  Dialog systems enriched with external knowledge can handle user queries that\nare outside the scope of the supporting databases/APIs. In this paper, we\nfollow the baseline provided in DSTC9 Track 1 and propose three subsystems,\nKDEAK, KnowleDgEFactor, and Ens-GPT, which form the pipeline for a\ntask-oriented dialog system capable of accessing unstructured knowledge.\nSpecifically, KDEAK performs knowledge-seeking turn detection by formulating\nthe problem as natural language inference using knowledge from dialogs,\ndatabases and FAQs. KnowleDgEFactor accomplishes the knowledge selection task\nby formulating a factorized knowledge/document retrieval problem with three\nmodules performing domain, entity and knowledge level analyses. Ens-GPT\ngenerates a response by first processing multiple knowledge snippets, followed\nby an ensemble algorithm that decides if the response should be solely derived\nfrom a GPT2-XL model, or regenerated in combination with the top-ranking\nknowledge snippet. Experimental results demonstrate that the proposed pipeline\nsystem outperforms the baseline and generates high-quality responses, achieving\nat least 58.77% improvement on BLEU-4 score.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06066",
		"pdf_url": "http://arxiv.org/pdf/2101.06066.pdf"
	},
	"821": {
		"title": "Efficient Semi-Implicit Variational Inference",
		"creator": [
			"Moens, Vincent",
			"Ren, Hang",
			"Maraval, Alexandre",
			"Tutunov, Rasul",
			"Wang, Jun",
			"Ammar, Haitham"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  In this paper, we propose CI-VI an efficient and scalable solver for\nsemi-implicit variational inference (SIVI). Our method, first, maps SIVI's\nevidence lower bound (ELBO) to a form involving a nonlinear functional nesting\nof expected values and then develops a rigorous optimiser capable of correctly\nhandling bias inherent to nonlinear nested expectations using an\nextrapolation-smoothing mechanism coupled with gradient sketching. Our\ntheoretical results demonstrate convergence to a stationary point of the ELBO\nin general non-convex settings typically arising when using deep network models\nand an order of $O(t^{-\\frac{4}{5}})$ gradient-bias-vanishing rate. We believe\nthese results generalise beyond the specific nesting arising from SIVI to other\nforms. Finally, in a set of experiments, we demonstrate the effectiveness of\nour algorithm in approximating complex posteriors on various data-sets\nincluding those from natural language processing.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06070",
		"pdf_url": "http://arxiv.org/pdf/2101.06070.pdf"
	},
	"822": {
		"title": "Dynamic Normalization",
		"creator": [
			"Liu, Chuan",
			"Gao, Yi",
			"Lv, Jiancheng"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Batch Normalization has become one of the essential components in CNN. It\nallows the network to use a higher learning rate and speed up training. And the\nnetwork doesn't need to be initialized carefully. However, in our work, we find\nthat a simple extension of BN can increase the performance of the network.\nFirst, we extend BN to adaptively generate scale and shift parameters for each\nmini-batch data, called DN-C (Batch-shared and Channel-wise). We use the\nstatistical characteristics of mini-batch data ($E[X],\nStd[X]\\in\\mathbb{R}^{c}$) as the input of SC module. Then we extend BN to\nadaptively generate scale and shift parameters for each channel of each sample,\ncalled DN-B (Batch and Channel-wise). Our experiments show that DN-C model\ncan't train normally, but DN-B model has very good robustness. In\nclassification task, DN-B can improve the accuracy of the MobileNetV2 on\nImageNet-100 more than 2% with only 0.6% additional Mult-Adds. In detection\ntask, DN-B can improve the accuracy of the SSDLite on MS-COCO nearly 4% mAP\nwith the same settings. Compared with BN, DN-B has stable performance when\nusing higher learning rate or smaller batch size.\n",
			"Comment: 9 pages, 5 figures"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06073",
		"pdf_url": "http://arxiv.org/pdf/2101.06073.pdf"
	},
	"823": {
		"title": "Preprocessing Imprecise Points for the Pareto Front",
		"creator": [
			"van der Hoog, Ivor",
			"Kostitsyna, Irina",
			"Löffler, Maarten",
			"Speckmann, Bettina"
		],
		"subject": "Computer Science - Computational Geometry",
		"description": "  In the preprocessing model for uncertain data we are given a set of regions R\nwhich model the uncertainty associated with an unknown set of points P. In this\nmodel there are two phases: a preprocessing phase, in which we have access only\nto R, followed by a reconstruction phase, in which we have access to points in\nP at a certain retrieval cost C per point. We study the following algorithmic\nquestion: how fast can we construct the pareto front of P in the preprocessing\nmodel?\n  We show that if R is a set of pairwise-disjoint axis-aligned rectangles, then\nwe can preprocess R to reconstruct the Pareto front of P efficiently. To refine\nour algorithmic analysis, we introduce a new notion of algorithmic optimality\nwhich relates to the entropy of the uncertainty regions. Our proposed\nuncertainty-region optimality falls on the spectrum between worst-case\noptimality and instance optimality. We prove that instance optimality is\nunobtainable in the preprocessing model, whenever the classic algorithmic\nproblem reduces to sorting. Our results are worst-case optimal in the\npreprocessing phase; in the reconstruction phase, our results are\nuncertainty-region optimal with respect to real RAM instructions, and instance\noptimal with respect to point retrievals.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06079",
		"pdf_url": "http://arxiv.org/pdf/2101.06079.pdf"
	},
	"824": {
		"title": "On the Verification and Validation of AI Navigation Algorithms",
		"creator": [
			"Porres, Ivan",
			"Azimi, Sepinoud",
			"Lafond, Sébastien",
			"Lilius, Johan",
			"Salokannel, Johanna",
			"Salokorpi, Mirva"
		],
		"subject": "Computer Science - Artificial Intelligence",
		"description": "  This paper explores the state of the art on to methods to verify and validate\nnavigation algorithms for autonomous surface ships. We perform a systematic\nmapping study to find research works published in the last 10 years proposing\nnew algorithms for autonomous navigation and collision avoidance and we have\nextracted what verification and validation approaches have been applied on\nthese algorithms. We observe that most research works use simulations to\nvalidate their algorithms. However, these simulations often involve just a few\nscenarios designed manually. This raises the question if the algorithms have\nbeen validated properly. To remedy this, we propose the use of a systematic\nscenario-based testing approach to validate navigation algorithms extensively.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06091",
		"pdf_url": "http://arxiv.org/pdf/2101.06091.pdf"
	},
	"825": {
		"title": "Black-box Adversarial Attacks in Autonomous Vehicle Technology",
		"creator": [
			"Kumar, K Naveen",
			"Vishnu, C",
			"Mitra, Reshmi",
			"Mohan, C Krishna"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Despite the high quality performance of the deep neural network in real-world\napplications, they are susceptible to minor perturbations of adversarial\nattacks. This is mostly undetectable to human vision. The impact of such\nattacks has become extremely detrimental in autonomous vehicles with real-time\n\"safety\" concerns. The black-box adversarial attacks cause drastic\nmisclassification in critical scene elements such as road signs and traffic\nlights leading the autonomous vehicle to crash into other vehicles or\npedestrians. In this paper, we propose a novel query-based attack method called\nModified Simple black-box attack (M-SimBA) to overcome the use of a white-box\nsource in transfer based attack method. Also, the issue of late convergence in\na Simple black-box attack (SimBA) is addressed by minimizing the loss of the\nmost confused class which is the incorrect class predicted by the model with\nthe highest probability, instead of trying to maximize the loss of the correct\nclass. We evaluate the performance of the proposed approach to the German\nTraffic Sign Recognition Benchmark (GTSRB) dataset. We show that the proposed\nmodel outperforms the existing models like Transfer-based projected gradient\ndescent (T-PGD), SimBA in terms of convergence time, flattening the\ndistribution of confused class probability, and producing adversarial samples\nwith least confidence on the true class.\n",
			"Comment: 7 pages, 10 figures, published in 49th Annual IEEE AIPR 2020: Trusted\n  Computing, Privacy, and Securing Multimedia Washington, D.C. October 13-15,\n  2020"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06092",
		"pdf_url": "http://arxiv.org/pdf/2101.06092.pdf"
	},
	"826": {
		"title": "Motorcycle System for Optimum Road Safety with Anti-theft Capability",
		"creator": "Godoy Jr, Carlo H",
		"subject": [
			"Computer Science - Computers and Society",
			"94A04",
			"B.1"
		],
		"description": [
			"  Due to road traffic accidents, 6941 Filipinos died in 2010, and thousands\nmore were wounded or disabled. Head and neck injuries are the main cause of\ndeath, severe injury, and motorcycle users disabilities. Motorcycle users make\nup a large proportion of those on the road who were killed. The main purpose of\nthe study is to develop an MCU Based Motorcycle System for Optimum Road Safety\nwith Anti-theft Capability that will help motorcycle riders to be safe while\ntravelling in national roads. The researchers will be using the prototyping\nmethodology where in a prototype is built according to the initial requirements\ngathered from the motorists themselves. The expected result of the proposed\nmethodology is the system will be utilizing the different function of each\nmodules to ensure that the riders will be able to detect and avoid possible\ndanger while on the road. As a result of different literature in relation to\neach module, the system is expected to provide a new leap to ensure the safety\nof all riders here in the Philippines. Future studies will ensure the\ndevelopment of the system, provide testing and improve the functionality of the\nsystem depending on the test result. Due to the high increase in the number of\ncars and motorcycle travelling on national road, the percentage of accidents\nalso is getting higher. In line with that, the proposed system is expected to\nlessen the percentage of accident by avoiding the possible cause of it.\n",
			"Comment: 10 pages. International Journal of Innovative Science and Research\n  Technology 2020"
		],
		"date": "2021-01-13",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06096",
			"doi:10.38124/ijisrt20jun314"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06096.pdf"
	},
	"827": {
		"title": "Impact of Autonomous Vehicle Technology on Long Distance Travel Behavior",
		"creator": [
			"Maleki, Maryam",
			"Chan, Yupo",
			"Arani, Mohammad"
		],
		"subject": "Computer Science - Computers and Society",
		"description": [
			"  Although rapid progress in-vehicle automated technology has sped up the\npossibility of using fully automated technology for public use, little research\nhas been done on the possible influences of autonomous vehicles (AVs)\ntechnology on long-distance travel. This technology has the potential to have a\nsignificant effect on intercity trips. This study analyzed a travel survey to\nanticipate the impact of this technology on long-distance trips. We have\ndivided trips into two different categories including trips for pleasure and\ntrips for business. Different hypotheses based on the authors' knowledge and\nassisted by existing literature have been defined for each type of trip. By\nusing the Pearson method these hypotheses have been tested and the positive or\nnegative responses from respondents have been evaluated. The findings show that\nusing AVs for pleasure trips can increase the number of travelers and stimulate\npeople to choose longer distances for their trips. In addition, people enjoy\nmore and will be interested to travel more frequently. For business trips, AV\ntechnology can reduce travel costs and job-related stress. Unlike pleasure\ntrips for which people are not interested in traveling at night, business\ntravelers prefer to travel at night.\n",
			"Comment: This paper has been accepted by the Institute of Industrial and\n  Systems Engineers (IISE) annual conference and expo 2020"
		],
		"date": "2021-01-12",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06097",
		"pdf_url": "http://arxiv.org/pdf/2101.06097.pdf"
	},
	"828": {
		"title": "A New Artificial Neuron Proposal with Trainable Simultaneous Local and\n  Global Activation Function",
		"creator": [
			"Ferreira, Tiago A. E.",
			"Mattheakis, Marios",
			"Protopapas, Pavlos"
		],
		"subject": [
			"Computer Science - Neural and Evolutionary Computing",
			"Computer Science - Machine Learning"
		],
		"description": "  The activation function plays a fundamental role in the artificial neural\nnetwork learning process. However, there is no obvious choice or procedure to\ndetermine the best activation function, which depends on the problem. This\nstudy proposes a new artificial neuron, named global-local neuron, with a\ntrainable activation function composed of two components, a global and a local.\nThe global component term used here is relative to a mathematical function to\ndescribe a general feature present in all problem domain. The local component\nis a function that can represent a localized behavior, like a transient or a\nperturbation. This new neuron can define the importance of each activation\nfunction component in the learning phase. Depending on the problem, it results\nin a purely global, or purely local, or a mixed global and local activation\nfunction after the training phase. Here, the trigonometric sine function was\nemployed for the global component and the hyperbolic tangent for the local\ncomponent. The proposed neuron was tested for problems where the target was a\npurely global function, or purely local function, or a composition of two\nglobal and local functions. Two classes of test problems were investigated,\nregression problems and differential equations solving. The experimental tests\ndemonstrated the Global-Local Neuron network's superior performance, compared\nwith simple neural networks with sine or hyperbolic tangent activation\nfunction, and with a hybrid network that combines these two simple neural\nnetworks.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06100",
		"pdf_url": "http://arxiv.org/pdf/2101.06100.pdf"
	},
	"829": {
		"title": "GSM-GPRS Based Smart Street Light",
		"creator": [
			"Kabir, Imran",
			"Ahamad, Shihab Uddin",
			"Uddin, Mohammad Naim",
			"Hossain, Shah Mohazzem",
			"Farjana, Faija",
			"Datta, Partha Protim",
			"Riad, Md. Raduanul Alam",
			"Hossam-E-Haider, Mohammed"
		],
		"subject": "Computer Science - Computers and Society",
		"description": [
			"  Street lighting system has always been the traditional manual system of\nilluminating the streets in Bangladesh, where a dedicated person is posted only\nto control the street lights of a zone, who roams around the zonal area to\nswitch on and switch off the lights two times a day, which brings about the\nexhibition of bright lights in street even after sunrise and in some cases\nmaybe the whole day. This results in insertion to the budget. In addition to\nthis, faulty lights may not come to the heed of the concerned authority for a\nlong time which leads to the technical downside. This paper demonstrates a\nprocess of controlling the street lights in country like Bangladesh employing\nSIM900 GSM-GPRS Shield which comes up with the provision of manual control,\nsemi-automated control as well as full-automated control.\n",
			"Comment: 5 pages, 10 figures, 2nd International Conference on Robotics,\n  electrical and Signal Processing Techniques (ICREST)"
		],
		"date": "2021-01-12",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06102",
		"pdf_url": "http://arxiv.org/pdf/2101.06102.pdf"
	},
	"830": {
		"title": "Is the Chen-Sbert Divergence a Metric?",
		"creator": [
			"Chen, Min",
			"Sbert, Mateu"
		],
		"subject": "Computer Science - Information Theory",
		"description": "  Recently, Chen and Sbert proposed a general divergence measure. This report\npresents some interim findings about the question whether the divergence\nmeasure is a metric or not. It has been postulated that (i) the measure might\nbe a metric when (0 < k <= 1), and (ii) the k-th root of the measure might be a\nmetric when (k > 1). The report shows that for a 2-letter alphabet, postulation\n(i) can be proved. The possible pathway for obtaining a proof for (i) in\nn-letter cases is also discussed. The authors hope that the report may\nstimulate more scholarly effort to study the mathematical properties of this\ndivergence measure.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06103",
		"pdf_url": "http://arxiv.org/pdf/2101.06103.pdf"
	},
	"831": {
		"title": "Modeling and Analysis of Three Properties of Mobile Interactive Systems\n  Based on Variable Petri Nets",
		"creator": [
			"Yang, Ru",
			"Ding, Zhijun",
			"Jiang, Changjun",
			"Zhou, MengChu"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Computer Science - Formal Languages and Automata Theory"
		],
		"description": [
			"  Due to the mobility and frequent disconnections, the correctness of mobile\ninteraction systems, such as mobile robot systems and mobile payment systems,\nare often difficult to analyze. This paper introduces three critical properties\nof systems, called system connectivity, interaction soundness and data\nvalidity, and presents a related modeling and analysis method, based on a kind\nof Petri nets called VPN. For a given system, a model including component nets\nand interaction structure nets is constructed by using VPNs. The component net\ndescribes the internal process of each component, while the interaction\nstructure net reflects the dynamic interaction between components. Based on\nthis model, three properties are defined and analyzed. The case study of a\npractical mobile payment system shows the effectiveness of the proposed method.\n",
			"Comment: 12 pages"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06104",
		"pdf_url": "http://arxiv.org/pdf/2101.06104.pdf"
	},
	"832": {
		"title": "Big Data Generated by Connected and Automated Vehicles for Safety\n  Monitoring, Assessment and Improvement, Final Report (Year 3)",
		"creator": [
			"Khattak, Asad J.",
			"Mahdinia, Iman",
			"Mohammadi, Sevin",
			"Mohammadnazar, Amin",
			"Wali, Behram"
		],
		"subject": "Computer Science - Computers and Society",
		"description": [
			"  This report focuses on safety aspects of connected and automated vehicles\n(CAVs). The fundamental question to be answered is how can CAVs improve road\nusers' safety? Using advanced data mining and thematic text analytics tools,\nthe goal is to systematically synthesize studies related to Big Data for safety\nmonitoring and improvement. Within this domain, the report systematically\ncompares Big Data initiatives related to transportation initiatives nationally\nand internationally and provides insights regarding the evolution of Big Data\nscience applications related to CAVs and new challenges. The objectives\naddressed are: 1-Creating a database of Big Data efforts by acquiring reports,\nwhite papers, and journal publications; 2-Applying text analytics tools to\nextract key concepts, and spot patterns and trends in Big Data initiatives;\n3-Understanding the evolution of CAV Big Data in the context of safety by\nquantifying granular taxonomies and modeling entity relations among contents in\nCAV Big Data research initiatives, and 4-Developing a foundation for exploring\nnew approaches to tracking and analyzing CAV Big Data and related innovations.\nThe study synthesizes and derives high-quality information from innovative\nresearch activities undertaken by various research entities through Big Data\ninitiatives. The results can provide a conceptual foundation for developing new\napproaches for guiding and tracking the safety implications of Big Data and\nrelated innovations.\n",
			"Comment: 47 pages, 21 figures,\n  http://ctr.utk.edu/STC-wordpress-docs/MRI-finals/Khattak-MRI4-Year-3-Final.pdf"
		],
		"date": "2021-01-09",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06106",
			"doi:10.13140/RG.2.2.22542.18246"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06106.pdf"
	},
	"833": {
		"title": "Bridging the Gap: the case for an Incompletely Theorized Agreement on AI\n  policy",
		"creator": [
			"Stix, Charlotte",
			"Maas, Matthijs M."
		],
		"subject": "Computer Science - Computers and Society",
		"description": "  Recent progress in artificial intelligence (AI) raises a wide array of\nethical and societal concerns. Accordingly, an appropriate policy approach is\nneeded today. While there has been a wave of scholarship in this field, the\nresearch community at times appears divided amongst those who emphasize\nnear-term concerns, and those focusing on long-term concerns and corresponding\npolicy measures. In this paper, we seek to map and critically examine this\nalleged gulf, with a view to understanding the practical space for\ninter-community collaboration on AI policy. This culminates in a proposal to\nmake use of the legal notion of an incompletely theorized agreement. We propose\nthat on certain issue areas, scholars working with near-term and long-term\nperspectives can converge and cooperate on selected mutually beneficial AI\npolicy projects all the while maintaining divergent perspectives.\n",
		"date": "2021-01-07",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06110",
			"doi:10.1007/s43681-020-00037-wAIET-D-20-00032"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06110.pdf"
	},
	"834": {
		"title": "Knowledge Graphs and Natural-Language Processing",
		"creator": "Opdahl, Andreas L",
		"subject": [
			"Computer Science - Computers and Society",
			"Computer Science - Computation and Language"
		],
		"description": [
			"  Emergency-relevant data comes in many varieties. It can be high volume and\nhigh velocity, and reaction times are critical, calling for efficient and\npowerful techniques for data analysis and management. Knowledge graphs\nrepresent data in a rich, flexible, and uniform way that is well matched with\nthe needs of emergency management. They build on existing standards, resources,\ntechniques, and tools for semantic data and computing. This chapter explains\nthe most important semantic technologies and how they support knowledge graphs.\nWe proceed to discuss their benefits and challenges and give examples of\nrelevant semantic data sources and vocabularies. Natural-language texts -- in\nparticular those collected from social media such as Twitter -- is a type of\ndata source that poses particular analysis challenges. We therefore include an\noverview of techniques for processing natural-language texts.\n",
			"Comment: In Big Data in Emergency Management: Exploitation Techniques for\n  Social and Mobile Data (pp. 75-91). Springer, Cham"
		],
		"date": "2020-12-15",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06111",
			"doi:10.1007/978-3-030-48099-8"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06111.pdf"
	},
	"835": {
		"title": "Approximations with deep neural networks in Sobolev time-space",
		"creator": [
			"Abdeljawad, Ahmed",
			"Grohs, Philipp"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Mathematics - Functional Analysis"
		],
		"description": [
			"  Solutions of evolution equation generally lies in certain Bochner-Sobolev\nspaces, in which the solution may has regularity and integrability properties\nfor the time variable that can be different for the space variables. Therefore,\nin this paper, we develop a framework shows that deep neural networks can\napproximate Sobolev-regular functions with respect to Bochner-Sobolev spaces.\nIn our work we use the so-called Rectified Cubic Unit (ReCU) as an activation\nfunction in our networks, which allows us to deduce approximation results of\nthe neural networks while avoiding issues caused by the non regularity of the\nmost commonly used Rectivied Linear Unit (ReLU) activation function.\n",
			"Comment: 34 pages. This is the first version of the paper. It is expected that\n  some changes will be performed for the next version. arXiv admin note: text\n  overlap with arXiv:1902.07896"
		],
		"date": "2020-12-23",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06115",
		"pdf_url": "http://arxiv.org/pdf/2101.06115.pdf"
	},
	"836": {
		"title": "Effect of Gameplay Uncertainty, Display Type, and Age on Virtual Reality\n  Exergames",
		"creator": [
			"Xu, Wenge",
			"Liang, Hai-Ning",
			"Yu, Kangyou",
			"Baghaei, Nilufar"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": [
			"  Uncertainty is widely acknowledged as an engaging gameplay element but rarely\nused in exergames. In this research, we explore the role of uncertainty in\nexergames and introduce three uncertain elements (false-attacks, misses, and\ncritical hits) to an exergame. We conducted a study under two conditions\n(uncertain and certain), with two display types (virtual reality and large\ndisplay) and across young and middle-aged adults to measure their effect on\ngame performance, experience, and exertion. Results show that (1) our designed\nuncertain elements are instrumental in increasing exertion levels; (2) when\nplaying a motion-based first-person perspective exergame, virtual reality can\nimprove performance, while maintaining the same motion sickness level as a\nlarge display; and (3) exergames for middle-aged adults should be designed with\nage-related declines in mind, similar to designing for elderly adults. We also\nframed two design guidelines for exergames that have similar features to the\ngame used in this research.\n",
			"Comment: Accepted to ACM 2021 CHI Conference on Human Factors in Computing\n  Systems (CHI 2021)"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06120",
			"CHI 2021",
			"doi:10.1145/3411764.3445801"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06120.pdf"
	},
	"837": {
		"title": "Identifying Authorship Style in Malicious Binaries: Techniques,\n  Challenges & Datasets",
		"creator": [
			"Gray, Jason",
			"Sgandurra, Daniele",
			"Cavallaro, Lorenzo"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": [
			"  Attributing a piece of malware to its creator typically requires threat\nintelligence. Binary attribution increases the level of difficulty as it mostly\nrelies upon the ability to disassemble binaries to identify authorship style.\nOur survey explores malicious author style and the adversarial techniques used\nby them to remain anonymous. We examine the adversarial impact on the\nstate-of-the-art methods. We identify key findings and explore the open\nresearch challenges. To mitigate the lack of ground truth datasets in this\ndomain, we publish alongside this survey the largest and most diverse\nmeta-information dataset of 15,660 malware labeled to 164 threat actor groups.\n",
			"Comment: 31 pages, 3 figures, 10 tables; Modified table headings to make them\n  readable"
		],
		"date": [
			"2021-01-15",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06124",
		"pdf_url": "http://arxiv.org/pdf/2101.06124.pdf"
	},
	"838": {
		"title": "The Impact of Post-editing and Machine Translation on Creativity and\n  Reading Experience",
		"creator": [
			"Arenas, Ana Guerberof",
			"Toral, Antonio"
		],
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  This article presents the results of a study involving the translation of a\nfictional story from English into Catalan in three modalities:\nmachine-translated (MT), post-edited (MTPE) and translated without aid (HT).\nEach translation was analysed to evaluate its creativity. Subsequently, a\ncohort of 88 Catalan participants read the story in a randomly assigned\nmodality and completed a survey. The results show that HT presented a higher\ncreativity score if compared to MTPE and MT. HT also ranked higher in narrative\nengagement, and translation reception, while MTPE ranked marginally higher in\nenjoyment. HT and MTPE show no statistically significant differences in any\ncategory, whereas MT does in all variables tested. We conclude that creativity\nis highest when professional translators intervene in the process, especially\nwhen working without any aid. We hypothesize that creativity in translation\ncould be the factor that enhances reading engagement and the reception of\ntranslated literary texts.\n",
			"Comment: 28 pages, 10 tables, 4 figures. Translation Spaces (2020)"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06125",
			"doi:10.1075/ts.20035.gue"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06125.pdf"
	},
	"839": {
		"title": "EAGER: Embedding-Assisted Entity Resolution for Knowledge Graphs",
		"creator": [
			"Obraczka, Daniel",
			"Schuchart, Jonathan",
			"Rahm, Erhard"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Databases",
			"I.2.4",
			"I.2.6"
		],
		"description": [
			"  Entity Resolution (ER) is a constitutional part for integrating different\nknowledge graphs in order to identify entities referring to the same real-world\nobject. A promising approach is the use of graph embeddings for ER in order to\ndetermine the similarity of entities based on the similarity of their graph\nneighborhood. The similarity computations for such embeddings translates to\ncalculating the distance between them in the embedding space which is\ncomparatively simple. However, previous work has shown that the use of graph\nembeddings alone is not sufficient to achieve high ER quality. We therefore\npropose a more comprehensive ER approach for knowledge graphs called EAGER\n(Embedding-Assisted Knowledge Graph Entity Resolution) to flexibly utilize both\nthe similarity of graph embeddings and attribute values within a supervised\nmachine learning approach. We evaluate our approach on 23 benchmark datasets\nwith differently sized and structured knowledge graphs and use hypothesis tests\nto ensure statistical significance of our results. Furthermore we compare our\napproach with state-of-the-art ER solutions, where our approach yields\ncompetitive results for table-oriented ER problems and shallow knowledge graphs\nbut much better results for deeper knowledge graphs.\n",
			"Comment: 10 pages, 7 figures"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06126",
		"pdf_url": "http://arxiv.org/pdf/2101.06126.pdf"
	},
	"840": {
		"title": "Let's Share VMs: Optimal Placement and Pricing across Base Stations in\n  MEC Systems",
		"creator": [
			"Siew, Marie",
			"Guo, Kun",
			"Cai, Desmond",
			"Li, Lingxiang",
			"Quek, Tony Q. S."
		],
		"subject": [
			"Computer Science - Information Theory",
			"Computer Science - Networking and Internet Architecture",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": [
			"  In mobile edge computing (MEC) systems, users offload computationally\nintensive tasks to edge servers at base stations. However, with unequal demand\nacross the network, there might be excess demand at some locations and\nunderutilized resources at other locations. To address such load-unbalanced\nproblem in MEC systems, in this paper we propose virtual machines (VMs) sharing\nacross base stations. Specifically, we consider the joint VM placement and\npricing problem across base stations to match demand and supply and maximize\nrevenue at the network level. To make this problem tractable, we decompose it\ninto master and slave problems. For the placement master problem, we propose a\nMarkov approximation algorithm MAP on the design of a continuous time Markov\nchain. As for the pricing slave problem, we propose OPA - an optimal VM pricing\nauction, where all users are truthful. Furthermore, given users' potential\nuntruthful behaviors, we propose an incentive compatible auction iCAT along\nwith a partitioning mechanism PUFF, for which we prove incentive compatibility\nand revenue guarantees. Finally, we combine MAP and OPA or PUFF to solve the\noriginal problem, and analyze the optimality gap. Simulation results show that\ncollaborative base stations increases revenue by up to 50%.\n",
			"Comment: Accepted at IEEE INFOCOM 2021 - IEEE Conference on Computer\n  Communications"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06129",
		"pdf_url": "http://arxiv.org/pdf/2101.06129.pdf"
	},
	"841": {
		"title": "Teaming up with information agents",
		"creator": [
			"van Diggelen, Jurriaan",
			"Jorritsma, Wiard",
			"van der Vecht, Bob"
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Despite the intricacies involved in designing a computer as a teampartner, we\ncan observe patterns in team behavior which allow us to describe at a general\nlevel how AI systems are to collaborate with humans. Whereas most work on\nhuman-machine teaming has focused on physical agents (e.g. robotic systems),\nour aim is to study how humans can collaborate with information agents. We\npropose some appropriate team design patterns, and test them using our\nCollaborative Intelligence Analysis (CIA) tool.\n",
			"Comment: 4 pages"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06133",
		"pdf_url": "http://arxiv.org/pdf/2101.06133.pdf"
	},
	"842": {
		"title": "Quantitative System-Level Security Verification of the IoV\n  Infrastructure",
		"creator": [
			"Lauinger, Jan",
			"Aslam, Mudassar",
			"Hamad, Mohammad",
			"Raza, Shahid",
			"Steinhorst, Sebastian"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": "  The Internet of Vehicles (IoV) equips vehicles with connectivity to the\nInternet and the Internet of Things (IoT) to support modern applications such\nas autonomous driving. However, the consolidation of complex computing domains\nof vehicles, the Internet, and the IoT limits the applicability of tailored\nsecurity solutions. In this paper, we propose a new methodology to\nquantitatively verify the security of single or system-level assets of the IoV\ninfrastructure. In detail, our methodology decomposes assets of the IoV\ninfrastructure with the help of reference sub-architectures and the 4+1 view\nmodel analysis to map identified assets into data, software, networking, and\nhardware categories. This analysis includes a custom threat modeling concept to\nperform parameterization of Common Vulnerability Scoring System (CVSS) scores\nper view model domain. As a result, our methodology is able to allocate assets\nfrom attack paths to view model domains. This equips assets of attack paths\nwith our IoV-driven CVSS scores. Our CVSS scores assess the attack likelihood\nwhich we use for Markov Chain transition probabilities. This way, we\nquantitatively verify system-level security among a set of IoV assets. Our\nresults show that our methodology applies to arbitrary IoV attack paths. Based\non our parameterization of CVSS scores and our selection of use cases, remote\nattacks are less likely to compromise location data compared to attacks from\nclose proximity for authorized and unauthorized attackers respectively.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06137",
		"pdf_url": "http://arxiv.org/pdf/2101.06137.pdf"
	},
	"843": {
		"title": "TrustSECO: An Interview Survey into Software Trust",
		"creator": [
			"Jansen, Floris",
			"Jansen, Slinger",
			"Hou, Fang"
		],
		"subject": "Computer Science - Software Engineering",
		"description": "  The software ecosystem is a trust-rich part of the world. Collaboratively,\nsoftware engineers trust major hubs in the ecosystem, such as package managers,\nrepository services, and programming language ecosystems. This trust, however,\nis often broken by vulnerabilities, ransomware, and abuse from malignant\nactors.\n  But what is trust? In this paper we explore, through twelve in-depth\ninterviews with software engineers, how they perceive trust in their daily\nwork. From the interviews we conclude three things. First, software engineers\nmake a distinction between an adoption factor and a trust factor when selecting\na package. Secondly, while in literature mostly technical factors are\nconsidered as the main trust factors, the software engineers in this study\nconclude that organizational factors are more important. Finally, we find that\ndifferent kinds of software engineers require different views on trust, and\nthat it is impossible to create one unified perception of trust.\n  Keywords: software ecosystem trust, empirical software engineering,\nTrustSECO, external software adoption, cross-sectional exploratory interview\nanalysis, trust perception.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06138",
		"pdf_url": "http://arxiv.org/pdf/2101.06138.pdf"
	},
	"844": {
		"title": "Ask Me or Tell Me? Enhancing the Effectiveness of Crowdsourced Design\n  Feedback",
		"creator": [
			"Lekschas, Fritz",
			"Ampanavos, Spyridon",
			"Siangliulue, Pao",
			"Pfister, Hanspeter",
			"Gajos, Krzysztof Z."
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": "  Crowdsourced design feedback systems are emerging resources for getting large\namounts of feedback in a short period of time. Traditionally, the feedback\ncomes in the form of a declarative statement, which often contains positive or\nnegative sentiment. Prior research has shown that overly negative or positive\nsentiment can strongly influence the perceived usefulness and acceptance of\nfeedback and, subsequently, lead to ineffective design revisions. To enhance\nthe effectiveness of crowdsourced design feedback, we investigate a new\napproach for mitigating the effects of negative or positive feedback by\ncombining open-ended and thought-provoking questions with declarative feedback\nstatements. We conducted two user studies to assess the effects of\nquestion-based feedback on the sentiment and quality of design revisions in the\ncontext of graphic design. We found that crowdsourced question-based feedback\ncontains more neutral sentiment than statement-based feedback. Moreover, we\nprovide evidence that presenting feedback as questions followed by statements\nleads to better design revisions than question- or statement-based feedback\nalone.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06143",
			"doi:10.1145/3411764.3445507"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06143.pdf"
	},
	"845": {
		"title": "Needmining: Designing Digital Support to Elicit Needs from Social Media",
		"creator": [
			"Kühl, Niklas",
			"Satzger, Gerhard"
		],
		"subject": [
			"Computer Science - Computers and Society",
			"Computer Science - Machine Learning"
		],
		"description": "  Today's businesses face a high pressure to innovate in order to succeed in\nhighly competitive markets. Successful innovations, though, typically require\nthe identification and analysis of customer needs. While traditional,\nestablished need elicitation methods are time-proven and have demonstrated\ntheir capabilities to deliver valuable insights, they lack automation and\nscalability and, thus, are expensive and time-consuming. In this article, we\npropose an approach to automatically identify and quantify customer needs by\nutilizing a novel data source: Users voluntarily and publicly expose\ninformation about themselves via social media, as for instance Facebook or\nTwitter. These posts may contain valuable information about the needs, wants,\nand demands of their authors. We apply a Design Science Research (DSR)\nmethodology to add design knowledge and artifacts for the digitalization of\ninnovation processes, in particular to provide digital support for the\nelicitation of customer needs. We want to investigate whether automated,\nspeedy, and scalable need elicitation from social media is feasible. We\nconcentrate on Twitter as a data source and on e-mobility as an application\ndomain. In a first design cycle we conceive, implement and evaluate a method to\ndemonstrate the feasibility of identifying those social media posts that\nactually express customer needs. In a second cycle, we build on this artifact\nto additionally quantify the need information elicited, and prove its\nfeasibility. Third, we integrate both developed methods into an end-user\nsoftware artifact and test usability in an industrial use case. Thus, we add\nnew methods for need elicitation to the body of knowledge, and introduce\nconcrete tooling for innovation management in practice.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06146",
		"pdf_url": "http://arxiv.org/pdf/2101.06146.pdf"
	},
	"846": {
		"title": "Estimation of the Frequency of Occurrence of Italian Phonemes in Text",
		"creator": [
			"Arango, Javi",
			"DeCaprio, Alec",
			"Baik, Sunwoo",
			"De Nardis, Luca",
			"Shattuck-Hufnagel, Stefanie",
			"Di Benedetto, Maria Gabriella"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Audio and Speech Processing",
			"Computer Science - Sound"
		],
		"description": [
			"  The purpose of this project was to derive a reliable estimate of the\nfrequency of occurrence of the 30 phonemes - plus consonant geminated\ncounterparts - of the Italian language, based on four selected written texts.\nSince no comparable dataset was found in previous literature, the present\nanalysis may serve as a reference in future studies. Four textual sources were\nconsidered: Come si fa una tesi di laurea: le materie umanistiche by Umberto\nEco, I promessi sposi by Alessandro Manzoni, a recent article in Corriere della\nSera (a popular daily Italian newspaper), and In altre parole by Jhumpa Lahiri.\nThe sources were chosen to represent varied genres, subject matter, time\nperiods, and writing styles. Results of the analysis, which also included an\nanalysis of variance, showed that, for all four sources, the frequencies of\noccurrence reached relatively stable values after about 6,000 phonemes (approx.\n1,250 words), varying by <0.025%. Estimated frequencies are provided for each\nsingle source and as an average across sources.\n",
			"Comment: submitted to Speech Communication"
		],
		"date": [
			"2021-01-14",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06147",
		"pdf_url": "http://arxiv.org/pdf/2101.06147.pdf"
	},
	"847": {
		"title": "SRACARE: Secure Remote Attestation with Code Authentication and\n  Resilience Engine",
		"creator": [
			"Dave, Avani",
			"Banerjee, Nilanjan",
			"Patel, Chintan"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": "  Recent technological advancements have enabled proliferated use of small\nembedded and IoT devices for collecting, processing, and transferring the\nsecurity-critical information and user data. This exponential use has acted as\na catalyst in the recent growth of sophisticated attacks such as the replay,\nman-in-the-middle, and malicious code modification to slink, leak, tweak or\nexploit the security-critical information in malevolent activities. Therefore,\nsecure communication and software state assurance (at run-time and boot-time)\nof the device has emerged as open security problems. Furthermore, these devices\nneed to have an appropriate recovery mechanism to bring them back to the\nknown-good operational state. Previous researchers have demonstrated\nindependent methods for attack detection and safeguard. However, the majority\nof them lack in providing onboard system recovery and secure communication\ntechniques. To bridge this gap, this manuscript proposes SRACARE- a framework\nthat utilizes the custom lightweight, secure communication protocol that\nperforms remote/local attestation, and secure boot with an onboard resilience\nrecovery mechanism to protect the devices from the above-mentioned attacks. The\nprototype employs an efficient lightweight, low-power 32-bit RISC-V processor,\nsecure communication protocol, code authentication, and resilience engine\nrunning on the Artix 7 Field Programmable Gate Array(FPGA) board. This work\npresents the performance evaluation and state-of-the-art comparison results,\nwhich shows promising resilience to attacks and demonstrate the novel\nprotection mechanism with onboard recovery. The framework achieves these with\nonly 8 % performance overhead and a very small increase in hardware-software\nfootprint.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06148",
		"pdf_url": "http://arxiv.org/pdf/2101.06148.pdf"
	},
	"848": {
		"title": "Annotation of epidemiological information in animal disease-related news\n  articles: guidelines",
		"creator": [
			"Valentin, Sarah",
			"Arsevska, Elena",
			"Vilain, Aline",
			"De Waele, Valérie",
			"Lancelot, Renaud",
			"Roche, Mathieu"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computation and Language"
		],
		"description": [
			"  This paper describes a method for annotation of epidemiological information\nin animal disease-related news articles. The annotation guidelines are generic\nand aim to embrace all animal or zoonotic infectious diseases, regardless of\nthe pathogen involved or its way of transmission (e.g. vector-borne, airborne,\nby contact). The framework relies on the successive annotation of all the\nsentences from a news article. The annotator evaluates the sentences in a\nspecific epidemiological context, corresponding to the publication of the news\narticle.\n",
			"Comment: 8 pages"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06150",
		"pdf_url": "http://arxiv.org/pdf/2101.06150.pdf"
	},
	"849": {
		"title": "Learning Invariant Representation for Continual Learning",
		"creator": [
			"Sokar, Ghada",
			"Mocanu, Decebal Constantin",
			"Pechenizkiy, Mykola"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  Continual learning aims to provide intelligent agents that are capable of\nlearning continually a sequence of tasks, building on previously learned\nknowledge. A key challenge in this learning paradigm is catastrophically\nforgetting previously learned tasks when the agent faces a new one. Current\nrehearsal-based methods show their success in mitigating the catastrophic\nforgetting problem by replaying samples from previous tasks during learning a\nnew one. However, these methods are infeasible when the data of previous tasks\nis not accessible. In this work, we propose a new pseudo-rehearsal-based\nmethod, named learning Invariant Representation for Continual Learning (IRCL),\nin which class-invariant representation is disentangled from a conditional\ngenerative model and jointly used with class-specific representation to learn\nthe sequential tasks. Disentangling the shared invariant representation helps\nto learn continually a sequence of tasks, while being more robust to forgetting\nand having better knowledge transfer. We focus on class incremental learning\nwhere there is no knowledge about task identity during inference. We\nempirically evaluate our proposed method on two well-known benchmarks for\ncontinual learning: split MNIST and split Fashion MNIST. The experimental\nresults show that our proposed method outperforms regularization-based methods\nby a big margin and is better than the state-of-the-art pseudo-rehearsal-based\nmethod. Finally, we analyze the role of the shared invariant representation in\nmitigating the forgetting problem especially when the number of replayed\nsamples for each previous task is small.\n",
			"Comment: Accepted at the AAAI Meta-Learning for Computer Vision Workshop\n  (2021)"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06162",
		"pdf_url": "http://arxiv.org/pdf/2101.06162.pdf"
	},
	"850": {
		"title": "Probabilistic Inference for Learning from Untrusted Sources",
		"creator": [
			"Nguyen, Duc Thien",
			"Lim, Shiau Hoong",
			"Wynter, Laura",
			"Cai, Desmond"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Distributed, Parallel, and Cluster Computing"
		],
		"description": "  Federated learning brings potential benefits of faster learning, better\nsolutions, and a greater propensity to transfer when heterogeneous data from\ndifferent parties increases diversity. However, because federated learning\ntasks tend to be large and complex, and training times non-negligible, it is\nimportant for the aggregation algorithm to be robust to non-IID data and\ncorrupted parties. This robustness relies on the ability to identify, and\nappropriately weight, incompatible parties. Recent work assumes that a\n\\textit{reference dataset} is available through which to perform the\nidentification. We consider settings where no such reference dataset is\navailable; rather, the quality and suitability of the parties needs to be\n\\textit{inferred}. We do so by bringing ideas from crowdsourced predictions and\ncollaborative filtering, where one must infer an unknown ground truth given\nproposals from participants with unknown quality. We propose novel federated\nlearning aggregation algorithms based on Bayesian inference that adapt to the\nquality of the parties. Empirically, we show that the algorithms outperform\nstandard and robust aggregation in federated learning on both synthetic and\nreal data.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06171",
		"pdf_url": "http://arxiv.org/pdf/2101.06171.pdf"
	},
	"851": {
		"title": "Empirical Evaluation of Supervision Signals for Style Transfer Models",
		"creator": [
			"Puzikov, Yevgeniy",
			"Stanley, Simoes",
			"Gurevych, Iryna",
			"Schweizer, Immanuel"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning",
			"68T50",
			"I.2.7"
		],
		"description": [
			"  Text style transfer has gained increasing attention from the research\ncommunity over the recent years. However, the proposed approaches vary in many\nways, which makes it hard to assess the individual contribution of the model\ncomponents. In style transfer, the most important component is the optimization\ntechnique used to guide the learning in the absence of parallel training data.\nIn this work we empirically compare the dominant optimization paradigms which\nprovide supervision signals during training: backtranslation, adversarial\ntraining and reinforcement learning. We find that backtranslation has\nmodel-specific limitations, which inhibits training style transfer models.\nReinforcement learning shows the best performance gains, while adversarial\ntraining, despite its popularity, does not offer an advantage over the latter\nalternative. In this work we also experiment with Minimum Risk Training, a\npopular technique in the machine translation community, which, to our\nknowledge, has not been empirically evaluated in the task of style transfer. We\nfill this research gap and empirically show its efficacy.\n",
			"Comment: 13 pages, 6 figures"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06172",
		"pdf_url": "http://arxiv.org/pdf/2101.06172.pdf"
	},
	"852": {
		"title": "PaddleSeg: A High-Efficient Development Toolkit for Image Segmentation",
		"creator": [
			"Liu, Yi",
			"Chu, Lutao",
			"Chen, Guowei",
			"Wu, Zewu",
			"Chen, Zeyu",
			"Lai, Baohua",
			"Hao, Yuying"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Image Segmentation plays an essential role in computer vision and image\nprocessing with various applications from medical diagnosis to autonomous car\ndriving. A lot of segmentation algorithms have been proposed for addressing\nspecific problems. In recent years, the success of deep learning techniques has\ntremendously influenced a wide range of computer vision areas, and the modern\napproaches of image segmentation based on deep learning are becoming prevalent.\nIn this article, we introduce a high-efficient development toolkit for image\nsegmentation, named PaddleSeg. The toolkit aims to help both developers and\nresearchers in the whole process of designing segmentation models, training\nmodels, optimizing performance and inference speed, and deploying models.\nCurrently, PaddleSeg supports around 20 popular segmentation models and more\nthan 50 pre-trained models from real-time and high-accuracy levels. With\nmodular components and backbone networks, users can easily build over one\nhundred models for different requirements. Furthermore, we provide\ncomprehensive benchmarks and evaluations to show that these segmentation\nalgorithms trained on our toolkit have more competitive accuracy. Also, we\nprovide various real industrial applications and practical cases based on\nPaddleSeg. All codes and examples of PaddleSeg are available at\nhttps://github.com/PaddlePaddle/PaddleSeg.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06175",
		"pdf_url": "http://arxiv.org/pdf/2101.06175.pdf"
	},
	"853": {
		"title": "Learning to Sample from Censored Markov Random Fields",
		"creator": [
			"Moitra, Ankur",
			"Mossel, Elchanan",
			"Sandon, Colin"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  We study learning Censor Markov Random Fields (abbreviated CMRFs). These are\nMarkov Random Fields where some of the nodes are censored (not observed). We\npresent an algorithm for learning high-temperature CMRFs within o(n)\ntransportation distance. Crucially our algorithm makes no assumption about the\nstructure of the graph or the number or location of the observed nodes. We\nobtain stronger results for high girth high-temperature CMRFs as well as\ncomputational lower bounds indicating that our results can not be qualitatively\nimproved.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06178",
		"pdf_url": "http://arxiv.org/pdf/2101.06178.pdf"
	},
	"854": {
		"title": "STENCIL-NET: Data-driven solution-adaptive discretization of partial\n  differential equations",
		"creator": [
			"Maddu, Suryanarayana",
			"Sturm, Dominik",
			"Cheeseman, Bevan L.",
			"Müller, Christian L.",
			"Sbalzarini, Ivo F."
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"Computer Science - Machine Learning"
		],
		"description": "  Numerical methods for approximately solving partial differential equations\n(PDE) are at the core of scientific computing. Often, this requires\nhigh-resolution or adaptive discretization grids to capture relevant\nspatio-temporal features in the PDE solution, e.g., in applications like\nturbulence, combustion, and shock propagation. Numerical approximation also\nrequires knowing the PDE in order to construct problem-specific\ndiscretizations. Systematically deriving such solution-adaptive discrete\noperators, however, is a current challenge. Here we present STENCIL-NET, an\nartificial neural network architecture for data-driven learning of problem- and\nresolution-specific local discretizations of nonlinear PDEs. STENCIL-NET\nachieves numerically stable discretization of the operators in an unknown\nnonlinear PDE by spatially and temporally adaptive parametric pooling on\nregular Cartesian grids, and by incorporating knowledge about discrete time\nintegration. Knowing the actual PDE is not necessary, as solution data is\nsufficient to train the network to learn the discrete operators. A once-trained\nSTENCIL-NET model can be used to predict solutions of the PDE on larger spatial\ndomains and for longer times than it was trained for, hence addressing the\nproblem of PDE-constrained extrapolation from data. To support this claim, we\npresent numerical experiments on long-term forecasting of chaotic PDE solutions\non coarse spatio-temporal grids. We also quantify the speed-up achieved by\nsubstituting base-line numerical methods with equation-free STENCIL-NET\npredictions on coarser grids with little compromise on accuracy.\n",
		"date": [
			"2021-01-15",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06182",
		"pdf_url": "http://arxiv.org/pdf/2101.06182.pdf"
	},
	"855": {
		"title": "Hybrid Quantum-Classical Graph Convolutional Network",
		"creator": [
			"Chen, Samuel Yen-Chi",
			"Wei, Tzu-Chieh",
			"Zhang, Chao",
			"Yu, Haiwang",
			"Yoo, Shinjae"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"High Energy Physics - Experiment",
			"Physics - Data Analysis, Statistics and Probability",
			"Quantum Physics"
		],
		"description": "  The high energy physics (HEP) community has a long history of dealing with\nlarge-scale datasets. To manage such voluminous data, classical machine\nlearning and deep learning techniques have been employed to accelerate physics\ndiscovery. Recent advances in quantum machine learning (QML) have indicated the\npotential of applying these techniques in HEP. However, there are only limited\nresults in QML applications currently available. In particular, the challenge\nof processing sparse data, common in HEP datasets, has not been extensively\nstudied in QML models. This research provides a hybrid quantum-classical graph\nconvolutional network (QGCNN) for learning HEP data. The proposed framework\ndemonstrates an advantage over classical multilayer perceptron and\nconvolutional neural networks in the aspect of number of parameters. Moreover,\nin terms of testing accuracy, the QGCNN shows comparable performance to a\nquantum convolutional neural network on the same HEP dataset while requiring\nless than $50\\%$ of the parameters. Based on numerical simulation results,\nstudying the application of graph convolutional operations and other QML models\nmay prove promising in advancing HEP research and other scientific fields.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06189",
		"pdf_url": "http://arxiv.org/pdf/2101.06189.pdf"
	},
	"856": {
		"title": "New Approximation Algorithms for Forest Closeness Centrality -- for\n  Individual Vertices and Vertex Groups",
		"creator": [
			"van der Grinten, Alexander",
			"Angriman, Eugenio",
			"Predari, Maria",
			"Meyerhenke, Henning"
		],
		"subject": "Computer Science - Data Structures and Algorithms",
		"description": "  The emergence of massive graph data sets requires fast mining algorithms.\nCentrality measures to identify important vertices belong to the most popular\nanalysis methods in graph mining. A measure that is gaining attention is forest\ncloseness centrality; it is closely related to electrical measures using\ncurrent flow but can also handle disconnected graphs. Recently, [Jin et al.,\nICDM'19] proposed an algorithm to approximate this measure probabilistically.\nTheir algorithm processes small inputs quickly, but does not scale well beyond\nhundreds of thousands of vertices.\n  In this paper, we first propose a different approximation algorithm; it is up\nto two orders of magnitude faster and more accurate in practice. Our method\nexploits the strong connection between uniform spanning trees and forest\ndistances by adapting and extending recent approximation algorithms for related\nsingle-vertex problems. This results in a nearly-linear time algorithm with an\nabsolute probabilistic error guarantee. In addition, we are the first to\nconsider the problem of finding an optimal group of vertices w.r.t. forest\ncloseness. We prove that this latter problem is NP-hard; to approximate it, we\nadapt a greedy algorithm by [Li et al., WWW'19], which is based on (partial)\nmatrix inversion. Moreover, our experiments show that on disconnected graphs,\ngroup forest closeness outperforms existing centrality measures in the context\nof semi-supervised vertex classification.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06192",
		"pdf_url": "http://arxiv.org/pdf/2101.06192.pdf"
	},
	"857": {
		"title": "Solving one variable word equations in the free group in cubic time",
		"creator": [
			"Ferens, Robert",
			"Jeż, Artur"
		],
		"subject": [
			"Mathematics - Group Theory",
			"Computer Science - Discrete Mathematics",
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Formal Languages and Automata Theory"
		],
		"description": [
			"  A word equation with one variable in a free group is given as $U = V$, where\nboth $U$ and $V$ are words over the alphabet of generators of the free group\nand $X, X^{-1}$, for a fixed variable $X$. An element of the free group is a\nsolution when substituting it for $X$ yields a true equality (interpreted in\nthe free group) of left- and right-hand sides. It is known that the set of all\nsolutions of a given word equation with one variable is a finite union of sets\nof the form $\\{\\alpha w^i \\beta \\: : \\: i \\in \\mathbb Z \\}$, where $\\alpha, w,\n\\beta$ are reduced words over the alphabet of generators, and a polynomial-time\nalgorithm (of a high degree) computing this set is known. We provide a cubic\ntime algorithm for this problem, which also shows that the set of solutions\nconsists of at most a quadratic number of the above-mentioned sets. The\nalgorithm uses only simple tools of word combinatorics and group theory and is\nsimple to state. Its analysis is involved and focuses on the combinatorics of\noccurrences of powers of a word within a larger word.\n",
			"Comment: 52 pages, accepted to STACS 2021"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06201",
		"pdf_url": "http://arxiv.org/pdf/2101.06201.pdf"
	},
	"858": {
		"title": "The Eye of Horus: Spotting and Analyzing Attacks on Ethereum Smart\n  Contracts",
		"creator": [
			"Torres, Christof Ferreira",
			"Iannillo, Antonio Ken",
			"Gervais, Arthur",
			"State, Radu"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": "  In recent years, Ethereum gained tremendously in popularity, growing from a\ndaily transaction average of 10K in January 2016 to an average of 500K in\nJanuary 2020. Similarly, smart contracts began to carry more value, making them\nappealing targets for attackers. As a result, they started to become victims of\nattacks, costing millions of dollars. In response to these attacks, both\nacademia and industry proposed a plethora of tools to scan smart contracts for\nvulnerabilities before deploying them on the blockchain. However, most of these\ntools solely focus on detecting vulnerabilities and not attacks, let alone\nquantifying or tracing the number of stolen assets. In this paper, we present\nHorus, a framework that empowers the automated detection and investigation of\nsmart contract attacks based on logic-driven and graph-driven analysis of\ntransactions. Horus provides quick means to quantify and trace the flow of\nstolen assets across the Ethereum blockchain. We perform a large-scale analysis\nof all the smart contracts deployed on Ethereum until May 2020. We identified\n1,888 attacked smart contracts and 8,095 adversarial transactions in the wild.\nOur investigation shows that the number of attacks did not necessarily decrease\nover the past few years, but for some vulnerabilities remained constant.\nFinally, we also demonstrate the practicality of our framework via an in-depth\nanalysis on the recent Uniswap and Lendf.me attacks.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06204",
		"pdf_url": "http://arxiv.org/pdf/2101.06204.pdf"
	},
	"859": {
		"title": "Cryptoasset Competition and Market Concentration in the Presence of\n  Network Effects",
		"creator": [
			"Stylianou, Konstantinos",
			"Spiegelberg, Leonhard",
			"Herlihy, Maurice",
			"Carter, Nic"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Computer Science - Computers and Society",
			"Computer Science - Social and Information Networks",
			"Physics - Physics and Society"
		],
		"description": "  When network products and services become more valuable as their userbase\ngrows (network effects), this tendency can become a major determinant of how\nthey compete with each other in the market and how the market is structured.\nNetwork effects are traditionally linked to high market concentration,\nearly-mover advantages, and entry barriers, and in the cryptoasset market they\nhave been used as a valuation tool too. The recent resurgence of Bitcoin has\nbeen partly attributed to network effects too. We study the existence of\nnetwork effects in six cryptoassets from their inception to obtain a high-level\noverview of the application of network effects in the cryptoasset market. We\nshow that contrary to the usual implications of network effects, they do not\nserve to concentrate the cryptoasset market, nor do they accord any one\ncryptoasset a definitive competitive advantage, nor are they consistent enough\nto be reliable valuation tools. Therefore, while network effects do occur in\ncryptoasset networks, they are not a defining feature of the cryptoasset market\nas a whole.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06210",
		"pdf_url": "http://arxiv.org/pdf/2101.06210.pdf"
	},
	"860": {
		"title": "A Novel Prediction Approach for Exploring PM2.5 Spatiotemporal\n  Propagation Based on Convolutional Recursive Neural Networks",
		"creator": [
			"Chen, Hsing-Chung",
			"Putra, Karisma Trinanda",
			"Chun-WeiLin, Jerry"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Neural and Evolutionary Computing"
		],
		"description": "  The spread of PM2.5 pollutants that endanger health is difficult to predict\nbecause it involves many atmospheric variables. These micron particles can\nspread rapidly from their source to residential areas, increasing the risk of\nrespiratory disease if exposed for long periods. The prediction system of PM2.5\npropagation provides more detailed and accurate information as an early warning\nsystem to reduce health impacts on the community. According to the idea of\ntransformative computing, the approach we propose in this paper allows\ncomputation on the dataset obtained from massive-scale PM2.5 sensor nodes via\nwireless sensor network. In the scheme, the deep learning model is implemented\non the server nodes to extract spatiotemporal features on these datasets. This\nresearch was conducted by using dataset of air quality monitoring systems in\nTaiwan. This study presents a new model based on the convolutional recursive\nneural network to generate the prediction map. In general, the model is able to\nprovide accurate predictive results by considering the bonds among measurement\nnodes in both spatially and temporally. Therefore, the particulate pollutant\npropagation of PM2.5 could be precisely monitored by using the model we propose\nin this paper.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06213",
		"pdf_url": "http://arxiv.org/pdf/2101.06213.pdf"
	},
	"861": {
		"title": "Player-AI Interaction: What Neural Network Games Reveal About AI as Play",
		"creator": [
			"Zhu, Jichen",
			"Villareale, Jennifer",
			"Javvaji, Nithesh",
			"Risi, Sebastian",
			"Löwe, Mathias",
			"Weigelt, Rush",
			"Harteveld, Casper"
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  The advent of artificial intelligence (AI) and machine learning (ML) bring\nhuman-AI interaction to the forefront of HCI research. This paper argues that\ngames are an ideal domain for studying and experimenting with how humans\ninteract with AI. Through a systematic survey of neural network games (n = 38),\nwe identified the dominant interaction metaphors and AI interaction patterns in\nthese games. In addition, we applied existing human-AI interaction guidelines\nto further shed light on player-AI interaction in the context of AI-infused\nsystems. Our core finding is that AI as play can expand current notions of\nhuman-AI interaction, which are predominantly productivity-based. In\nparticular, our work suggests that game and UX designers should consider flow\nto structure the learning curve of human-AI interaction, incorporate\ndiscovery-based learning to play around with the AI and observe the\nconsequences, and offer users an invitation to play to explore new forms of\nhuman-AI interaction.\n",
		"date": [
			"2021-01-15",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06220",
		"pdf_url": "http://arxiv.org/pdf/2101.06220.pdf"
	},
	"862": {
		"title": "Deep Reinforcement Learning for Haptic Shared Control in Unknown Tasks",
		"creator": [
			"Fernandez, Franklin Cardeñoso",
			"Caarls, Wouter"
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Recent years have shown a growing interest in using haptic shared control\n(HSC) in teleoperated systems. In HSC, the application of virtual guiding\nforces decreases the user's control effort and improves execution time in\nvarious tasks, presenting a good alternative in comparison with direct\nteleoperation. HSC, despite demonstrating good performance, opens a new gap:\nhow to design the guiding forces. For this reason, the challenge lies in\ndeveloping controllers to provide the optimal guiding forces for the tasks that\nare being performed. This work addresses this challenge by designing a\ncontroller based on the deep deterministic policy gradient (DDPG) algorithm to\nprovide the assistance, and a convolutional neural network (CNN) to perform the\ntask detection, called TAHSC (Task Agnostic Haptic Shared Controller). The\nagent learns to minimize the time it takes the human to execute the desired\ntask, while simultaneously minimizing their resistance to the provided\nfeedback. This resistance thus provides the learning algorithm with information\nabout which direction the human is trying to follow, in this case, the\npick-and-place task. Diverse results demonstrate the successful application of\nthe proposed approach by learning custom policies for each user who was asked\nto test the system. It exhibits stable convergence and aids the user in\ncompleting the task with the least amount of time possible.\n",
			"Comment: This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06227",
		"pdf_url": "http://arxiv.org/pdf/2101.06227.pdf"
	},
	"863": {
		"title": "Towards interpreting ML-based automated malware detection models: a\n  survey",
		"creator": [
			"Lin, Yuzhou",
			"Chang, Xiaolin"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Machine Learning"
		],
		"description": "  Malware is being increasingly threatening and malware detectors based on\ntraditional signature-based analysis are no longer suitable for current malware\ndetection. Recently, the models based on machine learning (ML) are developed\nfor predicting unknown malware variants and saving human strength. However,\nmost of the existing ML models are black-box, which made their pre-diction\nresults undependable, and therefore need further interpretation in order to be\neffectively deployed in the wild. This paper aims to examine and categorize the\nexisting researches on ML-based malware detector interpretability. We first\ngive a detailed comparison over the previous work on common ML model\ninter-pretability in groups after introducing the principles, attributes,\nevaluation indi-cators and taxonomy of common ML interpretability. Then we\ninvestigate the interpretation methods towards malware detection, by addressing\nthe importance of interpreting malware detectors, challenges faced by this\nfield, solutions for migitating these challenges, and a new taxonomy for\nclassifying all the state-of-the-art malware detection interpretability work in\nrecent years. The highlight of our survey is providing a new taxonomy towards\nmalware detection interpreta-tion methods based on the common taxonomy\nsummarized by previous re-searches in the common field. In addition, we are the\nfirst to evaluate the state-of-the-art approaches by interpretation method\nattributes to generate the final score so as to give insight to quantifying the\ninterpretability. By concluding the results of the recent researches, we hope\nour work can provide suggestions for researchers who are interested in the\ninterpretability on ML-based malware de-tection models.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06232",
		"pdf_url": "http://arxiv.org/pdf/2101.06232.pdf"
	},
	"864": {
		"title": "Predictive Optimization with Zero-Shot Domain Adaptation",
		"creator": [
			"Sakai, Tomoya",
			"Ohsaka, Naoto"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Prediction in a new domain without any training sample, called zero-shot\ndomain adaptation (ZSDA), is an important task in domain adaptation. While\nprediction in a new domain has gained much attention in recent years, in this\npaper, we investigate another potential of ZSDA. Specifically, instead of\npredicting responses in a new domain, we find a description of a new domain\ngiven a prediction. The task is regarded as predictive optimization, but\nexisting predictive optimization methods have not been extended to handling\nmultiple domains. We propose a simple framework for predictive optimization\nwith ZSDA and analyze the condition in which the optimization problem becomes\nconvex optimization. We also discuss how to handle the interaction of\ncharacteristics of a domain in predictive optimization. Through numerical\nexperiments, we demonstrate the potential usefulness of our proposed framework.\n",
			"Comment: SDM2021. Full version including appendix"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06233",
		"pdf_url": "http://arxiv.org/pdf/2101.06233.pdf"
	},
	"865": {
		"title": "A Random Algorithm for Profit Maximization with Multiple Adoptions in\n  Online Social Networks",
		"creator": [
			"Chen, Tiantian",
			"Liu, Bin",
			"Liu, Wenjing",
			"Fang, Qizhi",
			"Yuan, Jing",
			"Wu, Weili"
		],
		"subject": "Computer Science - Social and Information Networks",
		"description": [
			"  Online social networks have been one of the most effective platforms for\nmarketing and advertising. Through \"word of mouth\" effects, information or\nproduct adoption could spread from some influential individuals to millions of\nusers in social networks. Given a social network $G$ and a constant $k$, the\ninfluence maximization problem seeks for $k$ nodes in $G$ that can influence\nthe largest number of nodes. This problem has found important applications, and\na large amount of works have been devoted to identifying the few most\ninfluential users. But most of existing works only focus on the diffusion of a\nsingle idea or product in social networks. However, in reality, one company may\nproduce multiple kinds of products and one user may also have multiple\nadoptions.\n  Given multiple kinds of different products with different activation costs\nand profits, it is crucial for the company to distribute the limited budget\namong multiple products in order to achieve profit maximization. Profit\nMaximization with Multiple Adoptions (PM$^{2}$A) problem aims to seek for a\nseed set within the budget to maximize the overall profit. In this paper, a\nRandomized Modified Greedy (RMG) algorithm based on the Reverse Influence\nSampling (RIS) technique is presented for the PM$^{2}$A problem, which could\nachieve a $(1-1/e-\\varepsilon)$-approximate solution with high probability.\nCompared with the algorithm proposed in [16] that achieves a\n$\\frac{1}{2}(1-1/e^{2})$-approximate solution, our algorithm provides a better\nperformance ratio which is also the best performance ratio of the PM$^{2}$A\nproblem. Comprehensive experiments on three real-world social networks are\nconducted, and the results demonstrate that our RMG algorithm outperforms the\nalgorithm proposed in [16] and other heuristics in terms of profit\nmaximization, and could better allocate the budget.\n",
			"Comment: 21 pages, 6 figures"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06239",
			"Volume 803, 10 January 2020, Pages 36-47",
			"doi:10.1016/j.tcs.2019.03.028"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06239.pdf"
	},
	"866": {
		"title": "Towards Approximate Query Enumeration with Sublinear Preprocessing Time",
		"creator": [
			"Adler, Isolde",
			"Fahey, Polly"
		],
		"subject": [
			"Computer Science - Databases",
			"Computer Science - Logic in Computer Science"
		],
		"description": "  This paper aims at providing extremely efficient algorithms for approximate\nquery enumeration on sparse databases, that come with performance and accuracy\nguarantees. We introduce a new model for approximate query enumeration on\nclasses of relational databases of bounded degree. We first prove that on\ndatabases of bounded degree any local first-order definable query can be\nenumerated approximately with constant delay after a constant time\npreprocessing phase. We extend this, showing that on databases of bounded\ntree-width and bounded degree, every query that is expressible in first-order\nlogic can be enumerated approximately with constant delay after a sublinear\n(more precisely, polylogarithmic) time preprocessing phase.\n  Durand and Grandjean (ACM Transactions on Computational Logic 2007) proved\nthat exact enumeration of first-order queries on databases of bounded degree\ncan be done with constant delay after a linear time preprocessing phase. Hence\nwe achieve a significant speed-up in the preprocessing phase. Since sublinear\nrunning time does not allow reading the whole input database even once,\nsacrificing some accuracy is inevitable for our speed-up. Nevertheless, our\nenumeration algorithms come with guarantees: With high probability, (1) only\ntuples are enumerated that are answers to the query or `close' to being answers\nto the query, and (2) if the proportion of tuples that are answers to the query\nis sufficiently large, then all answers will be enumerated. Here the notion of\n`closeness' is a tuple edit distance in the input database. For local\nfirst-order queries, only actual answers are enumerated, strengthening (1).\nMoreover, both the `closeness' and the proportion required in (2) are\ncontrollable.\n  We combine methods from property testing of bounded degree graphs with logic\nand query enumeration, which we believe can inspire further research.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06240",
		"pdf_url": "http://arxiv.org/pdf/2101.06240.pdf"
	},
	"867": {
		"title": "Blind Image Deblurring based on Kernel Mixture",
		"creator": [
			"Biyouki, Sajjad Amrollahi",
			"Hwangbo, Hoon"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Blind Image deblurring tries to estimate blurriness and a latent image out of\na blurred image. This estimation, as being an ill-posed problem, requires\nimposing restrictions on the latent image or a blur kernel that represents\nblurriness. Different from recent studies that impose some priors on the latent\nimage, this paper regulates the structure of the blur kernel. We propose a\nkernel mixture structure while using the Gaussian kernel as a base kernel. By\ncombining multiple Gaussian kernels structurally enhanced in terms of scales\nand centers, the kernel mixture becomes capable of modeling nearly\nnon-parametric shape of blurriness. A data-driven decision for the number of\nbase kernels to combine makes the structure even more flexible. We apply this\napproach to a remote sensing problem to recover images from blurry images of\nsatellite. This case study shows the superiority of the proposed method\nregulating the blur kernel in comparison with state-of-the-art methods that\nregulates the latent image.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06241",
		"pdf_url": "http://arxiv.org/pdf/2101.06241.pdf"
	},
	"868": {
		"title": "Enhancing Security via Deliberate Unpredictability of Solutions in\n  Optimisation",
		"creator": [
			"Karapetyan, Daniel",
			"Parkes, Andrew J."
		],
		"subject": "Computer Science - Discrete Mathematics",
		"description": [
			"  The main aim of decision support systems is to find solutions that satisfy\nuser requirements. Often, this leads to predictability of those solutions, in\nthe sense that having the input data and the model, an adversary or enemy can\npredict to a great extent the solution produced by your decision support\nsystem. Such predictability can be undesirable, for example, in military or\nsecurity timetabling, or applications that require anonymity. In this paper, we\ndiscuss the notion of solution predictability and introduce potential\nmechanisms to intentionally avoid it.\n",
			"Comment: Accepted for publication in PATAT 2020"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06243",
		"pdf_url": "http://arxiv.org/pdf/2101.06243.pdf"
	},
	"869": {
		"title": "Internet of Robotic Things: Current Technologies, Applications,\n  Challenges and Future Directions",
		"creator": [
			"Villa, Davide",
			"Song, Xinchao",
			"Heim, Matthew",
			"Li, Liangshe"
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Computers and Society",
			"Computer Science - Networking and Internet Architecture"
		],
		"description": [
			"  Nowadays, the Internet of Things (IoT) concept is gaining more and more\nnotoriety bringing the number of connected devices to reach the order of\nbillion units. Its smart technology is influencing the research and\ndevelopments of advanced solutions in many areas. This paper focuses on the\nmerger between the IoT and robotics named the Internet of Robotic Things\n(IoRT). Allowing robotic systems to communicate over the internet at a minimal\ncost is an important technological opportunity. Robots can use the cloud to\nimprove the overall performance and for offloading demanding tasks. Since\ncommunicating to the cloud results in latency, data loss, and energy loss,\nfinding efficient techniques is a concern that can be addressed with current\nmachine learning methodologies. Moreover, the use of robotic generates ethical\nand regulation questions that should be answered for a proper coexistence\nbetween humans and robots. This paper aims at providing a better understanding\nof the new concept of IoRT with its benefits and limitations, as well as\nguidelines and directions for future research and studies.\n",
			"Comment: 8 pages, 6 figures, 1 table"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06256",
		"pdf_url": "http://arxiv.org/pdf/2101.06256.pdf"
	},
	"870": {
		"title": "Local Search Algorithms for Rank-Constrained Convex Optimization",
		"creator": [
			"Axiotis, Kyriakos",
			"Sviridenko, Maxim"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  We propose greedy and local search algorithms for rank-constrained convex\noptimization, namely solving $\\underset{\\mathrm{rank}(A)\\leq r^*}{\\min}\\, R(A)$\ngiven a convex function $R:\\mathbb{R}^{m\\times n}\\rightarrow \\mathbb{R}$ and a\nparameter $r^*$. These algorithms consist of repeating two steps: (a) adding a\nnew rank-1 matrix to $A$ and (b) enforcing the rank constraint on $A$. We\nrefine and improve the theoretical analysis of Shalev-Shwartz et al. (2011),\nand show that if the rank-restricted condition number of $R$ is $\\kappa$, a\nsolution $A$ with rank $O(r^*\\cdot \\min\\{\\kappa \\log\n\\frac{R(\\mathbf{0})-R(A^*)}{\\epsilon}, \\kappa^2\\})$ and $R(A) \\leq R(A^*) +\n\\epsilon$ can be recovered, where $A^*$ is the optimal solution. This\nsignificantly generalizes associated results on sparse convex optimization, as\nwell as rank-constrained convex optimization for smooth functions. We then\nintroduce new practical variants of these algorithms that have superior runtime\nand recover better solutions in practice. We demonstrate the versatility of\nthese methods on a wide range of applications involving matrix completion and\nrobust principal component analysis.\n",
			"Comment: Accepted in ICLR 2021"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06262",
		"pdf_url": "http://arxiv.org/pdf/2101.06262.pdf"
	},
	"871": {
		"title": "Data@Hand: Fostering Visual Exploration of Personal Data on Smartphones\n  Leveraging Speech and Touch Interaction",
		"creator": [
			"Kim, Young-Ho",
			"Lee, Bongshin",
			"Srinivasan, Arjun",
			"Choe, Eun Kyoung"
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"H.5.2"
		],
		"description": [
			"  Most mobile health apps employ data visualization to help people view their\nhealth and activity data, but these apps provide limited support for visual\ndata exploration. Furthermore, despite its huge potential benefits, mobile\nvisualization research in the personal data context is sparse. This work aims\nto empower people to easily navigate and compare their personal health data on\nsmartphones by enabling flexible time manipulation with speech. We designed and\ndeveloped Data@Hand, a mobile app that leverages the synergy of two\ncomplementary modalities: speech and touch. Through an exploratory study with\n13 long-term Fitbit users, we examined how multimodal interaction helps\nparticipants explore their own health data. Participants successfully adopted\nmultimodal interaction (i.e., speech and touch) for convenient and fluid data\nexploration. Based on the quantitative and qualitative findings, we discuss\ndesign implications and opportunities with multimodal interaction for better\nsupporting visual data exploration on mobile devices.\n",
			"Comment: To appear in ACM CHI 2021 Conference on Human Factors in Computing\n  Systems; 16 pages, 6 figures, 5 tables"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06283",
			"In CHI Conference on Human Factors in Computing Systems (CHI '21),\n  May 8-13, 2021, Yokohama, Japan",
			"doi:10.1145/3411764.3445421"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06283.pdf"
	},
	"872": {
		"title": "On the relationship between a Gamma distributed precision parameter and\n  the associated standard deviation in the context of Bayesian parameter\n  inference",
		"creator": "Eichenlaub, Manuel M.",
		"subject": [
			"Statistics - Methodology",
			"Computer Science - Machine Learning"
		],
		"description": "  In Bayesian inference, an unknown measurement uncertainty is often quantified\nin terms of a Gamma distributed precision parameter, which is impractical when\nprior information on the standard deviation of the measurement uncertainty\nshall be utilised during inference. This paper thus introduces a method for\ntransforming between a gamma distributed precision parameter and the\ndistribution of the associated standard deviation. The proposed method is based\non numerical optimisation and shows adequate results for a wide range of\nscenarios.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06289",
		"pdf_url": "http://arxiv.org/pdf/2101.06289.pdf"
	},
	"873": {
		"title": "A generalized inf-sup stable variational formulation for the wave\n  equation",
		"creator": [
			"Steinbach, Olaf",
			"Zank, Marco"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"Mathematics - Analysis of PDEs",
			"35L05, 35D30"
		],
		"description": [
			"  In this paper, we consider a variational formulation for the Dirichlet\nproblem of the wave equation with zero boundary and initial conditions, where\nwe use integration by parts in space and time. To prove unique solvability in a\nsubspace of $H^1(Q$) with $Q$ being the space-time domain, the classical\nassumption is to consider the right-hand side $f$ in $L^2(Q)$. Here, we analyze\na generalized setting of this variational formulation, which allows us to prove\nunique solvability also for $f$ being in the dual space of the test space,\ni.e., the solution operator is an isomorphism between the ansatz space and the\ndual of the test space. This new approach is based on a suitable extension of\nthe ansatz space to include the information of the differential operator of the\nwave equation at the initial time $t=0$. These results are of utmost importance\nfor the formulation and numerical analysis of unconditionally stable space-time\nfinite element methods, and for the numerical analysis of boundary element\nmethods to overcome the well-known norm gap in the analysis of boundary\nintegral operators.\n",
			"Comment: 27 pages"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06293",
		"pdf_url": "http://arxiv.org/pdf/2101.06293.pdf"
	},
	"874": {
		"title": "A second-order self-adjusting steepness based remapping method for\n  arbitrary quadrilateral meshes",
		"creator": "He, Zhiwei",
		"subject": [
			"Computer Science - Computational Engineering, Finance, and Science",
			"Mathematics - Numerical Analysis",
			"Physics - Computational Physics"
		],
		"description": "  In this paper, based on the idea of self-adjusting steepness based\nschemes[5], a two-dimensional calculation method of steepness parameter is\nproposed, and thus a two-dimensional self-adjusting steepness based limiter is\nconstructed. With the application of such limiter to the over-intersection\nbased remapping framework, a low dissipation remapping method has been proposed\nthat can be applied to the existing ALE method.\n",
		"date": "2020-12-26",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06298",
		"pdf_url": "http://arxiv.org/pdf/2101.06298.pdf"
	},
	"875": {
		"title": "CARE: Lightweight Attack Resilient Secure Boot Architecturewith Onboard\n  Recovery for RISC-V based SOC",
		"creator": [
			"Dave, Avani",
			"Banerjee, Nilanjan",
			"Patel, Chintan"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": "  Recent technological advancements have proliferated the use of small embedded\ndevices for collecting, processing, and transferring the security-critical\ninformation. The Internet of Things (IoT) has enabled remote access and control\nof these network-connected devices. Consequently, an attacker can exploit\nsecurity vulnerabilities and compromise these devices. In this context, the\nsecure boot becomes a useful security mechanism to verify the integrity and\nauthenticity of the software state of the devices. However, the current secure\nboot schemes focus on detecting the presence of potential malware on the device\nbut not on disinfecting and restoring the soft-ware to a benign state. This\nmanuscript presents CARE- the first secure boot framework that provides\ndetection, resilience, and onboard recovery mechanism for the com-promised\ndevices. The framework uses a prototype hybrid CARE: Code Authentication and\nResilience Engine to verify the software state and restore it to a benign\nstate. It uses Physical Memory Protection (PMP) and other security enchaining\ntechniques of RISC-V processor to pro-vide resilience from modern attacks. The\nstate-of-the-art comparison and performance analysis results indicate that the\nproposed secure boot framework provides a promising resilience and recovery\nmechanism with very little 8 % performance and resource overhead\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06300",
		"pdf_url": "http://arxiv.org/pdf/2101.06300.pdf"
	},
	"876": {
		"title": "Wi-Fi Wardriving Studies Must Account for Important Statistical Issues",
		"creator": [
			"Oughton, Edward J",
			"Kusuma, Julius",
			"Peyronel, Thibault",
			"Crowcroft, Jon"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Computer Science - Computers and Society"
		],
		"description": "  Knowledge of Wi-Fi networks helps to guide future engineering and spectrum\npolicy decisions. However, due to its unlicensed nature, the deployment of\nWi-Fi Access Points is undocumented meaning researchers are left making\neducated guesses as to the prevalence of these assets through remotely\ncollected or passively sensed measurements. One commonly used method is\nreferred to as `wardriving` essentially where a vehicle is used to collect\ngeospatial statistical data on wireless networks to inform mobile computing and\nnetworking security research. Surprisingly, there has been very little\nexamination of the statistical issues with wardriving data, despite the vast\nnumber of analyses being published in the literature using this approach. In\nthis paper, a sample of publicly collected wardriving data is compared to a\npredictive model for Wi-Fi Access Points. The results demonstrate several\nstatistical issues which future wardriving studies must account for, including\nselection bias, sample representativeness and the modifiable areal unit\nproblem.\n",
		"date": [
			"2021-01-15",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06301",
		"pdf_url": "http://arxiv.org/pdf/2101.06301.pdf"
	},
	"877": {
		"title": "The Role of Working Memory in Program Tracing",
		"creator": [
			"Crichton, Will",
			"Agrawala, Maneesh",
			"Hanrahan, Pat"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": [
			"  Program tracing, or mentally simulating a program on concrete inputs, is an\nimportant part of general program comprehension. Programs involve many kinds of\nvirtual state that must be held in memory, such as variable/value pairs and a\ncall stack. In this work, we examine the influence of short-term working memory\n(WM) on a person's ability to remember program state during tracing. We first\nconfirm that previous findings in cognitive psychology transfer to the\nprogramming domain: people can keep about 7 variable/value pairs in WM, and\npeople will accidentally swap associations between variables due to WM load. We\nuse a restricted focus viewing interface to further analyze the strategies\npeople use to trace through programs, and the relationship of tracing strategy\nto WM. Given a straight-line program, we find half of our participants traced a\nprogram from the top-down line-by-line (linearly), and the other half start at\nthe bottom and trace upward based on data dependencies (on-demand).\nParticipants with an on-demand strategy made more WM errors while tracing\nstraight-line code than with a linear strategy, but the two strategies\ncontained an equal number of WM errors when tracing code with functions. We\nconclude with the implications of these findings for the design of programming\ntools: first, programs should be analyzed to identify and refactor\nhuman-memory-intensive sections of code. Second, programming environments\nshould interactively visualize variable metadata to reduce WM load in\naccordance with a person's tracing strategy. Third, tools for program\ncomprehension should enable externalizing program state while tracing.\n",
			"Comment: To appear at CHI 2021"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06305",
			"doi:10.1145/3411764.3445257"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06305.pdf"
	},
	"878": {
		"title": "Privacy Protection of Grid Users Data with Blockchain and Adversarial\n  Machine Learning",
		"creator": [
			"Yilmaz, Ibrahim",
			"Kapoor, Kavish",
			"Siraj, Ambareen",
			"Abouyoussef, Mahmoud"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  Utilities around the world are reported to invest a total of around 30\nbillion over the next few years for installation of more than 300 million smart\nmeters, replacing traditional analog meters [1]. By mid-decade, with full\ncountry wide deployment, there will be almost 1.3 billion smart meters in place\n[1]. Collection of fine grained energy usage data by these smart meters\nprovides numerous advantages such as energy savings for customers with use of\ndemand optimization, a billing system of higher accuracy with dynamic pricing\nprograms, bidirectional information exchange ability between end-users for\nbetter consumer-operator interaction, and so on. However, all these perks\nassociated with fine grained energy usage data collection threaten the privacy\nof users. With this technology, customers' personal data such as sleeping\ncycle, number of occupants, and even type and number of appliances stream into\nthe hands of the utility companies and can be subject to misuse. This research\npaper addresses privacy violation of consumers' energy usage data collected\nfrom smart meters and provides a novel solution for the privacy protection\nwhile allowing benefits of energy data analytics. First, we demonstrate the\nsuccessful application of occupancy detection attacks using a deep neural\nnetwork method that yields high accuracy results. We then introduce Adversarial\nMachine Learning Occupancy Detection Avoidance with Blockchain (AMLODA-B)\nframework as a counter-attack by deploying an algorithm based on the Long Short\nTerm Memory (LSTM) model into the standardized smart metering infrastructure to\nprevent leakage of consumers personal information. Our privacy-aware approach\nprotects consumers' privacy without compromising the correctness of billing and\npreserves operational efficiency without use of authoritative intermediaries.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06308",
		"pdf_url": "http://arxiv.org/pdf/2101.06308.pdf"
	},
	"879": {
		"title": "Fundamental Tradeoffs in Distributionally Adversarial Training",
		"creator": [
			"Mehrabi, Mohammad",
			"Javanmard, Adel",
			"Rossi, Ryan A.",
			"Rao, Anup",
			"Mai, Tung"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Mathematics - Statistics Theory",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Adversarial training is among the most effective techniques to improve the\nrobustness of models against adversarial perturbations. However, the full\neffect of this approach on models is not well understood. For example, while\nadversarial training can reduce the adversarial risk (prediction error against\nan adversary), it sometimes increase standard risk (generalization error when\nthere is no adversary). Even more, such behavior is impacted by various\nelements of the learning problem, including the size and quality of training\ndata, specific forms of adversarial perturbations in the input, model\noverparameterization, and adversary's power, among others. In this paper, we\nfocus on \\emph{distribution perturbing} adversary framework wherein the\nadversary can change the test distribution within a neighborhood of the\ntraining data distribution. The neighborhood is defined via Wasserstein\ndistance between distributions and the radius of the neighborhood is a measure\nof adversary's manipulative power. We study the tradeoff between standard risk\nand adversarial risk and derive the Pareto-optimal tradeoff, achievable over\nspecific classes of models, in the infinite data limit with features dimension\nkept fixed. We consider three learning settings: 1) Regression with the class\nof linear models; 2) Binary classification under the Gaussian mixtures data\nmodel, with the class of linear classifiers; 3) Regression with the class of\nrandom features model (which can be equivalently represented as two-layer\nneural network with random first-layer weights). We show that a tradeoff\nbetween standard and adversarial risk is manifested in all three settings. We\nfurther characterize the Pareto-optimal tradeoff curves and discuss how a\nvariety of factors, such as features correlation, adversary's power or the\nwidth of two-layer neural network would affect this tradeoff.\n",
			"Comment: 23 pages, 3 figures"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06309",
		"pdf_url": "http://arxiv.org/pdf/2101.06309.pdf"
	},
	"880": {
		"title": "Automated Diagnosis of Intestinal Parasites: A new hybrid approach and\n  its benefits",
		"creator": [
			"Osaku, D.",
			"Cuba, C. F.",
			"Suzuki, Celso T. N.",
			"Gomes, J. F.",
			"Falcão, A. X."
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": [
			"  Intestinal parasites are responsible for several diseases in human beings. In\norder to eliminate the error-prone visual analysis of optical microscopy\nslides, we have investigated automated, fast, and low-cost systems for the\ndiagnosis of human intestinal parasites. In this work, we present a hybrid\napproach that combines the opinion of two decision-making systems with\ncomplementary properties: ($DS_1$) a simpler system based on very fast\nhandcrafted image feature extraction and support vector machine classification\nand ($DS_2$) a more complex system based on a deep neural network, Vgg-16, for\nimage feature extraction and classification. $DS_1$ is much faster than $DS_2$,\nbut it is less accurate than $DS_2$. Fortunately, the errors of $DS_1$ are not\nthe same of $DS_2$. During training, we use a validation set to learn the\nprobabilities of misclassification by $DS_1$ on each class based on its\nconfidence values. When $DS_1$ quickly classifies all images from a microscopy\nslide, the method selects a number of images with higher chances of\nmisclassification for characterization and reclassification by $DS_2$. Our\nhybrid system can improve the overall effectiveness without compromising\nefficiency, being suitable for the clinical routine -- a strategy that might be\nsuitable for other real applications. As demonstrated on large datasets, the\nproposed system can achieve, on average, 94.9%, 87.8%, and 92.5% of Cohen's\nKappa on helminth eggs, helminth larvae, and protozoa cysts, respectively.\n",
			"Comment: 18 pages, 11 figures"
		],
		"date": "2021-01-07",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06310",
			"Computers in Biology and Medicine, Volume 123, August 2020, 103917",
			"doi:10.1016/j.compbiomed.2020.103917"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06310.pdf"
	},
	"881": {
		"title": "Boosting performance for software defined networks from traffic\n  engineering perspective",
		"creator": [
			"Salman, Mohammed I.",
			"Wang, Bin"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": "  Paths selection algorithms and rate adaptation objective functions are\nusually studied separately. In contrast, this paper evaluates some traffic\nengineering (TE) systems for software defined networking obtained by combining\npath selection techniques with average delay and load balancing, the two most\npopular TE objective functions. Based on TE simulation results, the best TE\nsystem suitable for software defined networks is a system where the paths are\ncalculated using an oblivious routing model and its adaptation rate calculated\nusing an average delay objective function. Thus, we propose the RACKE+AD system\ncombining path sets computed using Racke's oblivious routing and traffic\nsplitting objective function using average delay. This model outperforms\ncurrent state-of-the-art models, maximizes throughput, achieves better network\nresource utilization, and minimizes delay. The proposed system outperformed\nSMORE and SWAN by 4.2% and 9.6% respectively, achieving 27% better utilization\nand delivering 34% more traffic with 50% less latency compared with both\nsystems on a GEANT network.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06311",
			"doi:10.1016/j.comcom.2020.12.018"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06311.pdf"
	},
	"882": {
		"title": "A Multi-Platform Study of Crowd Signals Associated with Successful\n  Online Fundraising",
		"creator": [
			"Dambanemuya, Henry K.",
			"Horvát, Emőke-Ágnes"
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"J.4"
		],
		"description": [
			"  The growing popularity of online fundraising (aka \"crowdfunding\") has\nattracted significant research on the subject. In contrast to previous studies\nthat attempt to predict the success of crowdfunded projects based on specific\ncharacteristics of the projects and their creators, we present a more general\napproach that focuses on crowd dynamics and is robust to the particularities of\ndifferent crowdfunding platforms. We rely on a multi-method analysis to\ninvestigate the correlates, predictive importance, and quasi-causal effects of\nfeatures that describe crowd dynamics in determining the success of crowdfunded\nprojects. By applying a multi-method analysis to a study of fundraising in\nthree different online markets, we uncover general crowd dynamics that\nultimately decide which projects will succeed. In all analyses and across the\nthree different platforms, we consistently find that funders' behavioural\nsignals (1) are significantly correlated with fundraising success; (2)\napproximate fundraising outcomes better than the characteristics of projects\nand their creators such as credit grade, company valuation, and subject domain;\nand (3) have significant quasi-causal effects on fundraising outcomes while\ncontrolling for potentially confounding project variables. By showing that\nuniversal features deduced from crowd behaviour are predictive of fundraising\nsuccess on different crowdfunding platforms, our work provides design-relevant\ninsights about novel types of collective decision-making online. This research\ninspires thus potential ways to leverage cues from the crowd and catalyses\nresearch into crowd-aware system design.\n",
			"Comment: To appear in the Proceedings of the ACM (PACM) Human-Computer\n  Interaction CSCW'21"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06315",
		"pdf_url": "http://arxiv.org/pdf/2101.06315.pdf"
	},
	"883": {
		"title": "Controlling the Risk of Conversational Search via Reinforcement Learning",
		"creator": [
			"Wang, Zhenduo",
			"Ai, Qingyao"
		],
		"subject": "Computer Science - Information Retrieval",
		"description": [
			"  Users often formulate their search queries with immature language without\nwell-developed keywords and complete structures. Such queries fail to express\ntheir true information needs and raise ambiguity as fragmental language often\nyield various interpretations and aspects. This gives search engines a hard\ntime processing and understanding the query, and eventually leads to\nunsatisfactory retrieval results. An alternative approach to direct answer\nwhile facing an ambiguous query is to proactively ask clarifying questions to\nthe user. Recent years have seen many works and shared tasks from both NLP and\nIR community about identifying the need for asking clarifying question and\nmethodology to generate them. An often neglected fact by these works is that\nalthough sometimes the need for clarifying questions is correctly recognized,\nthe clarifying questions these system generate are still off-topic and\ndissatisfaction provoking to users and may just cause users to leave the\nconversation.\n  In this work, we propose a risk-aware conversational search agent model to\nbalance the risk of answering user's query and asking clarifying questions. The\nagent is fully aware that asking clarifying questions can potentially collect\nmore information from user, but it will compare all the choices it has and\nevaluate the risks. Only after then, it will make decision between answering or\nasking. To demonstrate that our system is able to retrieve better answers, we\nconduct experiments on the MSDialog dataset which contains real-world customer\nservice conversations from Microsoft products community. We also purpose a\nreinforcement learning strategy which allows us to train our model on the\noriginal dataset directly and saves us from any further data annotation\nefforts. Our experiment results show that our risk-aware conversational search\nagent is able to significantly outperform strong non-risk-aware baselines.\n",
			"Comment: This paper is accepted by The Web Conference (WWW) 2021"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06327",
		"pdf_url": "http://arxiv.org/pdf/2101.06327.pdf"
	},
	"884": {
		"title": "Attention Based Video Summaries of Live Online Zoom Classes",
		"creator": [
			"Lee, Hyowon",
			"Liu, Mingming",
			"Riaz, Hamza",
			"Rajasekaren, Navaneethan",
			"Scriney, Michael",
			"Smeaton, Alan F."
		],
		"subject": [
			"Computer Science - Multimedia",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Human-Computer Interaction"
		],
		"description": [
			"  This paper describes a system developed to help University students get more\nfrom their online lectures, tutorials, laboratory and other live sessions. We\ndo this by logging their attention levels on their laptops during live Zoom\nsessions and providing them with personalised video summaries of those live\nsessions. Using facial attention analysis software we create personalised video\nsummaries composed of just the parts where a student's attention was below some\nthreshold. We can also factor in other criteria into video summary generation\nsuch as parts where the student was not paying attention while others in the\nclass were, and parts of the video that other students have replayed\nextensively which a given student has not. Attention and usage based video\nsummaries of live classes are a form of personalised content, they are\neducational video segments recommended to highlight important parts of live\nsessions, useful in both topic understanding and in exam preparation. The\nsystem also allows a Professor to review the aggregated attention levels of\nthose in a class who attended a live session and logged their attention levels.\nThis allows her to see which parts of the live activity students were paying\nmost, and least, attention to. The Help-Me-Watch system is deployed and in use\nat our University in a way that protects student's personal data, operating in\na GDPR-compliant way.\n",
			"Comment: Presented at AAAI-2021 Workshop on AI Education: \"Imagining\n  Post-COVID Education with AI\" (TIPCE-2021). 9 pages, 5 figures"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06328",
		"pdf_url": "http://arxiv.org/pdf/2101.06328.pdf"
	},
	"885": {
		"title": "Optical Flow Estimation via Motion Feature Recovery",
		"creator": [
			"Jiao, Yang",
			"Shi, Guangming",
			"Tran, Trac D."
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Optical flow estimation with occlusion or large displacement is a problematic\nchallenge due to the lost of corresponding pixels between consecutive frames.\nIn this paper, we discover that the lost information is related to a large\nquantity of motion features (more than 40%) computed from the popular\ndiscriminative cost-volume feature would completely vanish due to invalid\nsampling, leading to the low efficiency of optical flow learning. We call this\nphenomenon the Vanishing Cost Volume Problem. Inspired by the fact that local\nmotion tends to be highly consistent within a short temporal window, we propose\na novel iterative Motion Feature Recovery (MFR) method to address the vanishing\ncost volume via modeling motion consistency across multiple frames. In each MFR\niteration, invalid entries from original motion features are first determined\nbased on the current flow. Then, an efficient network is designed to adaptively\nlearn the motion correlation to recover invalid features for lost-information\nrestoration. The final optical flow is then decoded from the recovered motion\nfeatures. Experimental results on Sintel and KITTI show that our method\nachieves state-of-the-art performances. In fact, MFR currently ranks second on\nSintel public website.\n",
			"Comment: 5 pages"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06333",
		"pdf_url": "http://arxiv.org/pdf/2101.06333.pdf"
	},
	"886": {
		"title": "Slider: On the Design and Modeling of a 2D Floating Satellite Platform",
		"creator": [
			"Banerjee, Avijit",
			"Haluska, Jakub",
			"Satpute, Sumeet G.",
			"Kominiak, Dariusz",
			"Nikolakopoulos, George"
		],
		"subject": [
			"Computer Science - Robotics",
			"Electrical Engineering and Systems Science - Systems and Control",
			"Mathematics - Dynamical Systems"
		],
		"description": "  In this article, a floating robotic emulation platform for a virtual\ndemonstration of satellite motion in space is presented. The robotic platform\ndesign is characterized by its friction-less, levitating, yet planar motion\nover a hyper-smooth surface. The robotic platform, integrated with sensor and\nactuator units, is fully designed and manufactured from the Robotics and\nArtificial Intelligence Team at Lule\\aa\\ University of Technology. A detailed\ndesign description along with the mathematical modeling describing the\nplatform's dynamic motion is formulated. Finally, the proposed design is\nvalidated in extensive simulation studies, while the overall test bed\nexperimental setup, as well as the vehicle hardware and software architectures,\nare discussed in detail. Furthermore, the entire design, including 3D printing\nCAD model and different testbed elements, is provided in an open-source\nrepository and a test campaign is used to showcase its capabilities and\nillustrate its operations.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06335",
		"pdf_url": "http://arxiv.org/pdf/2101.06335.pdf"
	},
	"887": {
		"title": "Exponential Kernels with Latency in Hawkes Processes: Applications in\n  Finance",
		"creator": "Carreira, Marcos Costa Santos",
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning",
			"Quantitative Finance - Trading and Market Microstructure"
		],
		"description": "  The Tick library allows researchers in market microstructure to simulate and\nlearn Hawkes process in high-frequency data, with optimized parametric and\nnon-parametric learners. But one challenge is to take into account the correct\ncausality of order book events considering latency: the only way one order book\nevent can influence another is if the time difference between them (by the\ncentral order book timestamps) is greater than the minimum amount of time for\nan event to be (i) published in the order book, (ii) reach the trader\nresponsible for the second event, (iii) influence the decision (processing time\nat the trader) and (iv) the 2nd event reach the order book and be processed.\nFor this we can use exponential kernels shifted to the right by the latency\namount. We derive the expression for the log-likelihood to be minimized for the\n1-D and the multidimensional cases, and test this method with simulated data\nand real data. On real data we find that, although not all decays are the same,\nthe latency itself will determine most of the decays. We also show how the\ndecays are related to the latency. Code is available on GitHub at\nhttps://github.com/MarcosCarreira/Hawkes-With-Latency.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06348",
		"pdf_url": "http://arxiv.org/pdf/2101.06348.pdf"
	},
	"888": {
		"title": "Weakly-Supervised Hierarchical Models for Predicting Persuasive\n  Strategies in Good-faith Textual Requests",
		"creator": [
			"Chen, Jiaao",
			"Yang, Diyi"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Computers and Society"
		],
		"description": [
			"  Modeling persuasive language has the potential to better facilitate our\ndecision-making processes. Despite its importance, computational modeling of\npersuasion is still in its infancy, largely due to the lack of benchmark\ndatasets that can provide quantitative labels of persuasive strategies to\nexpedite this line of research. To this end, we introduce a large-scale\nmulti-domain text corpus for modeling persuasive strategies in good-faith text\nrequests. Moreover, we design a hierarchical weakly-supervised latent variable\nmodel that can leverage partially labeled data to predict such associated\npersuasive strategies for each sentence, where the supervision comes from both\nthe overall document-level labels and very limited sentence-level labels.\nExperimental results showed that our proposed method outperformed existing\nsemi-supervised baselines significantly. We have publicly released our code at\nhttps://github.com/GT-SALT/Persuasion_Strategy_WVAE.\n",
			"Comment: AAAI 2021"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06351",
		"pdf_url": "http://arxiv.org/pdf/2101.06351.pdf"
	},
	"889": {
		"title": "Rapid Method for Generation Prioritization during System Restoration\n  with Renewable Resources",
		"creator": [
			"Mate, Adam",
			"Cotilla-Sanchez, Eduardo"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  Quick and reliable power system restoration is critically important after\nnatural disasters or other sudden threats, such as cyber-attacks. Leveraging\nrenewable resources in system restoration shortens recovery times, resulting in\nprevented life-loss and avoided economic-loss, and improves the resilience of\nthe entire grid. However, it is not a common practice today; the inherent\nvariability of these resources represents a challenge for a streamlined\nrestoration process. This paper presents a prioritized method - starting with\nrenewable generator units then lowering priority to conventional units - to\nplan the operational schedule of a power system during the restoration process.\nThe goal is to achieve a well balanced system in the presence of significant\nrenewable penetration. Validation and benchmarking experiments were performed\non a customized version of the RTS-GMLC test system using six months out of\nyear-long data, tested through hourly simulations. After evaluating the\nperformance and computational costs, this method proved faster than common\napproaches: a MILP Unit Commitment algorithm, widely used today, and an\n\"enable-and-try\" algorithm. In summary, herein a more convenient method is\nprovided to be utilized during time-sensitive restoration, as an online\noperation-planning aid.\n",
			"Comment: 8 pages. 5 figures"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06355",
			"Proceedings of the 2019 IEEE/IAS 55th Industrial and Commercial\n  Power Systems Technical Conference, pp. 1-8, May 2019",
			"doi:10.1109/ICPS.2019.8733358"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06355.pdf"
	},
	"890": {
		"title": "SEDAT:Security Enhanced Device Attestation with TPM2.0",
		"creator": [
			"Dave, Avani",
			"Wiseman, Monty",
			"Safford, David"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Computers and Society"
		],
		"description": "  Remote attestation is one of the ways to verify the state of an untrusted\ndevice. Earlier research has attempted remote verification of a devices' state\nusing hardware, software, or hybrid approaches. Majority of them have used\nAttestation Key as a hardware root of trust, which does not detect hardware\nmodification or counterfeit issues. In addition, they do not have a secure\ncommunication channel between verifier and prover, which makes them susceptible\nto modern security attacks. This paper presents SEDAT, a novel methodology for\nremote attestation of the device via a security enhanced communication channel.\nSEDAT performs hardware, firmware, and software attestation. SEDAT enhances the\ncommunication protocol security between verifier and prover by using the Single\nPacket Authorization (SPA) technique, which provides replay and Denial of\nService (DoS) protection. SEDAT provides a way for verifier to get on-demand\ndevice integrity and authenticity status via a secure channel. It also enables\nthe verifier to detect counterfeit hardware, change in firmware, and software\ncode on the device. SEDAT validates the manufacturers` root CA certificate,\nplatform certificate, endorsement certificate (EK), and attributes certificates\nto perform platform hardware attestation. SEDAT is the first known tool that\nrepresents firmware, and Integrity Measurement Authority (IMA) event logs in\nthe Canonical Event Logs (CEL) format (recommended by Trusted Computing Group).\nSEDAT is the first implementation, to the best of our knowledge, that showcases\nend to end hardware, firmware, and software remote attestation using Trusted\nPlatform Module (TPM2.0) which is resilient to DoS and replay attacks. SEDAT is\nthe first remote verifier that is capable of retrieving a TPM2.0 quote from\nprover and validate it after regeneration, using a software TPM2.0 quote check.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06362",
		"pdf_url": "http://arxiv.org/pdf/2101.06362.pdf"
	},
	"891": {
		"title": "AR-based Modern Healthcare: A Review",
		"creator": [
			"Ara, Jinat",
			"Bhuiyan, Hanif",
			"Bhuiyan, Yeasin Arafat",
			"Bhyan, Salma Begum",
			"Bhuiyan, Muhammad Ismail"
		],
		"subject": [
			"Computer Science - Computers and Society",
			"Computer Science - Artificial Intelligence",
			"A.1",
			"H.4",
			"I.2",
			"J.3"
		],
		"description": [
			"  The recent advances of Augmented Reality (AR) in healthcare have shown that\ntechnology is a significant part of the current healthcare system. In recent\ndays, augmented reality has proposed numerous smart applications in healthcare\ndomain including wearable access, telemedicine, remote surgery, diagnosis of\nmedical reports, emergency medicine, etc. The aim of the developed augmented\nhealthcare application is to improve patient care, increase efficiency, and\ndecrease costs. This article puts on an effort to review the advances in\nAR-based healthcare technologies and goes to peek into the strategies that are\nbeing taken to further this branch of technology. This article explores the\nimportant services of augmented-based healthcare solutions and throws light on\nrecently invented ones as well as their respective platforms. It also addresses\nconcurrent concerns and their relevant future challenges. In addition, this\npaper analyzes distinct AR security and privacy including security requirements\nand attack terminologies. Furthermore, this paper proposes a security model to\nminimize security risks. Augmented reality advantages in healthcare, especially\nfor operating surgery, emergency diagnosis, and medical training is being\ndemonstrated here thorough proper analysis. To say the least, the article\nillustrates a complete overview of augmented reality technology in the modern\nhealthcare sector by demonstrating its impacts, advancements, current\nvulnerabilities; future challenges, and concludes with recommendations to a new\ndirection for further research.\n",
			"Comment: 14 pages, 7 figures, and 2 tables"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06364",
		"pdf_url": "http://arxiv.org/pdf/2101.06364.pdf"
	},
	"892": {
		"title": "Tuiteamos o pongamos un tuit? Investigating the Social Constraints of\n  Loanword Integration in Spanish Social Media",
		"creator": [
			"Stewart, Ian",
			"Yang, Diyi",
			"Eisenstein, Jacob"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"I.2.7"
		],
		"description": "  Speakers of non-English languages often adopt loanwords from English to\nexpress new or unusual concepts. While these loanwords may be borrowed\nunchanged, speakers may also integrate the words to fit the constraints of\ntheir native language, e.g. creating Spanish \"tuitear\" from English \"tweet.\"\nLinguists have often considered the process of loanword integration to be more\ndependent on language-internal constraints, but sociolinguistic constraints\nsuch as speaker background remain only qualitatively understood. We investigate\nthe role of social context and speaker background in Spanish speakers' use of\nintegrated loanwords on social media. We find first that newspaper authors use\nthe integrated forms of loanwords and native words more often than social media\nauthors, showing that integration is associated with formal domains. In social\nmedia, we find that speaker background and expectations of formality explain\nloanword and native word integration, such that authors who use more Spanish\nand who write to a wider audience tend to use integrated verb forms more often.\nThis study shows that loanword integration reflects not only language-internal\nconstraints but also social expectations that vary by conversation and speaker.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06368",
			"Society for Computation in Linguistics, 2021"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06368.pdf"
	},
	"893": {
		"title": "NNStreamer: Efficient and Agile Development of On-Device AI Systems",
		"creator": [
			"Ham, MyungJoo",
			"Moon, Jijoong",
			"Lim, Geunsik",
			"Jung, Jaeyun",
			"Ahn, Hyoungjoo",
			"Song, Wook",
			"Woo, Sangjung",
			"Kapoor, Parichay",
			"Chae, Dongju",
			"Jang, Gichan",
			"Ahn, Yongjoo",
			"Lee, Jihoon"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Software Engineering"
		],
		"description": [
			"  We propose NNStreamer, a software system that handles neural networks as\nfilters of stream pipelines, applying the stream processing paradigm to deep\nneural network applications. A new trend with the wide-spread of deep neural\nnetwork applications is on-device AI. It is to process neural networks on\nmobile devices or edge/IoT devices instead of cloud servers. Emerging privacy\nissues, data transmission costs, and operational costs signify the need for\non-device AI, especially if we deploy a massive number of devices. NNStreamer\nefficiently handles neural networks with complex data stream pipelines on\ndevices, significantly improving the overall performance with minimal efforts.\nBesides, NNStreamer simplifies implementations and allows reusing off-the-shelf\nmedia filters directly, which reduces developmental costs significantly. We are\nalready deploying NNStreamer for a wide range of products and platforms,\nincluding the Galaxy series and various consumer electronic devices. The\nexperimental results suggest a reduction in developmental costs and enhanced\nperformance of pipeline architectures and NNStreamer. It is an open-source\nproject incubated by Linux Foundation AI, available to the public and\napplicable to various hardware and software platforms.\n",
			"Comment: IEEE/ACM ICSE 2021 SEIP (preprint)"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06371",
		"pdf_url": "http://arxiv.org/pdf/2101.06371.pdf"
	},
	"894": {
		"title": "An Empirical Comparison of Deep Learning Models for Knowledge Tracing on\n  Large-Scale Dataset",
		"creator": [
			"Pandey, Shalini",
			"Karypis, George",
			"Srivastava, Jaideep"
		],
		"subject": "Computer Science - Artificial Intelligence",
		"description": [
			"  Knowledge tracing (KT) is the problem of modeling each student's mastery of\nknowledge concepts (KCs) as (s)he engages with a sequence of learning\nactivities. It is an active research area to help provide learners with\npersonalized feedback and materials. Various deep learning techniques have been\nproposed for solving KT. Recent release of large-scale student performance\ndataset \\cite{choi2019ednet} motivates the analysis of performance of deep\nlearning approaches that have been proposed to solve KT. Our analysis can help\nunderstand which method to adopt when large dataset related to student\nperformance is available. We also show that incorporating contextual\ninformation such as relation between exercises and student forget behavior\nfurther improves the performance of deep learning models.\n",
			"Comment: Accepted at AAAI workshop on AI in Education, Imagining Post-COVID\n  Education with AI, 2021"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06373",
		"pdf_url": "http://arxiv.org/pdf/2101.06373.pdf"
	},
	"895": {
		"title": "A Novel Local Binary Pattern Based Blind Feature Image Steganography",
		"creator": [
			"Chakraborty, Soumendu",
			"Jalal, Anand Singh"
		],
		"subject": [
			"Computer Science - Multimedia",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  Steganography methods in general terms tend to embed more and more secret\nbits in the cover images. Most of these methods are designed to embed secret\ninformation in such a way that the change in the visual quality of the\nresulting stego image is not detectable. There exists some methods which\npreserve the global structure of the cover after embedding. However, the\nembedding capacity of these methods is very less. In this paper a novel feature\nbased blind image steganography technique is proposed, which preserves the LBP\n(Local binary pattern) feature of the cover with comparable embedding rates.\nLocal binary pattern is a well known image descriptor used for image\nrepresentation. The proposed scheme computes the local binary pattern to hide\nthe bits of the secret image in such a way that the local relationship that\nexists in the cover are preserved in the resulting stego image. The performance\nof the proposed steganography method has been tested on several images of\ndifferent types to show the robustness. State of the art LSB based\nsteganography methods are compared with the proposed method to show the\neffectiveness of feature based image steganography\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06383",
			"Multimedia Tools and Applications, vol-79, no-27-28, pp.\n  19561-19574, 2020",
			"doi:10.1007/s11042-020-08828-3"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06383.pdf"
	},
	"896": {
		"title": "Informative core identification in complex networks",
		"creator": [
			"Miao, Ruizhong",
			"Li, Tianxi"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning",
			"Statistics - Methodology"
		],
		"description": "  In network analysis, the core structure of modeling interest is usually\nhidden in a larger network in which most structures are not informative. The\nnoise and bias introduced by the non-informative component in networks can\nobscure the salient structure and limit many network modeling procedures'\neffectiveness. This paper introduces a novel core-periphery model for the\nnon-informative periphery structure of networks without imposing a specific\nform for the informative core structure. We propose spectral algorithms for\ncore identification as a data preprocessing step for general downstream network\nanalysis tasks based on the model. The algorithm enjoys a strong theoretical\nguarantee of accuracy and is scalable for large networks. We evaluate the\nproposed method by extensive simulation studies demonstrating various\nadvantages over many traditional core-periphery methods. The method is applied\nto extract the informative core structure from a citation network and give more\ninformative results in the downstream hierarchical community detection.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06388",
		"pdf_url": "http://arxiv.org/pdf/2101.06388.pdf"
	},
	"897": {
		"title": "GridTracer: Automatic Mapping of Power Grids using Deep Learning and\n  Overhead Imagery",
		"creator": [
			"Huang, Bohao",
			"Yang, Jichen",
			"Streltsov, Artem",
			"Bradbury, Kyle",
			"Collins, Leslie M.",
			"Malof, Jordan"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Energy system information valuable for electricity access planning such as\nthe locations and connectivity of electricity transmission and distribution\ntowers, termed the power grid, is often incomplete, outdated, or altogether\nunavailable. Furthermore, conventional means for collecting this information is\ncostly and limited. We propose to automatically map the grid in overhead\nremotely sensed imagery using deep learning. Towards this goal, we develop and\npublicly-release a large dataset ($263km^2$) of overhead imagery with ground\ntruth for the power grid, to our knowledge this is the first dataset of its\nkind in the public domain. Additionally, we propose scoring metrics and\nbaseline algorithms for two grid mapping tasks: (1) tower recognition and (2)\npower line interconnection (i.e., estimating a graph representation of the\ngrid). We hope the availability of the training data, scoring metrics, and\nbaselines will facilitate rapid progress on this important problem to help\ndecision-makers address the energy needs of societies around the world.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06390",
		"pdf_url": "http://arxiv.org/pdf/2101.06390.pdf"
	},
	"898": {
		"title": "Unsupervised Noisy Tracklet Person Re-identification",
		"creator": [
			"Li, Minxian",
			"Zhu, Xiatian",
			"Gong, Shaogang"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Existing person re-identification (re-id) methods mostly rely on supervised\nmodel learning from a large set of person identity labelled training data per\ndomain. This limits their scalability and usability in large scale deployments.\nIn this work, we present a novel selective tracklet learning (STL) approach\nthat can train discriminative person re-id models from unlabelled tracklet data\nin an unsupervised manner. This avoids the tedious and costly process of\nexhaustively labelling person image/tracklet true matching pairs across camera\nviews. Importantly, our method is particularly more robust against arbitrary\nnoisy data of raw tracklets therefore scalable to learning discriminative\nmodels from unconstrained tracking data. This differs from a handful of\nexisting alternative methods that often assume the existence of true matches\nand balanced tracklet samples per identity class. This is achieved by\nformulating a data adaptive image-to-tracklet selective matching loss function\nexplored in a multi-camera multi-task deep learning model structure. Extensive\ncomparative experiments demonstrate that the proposed STL model surpasses\nsignificantly the state-of-the-art unsupervised learning and one-shot learning\nre-id methods on three large tracklet person re-id benchmarks.\n",
			"Comment: was submitted to ICCV2019"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06391",
		"pdf_url": "http://arxiv.org/pdf/2101.06391.pdf"
	},
	"899": {
		"title": "Real Time Incremental Foveal Texture Mapping for Autonomous Vehicles",
		"creator": [
			"Kumar, Ashish",
			"McBride, James R.",
			"Pandey, Gaurav"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Robotics"
		],
		"description": [
			"  We propose an end-to-end real time framework to generate high resolution\ngraphics grade textured 3D map of urban environment. The generated detailed map\nfinds its application in the precise localization and navigation of autonomous\nvehicles. It can also serve as a virtual test bed for various vision and\nplanning algorithms as well as a background map in the computer games. In this\npaper, we focus on two important issues: (i) incrementally generating a map\nwith coherent 3D surface, in real time and (ii) preserving the quality of color\ntexture. To handle the above issues, firstly, we perform a pose-refinement\nprocedure which leverages camera image information, Delaunay triangulation and\nexisting scan matching techniques to produce high resolution 3D map from the\nsparse input LIDAR scan. This 3D map is then texturized and accumulated by\nusing a novel technique of ray-filtering which handles occlusion and\ninconsistencies in pose-refinement. Further, inspired by human fovea, we\nintroduce foveal-processing which significantly reduces the computation time\nand also assists ray-filtering to maintain consistency in color texture and\ncoherency in 3D surface of the output map. Moreover, we also introduce texture\nerror (TE) and mean texture mapping error (MTME), which provides quantitative\nmeasure of texturing and overall quality of the textured maps.\n",
			"Comment: 8 Pages, 10 Figures, 2 Tables. 2018 IEEE/RSJ International Conference\n  on Intelligent Robots and Systems (IROS). IEEE, 2018"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06393",
		"pdf_url": "http://arxiv.org/pdf/2101.06393.pdf"
	},
	"900": {
		"title": "To Understand Representation of Layer-aware Sequence Encoders as\n  Multi-order-graph",
		"creator": [
			"Duan, Sufeng",
			"Zhao, Hai",
			"Wang, Rui"
		],
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  In this paper, we propose a unified explanation of representation for\nlayer-aware neural sequence encoders, which regards the representation as a\nrevisited multigraph called multi-order-graph (MoG), so that model encoding can\nbe viewed as a processing to capture all subgraphs in MoG. The relationship\nreflected by Multi-order-graph, called $n$-order dependency, can present what\nexisting simple directed graph explanation cannot present. Our proposed MoG\nexplanation allows to precisely observe every step of the generation of\nrepresentation, put diverse relationship such as syntax into a unifiedly\ndepicted framework. Based on the proposed MoG explanation, we further propose a\ngraph-based self-attention network empowered Graph-Transformer by enhancing the\nability of capturing subgraph information over the current models.\nGraph-Transformer accommodates different subgraphs into different groups, which\nallows model to focus on salient subgraphs. Result of experiments on neural\nmachine translation tasks show that the MoG-inspired model can yield effective\nperformance improvement.\n",
			"Comment: arXiv admin note: text overlap with arXiv:2009.07489"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06397",
		"pdf_url": "http://arxiv.org/pdf/2101.06397.pdf"
	},
	"901": {
		"title": "ComQA:Compositional Question Answering via Hierarchical Graph Neural\n  Networks",
		"creator": [
			"Wang, Bingning",
			"Yao, Ting",
			"Chen, Weipeng",
			"Xu, Jingfang",
			"Wang, Xiaochuan"
		],
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  With the development of deep learning techniques and large scale datasets,\nthe question answering (QA) systems have been quickly improved, providing more\naccurate and satisfying answers. However, current QA systems either focus on\nthe sentence-level answer, i.e., answer selection, or phrase-level answer,\ni.e., machine reading comprehension. How to produce compositional answers has\nnot been throughout investigated. In compositional question answering, the\nsystems should assemble several supporting evidence from the document to\ngenerate the final answer, which is more difficult than sentence-level or\nphrase-level QA. In this paper, we present a large-scale compositional question\nanswering dataset containing more than 120k human-labeled questions. The answer\nin this dataset is composed of discontiguous sentences in the corresponding\ndocument. To tackle the ComQA problem, we proposed a hierarchical graph neural\nnetworks, which represents the document from the low-level word to the\nhigh-level sentence. We also devise a question selection and node selection\ntask for pre-training. Our proposed model achieves a significant improvement\nover previous machine reading comprehension methods and pre-training methods.\nCodes and dataset can be found at \\url{https://github.com/benywon/ComQA}.\n",
			"Comment: Accepted by WWW2021"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06400",
		"pdf_url": "http://arxiv.org/pdf/2101.06400.pdf"
	},
	"902": {
		"title": "Semi Supervised Deep Quick Instance Detection and Segmentation",
		"creator": [
			"Kumar, Ashish",
			"Behera, L."
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Robotics"
		],
		"description": [
			"  In this paper, we present a semi supervised deep quick learning framework for\ninstance detection and pixel-wise semantic segmentation of images in a dense\nclutter of items. The framework can quickly and incrementally learn novel items\nin an online manner by real-time data acquisition and generating corresponding\nground truths on its own. To learn various combinations of items, it can\nsynthesize cluttered scenes, in real time. The overall approach is based on the\ntutor-child analogy in which a deep network (tutor) is pretrained for\nclass-agnostic object detection which generates labeled data for another deep\nnetwork (child). The child utilizes a customized convolutional neural network\nhead for the purpose of quick learning. There are broadly four key components\nof the proposed framework semi supervised labeling, occlusion aware clutter\nsynthesis, a customized convolutional neural network head, and instance\ndetection. The initial version of this framework was implemented during our\nparticipation in Amazon Robotics Challenge (ARC), 2017. Our system was ranked\n3rd, 4th and 5th worldwide in pick, stow-pick and stow task respectively. The\nproposed framework is an improved version over ARC17 where novel features such\nas instance detection and online learning has been added.\n",
			"Comment: 7 Pages, 7 Figures, 5 Tables. 2019 International Conference on\n  Robotics and Automation (ICRA). IEEE, 2019"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06405",
		"pdf_url": "http://arxiv.org/pdf/2101.06405.pdf"
	},
	"903": {
		"title": "Community Detection in Blockchain Social Networks",
		"creator": [
			"Wu, Sissi Xiaoxiao",
			"Wu, Zixian",
			"Chen, Shihui",
			"Li, Gangqiang",
			"Zhang, Shengli"
		],
		"subject": [
			"Computer Science - Social and Information Networks",
			"Computer Science - Information Theory"
		],
		"description": "  In this work, we consider community detection in blockchain networks. We\nspecifically take the Bitcoin network and Ethereum network as two examples,\nwhere community detection serves in different ways. For the Bitcoin network, we\nmodify the traditional community detection method and apply it to the\ntransaction social network to cluster users with similar characteristics. For\nthe Ethereum network, on the other hand, we define a bipartite social graph\nbased on the smart contract transactions. A novel community detection algorithm\nwhich is designed for low-rank signals on graph can help find users'\ncommunities based on user-token subscription. Based on these results, two\nstrategies are devised to deliver on-chain advertisements to those users in the\nsame community. We implement the proposed algorithms on real data. By adopting\nthe modified clustering algorithm, the community results in the Bitcoin network\nis basically consistent with the ground-truth of betting site community which\nhas been announced to the public. At the meanwhile, we run the proposed\nstrategy on real Ethereum data, visualize the results and implement an\nadvertisement delivery on the Ropsten test net.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06406",
		"pdf_url": "http://arxiv.org/pdf/2101.06406.pdf"
	},
	"904": {
		"title": "ACP: Automatic Channel Pruning via Clustering and Swarm Intelligence\n  Optimization for CNN",
		"creator": [
			"Chang, Jingfei",
			"Lu, Yang",
			"Xue, Ping",
			"Xu, Yiqun",
			"Wei, Zhen"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  As the convolutional neural network (CNN) gets deeper and wider in recent\nyears, the requirements for the amount of data and hardware resources have\ngradually increased. Meanwhile, CNN also reveals salient redundancy in several\ntasks. The existing magnitude-based pruning methods are efficient, but the\nperformance of the compressed network is unpredictable. While the accuracy loss\nafter pruning based on the structure sensitivity is relatively slight, the\nprocess is time-consuming and the algorithm complexity is notable. In this\narticle, we propose a novel automatic channel pruning method (ACP).\nSpecifically, we firstly perform layer-wise channel clustering via the\nsimilarity of the feature maps to perform preliminary pruning on the network.\nThen a population initialization method is introduced to transform the pruned\nstructure into a candidate population. Finally, we conduct searching and\noptimizing iteratively based on the particle swarm optimization (PSO) to find\nthe optimal compressed structure. The compact network is then retrained to\nmitigate the accuracy loss from pruning. Our method is evaluated against\nseveral state-of-the-art CNNs on three different classification datasets\nCIFAR-10/100 and ILSVRC-2012. On the ILSVRC-2012, when removing 64.36%\nparameters and 63.34% floating-point operations (FLOPs) of ResNet-50, the Top-1\nand Top-5 accuracy drop are less than 0.9%. Moreover, we demonstrate that\nwithout harming overall performance it is possible to compress SSD by more than\n50% on the target detection dataset PASCAL VOC. It further verifies that the\nproposed method can also be applied to other CNNs and application scenarios.\n",
			"Comment: 13 pages, 9 figures, 10 tables"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06407",
		"pdf_url": "http://arxiv.org/pdf/2101.06407.pdf"
	},
	"905": {
		"title": "Shape Back-Projection In 3D Scenes",
		"creator": [
			"Kumar, Ashish",
			"Behera, L."
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Robotics"
		],
		"description": [
			"  In this work, we propose a novel framework shape back-projection for\ncomputationally efficient point cloud processing in a probabilistic manner. The\nprimary component of the technique is shape histogram and a back-projection\nprocedure. The technique measures similarity between 3D surfaces, by analyzing\ntheir geometrical properties. It is analogous to color back-projection which\nmeasures similarity between images, simply by looking at their color\ndistributions. In the overall process, first, shape histogram of a sample\nsurface (e.g. planar) is computed, which captures the profile of surface\nnormals around a point in form of a probability distribution. Later, the\nhistogram is back-projected onto a test surface and a likelihood score is\nobtained. The score depicts that how likely a point in the test surface behaves\nsimilar to the sample surface, geometrically. Shape back-projection finds its\napplication in binary surface classification, high curvature edge detection in\nunorganized point cloud, automated point cloud labeling for 3D-CNNs\n(convolutional neural network) etc. The algorithm can also be used for\nreal-time robotic operations such as autonomous object picking in warehouse\nautomation, ground plane extraction for autonomous vehicles and can be deployed\neasily on computationally limited platforms (UAVs).\n",
			"Comment: 7 pages, 7 figures, 3 tables"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06409",
		"pdf_url": "http://arxiv.org/pdf/2101.06409.pdf"
	},
	"906": {
		"title": "Towards Deep Learning Assisted Autonomous UAVs for Manipulation Tasks in\n  GPS-Denied Environments",
		"creator": [
			"Kumar, Ashish",
			"Vohra, Mohit",
			"Prakash, Ravi",
			"Behera, L."
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  In this work, we present a pragmatic approach to enable unmanned aerial\nvehicle (UAVs) to autonomously perform highly complicated tasks of object pick\nand place. This paper is largely inspired by challenge-2 of MBZIRC 2020 and is\nprimarily focused on the task of assembling large 3D structures in outdoors and\nGPS-denied environments. Primary contributions of this system are: (i) a novel\ncomputationally efficient deep learning based unified multi-task visual\nperception system for target localization, part segmentation, and tracking,\n(ii) a novel deep learning based grasp state estimation, (iii) a retracting\nelectromagnetic gripper design, (iv) a remote computing approach which exploits\nstate-of-the-art MIMO based high speed (5000Mb/s) wireless links to allow the\nUAVs to execute compute intensive tasks on remote high end compute servers, and\n(v) system integration in which several system components are weaved together\nin order to develop an optimized software stack. We use DJI Matrice-600 Pro, a\nhex-rotor UAV and interface it with the custom designed gripper. Our framework\nis deployed on the specified UAV in order to report the performance analysis of\nthe individual modules. Apart from the manipulation system, we also highlight\nseveral hidden challenges associated with the UAVs in this context.\n",
			"Comment: 8 pages, 5 figures, 5 tables, 2020 IEEE/RSJ International Conference\n  on Intelligent Robots and Systems (IROS). IEEE, 2020"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06414",
		"pdf_url": "http://arxiv.org/pdf/2101.06414.pdf"
	},
	"907": {
		"title": "JITuNE: Just-In-Time Hyperparameter Tuning for Network Embedding\n  Algorithms",
		"creator": [
			"Guo, Mengying",
			"Yi, Tao",
			"Zhu, Yuqing",
			"Bao, Yungang"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Network embedding (NE) can generate succinct node representations for\nmassive-scale networks and enable direct applications of common machine\nlearning methods to the network structure. Various NE algorithms have been\nproposed and used in a number of applications, such as node classification and\nlink prediction. NE algorithms typically contain hyperparameters that are key\nto performance, but the hyperparameter tuning process can be time consuming. It\nis desirable to have the hyperparameters tuned within a specified length of\ntime. Although AutoML methods have been applied to the hyperparameter tuning of\nNE algorithms, the problem of how to tune hyperparameters in a given period of\ntime is not studied for NE algorithms before. In this paper, we propose JITuNE,\na just-in-time hyperparameter tuning framework for NE algorithms. Our JITuNE\nframework enables the time-constrained hyperparameter tuning for NE algorithms\nby employing the tuning over hierarchical network synopses and transferring the\nknowledge obtained on synopses to the whole network. The hierarchical\ngeneration of synopsis and a time-constrained tuning method enable the\nconstraining of overall tuning time. Extensive experiments demonstrate that\nJITuNE can significantly improve performances of NE algorithms, outperforming\nstate-of-the-art methods within the same number of algorithm runs.\n",
		"date": [
			"2021-01-16",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06427",
		"pdf_url": "http://arxiv.org/pdf/2101.06427.pdf"
	},
	"908": {
		"title": "Hashing and metric learning for charged particle tracking",
		"creator": [
			"Amrouche, Sabrina",
			"Kiehn, Moritz",
			"Golling, Tobias",
			"Salzburger, Andreas"
		],
		"subject": [
			"High Energy Physics - Experiment",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  We propose a novel approach to charged particle tracking at high intensity\nparticle colliders based on Approximate Nearest Neighbors search. With hundreds\nof thousands of measurements per collision to be reconstructed e.g. at the High\nLuminosity Large Hadron Collider, the currently employed combinatorial track\nfinding approaches become inadequate. Here, we use hashing techniques to\nseparate measurements into buckets of 20-50 hits and increase their purity\nusing metric learning. Two different approaches are studied to further resolve\ntracks inside buckets: Local Fisher Discriminant Analysis and Neural Networks\nfor triplet similarity learning. We demonstrate the proposed approach on\nsimulated collisions and show significant speed improvement with bucket\ntracking efficiency of 96% and a fake rate of 8% on unseen particle events.\n",
			"Comment: Second Workshop on Machine Learning and the Physical Sciences\n  (NeurIPS 2019), Vancouver, Canada"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06428",
		"pdf_url": "http://arxiv.org/pdf/2101.06428.pdf"
	},
	"909": {
		"title": "Hypernetworks: From Posets to Geometry",
		"creator": "Saucan, Emil",
		"subject": [
			"Mathematics - Algebraic Topology",
			"Computer Science - Computational Geometry",
			"Computer Science - Social and Information Networks",
			"Mathematics - Differential Geometry",
			"53Z50, 57Q70 55N31, 05C82"
		],
		"description": [
			"  We show that hypernetworks can be regarded as posets which, in their turn,\nhave a natural interpretation as simplicial complexes and, as such, are endowed\nwith an intrinsic notion of curvature, namely the Forman Ricci curvature, that\nstrongly correlates with the Euler characteristic of the simplicial complex.\nThis approach, inspired by the work of E. Bloch, allows us to canonically\nassociate a simplicial complex structure to a hypernetwork, directed or\nundirected. In particular, this greatly simplifying the geometric Persistent\nHomology method we previously proposed.\n",
			"Comment: 11 pages"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06429",
		"pdf_url": "http://arxiv.org/pdf/2101.06429.pdf"
	},
	"910": {
		"title": "New Low Rank Optimization Model and Convex Approach for Robust Spectral\n  Compressed Sensing",
		"creator": [
			"Yang, Zai",
			"Wu, Xunmeng"
		],
		"subject": [
			"Computer Science - Information Theory",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": [
			"  This paper investigates recovery of an undamped spectrally sparse signal and\nits spectral components from a set of regularly spaced samples within the\nframework of spectral compressed sensing and super-resolution. We show that the\nexisting Hankel-based optimization methods suffer from the fundamental\nlimitation that the prior of undampedness cannot be exploited. We propose a new\nlow rank optimization model partially inspired by forward-backward processing\nfor line spectral estimation and show its capability in restricting the\nspectral poles on the unit circle. We present convex relaxation approaches with\nthe model and show their provable accuracy and robustness to bounded and sparse\nnoise. All our results are generalized from the 1-D to arbitrary-dimensional\nspectral compressed sensing. Numerical simulations are provided that\ncorroborate our analysis and show efficiency of our model and advantageous\nperformance of our approach in improved accuracy and resolution as compared to\nthe state-of-the-art Hankel and atomic norm methods.\n",
			"Comment: 13 pages, double columns, 6 figures"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06433",
		"pdf_url": "http://arxiv.org/pdf/2101.06433.pdf"
	},
	"911": {
		"title": "Adaptive Remote Sensing Image Attribute Learning for Active Object\n  Detection",
		"creator": [
			"Xu, Nuo",
			"Huo, Chunlei",
			"Guo, Jiacheng",
			"Liu, Yiwei",
			"Wang, Jian",
			"Pan, Chunhong"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  In recent years, deep learning methods bring incredible progress to the field\nof object detection. However, in the field of remote sensing image processing,\nexisting methods neglect the relationship between imaging configuration and\ndetection performance, and do not take into account the importance of detection\nperformance feedback for improving image quality. Therefore, detection\nperformance is limited by the passive nature of the conventional object\ndetection framework. In order to solve the above limitations, this paper takes\nadaptive brightness adjustment and scale adjustment as examples, and proposes\nan active object detection method based on deep reinforcement learning. The\ngoal of adaptive image attribute learning is to maximize the detection\nperformance. With the help of active object detection and image attribute\nadjustment strategies, low-quality images can be converted into high-quality\nimages, and the overall performance is improved without retraining the\ndetector.\n",
			"Comment: Accepted in 25th International Conference on Pattern Recognition\n  (ICPR), (Milan, Italy), January 2021"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06438",
		"pdf_url": "http://arxiv.org/pdf/2101.06438.pdf"
	},
	"912": {
		"title": "Scale factor point spread function matching: Beyond aliasing in image\n  resampling",
		"creator": [
			"Cardoso, M. Jorge",
			"Modat, Marc",
			"Vercauteren, Tom",
			"Ourselin, Sebastien"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  Imaging devices exploit the Nyquist-Shannon sampling theorem to avoid both\naliasing and redundant oversampling by design. Conversely, in medical image\nresampling, images are considered as continuous functions, are warped by a\nspatial transformation, and are then sampled on a regular grid. In most cases,\nthe spatial warping changes the frequency characteristics of the continuous\nfunction and no special care is taken to ensure that the resampling grid\nrespects the conditions of the sampling theorem. This paper shows that this\noversight introduces artefacts, including aliasing, that can lead to important\nbias in clinical applications. One notable exception to this common practice is\nwhen multi-resolution pyramids are constructed, with low-pass \"anti-aliasing\"\nfilters being applied prior to downsampling. In this work, we illustrate why\nsimilar caution is needed when resampling images under general spatial\ntransformations and propose a novel method that is more respectful of the\nsampling theorem, minimising aliasing and loss of information. We introduce the\nnotion of scale factor point spread function (sfPSF) and employ Gaussian\nkernels to achieve a computationally tractable resampling scheme that can cope\nwith arbitrary non-linear spatial transformations and grid sizes. Experiments\ndemonstrate significant (p<1e-4) technical and clinical implications of the\nproposed method.\n",
			"Comment: Published in MICCAI 2015"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06440",
			"doi:10.1007/978-3-319-24571-3_81"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06440.pdf"
	},
	"913": {
		"title": "Evaluating User Experiences in Mixed Reality",
		"creator": [
			"Alexandrovsky, Dmitry",
			"Putze, Susanne",
			"Schwind, Valentin",
			"Mekler, Elisa D.",
			"Smeddinck, Jan David",
			"Kahl, Denise",
			"Krüger, Antonio",
			"Malaka, Rainer"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": [
			"  Measure user experience in MR (i.e., AR/VR) user studies is essential.\nResearchers apply a wide range of measuring methods using objective (e.g.,\nbiosignals, time logging), behavioral (e.g., gaze direction, movement\namplitude), and subjective (e.g., standardized questionnaires) metrics. Many of\nthese measurement instruments were adapted from use-cases outside of MR but\nhave not been validated for usage in MR experiments. However, researchers are\nfaced with various challenges and design alternatives when measuring immersive\nexperiences. These challenges become even more diverse when running out-of-the\nlab studies. Measurement methods of VR experience recently received much\nattention. For example, research has started embedding questionnaires in the VE\nfor various applications, allowing users to stay closer to the ongoing\nexperience while filling out the survey. However, there is a diversity in the\ninteraction methods and practices on how the assessment procedure is conducted.\nThis diversity in methods underlines a missing shared agreement of standardized\nmeasurement tools for VR experiences. AR research strongly orients on the\nresearch methods from VR, e.g., using the same type of subjective\nquestionnaires. However, some crucial technical differences require careful\nconsiderations during the evaluation. This workshop at CHI 2021 provides a\nfoundation to exchange expertise and address challenges and opportunities of\nresearch methods in MR user studies. By this, our workshop launches a\ndiscussion of research methods that should lead to standardizing assessment\nmethods in MR user studies. The outcomes of the workshop will be aggregated\ninto a collective special issue journal article.\n",
			"Comment: Workshop proposal at CHI '21"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06444",
		"pdf_url": "http://arxiv.org/pdf/2101.06444.pdf"
	},
	"914": {
		"title": "MPC-CSAS: Multi-Party Computation for Real-time Privacy-preserving Speed\n  Advisory Systems",
		"creator": [
			"Liu, Mingming",
			"Cheng, Long",
			"Gu, Yingqi",
			"Wang, Ying",
			"Liu, Qingzhi",
			"O'Connor, Noel E."
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  As a part of Advanced Driver Assistance Systems (ADASs), Consensus-based\nSpeed Advisory Systems (CSAS) have been proposed to recommend a common speed to\na group of vehicles for specific application purposes, such as emission control\nand energy management. With Vehicle-to-Vehicle (V2V), Vehicle-to-Infrastructure\n(V2I) technologies and advanced control theories in place, state-of-the-art\nCSAS can be designed to get an optimal speed in a privacy-preserving and\ndecentralized manner. However, the current method only works for specific cost\nfunctions of vehicles, and its execution usually involves many algorithm\niterations leading long convergence time. Therefore, the state-of-the-art\ndesign method is not applicable to a CSAS design which requires real-time\ndecision making. In this paper, we address the problem by introducing MPC-CSAS,\na Multi-Party Computation (MPC) based design approach for privacy-preserving\nCSAS. Our proposed method is simple to implement and applicable to all types of\ncost functions of vehicles. Moreover, our simulation results show that the\nproposed MPC-CSAS can achieve very promising system performance in just one\nalgorithm iteration without using extra infrastructure for a typical CSAS.\n",
			"Comment: This manuscript has been accepted by the IEEE Transactions on\n  Intelligent Transportation Systems"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06451",
		"pdf_url": "http://arxiv.org/pdf/2101.06451.pdf"
	},
	"915": {
		"title": "AGChain: A Blockchain-based Gateway for Permanent, Distributed, and\n  Secure App Delegation from Existing Mobile App Markets",
		"creator": [
			"Chen, Mengjie",
			"Wu, Daoyuan",
			"Yi, Xiao",
			"Xu, Jianliang"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Networking and Internet Architecture"
		],
		"description": [
			"  Mobile app markets are emerging with the popularity of smartphones. However,\nthey fall short in several aspects, including no transparent app listing, no\nworld-wide app access, and even insecure app downloading. To address these\nproblems, we propose a novel blockchain-based gateway, AGChain, to bridge end\nusers and app markets so that existing app markets could still provide services\nwhile users enjoy permanent, distributed, and secure app delegation from\nAGChain. To this end, we identify two previously under-estimated challenges and\npropose mechanisms to significantly reduce gas costs in our smart contract and\nmake IPFS (Inter-planetary File System) based file storage really distributed.\nWe also address three AGChain-specific system challenges to make it secure and\nsustainable. We have implemented an AGChain prototype\n(https://www.agchain.ltd/) on Ethereum. The evaluation shows that it achieves\nsecurity and decentralization with minimal gas costs and reasonable\nperformance.\n",
			"Comment: This is a technical report from The Chinese Chinese University of\n  Hong Kong"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06454",
		"pdf_url": "http://arxiv.org/pdf/2101.06454.pdf"
	},
	"916": {
		"title": "Robustness to Augmentations as a Generalization metric",
		"creator": [
			"K, Sumukh Aithal",
			"Kashyap, Dhruva",
			"Subramanyam, Natarajan"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  Generalization is the ability of a model to predict on unseen domains and is\na fundamental task in machine learning. Several generalization bounds, both\ntheoretical and empirical have been proposed but they do not provide tight\nbounds .In this work, we propose a simple yet effective method to predict the\ngeneralization performance of a model by using the concept that models that are\nrobust to augmentations are more generalizable than those which are not. We\nexperiment with several augmentations and composition of augmentations to check\nthe generalization capacity of a model. We also provide a detailed motivation\nbehind the proposed method. The proposed generalization metric is calculated\nbased on the change in the output of the model after augmenting the input. The\nproposed method was the first runner up solution for the NeurIPS competition on\nPredicting Generalization in Deep Learning.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06459",
		"pdf_url": "http://arxiv.org/pdf/2101.06459.pdf"
	},
	"917": {
		"title": "On linear codes with one-dimensional Euclidean hull and their\n  applications to EAQECCs",
		"creator": "Sok, Lin",
		"subject": "Computer Science - Information Theory",
		"description": [
			"  The Euclidean hull of a linear code $C$ is the intersection of $C$ with its\nEuclidean dual $C^\\perp$. The hull with low dimensions gets much interest due\nto its crucial role in determining the complexity of algorithms for computing\nthe automorphism group of a linear code and checking permutation equivalence of\ntwo linear codes. The Euclidean hull of a linear code has been applied to the\nso-called entanglement-assisted quantum error-correcting codes (EAQECCs) via\nclassical error-correcting codes. In this paper, we consider linear codes with\none-dimensional Euclidean hull from algebraic geometry codes. Several classes\nof optimal linear codes with one-dimensional Euclidean hull are constructed.\nSome new EAQECCs are presented.\n",
			"Comment: 13 pages"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06461",
		"pdf_url": "http://arxiv.org/pdf/2101.06461.pdf"
	},
	"918": {
		"title": "Galleon: Reshaping the Square Peg of NFV",
		"creator": [
			"Wang, Jianfeng",
			"Lévai, Tamás",
			"Li, Zhuojin",
			"Vieira, Marcos A. M.",
			"Govindan, Ramesh",
			"Raghavan, Barath"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Networking and Internet Architecture"
		],
		"description": [
			"  Software is often used for Network Functions (NFs) -- such as firewalls, NAT,\ndeep packet inspection, and encryption -- that are applied to traffic in the\nnetwork. The community has hoped that NFV would enable rapid development of new\nNFs and leverage commodity computing infrastructure. However, the challenge for\nresearchers and operators has been to align the square peg of high-speed packet\nprocessing with the round hole of cloud computing infrastructures and\nabstractions, all while delivering performance, scalability, and isolation.\nPast work has led to the belief that NFV is different enough that it requires\nnovel, custom approaches that deviate from today's norms. To the contrary, we\nshow that we can achieve performance, scalability, and isolation in NFV\njudiciously using mechanisms and abstractions of FaaS, the Linux kernel, NIC\nhardware, and OpenFlow switches. As such, with our system Galleon, NFV can be\npractically-deployable today in conventional cloud environments while\ndelivering up to double the performance per core compared to the state of the\nart.\n",
			"Comment: 14 pages"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06466",
		"pdf_url": "http://arxiv.org/pdf/2101.06466.pdf"
	},
	"919": {
		"title": "Adversarial cycle-consistent synthesis of cerebral microbleeds for data\n  augmentation",
		"creator": [
			"Faryna, Khrystyna",
			"Koschmieder, Kevin",
			"Paul, Marcella M.",
			"Heuvel, Thomas van den",
			"van der Eerden, Anke",
			"Manniesing, Rashindra",
			"van Ginneken, Bram"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  We propose a novel framework for controllable pathological image synthesis\nfor data augmentation. Inspired by CycleGAN, we perform cycle-consistent\nimage-to-image translation between two domains: healthy and pathological.\nGuided by a semantic mask, an adversarially trained generator synthesizes\npathology on a healthy image in the specified location. We demonstrate our\napproach on an institutional dataset of cerebral microbleeds in traumatic brain\ninjury patients. We utilize synthetic images generated with our method for data\naugmentation in cerebral microbleeds detection. Enriching the training dataset\nwith synthetic images exhibits the potential to increase detection performance\nfor cerebral microbleeds in traumatic brain injury patients.\n",
			"Comment: Accepted in Medical Imaging meets NIPS Workshop, NIPS 2020"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06468",
		"pdf_url": "http://arxiv.org/pdf/2101.06468.pdf"
	},
	"920": {
		"title": "Learning the Implicit Semantic Representation on Graph-Structured Data",
		"creator": [
			"Wu, Likang",
			"Li, Zhi",
			"Zhao, Hongke",
			"Liu, Qi",
			"Wang, Jun",
			"Zhang, Mengdi",
			"Chen, Enhong"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Existing representation learning methods in graph convolutional networks are\nmainly designed by describing the neighborhood of each node as a perceptual\nwhole, while the implicit semantic associations behind highly complex\ninteractions of graphs are largely unexploited. In this paper, we propose a\nSemantic Graph Convolutional Networks (SGCN) that explores the implicit\nsemantics by learning latent semantic-paths in graphs. In previous work, there\nare explorations of graph semantics via meta-paths. However, these methods\nmainly rely on explicit heterogeneous information that is hard to be obtained\nin a large amount of graph-structured data. SGCN first breaks through this\nrestriction via leveraging the semantic-paths dynamically and automatically\nduring the node aggregating process. To evaluate our idea, we conduct\nsufficient experiments on several standard datasets, and the empirical results\nshow the superior performance of our model.\n",
			"Comment: 16 pages, DASFAA 2021"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06471",
		"pdf_url": "http://arxiv.org/pdf/2101.06471.pdf"
	},
	"921": {
		"title": "Visual Analytics approach for finding spatiotemporal patterns from\n  COVID19",
		"creator": "Das, Arunav",
		"subject": [
			"Computer Science - Machine Learning",
			"Economics - General Economics"
		],
		"description": [
			"  Bounce Back Loan is amongst a number of UK business financial support schemes\nlaunched by UK Government in 2020 amidst pandemic lockdown. Through these\nschemes, struggling businesses are provided financial support to weather\neconomic slowdown from pandemic lockdown. {\\pounds}43.5bn loan value has been\nprovided as of 17th Dec2020. However, with no major checks for granting these\nloans and looming prospect of loan losses from write-offs from failed\nbusinesses and fraud, this paper theorizes prospect of applying spatiotemporal\nmodelling technique to explore if geospatial patterns and temporal analysis\ncould aid design of loan grant criteria for schemes. Application of Clustering\nand Visual Analytics framework to business demographics, survival rate and\nSector concentration shows Inner and Outer London spatial patterns which\nhistoric business failures and reversal of the patterns under COVID-19 implying\nsector influence on spatial clusters. Combination of unsupervised clustering\ntechnique with multinomial logistic regression modelling on research datasets\ncomplimented by additional datasets on other support schemes, business\nstructure and financial crime, is recommended for modelling business\nvulnerability to certain types of financial market or economic condition. The\nlimitations of clustering technique for high dimensional is discussed along\nwith relevance of an applicable model for continuing the research through next\nsteps.\n",
			"Comment: Coursework / concept paper"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06476",
		"pdf_url": "http://arxiv.org/pdf/2101.06476.pdf"
	},
	"922": {
		"title": "Wearable Sensors for Spatio-Temporal Grip Force Profiling",
		"creator": [
			"Liu, Rongrong",
			"Nageotte, Florent",
			"Zanne, Philippe",
			"de Mathelin, Michel",
			"Dresp-Langley, Birgitta"
		],
		"subject": "Computer Science - Robotics",
		"description": "  Wearable biosensor technology enables real-time, convenient, and continuous\nmonitoring of users behavioral signals. Such include signals relative to body\nmotion, body temperature, biological or biochemical markers, and individual\ngrip forces, which are studied in this paper. A four step pick and drop image\nguided and robot assisted precision task has been designed for exploiting a\nwearable wireless sensor glove system. Individual spatio temporal grip forces\nare analyzed on the basis of thousands of individual sensor data, collected\nfrom different locations on the dominant and non-dominant hands of each of\nthree users in ten successive task sessions. Statistical comparisons reveal\nspecific differences between grip force profiles of the individual users as a\nfunction of task skill level (expertise) and time.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06479",
			"Proceedings of the 1st IFSA Winter Conference on Automation,\n  Robotics, and Communications for Industry 4.0, 2021, Chamonix-Mont-Blanc,\n  France"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06479.pdf"
	},
	"923": {
		"title": "SelfMatch: Combining Contrastive Self-Supervision and Consistency for\n  Semi-Supervised Learning",
		"creator": [
			"Kim, Byoungjip",
			"Choo, Jinho",
			"Kwon, Yeong-Dae",
			"Joe, Seongho",
			"Min, Seungjai",
			"Gwon, Youngjune"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  This paper introduces SelfMatch, a semi-supervised learning method that\ncombines the power of contrastive self-supervised learning and consistency\nregularization. SelfMatch consists of two stages: (1) self-supervised\npre-training based on contrastive learning and (2) semi-supervised fine-tuning\nbased on augmentation consistency regularization. We empirically demonstrate\nthat SelfMatch achieves the state-of-the-art results on standard benchmark\ndatasets such as CIFAR-10 and SVHN. For example, for CIFAR-10 with 40 labeled\nexamples, SelfMatch achieves 93.19% accuracy that outperforms the strong\nprevious methods such as MixMatch (52.46%), UDA (70.95%), ReMixMatch (80.9%),\nand FixMatch (86.19%). We note that SelfMatch can close the gap between\nsupervised learning (95.87%) and semi-supervised learning (93.19%) by using\nonly a few labels for each class.\n",
			"Comment: 4 pages, NeurIPS 2020 Workshop: Self-Supervised Learning - Theory and\n  Practice"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06480",
		"pdf_url": "http://arxiv.org/pdf/2101.06480.pdf"
	},
	"924": {
		"title": "From hand to brain and back: Grip forces deliver insight into the\n  functional plasticity of somatosensory processes",
		"creator": "Dresp-Langley, Birgitta",
		"subject": "Computer Science - Robotics",
		"description": "  The human somatosensory cortex is intimately linked to other central brain\nfunctions such as vision, audition, mechanoreception, and motor planning and\ncontrol. These links are established through brain learning, and display a\nconsiderable functional plasticity. This latter fulfills an important adaptive\nrole and ensures, for example, that humans are able to reliably manipulate and\ncontrol objects in the physical world under constantly changing conditions in\ntheir immediate sensory environment. Variations in human grip force are a\ndirect reflection of this specific kind of functional plasticity. Data from\npreliminary experiments where wearable wireless sensor technology (sensor\ngloves) was exploited to measure human grip force variations under varying\nsensory input conditions (eyes open or shut, soft music or hard music during\ngripping) are discussed here to show the extent to which grip force sensing\npermits quantifying somatosensory brain interactions and their functional\nplasticity. Experiments to take this preliminary work further are suggested.\nImplications for robotics, in particular the development of end-effector robots\nfor upper limb movement planning and control, are brought forward.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06483",
			"Proceedings of the 1st IFSA Winter Conference on Automation,\n  Robotics, and Communications for Industry 4.0, 2021, Chamonix-Mont-Blanc,\n  France"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06483.pdf"
	},
	"925": {
		"title": "Artificial Intelligence for Emotion-Semantic Trending and People Emotion\n  Detection During COVID-19 Social Isolation",
		"creator": [
			"Jelodar, Hamed",
			"Orji, Rita",
			"Matwin, Stan",
			"Weerasinghe, Swarna",
			"Oyebode, Oladapo",
			"Wang, Yongli"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Information Retrieval",
			"Computer Science - Social and Information Networks"
		],
		"description": "  Taking advantage of social media platforms, such as Twitter, this paper\nprovides an effective framework for emotion detection among those who are\nquarantined. Early detection of emotional feelings and their trends help\nimplement timely intervention strategies. Given the limitations of medical\ndiagnosis of early emotional change signs during the quarantine period,\nartificial intelligence models provide effective mechanisms in uncovering early\nsigns, symptoms and escalating trends. Novelty of the approach presented herein\nis a multitask methodological framework of text data processing, implemented as\na pipeline for meaningful emotion detection and analysis, based on the\nPlutchik/Ekman approach to emotion detection and trend detection. We present an\nevaluation of the framework and a pilot system. Results of confirm the\neffectiveness of the proposed framework for topic trends and emotion detection\nof COVID-19 tweets. Our findings revealed Stay-At-Home restrictions result in\npeople expressing on twitter both negative and positive emotional semantics.\nSemantic trends of safety issues related to staying at home rapidly decreased\nwithin the 28 days and also negative feelings related to friends dying and\nquarantined life increased in some days. These findings have potential to\nimpact public health policy decisions through monitoring trends of emotional\nfeelings of those who are quarantined. The framework presented here has\npotential to assist in such monitoring by using as an online emotion detection\ntool kit.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06484",
		"pdf_url": "http://arxiv.org/pdf/2101.06484.pdf"
	},
	"926": {
		"title": "T-Lease: A Trusted Lease Primitive for Distributed Systems",
		"creator": [
			"Trach, Bohdan",
			"Faqeh, Rasha",
			"Oleksenko, Oleksii",
			"Ozga, Wojciech",
			"Bhatotia, Pramod",
			"Fetzer, Christof"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Cryptography and Security"
		],
		"description": "  A lease is an important primitive for building distributed protocols, and it\nis ubiquitously employed in distributed systems. However, the scope of the\nclassic lease abstraction is restricted to the trusted computing\ninfrastructure. Unfortunately, this important primitive cannot be employed in\nthe untrusted computing infrastructure because the trusted execution\nenvironments (TEEs) do not provide a trusted time source. In the untrusted\nenvironment, an adversary can easily manipulate the system clock to violate the\ncorrectness properties of lease-based systems. We tackle this problem by\nintroducing trusted lease -- a lease that maintains its correctness properties\neven in the presence of a clock-manipulating attacker. To achieve these\nproperties, we follow a \"trust but verify\" approach for an untrusted timer, and\ntransform it into a trusted timing primitive by leveraging two\nhardware-assisted ISA extensions (Intel TSX and SGX) available in commodity\nCPUs. We provide a design and implementation of trusted lease in a system\ncalled T-Lease -- the first trusted lease system that achieves high security,\nperformance, and precision. For the application developers, T-Lease exposes an\neasy-to-use generic APIs that facilitate its usage to build a wide range of\ndistributed protocols.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06485",
		"pdf_url": "http://arxiv.org/pdf/2101.06485.pdf"
	},
	"927": {
		"title": "Blind Optimal User Association in Small-Cell Networks",
		"creator": [
			"Chatzieleftheriou, Livia Elena",
			"Destounis, Apostolos",
			"Paschos, Georgios",
			"Koutsopoulos, Iordanis"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": [
			"  We learn optimal user association policies for traffic from different\nlocations to Access Points(APs), in the presence of unknown dynamic traffic\ndemand. We aim at minimizing a broad family of $\\alpha$-fair cost functions\nthat express various objectives in load assignment in the wireless downlink,\nsuch as total load or total delay minimization. Finding an optimal user\nassociation policy in dynamic environments is challenging because traffic\ndemand fluctuations over time are non-stationary and difficult to characterize\nstatistically, which obstructs the computation of cost-efficient associations.\nAssuming arbitrary traffic patterns over time, we formulate the problem of\nonline learning of optimal user association policies using the Online Convex\nOptimization (OCO) framework. We introduce a periodic benchmark for OCO\nproblems that generalizes state-of-the-art benchmarks. We exploit inherent\nproperties of the online user association problem and propose PerOnE, a simple\nonline learning scheme that dynamically adapts the association policy to\narbitrary traffic demand variations. We compare PerOnE against our periodic\nbenchmark and prove that it enjoys the no-regret property, with additional\nsublinear dependence of the network size. To the best of our knowledge, this is\nthe first work that introduces a periodic benchmark for OCO problems and a\nno-regret algorithm for the online user association problem. Our theoretical\nfindings are validated through results on a real-trace dataset.\n",
			"Comment: To appear in IEEE International Conference on Computer Communication\n  (INFOCOM) 2021"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06495",
		"pdf_url": "http://arxiv.org/pdf/2101.06495.pdf"
	},
	"928": {
		"title": "Bladder segmentation based on deep learning approaches: current\n  limitations and lessons",
		"creator": [
			"Bandyk, Mark G.",
			"Gopireddy, Dheeraj R",
			"Lall, Chandana",
			"Balaji, K. C.",
			"Dolz, Jose"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Precise determination and assessment of bladder cancer (BC) extent of muscle\ninvasion involvement guides proper risk stratification and personalized therapy\nselection. In this context, segmentation of both bladder walls and cancer are\nof pivotal importance, as it provides invaluable information to stage the\nprimary tumour. Hence, multi region segmentation on patients presenting with\nsymptoms of bladder tumours using deep learning heralds a new level of staging\naccuracy and prediction of the biologic behaviour of the tumour. Nevertheless,\ndespite the success of these models in other medical problems, progress in\nmulti region bladder segmentation is still at a nascent stage, with just a\nhandful of works tackling a multi region scenario. Furthermore, most existing\napproaches systematically follow prior literature in other clinical problems,\nwithout casting a doubt on the validity of these methods on bladder\nsegmentation, which may present different challenges. Inspired by this, we\nprovide an in-depth look at bladder cancer segmentation using deep learning\nmodels. The critical determinants for accurate differentiation of muscle\ninvasive disease, current status of deep learning based bladder segmentation,\nlessons and limitations of prior work are highlighted.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06498",
		"pdf_url": "http://arxiv.org/pdf/2101.06498.pdf"
	},
	"929": {
		"title": "Stable Matching for Selection of Intelligent Reflecting Surfaces in\n  Multiuser MISO Systems",
		"creator": [
			"Mirza, Jawad",
			"Ali, Bakhtiar",
			"Javed, Muhammad Awais"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  In this letter, we present an intelligent reflecting surface (IRS) selection\nstrategy for multiple IRSs aided multiuser multiple-input single-output (MISO)\nsystems. In particular, we pose the IRS selection problem as a stable matching\nproblem. A two stage user-IRS assignment algorithm is proposed, where the main\nobjective is to carry out a stable user-IRS matching, such that the sum rate of\nthe system is improved. The first stage of the proposed algorithm employs a\nwell-known Gale Shapley matching designed for the stable marriage problem.\nHowever, due to interference in multiuser systems, the matching obtained after\nthe first stage may not be stable. To overcome this issue, one-sided (i.e.,\nonly IRSs) blocking pairs (BPs) are identified in the second stage of the\nproposed algorithm, where the BP is a pair of IRSs which are better off after\nexchanging their partners. Thus, the second stage validates the stable matching\nin the proposed algorithm. Numerical results show that the proposed assignment\nachieves better sum rate performance compared to distance-based and random\nmatching algorithms.\n",
			"Comment: 5 pages and 4 figures, submitted for publication"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06502",
		"pdf_url": "http://arxiv.org/pdf/2101.06502.pdf"
	},
	"930": {
		"title": "Multi-objective Search of Robust Neural Architectures against Multiple\n  Types of Adversarial Attacks",
		"creator": [
			"Liu, Jia",
			"Jin, Yaochu"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Neural and Evolutionary Computing"
		],
		"description": "  Many existing deep learning models are vulnerable to adversarial examples\nthat are imperceptible to humans. To address this issue, various methods have\nbeen proposed to design network architectures that are robust to one particular\ntype of adversarial attacks. It is practically impossible, however, to predict\nbeforehand which type of attacks a machine learn model may suffer from. To\naddress this challenge, we propose to search for deep neural architectures that\nare robust to five types of well-known adversarial attacks using a\nmulti-objective evolutionary algorithm. To reduce the computational cost, a\nnormalized error rate of a randomly chosen attack is calculated as the\nrobustness for each newly generated neural architecture at each generation. All\nnon-dominated network architectures obtained by the proposed method are then\nfully trained against randomly chosen adversarial attacks and tested on two\nwidely used datasets. Our experimental results demonstrate the superiority of\noptimized neural architectures found by the proposed approach over\nstate-of-the-art networks that are widely used in the literature in terms of\nthe classification accuracy under different adversarial attacks.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06507",
		"pdf_url": "http://arxiv.org/pdf/2101.06507.pdf"
	},
	"931": {
		"title": "Phases of learning dynamics in artificial neural networks: with or\n  without mislabeled data",
		"creator": [
			"Feng, Yu",
			"Tu, Yuhai"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Condensed Matter - Statistical Mechanics",
			"Physics - Data Analysis, Statistics and Probability"
		],
		"description": "  Despite tremendous success of deep neural network in machine learning, the\nunderlying reason for its superior learning capability remains unclear. Here,\nwe present a framework based on statistical physics to study dynamics of\nstochastic gradient descent (SGD) that drives learning in neural networks. By\nusing the minibatch gradient ensemble, we construct order parameters to\ncharacterize dynamics of weight updates in SGD. Without mislabeled data, we\nfind that the SGD learning dynamics transitions from a fast learning phase to a\nslow exploration phase, which is associated with large changes in order\nparameters that characterize the alignment of SGD gradients and their mean\namplitude. In the case with randomly mislabeled samples, SGD learning dynamics\nfalls into four distinct phases. The system first finds solutions for the\ncorrectly labeled samples in phase I, it then wanders around these solutions in\nphase II until it finds a direction to learn the mislabeled samples during\nphase III, after which it finds solutions that satisfy all training samples\nduring phase IV. Correspondingly, the test error decreases during phase I and\nremains low during phase II; however, it increases during phase III and reaches\na high plateau during phase IV. The transitions between different phases can be\nunderstood by changes of order parameters that characterize the alignment of\nmean gradients for the correctly and incorrectly labeled samples and their\n(relative) strength during learning. We find that individual sample losses for\nthe two datasets are most separated during phase II, which leads to a cleaning\nprocess to eliminate mislabeled samples for improving generalization.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06509",
		"pdf_url": "http://arxiv.org/pdf/2101.06509.pdf"
	},
	"932": {
		"title": "Towards Searching Efficient and Accurate Neural Network Architectures in\n  Binary Classification Problems",
		"creator": [
			"Alparslan, Yigit",
			"Moyer, Ethan Jacob",
			"Isozaki, Isamu Mclean",
			"Schwartz, Daniel",
			"Dunlop, Adam",
			"Dave, Shesh",
			"Kim, Edward"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  In recent years, deep neural networks have had great success in machine\nlearning and pattern recognition. Architecture size for a neural network\ncontributes significantly to the success of any neural network. In this study,\nwe optimize the selection process by investigating different search algorithms\nto find a neural network architecture size that yields the highest accuracy. We\napply binary search on a very well-defined binary classification network search\nspace and compare the results to those of linear search. We also propose how to\nrelax some of the assumptions regarding the dataset so that our solution can be\ngeneralized to any binary classification problem. We report a 100-fold running\ntime improvement over the naive linear search when we apply the binary search\nmethod to our datasets in order to find the best architecture candidate. By\nfinding the optimal architecture size for any binary classification problem\nquickly, we hope that our research contributes to discovering intelligent\nalgorithms for optimizing architecture size selection in machine learning.\n",
			"Comment: 8 pages, 11 figures"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06511",
		"pdf_url": "http://arxiv.org/pdf/2101.06511.pdf"
	},
	"933": {
		"title": "Linguistically-Enriched and Context-Aware Zero-shot Slot Filling",
		"creator": [
			"Siddique, A. B.",
			"Jamour, Fuad",
			"Hristidis, Vagelis"
		],
		"subject": "Computer Science - Computation and Language",
		"description": "  Slot filling is identifying contiguous spans of words in an utterance that\ncorrespond to certain parameters (i.e., slots) of a user request/query. Slot\nfilling is one of the most important challenges in modern task-oriented dialog\nsystems. Supervised learning approaches have proven effective at tackling this\nchallenge, but they need a significant amount of labeled training data in a\ngiven domain. However, new domains (i.e., unseen in training) may emerge after\ndeployment. Thus, it is imperative that these models seamlessly adapt and fill\nslots from both seen and unseen domains -- unseen domains contain unseen slot\ntypes with no training data, and even seen slots in unseen domains are\ntypically presented in different contexts. This setting is commonly referred to\nas zero-shot slot filling. Little work has focused on this setting, with\nlimited experimental evaluation. Existing models that mainly rely on\ncontext-independent embedding-based similarity measures fail to detect slot\nvalues in unseen domains or do so only partially. We propose a new zero-shot\nslot filling neural model, LEONA, which works in three steps. Step one acquires\ndomain-oblivious, context-aware representations of the utterance word by\nexploiting (a) linguistic features; (b) named entity recognition cues; (c)\ncontextual embeddings from pre-trained language models. Step two fine-tunes\nthese rich representations and produces slot-independent tags for each word.\nStep three exploits generalizable context-aware utterance-slot similarity\nfeatures at the word level, uses slot-independent tags, and contextualizes them\nto produce slot-specific predictions for each word. Our thorough evaluation on\nfour diverse public datasets demonstrates that our approach consistently\noutperforms the SOTA models by 17.52%, 22.15%, 17.42%, and 17.95% on average\nfor unseen domains on SNIPS, ATIS, MultiWOZ, and SGD datasets, respectively.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06514",
		"pdf_url": "http://arxiv.org/pdf/2101.06514.pdf"
	},
	"934": {
		"title": "A Novel Approach for Earthquake Early Warning System Design using Deep\n  Learning Techniques",
		"creator": [
			"Mukherjee, Tonumoy",
			"Singh, Chandrani",
			"Biswas, Prabir Kumar"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Signal Processing",
			"Computer Science - Sound",
			"Electrical Engineering and Systems Science - Audio and Speech Processing"
		],
		"description": "  Earthquake signals are non-stationary in nature and thus in real-time, it is\ndifficult to identify and classify events based on classical approaches like\npeak ground displacement, peak ground velocity. Even the popular algorithm of\nSTA/LTA requires extensive research to determine basic thresholding parameters\nso as to trigger an alarm. Also, many times due to human error or other\nunavoidable natural factors such as thunder strikes or landslides, the\nalgorithm may end up raising a false alarm. This work focuses on detecting\nearthquakes by converting seismograph recorded data into corresponding audio\nsignals for better perception and then uses popular Speech Recognition\ntechniques of Filter bank coefficients and Mel Frequency Cepstral Coefficients\n(MFCC) to extract the features. These features were then used to train a\nConvolutional Neural Network(CNN) and a Long Short Term Memory(LSTM) network.\nThe proposed method can overcome the above-mentioned problems and help in\ndetecting earthquakes automatically from the waveforms without much human\nintervention. For the 1000Hz audio data set the CNN model showed a testing\naccuracy of 91.1% for 0.2-second sample window length while the LSTM model\nshowed 93.99% for the same. A total of 610 sounds consisting of 310 earthquake\nsounds and 300 non-earthquake sounds were used to train the models. While\ntesting, the total time required for generating the alarm was approximately 2\nseconds which included individual times for data collection, processing, and\nprediction taking into consideration the processing and prediction delays. This\nshows the effectiveness of the proposed method for Earthquake Early Warning\n(EEW) applications. Since the input of the method is only the waveform, it is\nsuitable for real-time processing, thus the models can also be used as an\nonsite EEW system requiring a minimum amount of preparation time and workload.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06517",
		"pdf_url": "http://arxiv.org/pdf/2101.06517.pdf"
	},
	"935": {
		"title": "Evaluating Online and Offline Accuracy Traversal Algorithms for\n  k-Complete Neural Network Architectures",
		"creator": [
			"Alparslan, Yigit",
			"Moyer, Ethan Jacob",
			"Kim, Edward"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Architecture sizes for neural networks have been studied widely and several\nsearch methods have been offered to find the best architecture size in the\nshortest amount of time possible. In this paper, we study compact neural\nnetwork architectures for binary classification and investigate improvements in\nspeed and accuracy when favoring overcomplete architecture candidates that have\na very high-dimensional representation of the input. We hypothesize that an\novercomplete model architecture that creates a relatively high-dimensional\nrepresentation of the input will be not only be more accurate but would also be\neasier and faster to find. In an NxM search space, we propose an online\ntraversal algorithm that finds the best architecture candidate in O(1) time for\nbest case and O(N) amortized time for average case for any compact binary\nclassification problem by using k-completeness as heuristics in our search. The\ntwo other offline search algorithms we implement are brute force traversal and\ndiagonal traversal, which both find the best architecture candidate in O(NxM)\ntime. We compare our new algorithm to brute force and diagonal searching as a\nbaseline and report search time improvement of 52.1% over brute force and of\n15.4% over diagonal search to find the most accurate neural network\narchitecture when given the same dataset. In all cases discussed in the paper,\nour online traversal algorithm can find an accurate, if not better,\narchitecture in significantly shorter amount of time.\n",
			"Comment: 8 pages, 18 figures"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06518",
		"pdf_url": "http://arxiv.org/pdf/2101.06518.pdf"
	},
	"936": {
		"title": "Intrusion Detection Systems for Smart Home IoT Devices: Experimental\n  Comparison Study",
		"creator": [
			"Alsakran, Faisal",
			"Bendiab, Gueltoum",
			"Shiaeles, Stavros",
			"Kolokotronis, Nicholas"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": [
			"  Smart homes are one of the most promising applications of the emerging\nInternet of Things (IoT) technology. With the growing number of IoT related\ndevices such as smart thermostats, smart fridges, smart speaker, smart light\nbulbs and smart locks, smart homes promise to make our lives easier and more\ncomfortable. However, the increased deployment of such smart devices brings an\nincrease in potential security risks and home privacy breaches. In order to\novercome such risks, Intrusion Detection Systems are presented as pertinent\ntools that can provide network-level protection for smart devices deployed in\nhome environments. These systems monitor the network activities of the smart\nhome-connected de-vices and focus on alerting suspicious or malicious activity.\nThey also can deal with detected abnormal activities by hindering the impostors\nin accessing the victim devices. However, the employment of such systems in the\ncontext of a smart home can be challenging due to the devices hardware\nlimitations, which may restrict their ability to counter the existing and\nemerging attack vectors. Therefore, this paper proposes an experimental\ncomparison between the widely used open-source NIDSs namely Snort, Suricata and\nBro IDS to find the most appropriate one for smart homes in term of detection\naccuracy and resources consumption including CP and memory utilization.\nExperimental Results show that Suricata is the best performing NIDS for smart\nhomes\n",
			"Comment: 7 pages, 4 figures, 2 tables"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06519",
			"International Symposium on Security in Computing and\n  Communication. SSCC 2019: Security in Computing and Communications",
			"doi:10.1007/978-981-15-4825-3_7"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06519.pdf"
	},
	"937": {
		"title": "Big Data application in congestion detection and classification using\n  Apache spark",
		"creator": [
			"Zarindast, Atousa",
			"Sharma, Anuj"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Machine Learning"
		],
		"description": "  With the era of big data, an explosive amount of information is now\navailable. This enormous increase of Big Data in both academia and industry\nrequires large-scale data processing systems. A large body of research is\nbehind optimizing Spark's performance to make it state of the art, a fast and\ngeneral data processing system. Many science and engineering fields have\nadvanced with Big Data analytics, such as Biology, finance, and transportation.\nIntelligent transportation systems (ITS) gain popularity and direct benefit\nfrom the richness of information. The objective is to improve the safety and\nmanagement of transportation networks by reducing congestion and incidents. The\nfirst step toward the goal is better understanding, modeling, and detecting\ncongestion across a network efficiently and effectively. In this study, we\nintroduce an efficient congestion detection model. The underlying network\nconsists of 3017 segments in I-35, I-80, I-29, and I-380 freeways with an\noverall length of 1570 miles and averaged (0.4-0.6) miles per segment. The\nresult of congestion detection shows the proposed method is 90% accurate while\nhas reduced computation time by 99.88%.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06524",
		"pdf_url": "http://arxiv.org/pdf/2101.06524.pdf"
	},
	"938": {
		"title": "Sensitivity of Mean-Field Fluctuations in Erlang loss models with\n  randomized routing",
		"creator": [
			"Vasantam, Thirupathaiah",
			"Mazumdar, Ravi R."
		],
		"subject": [
			"Mathematics - Probability",
			"Computer Science - Performance",
			"60F17, 60M20, 68M20"
		],
		"description": [
			"  In this paper, we study a large system of $N$ servers each with capacity to\nprocess at most $C$ simultaneous jobs and an incoming job is routed to a server\nif it has the lowest occupancy amongst $d$ (out of N) randomly selected\nservers. A job that is routed to a server with no vacancy is assumed to be\nblocked and lost. Such randomized policies are referred to JSQ(d) (Join the\nShortest Queue out of $d$) policies. Under the assumption that jobs arrive\naccording to a Poisson process with rate $N\\lambda^{(N)}$ where\n$\\lambda^{(N)}=\\sigma-\\frac{\\beta}{\\sqrt{N}}$, $\\sigma\\in\\mb{R}_+$ and\n$\\beta\\in\\mb{R}$, we establish functional central limit theorems (FCLTs) for\nthe fluctuation process in both the transient and stationary regimes when\nservice time distributions are exponential. In particular, we show that the\nlimit is an Ornstein-Uhlenbeck process whose mean and variance depend on the\nmean-field of the considered model. Using this, we obtain approximations to the\nblocking probabilities for large $N$, where we can precisely estimate the\naccuracy of first-order approximations.\n",
			"Comment: 29 pages"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06529",
		"pdf_url": "http://arxiv.org/pdf/2101.06529.pdf"
	},
	"939": {
		"title": "Dissecting the Meme Magic: Understanding Indicators of Virality in Image\n  Memes",
		"creator": [
			"Ling, Chen",
			"AbuHilal, Ihab",
			"Blackburn, Jeremy",
			"De Cristofaro, Emiliano",
			"Zannettou, Savvas",
			"Stringhini, Gianluca"
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Computers and Society",
			"Computer Science - Social and Information Networks"
		],
		"description": [
			"  Despite the increasingly important role played by image memes, we do not yet\nhave a solid understanding of the elements that might make a meme go viral on\nsocial media. In this paper, we investigate what visual elements distinguish\nimage memes that are highly viral on social media from those that do not get\nre-shared, across three dimensions: composition, subjects, and target audience.\nDrawing from research in art theory, psychology, marketing, and neuroscience,\nwe develop a codebook to characterize image memes, and use it to annotate a set\nof 100 image memes collected from 4chan's Politically Incorrect Board (/pol/).\nOn the one hand, we find that highly viral memes are more likely to use a\nclose-up scale, contain characters, and include positive or negative emotions.\nOn the other hand, image memes that do not present a clear subject the viewer\ncan focus attention on, or that include long text are not likely to be\nre-shared by users.\n  We train machine learning models to distinguish between image memes that are\nlikely to go viral and those that are unlikely to be re-shared, obtaining an\nAUC of 0.866 on our dataset. We also show that the indicators of virality\nidentified by our model can help characterize the most viral memes posted on\nmainstream online social networks too, as our classifiers are able to predict\n19 out of the 20 most popular image memes posted on Twitter and Reddit between\n2016 and 2018. Overall, our analysis sheds light on what indicators\ncharacterize viral and non-viral visual content online, and set the basis for\ndeveloping better techniques to create or moderate content that is more likely\nto catch the viewer's attention.\n",
			"Comment: To appear at the 24th ACM Conference on Computer-Supported Coop-\n  erative Work and Social Computing (CSCW 2021)"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06535",
		"pdf_url": "http://arxiv.org/pdf/2101.06535.pdf"
	},
	"940": {
		"title": "SceneGen: Learning to Generate Realistic Traffic Scenes",
		"creator": [
			"Tan, Shuhan",
			"Wong, Kelvin",
			"Wang, Shenlong",
			"Manivasagam, Sivabalan",
			"Ren, Mengye",
			"Urtasun, Raquel"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning",
			"Computer Science - Robotics"
		],
		"description": "  We consider the problem of generating realistic traffic scenes automatically.\nExisting methods typically insert actors into the scene according to a set of\nhand-crafted heuristics and are limited in their ability to model the true\ncomplexity and diversity of real traffic scenes, thus inducing a content gap\nbetween synthesized traffic scenes versus real ones. As a result, existing\nsimulators lack the fidelity necessary to train and test self-driving vehicles.\nTo address this limitation, we present SceneGen, a neural autoregressive model\nof traffic scenes that eschews the need for rules and heuristics. In\nparticular, given the ego-vehicle state and a high definition map of\nsurrounding area, SceneGen inserts actors of various classes into the scene and\nsynthesizes their sizes, orientations, and velocities. We demonstrate on two\nlarge-scale datasets SceneGen's ability to faithfully model distributions of\nreal traffic scenes. Moreover, we show that SceneGen coupled with sensor\nsimulation can be used to train perception models that generalize to the real\nworld.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06541",
		"pdf_url": "http://arxiv.org/pdf/2101.06541.pdf"
	},
	"941": {
		"title": "VideoClick: Video Object Segmentation with a Single Click",
		"creator": [
			"Homayounfar, Namdar",
			"Liang, Justin",
			"Ma, Wei-Chiu",
			"Urtasun, Raquel"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Annotating videos with object segmentation masks typically involves a two\nstage procedure of drawing polygons per object instance for all the frames and\nthen linking them through time. While simple, this is a very tedious, time\nconsuming and expensive process, making the creation of accurate annotations at\nscale only possible for well-funded labs. What if we were able to segment an\nobject in the full video with only a single click? This will enable video\nsegmentation at scale with a very low budget opening the door to many\napplications. Towards this goal, in this paper we propose a bottom up approach\nwhere given a single click for each object in a video, we obtain the\nsegmentation masks of these objects in the full video. In particular, we\nconstruct a correlation volume that assigns each pixel in a target frame to\neither one of the objects in the reference frame or the background. We then\nrefine this correlation volume via a recurrent attention module and decode the\nfinal segmentation. To evaluate the performance, we label the popular and\nchallenging Cityscapes dataset with video object segmentations. Results on this\nnew CityscapesVideo dataset show that our approach outperforms all the\nbaselines in this challenging setting.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06545",
		"pdf_url": "http://arxiv.org/pdf/2101.06545.pdf"
	},
	"942": {
		"title": "RVE-CV2X: A Scalable Emulation Framework for Real-Time Evaluation of\n  CV2X-Based Connected Vehicle Applications",
		"creator": [
			"Shah, Ghayoor",
			"Saifuddin, MD",
			"Fallah, Yaser P.",
			"Gupta, Somak Datta"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": "  Vehicle-to-Everything (V2X) communication has become an integral component of\nIntelligent Transportation Systems (ITS) due to its ability to connect\nvehicles, pedestrians, infrastructure, and create situational awareness among\nvehicles. Cellular-Vehicle-to-Everything (C-V2X), based on 3rd Generation\nPartnership Project (3GPP) Release 14, is one such communication technology\nthat has recently gained significant attention to cater the needs of V2X\ncommunication. However, for a successful deployment of C-V2X, it is of\nparamount significance to thoroughly test the performance of this technology.\nIt is unfeasible to physically conduct a V2X communication experiment to test\nthe performance of C-V2X by arranging hundreds of real vehicles and their\ntransceiving on-board units. Although multiple simulators based on frameworks\nsuch as NS-3, OMNET++ and OPNET have proven to be reliable and economic\nalternatives to using real vehicles, all these simulators are time-consuming\nand require several orders of magnitudes longer than the actual simulation\ntime. As opposed to physical field- and simulation-based testing, network\nemulators can provide more realistic and repeatable results for testing\nvehicular communication. This paper proposes a real-time, high-fidelity,\nhardware-in-the-loop network emulator (RVE-CV2X) based on C-V2X mode 4 that can\nprovide scalable, reliable and repeatable testing scenarios for V2X\ncommunication. The accuracy of this emulator is verified by comparing it to an\nalready validated C-V2X simulator based on the NS-3 framework.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06548",
		"pdf_url": "http://arxiv.org/pdf/2101.06548.pdf"
	},
	"943": {
		"title": "GPU Methodologies for Numerical Partial Differential Equations",
		"creator": "Gloster, Andrew",
		"subject": [
			"Mathematics - Numerical Analysis",
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Mathematical Software"
		],
		"description": [
			"  In this thesis we develop techniques to efficiently solve numerical Partial\nDifferential Equations (PDEs) using Graphical Processing Units (GPUs). Focus is\nput on both performance and re--usability of the methods developed, to this end\na library, cuSten, for applying finite--difference stencils to numerical grids\nis presented herein. On top of this various batched tridiagonal and\npentadiagonal matrix solvers are discussed. These have been benchmarked against\nthe current state of the art and shown to improve performance in the solution\nof numerical PDEs. A variety of other benchmarks and use cases for the GPU\nmethodologies are presented using the Cahn--Hilliard equation as a core\nexample, but it is emphasised the methods are completely general. Finally\nthrough the application of the GPU methodologies to the Cahn--Hilliard equation\nnew results are presented on the growth rates of the coarsened domains. In\nparticular a statistical model is built up using batches of simulations run on\nGPUs from which the growth rates are extracted, it is shown that in a finite\ndomain that the traditionally presented results of 1/3 scaling is in fact a\ndistribution around this value. This result is discussed in conjunction with\nmodelling via a stochastic PDE and sheds new light on the behaviour of the\nCahn--Hilliard equation in finite domains.\n",
			"Comment: PhD Thesis"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06550",
		"pdf_url": "http://arxiv.org/pdf/2101.06550.pdf"
	},
	"944": {
		"title": "A multilevel clustering technique for community detection",
		"creator": [
			"Inuwa-Dutse, Isa",
			"Liptrott, Mark",
			"Korkontzelos, Yannis"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Social and Information Networks"
		],
		"description": [
			"  A network is a composition of many communities, i.e., sets of nodes and edges\nwith stronger relationships, with distinct and overlapping properties.\nCommunity detection is crucial for various reasons, such as serving as a\nfunctional unit of a network that captures local interactions among nodes.\nCommunities come in various forms and types, ranging from biologically to\ntechnology-induced ones. As technology-induced communities, social media\nnetworks such as Twitter and Facebook connect a myriad of diverse users,\nleading to a highly connected and dynamic ecosystem. Although many algorithms\nhave been proposed for detecting socially cohesive communities on Twitter,\nmining and related tasks remain challenging. This study presents a novel\ndetection method based on a scalable framework to identify related communities\nin a network. We propose a multilevel clustering technique (MCT) that leverages\nstructural and textual information to identify local communities termed\nmicrocosms. Experimental evaluation on benchmark models and datasets\ndemonstrate the efficacy of the approach. This study contributes a new\ndimension for the detection of cohesive communities in social networks. The\napproach offers a better understanding and clarity toward describing how\nlow-level communities evolve and behave on Twitter. From an application point\nof view, identifying such communities can better inform recommendation, among\nother benefits.\n",
			"Comment: 32 pages, 8 figures, journal article"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06551",
		"pdf_url": "http://arxiv.org/pdf/2101.06551.pdf"
	},
	"945": {
		"title": "Diverse Complexity Measures for Dataset Curation in Self-driving",
		"creator": [
			"Sadat, Abbas",
			"Segal, Sean",
			"Casas, Sergio",
			"Tu, James",
			"Yang, Bin",
			"Urtasun, Raquel",
			"Yumer, Ersin"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Robotics"
		],
		"description": [
			"  Modern self-driving autonomy systems heavily rely on deep learning. As a\nconsequence, their performance is influenced significantly by the quality and\nrichness of the training data. Data collecting platforms can generate many\nhours of raw data in a daily basis, however, it is not feasible to label\neverything. It is thus of key importance to have a mechanism to identify \"what\nto label\". Active learning approaches identify examples to label, but their\ninterestingness is tied to a fixed model performing a particular task. These\nassumptions are not valid in self-driving, where we have to solve a diverse set\nof tasks (i.e., perception, and motion forecasting) and our models evolve over\ntime frequently. In this paper we introduce a novel approach and propose a new\ndata selection method that exploits a diverse set of criteria that quantize\ninterestingness of traffic scenes. Our experiments on a wide range of tasks and\nmodels show that the proposed curation pipeline is able to select datasets that\nlead to better generalization and higher performance.\n",
			"Comment: 13 pages"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06554",
		"pdf_url": "http://arxiv.org/pdf/2101.06554.pdf"
	},
	"946": {
		"title": "TrafficSim: Learning to Simulate Realistic Multi-Agent Behaviors",
		"creator": [
			"Suo, Simon",
			"Regalado, Sebastian",
			"Casas, Sergio",
			"Urtasun, Raquel"
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  Simulation has the potential to massively scale evaluation of self-driving\nsystems enabling rapid development as well as safe deployment. To close the gap\nbetween simulation and the real world, we need to simulate realistic\nmulti-agent behaviors. Existing simulation environments rely on heuristic-based\nmodels that directly encode traffic rules, which cannot capture irregular\nmaneuvers (e.g., nudging, U-turns) and complex interactions (e.g., yielding,\nmerging). In contrast, we leverage real-world data to learn directly from human\ndemonstration and thus capture a more diverse set of actor behaviors. To this\nend, we propose TrafficSim, a multi-agent behavior model for realistic traffic\nsimulation. In particular, we leverage an implicit latent variable model to\nparameterize a joint actor policy that generates socially-consistent plans for\nall actors in the scene jointly. To learn a robust policy amenable for long\nhorizon simulation, we unroll the policy in training and optimize through the\nfully differentiable simulation across time. Our learning objective\nincorporates both human demonstrations as well as common sense. We show\nTrafficSim generates significantly more realistic and diverse traffic scenarios\nas compared to a diverse set of baselines. Notably, we can exploit trajectories\ngenerated by TrafficSim as effective data augmentation for training better\nmotion planner.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06557",
		"pdf_url": "http://arxiv.org/pdf/2101.06557.pdf"
	},
	"947": {
		"title": "Deep-Mobility: A Deep Learning Approach for an Efficient and Reliable 5G\n  Handover",
		"creator": [
			"Paropkari, Rahul Arun",
			"Thantharate, Anurag",
			"Beard, Cory"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Neural and Evolutionary Computing",
			"C.2",
			"H.2",
			"I.4",
			"J.6"
		],
		"description": [
			"  5G cellular networks are being deployed all over the world and this\narchitecture supports ultra-dense network (UDN) deployment. Small cells have a\nvery important role in providing 5G connectivity to the end users. Exponential\nincreases in devices, data and network demands make it mandatory for the\nservice providers to manage handovers better, to cater to the services that a\nuser desire. In contrast to any traditional handover improvement scheme, we\ndevelop a 'Deep-Mobility' model by implementing a deep learning neural network\n(DLNN) to manage network mobility, utilizing in-network deep learning and\nprediction. We use network key performance indicators (KPIs) to train our model\nto analyze network traffic and handover requirements. In this method, RF signal\nconditions are continuously observed and tracked using deep learning neural\nnetworks such as the Recurrent neural network (RNN) or Long Short-Term Memory\nnetwork (LSTM) and system level inputs are also considered in conjunction, to\ntake a collective decision for a handover. We can study multiple parameters and\ninteractions between system events along with the user mobility, which would\nthen trigger a handoff in any given scenario. Here, we show the fundamental\nmodeling approach and demonstrate usefulness of our model while investigating\nimpacts and sensitivities of certain KPIs from the user equipment (UE) and\nnetwork side.\n",
			"Comment: This paper was accepted at the 29th ICCCN 2020"
		],
		"date": [
			"2021-01-16",
			"2021-01-18"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06558",
		"pdf_url": "http://arxiv.org/pdf/2101.06558.pdf"
	},
	"948": {
		"title": "Stereo Camera Visual SLAM with Hierarchical Masking and Motion-state\n  Classification at Outdoor Construction Sites Containing Large Dynamic Objects",
		"creator": [
			"Bao, Runqiu",
			"Komatsu, Ren",
			"Miyagusuku, Renato",
			"Chino, Masaki",
			"Yamashita, Atsushi",
			"Asama, Hajime"
		],
		"subject": "Computer Science - Robotics",
		"description": [
			"  At modern construction sites, utilizing GNSS (Global Navigation Satellite\nSystem) to measure the real-time location and orientation (i.e. pose) of\nconstruction machines and navigate them is very common. However, GNSS is not\nalways available. Replacing GNSS with on-board cameras and visual simultaneous\nlocalization and mapping (visual SLAM) to navigate the machines is a\ncost-effective solution. Nevertheless, at construction sites, multiple\nconstruction machines will usually work together and side-by-side, causing\nlarge dynamic occlusions in the cameras' view. Standard visual SLAM cannot\nhandle large dynamic occlusions well. In this work, we propose a motion\nsegmentation method to efficiently extract static parts from crowded dynamic\nscenes to enable robust tracking of camera ego-motion. Our method utilizes\nsemantic information combined with object-level geometric constraints to\nquickly detect the static parts of the scene. Then, we perform a two-step\ncoarse-to-fine ego-motion tracking with reference to the static parts. This\nleads to a novel dynamic visual SLAM formation. We test our proposals through a\nreal implementation based on ORB-SLAM2, and datasets we collected from real\nconstruction sites. The results show that when standard visual SLAM fails, our\nmethod can still retain accurate camera ego-motion tracking in real-time.\nComparing to state-of-the-art dynamic visual SLAM methods, ours shows\noutstanding efficiency and competitive result trajectory accuracy.\n",
			"Comment: This is an Accepted Manuscript of an article published by Taylor &\n  Francis in Advanced Robotics on Jan. 11th, 2021, available online:\n  https://www.tandfonline.com/doi/full/10.1080/01691864.2020.1869586 [Article\n  DOI:10.1080/01691864.2020.1869586]"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06563",
			"Advanced Robotics (2021) 1-14",
			"doi:10.1080/01691864.2020.1869586"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06563.pdf"
	},
	"949": {
		"title": "Privacy-Preserving Learning of Human Activity Predictors in Smart\n  Environments",
		"creator": [
			"Zehtabian, Sharare",
			"Khodadadeh, Siavash",
			"Bölöni, Ladislau",
			"Turgut, Damla"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Networking and Internet Architecture"
		],
		"description": "  The daily activities performed by a disabled or elderly person can be\nmonitored by a smart environment, and the acquired data can be used to learn a\npredictive model of user behavior. To speed up the learning, several\nresearchers designed collaborative learning systems that use data from multiple\nusers. However, disclosing the daily activities of an elderly or disabled user\nraises privacy concerns. In this paper, we use state-of-the-art deep neural\nnetwork-based techniques to learn predictive human activity models in the\nlocal, centralized, and federated learning settings. A novel aspect of our work\nis that we carefully track the temporal evolution of the data available to the\nlearner and the data shared by the user. In contrast to previous work where\nusers shared all their data with the centralized learner, we consider users\nthat aim to preserve their privacy. Thus, they choose between approaches in\norder to achieve their goals of predictive accuracy while minimizing the shared\ndata. To help users make decisions before disclosing any data, we use machine\nlearning to predict the degree to which a user would benefit from collaborative\nlearning. We validate our approaches on real-world data.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06564",
		"pdf_url": "http://arxiv.org/pdf/2101.06564.pdf"
	},
	"950": {
		"title": "Joint Beamforming and Location Optimization for Secure Data Collection\n  in Wireless Sensor Networks with UAV-Carried Intelligent Reflecting Surface",
		"creator": [
			"Nnamani, Christantus O.",
			"Khandaker, Muhammad R. A.",
			"Sellathurai, Mathini"
		],
		"subject": [
			"Computer Science - Information Theory",
			"Computer Science - Cryptography and Security"
		],
		"description": [
			"  This paper considers unmanned aerial vehicle (UAV)-carried intelligent\nreflecting surface (IRS) for secure data collection in wireless sensor\nnetworks. An eavesdropper (Eve) lurks within the vicinity of the main receiver\n(Bob) while several randomly placed sensor nodes beamform collaboratively to\nthe UAV-carried IRS that reflects the signal to the main receiver (Bob). The\ndesign objective is to maximise the achievable secrecy rate in the noisy\ncommunication channel by jointly optimizing the collaborative beamforming\nweights of the sensor nodes, the trajectory of the UAV and the reflection\ncoefficients of the IRS elements. By designing the IRS reflection coefficients\nwith and without the knowledge of the eavesdropper's channel, we develop a\nnon-iterative sub-optimal solution for the secrecy rate maximization problem.\nIt has been shown analytically that the UAV flight time and the randomness in\nthe distribution of the sensor nodes, obtained by varying the sensor\ndistribution area, can greatly affect secrecy performance. In addition, the\nmaximum allowable number of IRS elements as well as a bound on the attainable\naverage secrecy rate of the IRS aided noisy communication channel have also\nbeen derived. Extensive simulation results demonstrate the superior performance\nof the proposed algorithms compared to the existing schemes.\n",
			"Comment: Submitted to IEEE Transactions on Communications"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06565",
		"pdf_url": "http://arxiv.org/pdf/2101.06565.pdf"
	},
	"951": {
		"title": "A Literature Review of Recent Graph Embedding Techniques for Biomedical\n  Data",
		"creator": [
			"Chen, Yankai",
			"Wu, Yaozu",
			"Ma, Shicheng",
			"King, Irwin"
		],
		"subject": "Computer Science - Artificial Intelligence",
		"description": "  With the rapid development of biomedical software and hardware, a large\namount of relational data interlinking genes, proteins, chemical components,\ndrugs, diseases, and symptoms has been collected for modern biomedical\nresearch. Many graph-based learning methods have been proposed to analyze such\ntype of data, giving a deeper insight into the topology and knowledge behind\nthe biomedical data, which greatly benefit to both academic research and\nindustrial application for human healthcare. However, the main difficulty is\nhow to handle high dimensionality and sparsity of the biomedical graphs.\nRecently, graph embedding methods provide an effective and efficient way to\naddress the above issues. It converts graph-based data into a low dimensional\nvector space where the graph structural properties and knowledge information\nare well preserved. In this survey, we conduct a literature review of recent\ndevelopments and trends in applying graph embedding methods for biomedical\ndata. We also introduce important applications and tasks in the biomedical\ndomain as well as associated public biomedical datasets.\n",
		"date": [
			"2021-01-16",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06569",
		"pdf_url": "http://arxiv.org/pdf/2101.06569.pdf"
	},
	"952": {
		"title": "S3: Neural Shape, Skeleton, and Skinning Fields for 3D Human Modeling",
		"creator": [
			"Yang, Ze",
			"Wang, Shenlong",
			"Manivasagam, Sivabalan",
			"Huang, Zeng",
			"Ma, Wei-Chiu",
			"Yan, Xinchen",
			"Yumer, Ersin",
			"Urtasun, Raquel"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Constructing and animating humans is an important component for building\nvirtual worlds in a wide variety of applications such as virtual reality or\nrobotics testing in simulation. As there are exponentially many variations of\nhumans with different shape, pose and clothing, it is critical to develop\nmethods that can automatically reconstruct and animate humans at scale from\nreal world data. Towards this goal, we represent the pedestrian's shape, pose\nand skinning weights as neural implicit functions that are directly learned\nfrom data. This representation enables us to handle a wide variety of different\npedestrian shapes and poses without explicitly fitting a human parametric body\nmodel, allowing us to handle a wider range of human geometries and topologies.\nWe demonstrate the effectiveness of our approach on various datasets and show\nthat our reconstructions outperform existing state-of-the-art methods.\nFurthermore, our re-animation experiments show that we can generate 3D human\nanimations at scale from a single RGB image (and/or an optional LiDAR sweep) as\ninput.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06571",
		"pdf_url": "http://arxiv.org/pdf/2101.06571.pdf"
	},
	"953": {
		"title": "Understanding in Artificial Intelligence",
		"creator": [
			"Maetschke, Stefan",
			"Iraola, David Martinez",
			"Barnard, Pieter",
			"ShafieiBavani, Elaheh",
			"Zhong, Peter",
			"Xu, Ying",
			"Yepes, Antonio Jimeno"
		],
		"subject": "Computer Science - Artificial Intelligence",
		"description": [
			"  Current Artificial Intelligence (AI) methods, most based on deep learning,\nhave facilitated progress in several fields, including computer vision and\nnatural language understanding. The progress of these AI methods is measured\nusing benchmarks designed to solve challenging tasks, such as visual question\nanswering. A question remains of how much understanding is leveraged by these\nmethods and how appropriate are the current benchmarks to measure understanding\ncapabilities. To answer these questions, we have analysed existing benchmarks\nand their understanding capabilities, defined by a set of understanding\ncapabilities, and current research streams. We show how progress has been made\nin benchmark development to measure understanding capabilities of AI methods\nand we review as well how current methods develop understanding capabilities.\n",
			"Comment: 28 pages, 282 references"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06573",
		"pdf_url": "http://arxiv.org/pdf/2101.06573.pdf"
	},
	"954": {
		"title": "Telescopers for differential forms with one parameter",
		"creator": [
			"Chen, Shaoshi",
			"Feng, Ruyong",
			"Li, Ziming",
			"Singer, Michael F.",
			"Watt, Stephen"
		],
		"subject": [
			"Computer Science - Symbolic Computation",
			"68W30"
		],
		"description": [
			"  Telescopers for a function are linear differential (resp. difference)\noperators annihilated by the definite integral (resp. definite sum) of this\nfunction. They play a key role in Wilf-Zeilberger theory and algorithms for\ncomputing them have been extensively studied in the past thirty years. In this\npaper, we introduce the notion of telescopers for differential forms with\n$D$-finite function coefficients. These telescopers appear in several areas of\nmathematics, for instance parametrized differential Galois theory and mirror\nsymmetry. We give a sufficient and necessary condition for the existence of\ntelescopers for a differential form and describe a method to compute them if\nthey exist. Algorithms for verifying this condition are also given.\n",
			"Comment: 26 pages"
		],
		"date": [
			"2021-01-16",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06576",
		"pdf_url": "http://arxiv.org/pdf/2101.06576.pdf"
	},
	"955": {
		"title": "Physics-Informed Deep Learning for Traffic State Estimation",
		"creator": [
			"Shi, Rongye",
			"Mo, Zhaobin",
			"Huang, Kuang",
			"Di, Xuan",
			"Du, Qiang"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Traffic state estimation (TSE), which reconstructs the traffic variables\n(e.g., density) on road segments using partially observed data, plays an\nimportant role on efficient traffic control and operation that intelligent\ntransportation systems (ITS) need to provide to people. Over decades, TSE\napproaches bifurcate into two main categories, model-driven approaches and\ndata-driven approaches. However, each of them has limitations: the former\nhighly relies on existing physical traffic flow models, such as\nLighthill-Whitham-Richards (LWR) models, which may only capture limited\ndynamics of real-world traffic, resulting in low-quality estimation, while the\nlatter requires massive data in order to perform accurate and generalizable\nestimation. To mitigate the limitations, this paper introduces a\nphysics-informed deep learning (PIDL) framework to efficiently conduct\nhigh-quality TSE with small amounts of observed data. PIDL contains both\nmodel-driven and data-driven components, making possible the integration of the\nstrong points of both approaches while overcoming the shortcomings of either.\nThis paper focuses on highway TSE with observed data from loop detectors, using\ntraffic density as the traffic variables. We demonstrate the use of PIDL to\nsolve (with data from loop detectors) two popular physical traffic flow models,\ni.e., Greenshields-based LWR and three-parameter-based LWR, and discover the\nmodel parameters. We then evaluate the PIDL-based highway TSE using the Next\nGeneration SIMulation (NGSIM) dataset. The experimental results show the\nadvantages of the PIDL-based approach in terms of estimation accuracy and data\nefficiency over advanced baseline TSE methods.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06580",
		"pdf_url": "http://arxiv.org/pdf/2101.06580.pdf"
	},
	"956": {
		"title": "Tailored Learning-Based Scheduling for Kubernetes-Oriented Edge-Cloud\n  System",
		"creator": [
			"Han, Yiwen",
			"Shen, Shihao",
			"Wang, Xiaofei",
			"Wang, Shiqiang",
			"Leung, Victor C. M."
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Kubernetes (k8s) has the potential to merge the distributed edge and the\ncloud but lacks a scheduling framework specifically for edge-cloud systems.\nBesides, the hierarchical distribution of heterogeneous resources and the\ncomplex dependencies among requests and resources make the modeling and\nscheduling of k8s-oriented edge-cloud systems particularly sophisticated. In\nthis paper, we introduce KaiS, a learning-based scheduling framework for such\nedge-cloud systems to improve the long-term throughput rate of request\nprocessing. First, we design a coordinated multi-agent actor-critic algorithm\nto cater to decentralized request dispatch and dynamic dispatch spaces within\nthe edge cluster. Second, for diverse system scales and structures, we use\ngraph neural networks to embed system state information, and combine the\nembedding results with multiple policy networks to reduce the orchestration\ndimensionality by stepwise scheduling. Finally, we adopt a two-time-scale\nscheduling mechanism to harmonize request dispatch and service orchestration,\nand present the implementation design of deploying the above algorithms\ncompatible with native k8s components. Experiments using real workload traces\nshow that KaiS can successfully learn appropriate scheduling policies,\nirrespective of request arrival patterns and system scales. Moreover, KaiS can\nenhance the average system throughput rate by 14.3% while reducing scheduling\ncost by 34.7% compared to baselines.\n",
			"Comment: IEEE INFOCOM 2021"
		],
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06582",
		"pdf_url": "http://arxiv.org/pdf/2101.06582.pdf"
	},
	"957": {
		"title": "Cost-Efficient Online Hyperparameter Optimization",
		"creator": [
			"Wang, Jingkang",
			"Ren, Mengye",
			"Bogunovic, Ilija",
			"Xiong, Yuwen",
			"Urtasun, Raquel"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Statistics - Machine Learning"
		],
		"description": "  Recent work on hyperparameters optimization (HPO) has shown the possibility\nof training certain hyperparameters together with regular parameters. However,\nthese online HPO algorithms still require running evaluation on a set of\nvalidation examples at each training step, steeply increasing the training\ncost. To decide when to query the validation loss, we model online HPO as a\ntime-varying Bayesian optimization problem, on top of which we propose a novel\n\\textit{costly feedback} setting to capture the concept of the query cost.\nUnder this setting, standard algorithms are cost-inefficient as they evaluate\non the validation set at every round. In contrast, the cost-efficient GP-UCB\nalgorithm proposed in this paper queries the unknown function only when the\nmodel is less confident about current decisions. We evaluate our proposed\nalgorithm by tuning hyperparameters online for VGG and ResNet on CIFAR-10 and\nImageNet100. Our proposed online HPO algorithm reaches human expert-level\nperformance within a single run of the experiment, while incurring only modest\ncomputational overhead compared to regular training.\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06590",
		"pdf_url": "http://arxiv.org/pdf/2101.06590.pdf"
	},
	"958": {
		"title": "TSEC: a framework for online experimentation under experimental\n  constraints",
		"creator": [
			"Mak, Simon",
			"Zhou, Yuanshuo",
			"Hoang, Lavonne",
			"Wu, C. F. Jeff"
		],
		"subject": [
			"Statistics - Methodology",
			"Computer Science - Machine Learning"
		],
		"description": "  Thompson sampling is a popular algorithm for solving multi-armed bandit\nproblems, and has been applied in a wide range of applications, from website\ndesign to portfolio optimization. In such applications, however, the number of\nchoices (or arms) $N$ can be large, and the data needed to make adaptive\ndecisions require expensive experimentation. One is then faced with the\nconstraint of experimenting on only a small subset of $K \\ll N$ arms within\neach time period, which poses a problem for traditional Thompson sampling. We\npropose a new Thompson Sampling under Experimental Constraints (TSEC) method,\nwhich addresses this so-called \"arm budget constraint\". TSEC makes use of a\nBayesian interaction model with effect hierarchy priors, to model correlations\nbetween rewards on different arms. This fitted model is then integrated within\nThompson sampling, to jointly identify a good subset of arms for\nexperimentation and to allocate resources over these arms. We demonstrate the\neffectiveness of TSEC in two problems with arm budget constraints. The first is\na simulated website optimization study, where TSEC shows noticeable\nimprovements over industry benchmarks. The second is a portfolio optimization\napplication on industry-based exchange-traded funds, where TSEC provides more\nconsistent and greater wealth accumulation over standard investment strategies.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06592",
		"pdf_url": "http://arxiv.org/pdf/2101.06592.pdf"
	},
	"959": {
		"title": "Simultaneous Embedding of Colored Graphs",
		"creator": "Mondal, Debajyoti",
		"subject": [
			"Computer Science - Computational Geometry",
			"68R10",
			"G.2.2"
		],
		"description": "  A set of colored graphs are compatible, if for every color $i$, the number of\nvertices of color $i$ is the same in every graph. A simultaneous embedding of\n$k$ compatibly colored graphs, each with $n$ vertices, consists of $k$ planar\npolyline drawings of these graphs such that the vertices of the same color are\nmapped to a common set of vertex locations.\n  We prove that simultaneous embedding of $k\\in o(\\log \\log n)$ colored planar\ngraphs, each with $n$ vertices, can always be computed with a sublinear number\nof bends per edge. Specifically, we show an $O(\\min\\{c, n^{1-1/\\gamma}\\})$\nupper bound on the number of bends per edge, where $\\gamma = 2^{\\lceil k/2\n\\rceil}$ and $c$ is the total number of colors. Our bound, which results from a\nbetter analysis of a previously known algorithm [Durocher and Mondal, SIAM J.\nDiscrete Math., 32(4), 2018], improves the bound for $k$, as well as the bend\ncomplexity by a factor of $\\sqrt{2}^{k}$. The algorithm can be generalized to\nobtain small universal point sets for colored graphs. We prove that $n\\lceil\nc/b \\rceil$ vertex locations, where $b\\ge 1$, suffice to embed any set of\ncompatibly colored $n$-vertex planar graphs with bend complexity $O(b)$, where\n$c$ is the number of colors.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06596",
		"pdf_url": "http://arxiv.org/pdf/2101.06596.pdf"
	},
	"960": {
		"title": "OPAR: Optimized Predictive and Adaptive Routing for Cooperative UAV\n  Networks",
		"creator": [
			"Gharib, Mohammed",
			"Afghah, Fatemeh",
			"Bentley, Elizabeth"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": [
			"  Cooperative UAV networks are becoming increasingly popular in military and\ncivilian applications. Alas, the typical ad-hoc routing protocols, which aim at\nfinding the shortest path, lead to significant performance degradation because\nof the 3-dimension highly-dynamic nature of UAV networks and the uneven\ndistribution of nodes across the network. This paper proposes OPAR, an\noptimized predictive and adaptive routing protocol, to face this challenging\nproblem. We model the routing problem with linear programming (LP), where the\ngoal is to maximize network performance, considering the path lifetime and\npath-length together. This model relies on a precise link lifetime prediction\nmechanism. We support the LP problem with a lightweight algorithm to find the\noptimized solution with a computation complexity of $O(|E|^2)$, where $|E|$ is\nthe number of network links. We evaluate the OPAR performance and compare it\nwith the well-known routing algorithms AODV, DSDV, and OLSR to cover a wide\nrange of proactive and reactive protocols as well as distance vector and\nlink-state techniques. We performed extensive simulations for different network\ndensities and mobility patterns using the ns-3 simulator. Results show that\nOPAR prevents a high volume of routing traffic, increases the successful\ndelivery by more than $30\\%$, improves the throughput $25\\%$ on average, and\ndecreases the flow completion time by an average of $35\\%$.\n",
			"Comment: 6 pages, 6 figures, Infocom workshop accepted paper"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06602",
		"pdf_url": "http://arxiv.org/pdf/2101.06602.pdf"
	},
	"961": {
		"title": "Network Automatic Pruning: Start NAP and Take a Nap",
		"creator": [
			"Zeng, Wenyuan",
			"Xiong, Yuwen",
			"Urtasun, Raquel"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Network pruning can significantly reduce the computation and memory footprint\nof large neural networks. To achieve a good trade-off between model size and\nperformance, popular pruning techniques usually rely on hand-crafted heuristics\nand require manually setting the compression ratio for each layer. This process\nis typically time-consuming and requires expert knowledge to achieve good\nresults. In this paper, we propose NAP, a unified and automatic pruning\nframework for both fine-grained and structured pruning. It can find out\nunimportant components of a network and automatically decide appropriate\ncompression ratios for different layers, based on a theoretically sound\ncriterion. Towards this goal, NAP uses an efficient approximation of the\nHessian for evaluating the importances of components, based on a\nKronecker-factored Approximate Curvature method. Despite its simpleness to use,\nNAP outperforms previous pruning methods by large margins. For fine-grained\npruning, NAP can compress AlexNet and VGG16 by 25x, and ResNet-50 by 6.7x\nwithout loss in accuracy on ImageNet. For structured pruning (e.g. channel\npruning), it can reduce flops of VGG16 by 5.4x and ResNet-50 by 2.3x with only\n1% accuracy drop. More importantly, this method is almost free from\nhyper-parameter tuning and requires no expert knowledge. You can start NAP and\nthen take a nap!\n",
			"Comment: An updated version of 'MLPrune: Multi-Layer Pruning for Automated\n  Neural Network Compression'"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06608",
		"pdf_url": "http://arxiv.org/pdf/2101.06608.pdf"
	},
	"962": {
		"title": "Disentangling Observed Causal Effects from Latent Confounders using\n  Method of Moments",
		"creator": [
			"Liu, Anqi",
			"Liu, Hao",
			"Li, Tongxin",
			"Karimi-Bidhendi, Saeed",
			"Yue, Yisong",
			"Anandkumar, Anima"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Discovering the complete set of causal relations among a group of variables\nis a challenging unsupervised learning problem. Often, this challenge is\ncompounded by the fact that there are latent or hidden confounders. When only\nobservational data is available, the problem is ill-posed, i.e. the causal\nrelationships are non-identifiable unless strong modeling assumptions are made.\nWhen interventions are available, we provide guarantees on identifiability and\nlearnability under mild assumptions. We assume a linear structural equation\nmodel (SEM) with independent latent factors and directed acyclic graph (DAG)\nrelationships among the observables. Since the latent variable inference is\nbased on independent component analysis (ICA), we call this model SEM-ICA. We\nuse the method of moments principle to establish model identifiability. We\ndevelop efficient algorithms based on coupled tensor decomposition with linear\nconstraints to obtain scalable and guaranteed solutions. Thus, we provide a\nprincipled approach to tackling the joint problem of causal discovery and\nlatent variable inference.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06614",
		"pdf_url": "http://arxiv.org/pdf/2101.06614.pdf"
	},
	"963": {
		"title": "Continuous Multi-objective Zero-touch Network Slicing via Twin Delayed\n  DDPG and OpenAI Gym",
		"creator": [
			"Rezazadeh, Farhad",
			"Chergui, Hatim",
			"Alonso, Luis",
			"Verikoukis, Christos"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": [
			"  Artificial intelligence (AI)-driven zero-touch network slicing (NS) is a new\nparadigm enabling the automation of resource management and orchestration\n(MANO) in multi-tenant beyond 5G (B5G) networks. In this paper, we tackle the\nproblem of cloud-RAN (C-RAN) joint slice admission control and resource\nallocation by first formulating it as a Markov decision process (MDP). We then\ninvoke an advanced continuous deep reinforcement learning (DRL) method called\ntwin delayed deep deterministic policy gradient (TD3) to solve it. In this\nintent, we introduce a multi-objective approach to make the central unit (CU)\nlearn how to re-configure computing resources autonomously while minimizing\nlatency, energy consumption and virtual network function (VNF) instantiation\ncost for each slice. Moreover, we build a complete 5G C-RAN network slicing\nenvironment using OpenAI Gym toolkit where, thanks to its standardized\ninterface, it can be easily tested with different DRL schemes. Finally, we\npresent extensive experimental results to showcase the gain of TD3 as well as\nthe adopted multi-objective strategy in terms of achieved slice admission\nsuccess rate, latency, energy saving and CPU utilization.\n",
			"Comment: 6 pages, 4 figures, accepted for publication at IEEE GLOBECOM 2020"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06617",
		"pdf_url": "http://arxiv.org/pdf/2101.06617.pdf"
	},
	"964": {
		"title": "Solving QSAT problems with neural MCTS",
		"creator": [
			"Xu, Ruiyang",
			"Lieberherr, Karl"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": "  Recent achievements from AlphaZero using self-play has shown remarkable\nperformance on several board games. It is plausible to think that self-play,\nstarting from zero knowledge, can gradually approximate a winning strategy for\ncertain two-player games after an amount of training. In this paper, we try to\nleverage the computational power of neural Monte Carlo Tree Search (neural\nMCTS), the core algorithm from AlphaZero, to solve Quantified Boolean Formula\nSatisfaction (QSAT) problems, which are PSPACE complete. Knowing that every\nQSAT problem is equivalent to a QSAT game, the game outcome can be used to\nderive the solutions of the original QSAT problems. We propose a way to encode\nQuantified Boolean Formulas (QBFs) as graphs and apply a graph neural network\n(GNN) to embed the QBFs into the neural MCTS. After training, an off-the-shelf\nQSAT solver is used to evaluate the performance of the algorithm. Our result\nshows that, for problems within a limited size, the algorithm learns to solve\nthe problem correctly merely from self-play.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06619",
		"pdf_url": "http://arxiv.org/pdf/2101.06619.pdf"
	},
	"965": {
		"title": "Regional Attention Network (RAN) for Head Pose and Fine-grained Gesture\n  Recognition",
		"creator": [
			"Behera, Ardhendu",
			"Wharton, Zachary",
			"Ghahremani, Morteza",
			"Kumar, Swagat",
			"Bessis, Nik"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Affect is often expressed via non-verbal body language such as\nactions/gestures, which are vital indicators for human behaviors. Recent\nstudies on recognition of fine-grained actions/gestures in monocular images\nhave mainly focused on modeling spatial configuration of body parts\nrepresenting body pose, human-objects interactions and variations in local\nappearance. The results show that this is a brittle approach since it relies on\naccurate body parts/objects detection. In this work, we argue that there exist\nlocal discriminative semantic regions, whose \"informativeness\" can be evaluated\nby the attention mechanism for inferring fine-grained gestures/actions. To this\nend, we propose a novel end-to-end \\textbf{Regional Attention Network (RAN)},\nwhich is a fully Convolutional Neural Network (CNN) to combine multiple\ncontextual regions through attention mechanism, focusing on parts of the images\nthat are most relevant to a given task. Our regions consist of one or more\nconsecutive cells and are adapted from the strategies used in computing HOG\n(Histogram of Oriented Gradient) descriptor. The model is extensively evaluated\non ten datasets belonging to 3 different scenarios: 1) head pose recognition,\n2) drivers state recognition, and 3) human action and facial expression\nrecognition. The proposed approach outperforms the state-of-the-art by a\nconsiderable margin in different metrics.\n",
			"Comment: This manuscript is the accepted version of the published paper in\n  IEEE Transaction on Affective Computing"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06634",
			"IEEE Transaction on Affective Computing 2020",
			"doi:10.1109/TAFFC.2020.3031841"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06634.pdf"
	},
	"966": {
		"title": "Context-aware Attentional Pooling (CAP) for Fine-grained Visual\n  Classification",
		"creator": [
			"Behera, Ardhendu",
			"Wharton, Zachary",
			"Hewage, Pradeep",
			"Bera, Asish"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Deep convolutional neural networks (CNNs) have shown a strong ability in\nmining discriminative object pose and parts information for image recognition.\nFor fine-grained recognition, context-aware rich feature representation of\nobject/scene plays a key role since it exhibits a significant variance in the\nsame subcategory and subtle variance among different subcategories. Finding the\nsubtle variance that fully characterizes the object/scene is not\nstraightforward. To address this, we propose a novel context-aware attentional\npooling (CAP) that effectively captures subtle changes via sub-pixel gradients,\nand learns to attend informative integral regions and their importance in\ndiscriminating different subcategories without requiring the bounding-box\nand/or distinguishable part annotations. We also introduce a novel feature\nencoding by considering the intrinsic consistency between the informativeness\nof the integral regions and their spatial structures to capture the semantic\ncorrelation among them. Our approach is simple yet extremely effective and can\nbe easily applied on top of a standard classification backbone network. We\nevaluate our approach using six state-of-the-art (SotA) backbone networks and\neight benchmark datasets. Our method significantly outperforms the SotA\napproaches on six datasets and is very competitive with the remaining two.\n",
			"Comment: Extended version of the accepted paper in 35th AAAI Conference on\n  Artificial Intelligence 2021"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06635",
			"35th AAAI Conference on Artificial Intelligence 2021"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06635.pdf"
	},
	"967": {
		"title": "Coarse Temporal Attention Network (CTA-Net) for Driver's Activity\n  Recognition",
		"creator": [
			"Wharton, Zachary",
			"Behera, Ardhendu",
			"Liu, Yonghuai",
			"Bessis, Nik"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  There is significant progress in recognizing traditional human activities\nfrom videos focusing on highly distinctive actions involving discriminative\nbody movements, body-object and/or human-human interactions. Driver's\nactivities are different since they are executed by the same subject with\nsimilar body parts movements, resulting in subtle changes. To address this, we\npropose a novel framework by exploiting the spatiotemporal attention to model\nthe subtle changes. Our model is named Coarse Temporal Attention Network\n(CTA-Net), in which coarse temporal branches are introduced in a trainable\nglimpse network. The goal is to allow the glimpse to capture high-level\ntemporal relationships, such as 'during', 'before' and 'after' by focusing on a\nspecific part of a video. These branches also respect the topology of the\ntemporal dynamics in the video, ensuring that different branches learn\nmeaningful spatial and temporal changes. The model then uses an innovative\nattention mechanism to generate high-level action specific contextual\ninformation for activity recognition by exploring the hidden states of an LSTM.\nThe attention mechanism helps in learning to decide the importance of each\nhidden state for the recognition task by weighing them when constructing the\nrepresentation of the video. Our approach is evaluated on four publicly\naccessible datasets and significantly outperforms the state-of-the-art by a\nconsiderable margin with only RGB video as input.\n",
			"Comment: Extended version of the accepted WACV 2021"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06636",
			"Winter Conference on Applications of Computer Vision (WACV 2021)"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06636.pdf"
	},
	"968": {
		"title": "AMALGAM: A Matching Approach to fairfy tabuLar data with knowledGe grAph\n  Model",
		"creator": [
			"Azzi, Rabia",
			"Diallo, Gayo"
		],
		"subject": [
			"Computer Science - Databases",
			"Computer Science - Information Retrieval"
		],
		"description": [
			"  In this paper we present AMALGAM, a matching approach to fairify tabular data\nwith the use of a knowledge graph. The ultimate goal is to provide fast and\nefficient approach to annotate tabular data with entities from a background\nknowledge. The approach combines lookup and filtering services combined with\ntext pre-processing techniques. Experiments conducted in the context of the\n2020 Semantic Web Challenge on Tabular Data to Knowledge Graph Matching with\nboth Column Type Annotation and Cell Type Annotation tasks showed promising\nresults.\n",
			"Comment: 10 pages"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06637",
		"pdf_url": "http://arxiv.org/pdf/2101.06637.pdf"
	},
	"969": {
		"title": "HySTER: A Hybrid Spatio-Temporal Event Reasoner",
		"creator": [
			"Sautory, Theophile",
			"Cingillioglu, Nuri",
			"Russo, Alessandra"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computation and Language",
			"Computer Science - Logic in Computer Science"
		],
		"description": [
			"  The task of Video Question Answering (VideoQA) consists in answering natural\nlanguage questions about a video and serves as a proxy to evaluate the\nperformance of a model in scene sequence understanding. Most methods designed\nfor VideoQA up-to-date are end-to-end deep learning architectures which\nstruggle at complex temporal and causal reasoning and provide limited\ntransparency in reasoning steps. We present the HySTER: a Hybrid\nSpatio-Temporal Event Reasoner to reason over physical events in videos. Our\nmodel leverages the strength of deep learning methods to extract information\nfrom video frames with the reasoning capabilities and explainability of\nsymbolic artificial intelligence in an answer set programming framework. We\ndefine a method based on general temporal, causal and physics rules which can\nbe transferred across tasks. We apply our model to the CLEVRER dataset and\ndemonstrate state-of-the-art results in question answering accuracy. This work\nsets the foundations for the incorporation of inductive logic programming in\nthe field of VideoQA.\n",
			"Comment: Preprint accepted by the 35th AAAI Conference on Artificial\n  Intelligence (AAAI-21) Workshop on Hybrid Artificial Intelligence (HAI)"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06644",
		"pdf_url": "http://arxiv.org/pdf/2101.06644.pdf"
	},
	"970": {
		"title": "LaneRCNN: Distributed Representations for Graph-Centric Motion\n  Forecasting",
		"creator": [
			"Zeng, Wenyuan",
			"Liang, Ming",
			"Liao, Renjie",
			"Urtasun, Raquel"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Robotics"
		],
		"description": "  Forecasting the future behaviors of dynamic actors is an important task in\nmany robotics applications such as self-driving. It is extremely challenging as\nactors have latent intentions and their trajectories are governed by complex\ninteractions between the other actors, themselves, and the maps. In this paper,\nwe propose LaneRCNN, a graph-centric motion forecasting model. Importantly,\nrelying on a specially designed graph encoder, we learn a local lane graph\nrepresentation per actor (LaneRoI) to encode its past motions and the local map\ntopology. We further develop an interaction module which permits efficient\nmessage passing among local graph representations within a shared global lane\ngraph. Moreover, we parameterize the output trajectories based on lane graphs,\na more amenable prediction parameterization. Our LaneRCNN captures the\nactor-to-actor and the actor-to-map relations in a distributed and map-aware\nmanner. We demonstrate the effectiveness of our approach on the large-scale\nArgoverse Motion Forecasting Benchmark. We achieve the 1st place on the\nleaderboard and significantly outperform previous best results.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06653",
		"pdf_url": "http://arxiv.org/pdf/2101.06653.pdf"
	},
	"971": {
		"title": "Zero-touch Continuous Network Slicing Control via Scalable Actor-Critic\n  Learning",
		"creator": [
			"Rezazadeh, Farhad",
			"Chergui, Hatim",
			"Verikoukis, Christos"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": "  Artificial intelligence (AI)-driven zero-touch network slicing is envisaged\nas a promising cutting-edge technology to harness the full potential of\nheterogeneous 5G and beyond 5G (B5G) communication systems and enable the\nautomation of demand-aware resource management and orchestration (MANO). In\nthis paper, we tackle the issue of B5G radio access network (RAN) joint slice\nadmission control and resource allocation according to proposed slice-enabling\ncell-free massive multiple-input multiple-output (mMIMO) setup by invoking a\ncontinuous deep reinforcement learning (DRL) method. We present a novel\nActor-Critic-based network slicing approach called, prioritized twin delayed\ndistributional deep deterministic policy gradient (D-TD3)}. The paper defines\nand corroborates via extensive experimental results a zero-touch network\nslicing scheme with a multi-objective approach where the central server learns\ncontinuously to accumulate the knowledge learned in the past to solve future\nproblems and re-configure computing resources autonomously while minimizing\nlatency, energy consumption, and virtual network function (VNF) instantiation\ncost for each slice. Moreover, we pursue a state-action return distribution\nlearning approach with the proposed replay policy and reward-penalty\nmechanisms. Finally, we present numerical results to showcase the gain of the\nadopted multi-objective strategy and verify the performance in terms of\nachieved slice admission rate, latency, energy, CPU utilization, and time\nefficiency.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06654",
		"pdf_url": "http://arxiv.org/pdf/2101.06654.pdf"
	},
	"972": {
		"title": "On the simultaneous recovery of the conductivity and the nonlinear\n  reaction term in a parabolic equation",
		"creator": [
			"Kaltenbacher, Barbara",
			"Rundell, William"
		],
		"subject": [
			"Mathematics - Analysis of PDEs",
			"Mathematics - Numerical Analysis",
			"Primary: 35R30, 65M32, Secondary: 35R11"
		],
		"description": "  This paper considers the inverse problem of recovering both the unknown,\nspatially-dependent conductivity $a(x)$ and the nonlinear reaction term $f(u)$\nin a reaction-diffusion equation from overposed data. These measurements can\nconsist of: the value of two different solution measurements taken at a later\ntime $T$; time-trace profiles from two solutions; or both final time and\ntime-trace measurements from a single forwards solve data run. We prove both\nuniqueness results and the convergence of iteration schemes designed to recover\nthese coefficients. The last section of the paper shows numerical\nreconstructions based on these algorithms.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06656",
			"Inverse Problems and Imaging, 14:939-966, 2020",
			"doi:10.3934/ipi.2020043"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06656.pdf"
	},
	"973": {
		"title": "A Non-intrusive Failure Prediction Mechanism for Deployed Optical\n  Networks",
		"creator": [
			"Das, Dibakar",
			"Imteyaz, Mohammad Fahad",
			"Bapat, Jyotsna",
			"Das, Debabrata"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": "  Failures in optical network backbone can lead to major disruption of internet\ndata traffic. Hence, minimizing such failures is of paramount importance for\nthe network operators. Even better, if the network failures can be predicted\nand preventive steps can be taken in advance to avoid any disruption in\ntraffic. Various data driven and machine learning techniques have been proposed\nin literature for failure prediction. Most of these techniques need real time\ndata from the networks and also need different monitors to measure key optical\nparameters. This means provision for failure prediction has to be available in\nnetwork nodes, e.g., routers and network management systems. However, sometimes\ndeployed networks do not have failure prediction built into their initial\ndesign but subsequently need arises for such mechanisms. For such systems,\nthere are two key challenges. Firstly, statistics of failure distribution,\ndata, etc., are not readily available. Secondly, major changes cannot be made\nto the network nodes which are already commercially deployed. This paper\nproposes a novel implementable non-intrusive failure prediction mechanism for\ndeployed network nodes using information from log files of those devices.\nNumerical results show that the mechanism has near perfect accuracy in\npredicting failures of individual network nodes.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06661",
		"pdf_url": "http://arxiv.org/pdf/2101.06661.pdf"
	},
	"974": {
		"title": "Separable Batch Normalization for Robust Facial Landmark Localization\n  with Cross-protocol Network Training",
		"creator": [
			"Jin, Shuangping",
			"Feng, Zhenhua",
			"Yang, Wankou",
			"Kittler, Josef"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  A big, diverse and balanced training data is the key to the success of deep\nneural network training. However, existing publicly available datasets used in\nfacial landmark localization are usually much smaller than those for other\ncomputer vision tasks. A small dataset without diverse and balanced training\nsamples cannot support the training of a deep network effectively. To address\nthe above issues, this paper presents a novel Separable Batch Normalization\n(SepBN) module with a Cross-protocol Network Training (CNT) strategy for robust\nfacial landmark localization. Different from the standard BN layer that uses\nall the training data to calculate a single set of parameters, SepBN considers\nthat the samples of a training dataset may belong to different sub-domains.\nAccordingly, the proposed SepBN module uses multiple sets of parameters, each\ncorresponding to a specific sub-domain. However, the selection of an\nappropriate branch in the inference stage remains a challenging task because\nthe sub-domain of a test sample is unknown. To mitigate this difficulty, we\npropose a novel attention mechanism that assigns different weights to each\nbranch for automatic selection in an effective style. As a further innovation,\nthe proposed CNT strategy trains a network using multiple datasets having\ndifferent facial landmark annotation systems, boosting the performance and\nenhancing the generalization capacity of the trained network. The experimental\nresults obtained on several well-known datasets demonstrate the effectiveness\nof the proposed method.\n",
			"Comment: 10 pages,6 figures"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06663",
		"pdf_url": "http://arxiv.org/pdf/2101.06663.pdf"
	},
	"975": {
		"title": "Brightening the Optical Flow through Posit Arithmetic",
		"creator": [
			"Saxena, Vinay",
			"Reddy, Ankitha",
			"Neudorfer, Jonathan",
			"Gustafson, John",
			"Nambiar, Sangeeth",
			"Leupers, Rainer",
			"Merchant, Farhad"
		],
		"subject": [
			"Computer Science - Hardware Architecture",
			"Computer Science - Mathematical Software"
		],
		"description": [
			"  As new technologies are invented, their commercial viability needs to be\ncarefully examined along with their technical merits and demerits. The posit\ndata format, proposed as a drop-in replacement for IEEE 754 float format, is\none such invention that requires extensive theoretical and experimental study\nto identify products that can benefit from the advantages of posits for\nspecific market segments. In this paper, we present an extensive empirical\nstudy of posit-based arithmetic vis-\\`a-vis IEEE 754 compliant arithmetic for\nthe optical flow estimation method called Lucas-Kanade (LuKa). First, we use\nSoftPosit and SoftFloat format emulators to perform an empirical error analysis\nof the LuKa method. Our study shows that the average error in LuKa with\nSoftPosit is an order of magnitude lower than LuKa with SoftFloat. We then\npresent the integration of the hardware implementation of a posit adder and\nmultiplier in a RISC-V open-source platform. We make several recommendations,\nalong with the analysis of LuKa in the RISC-V context, for future generation\nplatforms incorporating posit arithmetic units.\n",
			"Comment: To appear in ISQED 2021"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06665",
		"pdf_url": "http://arxiv.org/pdf/2101.06665.pdf"
	},
	"976": {
		"title": "Deep Learning-Aided 5G Channel Estimation",
		"creator": [
			"Ha, An Le",
			"Van Chien, Trinh",
			"Nguyen, Tien Hoa",
			"Choi, Wan",
			"Nguyen, Van Duc"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  Deep learning has demonstrated the important roles in improving the system\nperformance and reducing computational complexity for $5$G-and-beyond networks.\nIn this paper, we propose a new channel estimation method with the assistance\nof deep learning in order to support the least squares estimation, which is a\nlow-cost method but having relatively high channel estimation errors. This goal\nis achieved by utilizing a MIMO (multiple-input multiple-output) system with a\nmulti-path channel profile used for simulations in the 5G networks under the\nseverity of Doppler effects. Numerical results demonstrate the superiority of\nthe proposed deep learning-assisted channel estimation method over the other\nchannel estimation methods in previous works in terms of mean square errors.\n",
			"Comment: 7 pages, 8 figures, and 3 tables. This paper was presented at IMCOM\n  2021"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06666",
		"pdf_url": "http://arxiv.org/pdf/2101.06666.pdf"
	},
	"977": {
		"title": "A Technical Report for Light-Edge: A Lightweight Authentication Protocol\n  for IoT Devices in an Edge-Cloud Environment",
		"creator": [
			"Shahidinejad, Ali",
			"Ghobaei-Arani, Mostafa",
			"Souri, Alireza",
			"Shojafar, Mohammad",
			"Kumari, Saru"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Information Theory"
		],
		"description": [
			"  Selected procedures in [1] and additional simulation results are presented in\ndetail in this report. We first present the IoT device registration in Section\nI, and we provide the details of fuzzy-based trust computation in Section II.\nIn the end, we show some additional simulation results for formal validation of\nthe Light-Edge under On-the-Fly Model Checker (OFMC) and Constraint-Logic-based\nATtack SEarcher (CLAtse) tools in Section III. See the original paper [1] for\nmore detail.\n",
			"Comment: 5 pages, 13 figures, 5 tables, technical report of IEEE Consumer\n  Electronics Magazine paper (Light-Edge)"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06676",
		"pdf_url": "http://arxiv.org/pdf/2101.06676.pdf"
	},
	"978": {
		"title": "End-to-end Interpretable Neural Motion Planner",
		"creator": [
			"Zeng, Wenyuan",
			"Luo, Wenjie",
			"Suo, Simon",
			"Sadat, Abbas",
			"Yang, Bin",
			"Casas, Sergio",
			"Urtasun, Raquel"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Robotics"
		],
		"description": [
			"  In this paper, we propose a neural motion planner (NMP) for learning to drive\nautonomously in complex urban scenarios that include traffic-light handling,\nyielding, and interactions with multiple road-users. Towards this goal, we\ndesign a holistic model that takes as input raw LIDAR data and a HD map and\nproduces interpretable intermediate representations in the form of 3D\ndetections and their future trajectories, as well as a cost volume defining the\ngoodness of each position that the self-driving car can take within the\nplanning horizon. We then sample a set of diverse physically possible\ntrajectories and choose the one with the minimum learned cost. Importantly, our\ncost volume is able to naturally capture multi-modality. We demonstrate the\neffectiveness of our approach in real-world driving data captured in several\ncities in North America. Our experiments show that the learned cost volume can\ngenerate safer planning than all the baselines.\n",
			"Comment: CVPR 2019 (Oral)"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06679",
		"pdf_url": "http://arxiv.org/pdf/2101.06679.pdf"
	},
	"979": {
		"title": "KCP: Kernel Cluster Pruning for Dense Labeling Neural Networks",
		"creator": [
			"Yu, Po-Hsiang",
			"Wu, Sih-Sian",
			"Chen, Liang-Gee"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Pruning has become a promising technique used to compress and accelerate\nneural networks. Existing methods are mainly evaluated on spare labeling\napplications. However, dense labeling applications are those closer to real\nworld problems that require real-time processing on resource-constrained mobile\ndevices. Pruning for dense labeling applications is still a largely unexplored\nfield. The prevailing filter channel pruning method removes the entire filter\nchannel. Accordingly, the interaction between each kernel in one filter channel\nis ignored.\n  In this study, we proposed kernel cluster pruning (KCP) to prune dense\nlabeling networks. We developed a clustering technique to identify the least\nrepresentational kernels in each layer. By iteratively removing those kernels,\nthe parameter that can better represent the entire network is preserved; thus,\nwe achieve better accuracy with a decent model size and computation reduction.\nWhen evaluated on stereo matching and semantic segmentation neural networks,\nour method can reduce more than 70% of FLOPs with less than 1% of accuracy\ndrop. Moreover, for ResNet-50 on ILSVRC-2012, our KCP can reduce more than 50%\nof FLOPs reduction with 0.13% Top-1 accuracy gain. Therefore, KCP achieves\nstate-of-the-art pruning results.\n",
			"Comment: 17 pages, 16 figures"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06686",
		"pdf_url": "http://arxiv.org/pdf/2101.06686.pdf"
	},
	"980": {
		"title": "On uniqueness and reconstruction of a nonlinear diffusion term in a\n  parabolic equation",
		"creator": [
			"Kaltenbacher, Barbara",
			"Rundell, William"
		],
		"subject": [
			"Mathematics - Analysis of PDEs",
			"Mathematics - Numerical Analysis",
			"35R30, 35K15, 35K58, 80A23"
		],
		"description": "  The problem of recovering coefficients in a diffusion equation is one of the\nbasic inverse problems. Perhaps the most important term is the one that couples\nthe length and time scales and is often referred to as {\\it the\\/} diffusion\ncoefficient $a$ in $u_t - \\nabla(a\\nabla u) = f$. In this paper we seek the\nunknown $a$ assuming that $a=a(u)$ depends only on the value of the solution at\na given point. Such diffusion models are the basic of a wide range of physical\nphenomena such as nonlinear heat conduction, chemical mixing and population\ndynamics. We shall look at two types of overposed data in order to effect\nrecovery of $a(u)$: the value of a time trace $u(x_0,t)$ for some fixed point\n$x_0$ on the boundary of the region $\\Omega$; or the value of $u$ on an\ninterior curve $\\Sigma$ lying within $\\Omega$. As examples, these might\nrepresent a temperature measurement on the boundary or a census of the\npopulation in some subset of $\\Omega$ taken at a fixed time $T>0$. In the\nlatter case we shall show a uniqueness result that leads to a constructive\nmethod for recovery of $a$. Indeed, for both types of measured data we shall\nshow reconstructions based on the iterative algorithms developed in the paper.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06696",
		"pdf_url": "http://arxiv.org/pdf/2101.06696.pdf"
	},
	"981": {
		"title": "Adversarial Interaction Attack: Fooling AI to Misinterpret Human\n  Intentions",
		"creator": [
			"Koren, Nodens",
			"Ke, Qiuhong",
			"Wang, Yisen",
			"Bailey, James",
			"Ma, Xingjun"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Cryptography and Security",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Understanding the actions of both humans and artificial intelligence (AI)\nagents is important before modern AI systems can be fully integrated into our\ndaily life. In this paper, we show that, despite their current huge success,\ndeep learning based AI systems can be easily fooled by subtle adversarial noise\nto misinterpret the intention of an action in interaction scenarios. Based on a\ncase study of skeleton-based human interactions, we propose a novel adversarial\nattack on interactions, and demonstrate how DNN-based interaction models can be\ntricked to predict the participants' reactions in unexpected ways. From a\nbroader perspective, the scope of our proposed attack method is not confined to\nproblems related to skeleton data but can also be extended to any type of\nproblems involving sequential regressions. Our study highlights potential risks\nin the interaction loop with AI and humans, which need to be carefully\naddressed when deploying AI systems in safety-critical applications.\n",
			"Comment: Preprint"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06704",
		"pdf_url": "http://arxiv.org/pdf/2101.06704.pdf"
	},
	"982": {
		"title": "Human Activity Recognition Using Multichannel Convolutional Neural\n  Network",
		"creator": [
			"Sikder, Niloy",
			"Chowdhury, Md. Sanaullah",
			"Arif, Abu Shamim Mohammad",
			"Nahid, Abdullah-Al"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Human Activity Recognition (HAR) simply refers to the capacity of a machine\nto perceive human actions. HAR is a prominent application of advanced Machine\nLearning and Artificial Intelligence techniques that utilize computer vision to\nunderstand the semantic meanings of heterogeneous human actions. This paper\ndescribes a supervised learning method that can distinguish human actions based\non data collected from practical human movements. The primary challenge while\nworking with HAR is to overcome the difficulties that come with the\ncyclostationary nature of the activity signals. This study proposes a HAR\nclassification model based on a two-channel Convolutional Neural Network (CNN)\nthat makes use of the frequency and power features of the collected human\naction signals. The model was tested on the UCI HAR dataset, which resulted in\na 95.25% classification accuracy. This approach will help to conduct further\nresearches on the recognition of human activities based on their biomedical\nsignals.\n",
			"Comment: 10 pages, Proceedings of the 2019 5th International Conference on\n  Advances in Electrical Engineering (ICAEE), 26-28 September, Dhaka,\n  Bangladesh"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06709",
			"doi:10.1109/ICAEE48663.2019.8975649"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06709.pdf"
	},
	"983": {
		"title": "Heterogeneous Hand Guise Classification Based on Surface\n  Electromyographic Signals Using Multichannel Convolutional Neural Network",
		"creator": [
			"Sikder, Niloy",
			"Arif, Abu Shamim Mohammad",
			"Nahid, Abdullah-Al"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Electromyography (EMG) is a way of measuring the bioelectric activities that\ntake place inside the muscles. EMG is usually performed to detect abnormalities\nwithin the nerves or muscles of a target area. The recent developments in the\nfield of Machine Learning allow us to use EMG signals to teach machines the\ncomplex properties of human movements. Modern machines are capable of detecting\nnumerous human activities and distinguishing among them solely based on the EMG\nsignals produced by those activities. However, success in accomplishing this\ntask mostly depends on the learning technique used by the machine to analyze\nEMG signals; and even the latest algorithms do not result in flawless\nclassification. In this study, a novel classification method has been described\nemploying a multichannel Convolutional Neural Network (CNN) that interprets\nsurface EMG signals by the properties they exhibit in the power domain. The\nproposed method was tested on a well-established EMG dataset, and the result\nyields very high classification accuracy. This learning model will help\nresearchers to develop prosthetic arms capable of detecting various hand\ngestures to mimic them afterwards.\n",
			"Comment: 10 pages, 2019 22nd International Conference of Computer and\n  Information Technology (ICCIT), 18-20 December, 2019"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06715",
			"doi:10.1109/ICCIT48885.2019.9038173"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06715.pdf"
	},
	"984": {
		"title": "Observer Design for Systems of Conservation Laws with Lipschitz\n  Nonlinear Boundary Dynamics",
		"creator": [
			"Ferrante, Francesco",
			"Cristofaro, Andrea"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  The problem of state estimation for a system of coupled hyperbolic PDEs and\nODEs with Lipschitz nonlinearities with boundary measurements is considered. An\ninfinite dimensional observer with a linear boundary injection term is used to\nsolve the state estimation problem. The interconnection of the observer and the\nsystem is written in estimation error coordinates and analyzed as an abstract\ndynamical system. The observer is designed to achieve global exponential\nstability of estimation error with respect to a suitable norm. Sufficient\nconditions in the form of matrix inequalities are proposed to design the\nobserver. Numerical simulations support and corroborate the theoretical\nresults.\n",
			"Comment: This version fixes a few minor typos and proposes a clearer proof\n  sketch for Proposition 1"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06719",
			"Proceedings of the American Control Conference 2020, pages\n  3431-3436",
			"doi:10.23919/ACC45564.2020.9147240"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06719.pdf"
	},
	"985": {
		"title": "On the detection and identification of edge disconnections in a\n  multi-agent consensus network",
		"creator": [
			"Parlangeli, Gianfranco",
			"Valcher, Maria Elena"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": "  In this paper we investigate the problem of the sudden disconnection of an\nedge in a discrete-time multi-agent consensus network. If the graph remains\nstrongly connected, the multi-agent system still achieves consensus, but in\ngeneral, unless the information exchange between each pair of agents is\nsymmetric, the agents' states converge to a drifted value of the original\nconsensus value. Consequently the edge disconnection can go unnoticed. In this\npaper the problems of detecting an edge disconnection and of identifying in a\nfinite number of steps the exact edge that got disconnected are investigated.\nNecessary and sufficient conditions for both problems to be solvable are\npresented, both in case all the agents' states are available and in case only a\nsubset of the agents' states is measured. Finally, an example of a network of 7\nagents is provided, to illustrate some of the theoretical results derived in\nthe paper.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06728",
		"pdf_url": "http://arxiv.org/pdf/2101.06728.pdf"
	},
	"986": {
		"title": "Profiling Software Developers with Process Mining and N-Gram Language\n  Models",
		"creator": [
			"Caldeira, João",
			"Abreu, Fernando Brito e",
			"Cardoso, Jorge",
			"Ribeiro, Ricardo",
			"Werner, Claudia"
		],
		"subject": "Computer Science - Software Engineering",
		"description": "  Context: Profiling developers is challenging since many factors, such as\ntheir skills, experience, development environment and behaviors, may influence\na detailed analysis and the delivery of coherent interpretations.\n  Objective: We aim at profiling software developers by mining their software\ndevelopment process. To do so, we performed a controlled experiment where, in\nthe realm of a Python programming contest, a group of developers had the same\nwell-defined set of requirements specifications and a well-defined sprint\nschedule. Events were collected from the PyCharm IDE, and from the Mooshak\nautomatic jury where subjects checked-in their code.\n  Method: We used n-gram language models and text mining to characterize\ndevelopers' profiles, and process mining algorithms to discover their overall\nworkflows and extract the correspondent metrics for further evaluation.\n  Results: Findings show that we can clearly characterize with a coherent\nrationale most developers, and distinguish the top performers from the ones\nwith more challenging behaviors. This approach may lead ultimately to the\ncreation of a catalog of software development process smells.\n  Conclusions: The profile of a developer provides a software project manager a\nclue for the selection of appropriate tasks he/she should be assigned. With the\nincreasing usage of low and no-code platforms, where coding is automatically\ngenerated from an upper abstraction layer, mining developer's actions in the\ndevelopment platforms is a promising approach to early detect not only\nbehaviors but also assess project complexity and model effort.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06733",
		"pdf_url": "http://arxiv.org/pdf/2101.06733.pdf"
	},
	"987": {
		"title": "The BIVEE Project: an overview of methodology and tools",
		"creator": [
			"Missikoff, M.",
			"Assogna, P."
		],
		"subject": [
			"Computer Science - Computers and Society",
			"H.4.m",
			"H.m"
		],
		"description": [
			"  EU needs an effective exit strategy from the crisis, with a special attention\nto SMEs that represent the 99% of the enterprises active in the European\nproduction system. To this end, innovation appears to be a key factor to\nrelaunch the EU industrial system. The BIVEE project proceeded for almost 4\nyears to develop a rich framework, i.e., a methodology and a cloud-based\nsoftware environment, that includes business principles, models, and best\npractices, plus a number of advanced software services, to support and promote\nproduction improvement and business innovation in virtual enterprise\nenvironments (essentially, enterprise networks.)\n",
			"Comment: 26 pages, 8 figures"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06736",
		"pdf_url": "http://arxiv.org/pdf/2101.06736.pdf"
	},
	"988": {
		"title": "Energy-based Dropout in Restricted Boltzmann Machines: Why not go random",
		"creator": [
			"Roder, Mateus",
			"de Rosa, Gustavo H.",
			"de Albuquerque, Victor Hugo C.",
			"Rossi, André L. D.",
			"Papa, João P."
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  Deep learning architectures have been widely fostered throughout the last\nyears, being used in a wide range of applications, such as object recognition,\nimage reconstruction, and signal processing. Nevertheless, such models suffer\nfrom a common problem known as overfitting, which limits the network from\npredicting unseen data effectively. Regularization approaches arise in an\nattempt to address such a shortcoming. Among them, one can refer to the\nwell-known Dropout, which tackles the problem by randomly shutting down a set\nof neurons and their connections according to a certain probability. Therefore,\nthis approach does not consider any additional knowledge to decide which units\nshould be disconnected. In this paper, we propose an energy-based Dropout\n(E-Dropout) that makes conscious decisions whether a neuron should be dropped\nor not. Specifically, we design this regularization method by correlating\nneurons and the model's energy as an importance level for further applying it\nto energy-based models, such as Restricted Boltzmann Machines (RBMs). The\nexperimental results over several benchmark datasets revealed the proposed\napproach's suitability compared to the traditional Dropout and the standard\nRBMs.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06741",
			"doi:10.1109/TETCI.2020.3043764"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06741.pdf"
	},
	"989": {
		"title": "Deep Parametric Continuous Convolutional Neural Networks",
		"creator": [
			"Wang, Shenlong",
			"Suo, Simon",
			"Ma, Wei-Chiu",
			"Pokrovsky, Andrei",
			"Urtasun, Raquel"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning",
			"Computer Science - Robotics",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Standard convolutional neural networks assume a grid structured input is\navailable and exploit discrete convolutions as their fundamental building\nblocks. This limits their applicability to many real-world applications. In\nthis paper we propose Parametric Continuous Convolution, a new learnable\noperator that operates over non-grid structured data. The key idea is to\nexploit parameterized kernel functions that span the full continuous vector\nspace. This generalization allows us to learn over arbitrary data structures as\nlong as their support relationship is computable. Our experiments show\nsignificant improvement over the state-of-the-art in point cloud segmentation\nof indoor and outdoor scenes, and lidar motion estimation of driving scenes.\n",
			"Comment: Accepted by CVPR 2018"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06742",
			"doi:10.1109/CVPR.2018.00274"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06742.pdf"
	},
	"990": {
		"title": "Intestinal Parasites Classification Using Deep Belief Networks",
		"creator": [
			"Roder, Mateus",
			"Passos, Leandro A.",
			"Ribeiro, Luiz Carlos Felix",
			"Benato, Barbara Caroline",
			"Falcão, Alexandre Xavier",
			"Papa, João Paulo"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Currently, approximately $4$ billion people are infected by intestinal\nparasites worldwide. Diseases caused by such infections constitute a public\nhealth problem in most tropical countries, leading to physical and mental\ndisorders, and even death to children and immunodeficient individuals. Although\nsubjected to high error rates, human visual inspection is still in charge of\nthe vast majority of clinical diagnoses. In the past years, some works\naddressed intelligent computer-aided intestinal parasites classification, but\nthey usually suffer from misclassification due to similarities between\nparasites and fecal impurities. In this paper, we introduce Deep Belief\nNetworks to the context of automatic intestinal parasites classification.\nExperiments conducted over three datasets composed of eggs, larvae, and\nprotozoa provided promising results, even considering unbalanced classes and\nalso fecal impurities.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06747",
			"doi:10.1007/978-3-030-61401-0_23"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06747.pdf"
	},
	"991": {
		"title": "A Layer-Wise Information Reinforcement Approach to Improve Learning in\n  Deep Belief Networks",
		"creator": [
			"Roder, Mateus",
			"Passos, Leandro A.",
			"Ribeiro, Luiz Carlos Felix",
			"Pereira, Clayton",
			"Papa, João Paulo"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": "  With the advent of deep learning, the number of works proposing new methods\nor improving existent ones has grown exponentially in the last years. In this\nscenario, \"very deep\" models were emerging, once they were expected to extract\nmore intrinsic and abstract features while supporting a better performance.\nHowever, such models suffer from the gradient vanishing problem, i.e.,\nbackpropagation values become too close to zero in their shallower layers,\nultimately causing learning to stagnate. Such an issue was overcome in the\ncontext of convolution neural networks by creating \"shortcut connections\"\nbetween layers, in a so-called deep residual learning framework. Nonetheless, a\nvery popular deep learning technique called Deep Belief Network still suffers\nfrom gradient vanishing when dealing with discriminative tasks. Therefore, this\npaper proposes the Residual Deep Belief Network, which considers the\ninformation reinforcement layer-by-layer to improve the feature extraction and\nknowledge retaining, that support better discriminative performance.\nExperiments conducted over three public datasets demonstrate its robustness\nconcerning the task of binary image classification.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06749",
			"doi:10.1007/978-3-030-61401-0_22"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06749.pdf"
	},
	"992": {
		"title": "Data stream fusion for accurate quantile tracking and analysis",
		"creator": [
			"Cafaro, Massimo",
			"Melle, Catiuscia",
			"Epicoco, Italo",
			"Pulimeno, Marco"
		],
		"subject": [
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Databases",
			"Computer Science - Distributed, Parallel, and Cluster Computing"
		],
		"description": "  UDDSKETCH is a recent algorithm for accurate tracking of quantiles in data\nstreams, derived from the DDSKETCH algorithm. UDDSKETCH provides accuracy\nguarantees covering the full range of quantiles independently of the input\ndistribution and greatly improves the accuracy with regard to DDSKETCH. In this\npaper we show how to compress and fuse data streams (or datasets) by using\nUDDSKETCH data summaries that are fused into a new summary related to the union\nof the streams (or datasets) processed by the input summaries whilst preserving\nboth the error and size guarantees provided by UDDSKETCH. This property of\nsketches, known as mergeability, enables parallel and distributed processing.\nWe prove that UDDSKETCH is fully mergeable and introduce a parallel version of\nUDDSKETCH suitable for message-passing based architectures. We formally prove\nits correctness and compare it to a parallel version of DDSKETCH, showing\nthrough extensive experimental results that our parallel algorithm almost\nalways outperforms the parallel DDSKETCH algorithm with regard to the overall\naccuracy in determining the quantiles.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06758",
		"pdf_url": "http://arxiv.org/pdf/2101.06758.pdf"
	},
	"993": {
		"title": "Proceedings of the 2020 Scheme and Functional Programming Workshop",
		"creator": [
			"Saleil, Baptiste",
			"Adams, Michael D."
		],
		"subject": [
			"Computer Science - Programming Languages",
			"D.3.m"
		],
		"description": [
			"  This report aggregates the papers presented at the twenty-first annual Scheme\nand Functional Programming Workshop, hosted on August 28th, 2020, online and\nco-located with the twenty-fifth International Conference on Functional\nProgramming. The Scheme and Functional Programming Workshop is held every year\nto provide an opportunity for researchers and practitioners using Scheme and\nrelated functional programming languages like Racket, Clojure, and Lisp, to\nshare research findings and discuss the future of the Scheme programming\nlanguage.\n",
			"Comment: 85 pages; 30 figures; workshop website at\n  https://icfp20.sigplan.org/home/scheme-2020"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06759",
		"pdf_url": "http://arxiv.org/pdf/2101.06759.pdf"
	},
	"994": {
		"title": "Spatial Network Decomposition for Fast and Scalable AC-OPF Learning",
		"creator": [
			"Chatzos, Minas",
			"Mak, Terrence W. K.",
			"Van Hentenryck, Pascal"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": "  This paper proposes a novel machine-learning approach for predicting AC-OPF\nsolutions that features a fast and scalable training. It is motivated by the\ntwo critical considerations: (1) the fact that topology optimization and the\nstochasticity induced by renewable energy sources may lead to fundamentally\ndifferent AC-OPF instances; and (2) the significant training time needed by\nexisting machine-learning approaches for predicting AC-OPF. The proposed\napproach is a 2-stage methodology that exploits a spatial decomposition of the\npower network that is viewed as a set of regions. The first stage learns to\npredict the flows and voltages on the buses and lines coupling the regions, and\nthe second stage trains, in parallel, the machine-learning models for each\nregion. Experimental results on the French transmission system (up to 6,700\nbuses and 9,000 lines) demonstrate the potential of the approach. Within a\nshort training time, the approach predicts AC-OPF solutions with very high\nfidelity and minor constraint violations, producing significant improvements\nover the state-of-the-art. The results also show that the predictions can seed\na load flow optimization to return a feasible solution within 0.03% of the\nAC-OPF objective, while reducing running times significantly.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06768",
		"pdf_url": "http://arxiv.org/pdf/2101.06768.pdf"
	},
	"995": {
		"title": "Improving Apparel Detection with Category Grouping and Multi-grained\n  Branches",
		"creator": [
			"Tian, Qing",
			"Chanda, Sampath",
			"Kumar, K C Amit",
			"Gray, Douglas"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Training an accurate object detector is expensive and time-consuming. One\nmain reason lies in the laborious labeling process, i.e., annotating category\nand bounding box information for all instances in every image. In this paper,\nwe examine ways to improve performance of deep object detectors without extra\nlabeling. We first explore to group existing categories of high visual and\nsemantic similarities together as one super category (or, a superclass). Then,\nwe study how this knowledge of hierarchical categories can be exploited to\nbetter detect object using multi-grained RCNN top branches. Experimental\nresults on DeepFashion2 and OpenImagesV4-Clothing reveal that the proposed\ndetection heads with multi-grained branches can boost the overall performance\nby 2.3 mAP for DeepFashion2 and 2.5 mAP for OpenImagesV4-Clothing with no\nadditional time-consuming annotations. More importantly, classes that have\nfewer training samples tend to benefit more from the proposed multi-grained\nheads with superclass grouping. In particular, we improve the mAP for last 30%\ncategories (in terms of training sample number) by 2.6 and 4.6 for DeepFashion2\nand OpenImagesV4-Clothing, respectively.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06770",
		"pdf_url": "http://arxiv.org/pdf/2101.06770.pdf"
	},
	"996": {
		"title": "Temporal Spatial-Adaptive Interpolation with Deformable Refinement for\n  Electron Microscopic Images",
		"creator": [
			"Wang, Zejin",
			"Sun, Guodong",
			"Zhang, Lina",
			"Li, Guoqing",
			"Han, Hua"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Recently, flow-based methods have achieved promising success in video frame\ninterpolation. However, electron microscopic (EM) images suffer from unstable\nimage quality, low PSNR, and disorderly deformation. Existing flow-based\ninterpolation methods cannot precisely compute optical flow for EM images since\nonly predicting each position's unique offset. To overcome these problems, we\npropose a novel interpolation framework for EM images that progressively\nsynthesizes interpolated features in a coarse-to-fine manner. First, we extract\nmissing intermediate features by the proposed temporal spatial-adaptive (TSA)\ninterpolation module. The TSA interpolation module aggregates temporal contexts\nand then adaptively samples the spatial-related features with the proposed\nresidual spatial adaptive block. Second, we introduce a stacked deformable\nrefinement block (SDRB) further enhance the reconstruction quality, which is\naware of the matching positions and relevant features from input frames with\nthe feedback mechanism. Experimental results demonstrate the superior\nperformance of our approach compared to previous works, both quantitatively and\nqualitatively.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06771",
		"pdf_url": "http://arxiv.org/pdf/2101.06771.pdf"
	},
	"997": {
		"title": "Latent Space Analysis of VAE and Intro-VAE applied to 3-dimensional MR\n  Brain Volumes of Multiple Sclerosis, Leukoencephalopathy, and Healthy\n  Patients",
		"creator": [
			"Vogelsanger, Christopher",
			"Federau, Christian"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  Multiple Sclerosis (MS) and microvascular leukoencephalopathy are two\ndistinct neurological conditions, the first caused by focal autoimmune\ninflammation in the central nervous system, the second caused by chronic white\nmatter damage from atherosclerotic microvascular disease. Both conditions lead\nto signal anomalies on Fluid Attenuated Inversion Recovery (FLAIR) magnetic\nresonance (MR) images, which can be distinguished by an expert\nneuroradiologist, but which can look very similar to the untrained eye as well\nas in the early stage of both diseases. In this paper, we attempt to train a\n3-dimensional deep neural network to learn the specific features of both\ndiseases in an unsupervised manner. For this manner, in a first step we train a\ngenerative neural network to create artificial MR images of both conditions\nwith approximate explicit density, using a mixed dataset of multiple sclerosis,\nleukoencephalopathy and healthy patients containing in total 5404 volumes of\n3096 patients. In a second step, we distinguish features between the different\ndiseases in the latent space of this network, and use them to classify new\ndata.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06772",
		"pdf_url": "http://arxiv.org/pdf/2101.06772.pdf"
	},
	"998": {
		"title": "Learning from pandemics: using extraordinary events can improve disease\n  now-casting models",
		"creator": [
			"Mesquita, Sara",
			"Vieira, Cláudio Haupt",
			"Perfeito, Lília",
			"Gonçalves-Sá, Joana"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Online searches have been used to study different health-related behaviours,\nincluding monitoring disease outbreaks. An obvious caveat is that several\nreasons can motivate individuals to seek online information and models that are\nblind to people's motivations are of limited use and can even mislead. This is\nparticularly true during extraordinary public health crisis, such as the\nongoing pandemic, when fear, curiosity and many other reasons can lead\nindividuals to search for health-related information, masking the\ndisease-driven searches. However, health crisis can also offer an opportunity\nto disentangle between different drivers and learn about human behavior. Here,\nwe focus on the two pandemics of the 21st century (2009-H1N1 flu and Covid-19)\nand propose a methodology to discriminate between search patterns linked to\ngeneral information seeking (media driven) and search patterns possibly more\nassociated with actual infection (disease driven). We show that by learning\nfrom such pandemic periods, with high anxiety and media hype, it is possible to\nselect online searches and improve model performance both in pandemic and\nseasonal settings. Moreover, and despite the common claim that more data is\nalways better, our results indicate that lower volume of the right data can be\nbetter than including large volumes of apparently similar data, especially in\nthe long run. Our work provides a general framework that can be applied beyond\nspecific events and diseases, and argues that algorithms can be improved simply\nby using less (better) data. This has important consequences, for example, to\nsolve the accuracy-explainability trade-off in machine-learning.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06774",
		"pdf_url": "http://arxiv.org/pdf/2101.06774.pdf"
	},
	"999": {
		"title": "Symmetric-Constrained Irregular Structure Inpainting for Brain MRI\n  Registration with Tumor Pathology",
		"creator": [
			"Liu, Xiaofeng",
			"Xing, Fangxu",
			"Yang, Chao",
			"Kuo, C. -C. Jay",
			"ElFakhri, Georges",
			"Woo, Jonghye"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  Deformable registration of magnetic resonance images between patients with\nbrain tumors and healthy subjects has been an important tool to specify tumor\ngeometry through location alignment and facilitate pathological analysis. Since\ntumor region does not match with any ordinary brain tissue, it has been\ndifficult to deformably register a patients brain to a normal one. Many patient\nimages are associated with irregularly distributed lesions, resulting in\nfurther distortion of normal tissue structures and complicating registration's\nsimilarity measure. In this work, we follow a multi-step context-aware image\ninpainting framework to generate synthetic tissue intensities in the tumor\nregion. The coarse image-to-image translation is applied to make a rough\ninference of the missing parts. Then, a feature-level patch-match refinement\nmodule is applied to refine the details by modeling the semantic relevance\nbetween patch-wise features. A symmetry constraint reflecting a large degree of\nanatomical symmetry in the brain is further proposed to achieve better\nstructure understanding. Deformable registration is applied between inpainted\npatient images and normal brains, and the resulting deformation field is\neventually used to deform original patient data for the final alignment. The\nmethod was applied to the Multimodal Brain Tumor Segmentation (BraTS) 2018\nchallenge database and compared against three existing inpainting methods. The\nproposed method yielded results with increased peak signal-to-noise ratio,\nstructural similarity index, inception score, and reduced L1 error, leading to\nsuccessful patient-to-normal brain image registration.\n",
			"Comment: Published at MICCAI Brainles 2020"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06775",
		"pdf_url": "http://arxiv.org/pdf/2101.06775.pdf"
	},
	"1000": {
		"title": "An embedded multichannel sound acquisition system for drone audition",
		"creator": [
			"Clayton, Michael",
			"Wang, Lin",
			"McPherson, Andrew",
			"Cavallaro, Andrea"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Audio and Speech Processing",
			"Computer Science - Sound",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": "  Microphone array techniques can improve the acoustic sensing performance on\ndrones, compared to the use of a single microphone. However, multichannel sound\nacquisition systems are not available in current commercial drone platforms. To\nencourage the research in drone audition, we present an embedded sound\nacquisition and recording system with eight microphones and a multichannel\nsound recorder mounted on a quadcopter. In addition to recording and storing\nlocally the sound from multiple microphones simultaneously, the embedded system\ncan connect wirelessly to a remote terminal to transfer audio files for further\nprocessing. This will be the first stage towards creating a fully embedded\nsolution for drone audition. We present experimental results obtained by\nstate-of-the-art drone audition algorithms applied to the sound recorded by the\nembedded system.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06795",
		"pdf_url": "http://arxiv.org/pdf/2101.06795.pdf"
	},
	"1001": {
		"title": "MPC-MPNet: Model-Predictive Motion Planning Networks for Fast,\n  Near-Optimal Planning under Kinodynamic Constraints",
		"creator": [
			"Li, Linjun",
			"Miao, Yinglong",
			"Qureshi, Ahmed H.",
			"Yip, Michael C."
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": "  Kinodynamic Motion Planning (KMP) is to find a robot motion subject to\nconcurrent kinematics and dynamics constraints. To date, quite a few methods\nsolve KMP problems and those that exist struggle to find near-optimal solutions\nand exhibit high computational complexity as the planning space dimensionality\nincreases. To address these challenges, we present a scalable, imitation\nlearning-based, Model-Predictive Motion Planning Networks framework that\nquickly finds near-optimal path solutions with worst-case theoretical\nguarantees under kinodynamic constraints for practical underactuated systems.\nOur framework introduces two algorithms built on a neural generator,\ndiscriminator, and a parallelizable Model Predictive Controller (MPC). The\ngenerator outputs various informed states towards the given target, and the\ndiscriminator selects the best possible subset from them for the extension. The\nMPC locally connects the selected informed states while satisfying the given\nconstraints leading to feasible, near-optimal solutions. We evaluate our\nalgorithms on a range of cluttered, kinodynamically constrained, and\nunderactuated planning problems with results indicating significant\nimprovements in computation times, path qualities, and success rates over\nexisting methods.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06798",
		"pdf_url": "http://arxiv.org/pdf/2101.06798.pdf"
	},
	"1002": {
		"title": "Heterogeneous Similarity Graph Neural Network on Electronic Health\n  Records",
		"creator": [
			"Liu, Zheng",
			"Li, Xiaohan",
			"Peng, Hao",
			"He, Lifang",
			"Yu, Philip S."
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Mining Electronic Health Records (EHRs) becomes a promising topic because of\nthe rich information they contain. By learning from EHRs, machine learning\nmodels can be built to help human experts to make medical decisions and thus\nimprove healthcare quality. Recently, many models based on sequential or graph\nmodels are proposed to achieve this goal. EHRs contain multiple entities and\nrelations and can be viewed as a heterogeneous graph. However, previous studies\nignore the heterogeneity in EHRs. On the other hand, current heterogeneous\ngraph neural networks cannot be simply used on an EHR graph because of the\nexistence of hub nodes in it. To address this issue, we propose Heterogeneous\nSimilarity Graph Neural Network (HSGNN) analyze EHRs with a novel heterogeneous\nGNN. Our framework consists of two parts: one is a preprocessing method and the\nother is an end-to-end GNN. The preprocessing method normalizes edges and\nsplits the EHR graph into multiple homogeneous graphs while each homogeneous\ngraph contains partial information of the original EHR graph. The GNN takes all\nhomogeneous graphs as input and fuses all of them into one graph to make a\nprediction. Experimental results show that HSGNN outperforms other baselines in\nthe diagnosis prediction task.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06800",
		"pdf_url": "http://arxiv.org/pdf/2101.06800.pdf"
	},
	"1003": {
		"title": "Measure-conditional Discriminator with Stationary Optimum for GANs and\n  Statistical Distance Surrogates",
		"creator": [
			"Yang, Liu",
			"Meng, Tingwei",
			"Karniadakis, George Em"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  We propose a simple but effective modification of the discriminators, namely\nmeasure-conditional discriminators, as a plug-and-play module for different\nGANs. By taking the generated distributions as part of input so that the target\noptimum for the discriminator is stationary, the proposed discriminator is more\nrobust than the vanilla one. A variant of the measure-conditional discriminator\ncan also handle multiple target distributions, or act as a surrogate model of\nstatistical distances such as KL divergence with applications to transfer\nlearning.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06802",
		"pdf_url": "http://arxiv.org/pdf/2101.06802.pdf"
	},
	"1004": {
		"title": "Narration Generation for Cartoon Videos",
		"creator": [
			"Papasarantopoulos, Nikos",
			"Cohen, Shay B."
		],
		"subject": "Computer Science - Computation and Language",
		"description": "  Research on text generation from multimodal inputs has largely focused on\nstatic images, and less on video data. In this paper, we propose a new task,\nnarration generation, that is complementing videos with narration texts that\nare to be interjected in several places. The narrations are part of the video\nand contribute to the storyline unfolding in it. Moreover, they are\ncontext-informed, since they include information appropriate for the timeframe\nof video they cover, and also, do not need to include every detail shown in\ninput scenes, as a caption would. We collect a new dataset from the animated\ntelevision series Peppa Pig. Furthermore, we formalize the task of narration\ngeneration as including two separate tasks, timing and content generation, and\npresent a set of models on the new task.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06803",
		"pdf_url": "http://arxiv.org/pdf/2101.06803.pdf"
	},
	"1005": {
		"title": "What Makes Good In-Context Examples for GPT-$3$?",
		"creator": [
			"Liu, Jiachang",
			"Shen, Dinghan",
			"Zhang, Yizhe",
			"Dolan, Bill",
			"Carin, Lawrence",
			"Chen, Weizhu"
		],
		"subject": "Computer Science - Computation and Language",
		"description": "  GPT-$3$ has attracted lots of attention due to its superior performance\nacross a wide range of NLP tasks, especially with its powerful and versatile\nin-context few-shot learning ability. Despite its success, we found that the\nempirical results of GPT-$3$ depend heavily on the choice of in-context\nexamples. In this work, we investigate whether there are more effective\nstrategies for judiciously selecting in-context examples (relative to random\nsampling) that better leverage GPT-$3$'s few-shot capabilities. Inspired by the\nrecent success of leveraging a retrieval module to augment large-scale neural\nnetwork models, we propose to retrieve examples that are semantically-similar\nto a test sample to formulate its corresponding prompt. Intuitively, the\nin-context examples selected with such a strategy may serve as more informative\ninputs to unleash GPT-$3$'s extensive knowledge. We evaluate the proposed\napproach on several natural language understanding and generation benchmarks,\nwhere the retrieval-based prompt selection approach consistently outperforms\nthe random baseline. Moreover, it is observed that the sentence encoders\nfine-tuned on task-related datasets yield even more helpful retrieval results.\nNotably, significant gains are observed on tasks such as table-to-text\ngeneration (41.9% on the ToTTo dataset) and open-domain question answering\n(45.5% on the NQ dataset). We hope our investigation could help understand the\nbehaviors of GPT-$3$ and large-scale pre-trained LMs in general and enhance\ntheir few-shot capabilities.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06804",
		"pdf_url": "http://arxiv.org/pdf/2101.06804.pdf"
	},
	"1006": {
		"title": "MP3: A Unified Model to Map, Perceive, Predict and Plan",
		"creator": [
			"Casas, Sergio",
			"Sadat, Abbas",
			"Urtasun, Raquel"
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  High-definition maps (HD maps) are a key component of most modern\nself-driving systems due to their valuable semantic and geometric information.\nUnfortunately, building HD maps has proven hard to scale due to their cost as\nwell as the requirements they impose in the localization system that has to\nwork everywhere with centimeter-level accuracy. Being able to drive without an\nHD map would be very beneficial to scale self-driving solutions as well as to\nincrease the failure tolerance of existing ones (e.g., if localization fails or\nthe map is not up-to-date). Towards this goal, we propose MP3, an end-to-end\napproach to mapless driving where the input is raw sensor data and a high-level\ncommand (e.g., turn left at the intersection). MP3 predicts intermediate\nrepresentations in the form of an online map and the current and future state\nof dynamic agents, and exploits them in a novel neural motion planner to make\ninterpretable decisions taking into account uncertainty. We show that our\napproach is significantly safer, more comfortable, and can follow commands\nbetter than the baselines in challenging long-term closed-loop simulations, as\nwell as when compared to an expert driver in a large-scale real-world dataset.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06806",
		"pdf_url": "http://arxiv.org/pdf/2101.06806.pdf"
	},
	"1007": {
		"title": "Optimal Pre-Processing to Achieve Fairness and Its Relationship with\n  Total Variation Barycenter",
		"creator": "Farokhi, Farhad",
		"subject": [
			"Computer Science - Information Theory",
			"Computer Science - Machine Learning",
			"Mathematics - Optimization and Control",
			"Statistics - Machine Learning"
		],
		"description": "  We use disparate impact, i.e., the extent that the probability of observing\nan output depends on protected attributes such as race and gender, to measure\nfairness. We prove that disparate impact is upper bounded by the total\nvariation distance between the distribution of the inputs given the protected\nattributes. We then use pre-processing, also known as data repair, to enforce\nfairness. We show that utility degradation, i.e., the extent that the success\nof a forecasting model changes by pre-processing the data, is upper bounded by\nthe total variation distance between the distribution of the data before and\nafter pre-processing. Hence, the problem of finding the optimal pre-processing\nregiment for enforcing fairness can be cast as minimizing total variations\ndistance between the distribution of the data before and after pre-processing\nsubject to a constraint on the total variation distance between the\ndistribution of the inputs given protected attributes. This problem is a linear\nprogram that can be efficiently solved. We show that this problem is intimately\nrelated to finding the barycenter (i.e., center of mass) of two distributions\nwhen distances in the probability space are measured by total variation\ndistance. We also investigate the effect of differential privacy on fairness\nusing the proposed the total variation distances. We demonstrate the results\nusing numerical experimentation with a practice dataset.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06811",
		"pdf_url": "http://arxiv.org/pdf/2101.06811.pdf"
	},
	"1008": {
		"title": "Fast and accurate learned multiresolution dynamical downscaling for\n  precipitation",
		"creator": [
			"Wang, Jiali",
			"Liu, Zhengchun",
			"Foster, Ian",
			"Chang, Won",
			"Kettimuthu, Rajkumar",
			"Kotamarthi, Rao"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Statistics - Applications"
		],
		"description": "  This study develops a neural network-based approach for emulating\nhigh-resolution modeled precipitation data with comparable statistical\nproperties but at greatly reduced computational cost. The key idea is to use\ncombination of low- and high- resolution simulations to train a neural network\nto map from the former to the latter. Specifically, we define two types of\nCNNs, one that stacks variables directly and one that encodes each variable\nbefore stacking, and we train each CNN type both with a conventional loss\nfunction, such as mean square error (MSE), and with a conditional generative\nadversarial network (CGAN), for a total of four CNN variants. We compare the\nfour new CNN-derived high-resolution precipitation results with precipitation\ngenerated from original high resolution simulations, a bilinear interpolater\nand the state-of-the-art CNN-based super-resolution (SR) technique. Results\nshow that the SR technique produces results similar to those of the bilinear\ninterpolator with smoother spatial and temporal distributions and smaller data\nvariabilities and extremes than the original high resolution simulations. While\nthe new CNNs trained by MSE generate better results over some regions than the\ninterpolator and SR technique do, their predictions are still not as close as\nthe original high resolution simulations. The CNNs trained by CGAN generate\nmore realistic and physically reasonable results, better capturing not only\ndata variability in time and space but also extremes such as intense and\nlong-lasting storms. The new proposed CNN-based downscaling approach can\ndownscale precipitation from 50~km to 12~km in 14~min for 30~years once the\nnetwork is trained (training takes 4~hours using 1~GPU), while the conventional\ndynamical downscaling would take 1~month using 600 CPU cores to generate\nsimulations at the resolution of 12~km over contiguous United States.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06813",
		"pdf_url": "http://arxiv.org/pdf/2101.06813.pdf"
	},
	"1009": {
		"title": "Approximating monomials using Chebyshev polynomials",
		"creator": "Saibaba, Arvind K.",
		"subject": "Mathematics - Numerical Analysis",
		"description": [
			"  This paper considers the approximation of a monomial $x^n$ over the interval\n$[-1,1]$ by a lower-degree polynomial. This polynomial approximation can be\neasily computed analytically and is obtained by truncating the analytical\nChebyshev series expansion of $x^n$. The error in the polynomial approximation\nin the supremum norm has an exact expression with an interesting probabilistic\ninterpretation. We use this interpretation along with concentration\ninequalities to develop a useful upper bound for the error.\n",
			"Comment: 6 pages, 2 figures"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06818",
		"pdf_url": "http://arxiv.org/pdf/2101.06818.pdf"
	},
	"1010": {
		"title": "Chaotic-to-Fine Clustering for Unlabeled Plant Disease Images",
		"creator": [
			"Fang, Uno",
			"Li, Jianxin",
			"Lu, Xuequan",
			"Ali, Mumtaz",
			"Gao, Longxiang",
			"Xiang, Yong"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Current annotation for plant disease images depends on manual sorting and\nhandcrafted features by agricultural experts, which is time-consuming and\nlabour-intensive. In this paper, we propose a self-supervised clustering\nframework for grouping plant disease images based on the vulnerability of\nKernel K-means. The main idea is to establish a cross iterative\nunder-clustering algorithm based on Kernel K-means to produce the\npseudo-labeled training set and a chaotic cluster to be further classified by a\ndeep learning module. In order to verify the effectiveness of our proposed\nframework, we conduct extensive experiments on three different plant disease\ndatatsets with five plants and 17 plant diseases. The experimental results show\nthe high superiority of our method to do image-based plant disease\nclassification over balanced and unbalanced datasets by comparing with five\nstate-of-the-art existing works in terms of different metrics.\n",
			"Comment: This paper has been submitted to Computer Vision and Image\n  Understanding"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06820",
		"pdf_url": "http://arxiv.org/pdf/2101.06820.pdf"
	},
	"1011": {
		"title": "ZeRO-Offload: Democratizing Billion-Scale Model Training",
		"creator": [
			"Ren, Jie",
			"Rajbhandari, Samyam",
			"Aminabadi, Reza Yazdani",
			"Ruwase, Olatunji",
			"Yang, Shuangyan",
			"Zhang, Minjia",
			"Li, Dong",
			"He, Yuxiong"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Machine Learning"
		],
		"description": "  Large-scale model training has been a playing ground for a limited few\nrequiring complex model refactoring and access to prohibitively expensive GPU\nclusters. ZeRO-Offload changes the large model training landscape by making\nlarge model training accessible to nearly everyone. It can train models with\nover 13 billion parameters on a single GPU, a 10x increase in size compared to\npopular framework such as PyTorch, and it does so without requiring any model\nchange from the data scientists or sacrificing computational efficiency.\nZeRO-Offload enables large model training by offloading data and compute to\nCPU. To preserve compute efficiency, it is designed to minimize the data\nmovement to/from GPU, and reduce CPU compute time while maximizing memory\nsavings on GPU. As a result, ZeRO-Offload can achieve 40 TFlops/GPU on a single\nNVIDIA V100 GPU for 10B parameter model compared to 30TF using PyTorch alone\nfor a 1.4B parameter model, the largest that can be trained without running out\nof memory. ZeRO-Offload is also designed to scale on multiple-GPUs when\navailable, offering near linear speedup on up to 128 GPUs. Additionally, it can\nwork together with model parallelism to train models with over 70 billion\nparameters on a single DGX-2 box, a 4.5x increase in model size compared to\nusing model parallelism alone. By combining compute and memory efficiency with\nease-of-use, ZeRO-Offload democratizes large-scale model training making it\naccessible to even data scientists with access to just a single GPU.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06840",
		"pdf_url": "http://arxiv.org/pdf/2101.06840.pdf"
	},
	"1012": {
		"title": "On the Differentially Private Nature of Perturbed Gradient Descent",
		"creator": [
			"Tholeti, Thulasi",
			"Kalyani, Sheetal"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Cryptography and Security"
		],
		"description": "  We consider the problem of empirical risk minimization given a database,\nusing the gradient descent algorithm. We note that the function to be optimized\nmay be non-convex, consisting of saddle points which impede the convergence of\nthe algorithm. A perturbed gradient descent algorithm is typically employed to\nescape these saddle points. We show that this algorithm, that perturbs the\ngradient, inherently preserves the privacy of the data. We then employ the\ndifferential privacy framework to quantify the privacy hence achieved. We also\nanalyze the change in privacy with varying parameters such as problem dimension\nand the distance between the databases.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06847",
		"pdf_url": "http://arxiv.org/pdf/2101.06847.pdf"
	},
	"1013": {
		"title": "Stacked LSTM Based Deep Recurrent Neural Network with Kalman Smoothing\n  for Blood Glucose Prediction",
		"creator": [
			"Rabby, Md Fazle",
			"Tu, Yazhou",
			"Hossen, Md Imran",
			"Le, Insup",
			"Maida, Anthony S",
			"Hei, Xiali"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  Blood glucose (BG) management is crucial for type-1 diabetes patients\nresulting in the necessity of reliable artificial pancreas or insulin infusion\nsystems. In recent years, deep learning techniques have been utilized for a\nmore accurate BG level prediction system. However, continuous glucose\nmonitoring (CGM) readings are susceptible to sensor errors. As a result,\ninaccurate CGM readings would affect BG prediction and make it unreliable, even\nif the most optimal machine learning model is used. In this work, we propose a\nnovel approach to predicting blood glucose level with a stacked Long short-term\nmemory (LSTM) based deep recurrent neural network (RNN) model considering\nsensor fault. We use the Kalman smoothing technique for the correction of the\ninaccurate CGM readings due to sensor error. For the OhioT1DM dataset,\ncontaining eight weeks' data from six different patients, we achieve an average\nRMSE of 6.45 and 17.24 mg/dl for 30 minutes and 60 minutes of prediction\nhorizon (PH), respectively. To the best of our knowledge, this is the leading\naverage prediction accuracy for the ohioT1DM dataset. Different physiological\ninformation, e.g., Kalman smoothed CGM data, carbohydrates from the meal, bolus\ninsulin, and cumulative step counts in a fixed time interval, are crafted to\nrepresent meaningful features used as input to the model. The goal of our\napproach is to lower the difference between the predicted CGM values and the\nfingerstick blood glucose readings - the ground truth. Our results indicate\nthat the proposed approach is feasible for more reliable BG forecasting that\nmight improve the performance of the artificial pancreas and insulin infusion\nsystem for T1D diabetes management.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06850",
		"pdf_url": "http://arxiv.org/pdf/2101.06850.pdf"
	},
	"1014": {
		"title": "High order efficient algorithm for computation of MHD flow ensembles",
		"creator": "Mohebujjaman, Muhammad",
		"subject": [
			"Mathematics - Numerical Analysis",
			"65M12, 65M22, 65M60, 76W05"
		],
		"description": [
			"  In this paper, we propose, analyze, and test a new fully discrete, efficient,\ndecoupled, stable, and practically second-order time-stepping algorithm for\ncomputing MHD ensemble flow averages under uncertainties in the initial\nconditions and forcing. For each viscosity and magnetic diffusivity pair, the\nalgorithm picks the largest possible parameter $\\theta\\in[0,1]$ to avoid the\ninstability that arises due to the presence of some explicit viscous terms. At\neach time step, the algorithm shares the same system matrix with all $J$\nrealizations but with different right-hand-side vectors. That saves assembling\ntime and computer memory, allows the reuse of the same preconditioner, and can\ntake the advantage of block linear solvers. For the proposed algorithm, we\nprove stability and convergence rigorously. To illustrate the predicted\nconvergence rates of our analysis, numerical experiments with manufactured\nsolutions are given on a unit square domain. Finally, we test the scheme on a\nbenchmark channel flow over a step problem and it performs well.\n",
			"Comment: 19 pages, 10 figures. arXiv admin note: substantial text overlap with\n  arXiv:1803.06980"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06852",
		"pdf_url": "http://arxiv.org/pdf/2101.06852.pdf"
	},
	"1015": {
		"title": "Deep Symmetric Adaptation Network for Cross-modality Medical Image\n  Segmentation",
		"creator": [
			"Han, Xiaoting",
			"Qi, Lei",
			"Yu, Qian",
			"Zhou, Ziqi",
			"Zheng, Yefeng",
			"Shi, Yinghuan",
			"Gao, Yang"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  Unsupervised domain adaptation (UDA) methods have shown their promising\nperformance in the cross-modality medical image segmentation tasks. These\ntypical methods usually utilize a translation network to transform images from\nthe source domain to target domain or train the pixel-level classifier merely\nusing translated source images and original target images. However, when there\nexists a large domain shift between source and target domains, we argue that\nthis asymmetric structure could not fully eliminate the domain gap. In this\npaper, we present a novel deep symmetric architecture of UDA for medical image\nsegmentation, which consists of a segmentation sub-network, and two symmetric\nsource and target domain translation sub-networks. To be specific, based on two\ntranslation sub-networks, we introduce a bidirectional alignment scheme via a\nshared encoder and private decoders to simultaneously align features 1) from\nsource to target domain and 2) from target to source domain, which helps\neffectively mitigate the discrepancy between domains. Furthermore, for the\nsegmentation sub-network, we train a pixel-level classifier using not only\noriginal target images and translated source images, but also original source\nimages and translated target images, which helps sufficiently leverage the\nsemantic information from the images with different styles. Extensive\nexperiments demonstrate that our method has remarkable advantages compared to\nthe state-of-the-art methods in both cross-modality Cardiac and BraTS\nsegmentation tasks.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06853",
		"pdf_url": "http://arxiv.org/pdf/2101.06853.pdf"
	},
	"1016": {
		"title": "Understanding Patterns of Users Who Repost Censored Posts on Weibo",
		"creator": [
			"Qian, Yichi",
			"Yuan, Feng",
			"Lyu, Hanjia",
			"Luo, Jiebo"
		],
		"subject": "Computer Science - Social and Information Networks",
		"description": "  In this study, we focus on understanding patterns of users whose repost\ncontents would later be censored on Weibo, a counterpart of Twitter in China as\na social media platform. Little is known about the way regulations and\ncensorship work in this indigenous platform and what role it plays in affecting\nusers' expression of ideas. We collect over a million reposts from over 18,000\nusers and investigate the patterns of users whose reposts contain content that\nis no longer visible to the public, from the perspective of user location,\ndevice, gender, social capital as well as certified status. We find that user\ncharacteristics play an important role in affecting behaviors on Weibo.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06864",
		"pdf_url": "http://arxiv.org/pdf/2101.06864.pdf"
	},
	"1017": {
		"title": "Non-parametric Memory for Spatio-Temporal Segmentation of Construction\n  Zones for Self-Driving",
		"creator": [
			"Bai, Min",
			"Wang, Shenlong",
			"Wong, Kelvin",
			"Yumer, Ersin",
			"Urtasun, Raquel"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  In this paper, we introduce a non-parametric memory representation for\nspatio-temporal segmentation that captures the local space and time around an\nautonomous vehicle (AV). Our representation has three important properties: (i)\nit remembers what it has seen in the past, (ii) it reinforces and (iii) forgets\nits past beliefs based on new evidence. Reinforcing is important as the first\ntime we see an element we might be uncertain, e.g, if the element is heavily\noccluded or at range. Forgetting is desirable, as otherwise false positives\nwill make the self driving vehicle behave erratically. Our process is informed\nby 3D reasoning, as occlusion is key to distinguishing between the desire to\nforget and to remember. We show how our method can be used as an online\ncomponent to complement static world representations such as HD maps by\ndetecting and remembering changes that should be superimposed on top of this\nstatic view due to such events.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06865",
		"pdf_url": "http://arxiv.org/pdf/2101.06865.pdf"
	},
	"1018": {
		"title": "Graph complements of circular graphs",
		"creator": "Knill, Oliver",
		"subject": [
			"Mathematics - Combinatorics",
			"Computer Science - Discrete Mathematics",
			"57M15, 68R10, 05C50"
		],
		"description": [
			"  Graph complements G(n) of cyclic graphs are circulant, vertex-transitive,\nclaw-free, strongly regular, Hamiltonian graphs with a Z(n) symmetry, Shannon\ncapacity 2 and known Wiener and Harary index. There is an explicit spectral\nzeta function and tree or forest data. The forest-tree ratio converges to e.\nThe graphs G(n) are Cayley graphs and so Platonic with isomorphic unit spheres\nG(n-3)^+, complements of path graphs. G(3d+3) are homotop to wedge sums of two\nd-spheres and G(3d+2),G(3d+4) are homotop to d-spheres, G(3d+1)^+ are\ncontractible, G(3d+2)^+,G(3d+3)^+ are d-spheres. Since disjoint unions are dual\nto Zykov joins, graph complements of 1-dimensional discrete manifolds G are\nhomotop to a point, a sphere or a wedge sums of spheres. If the length of every\nconnected component of a 1-manifold is not divisible by 3, the graph complement\nof G is a sphere. In general, the graph complement of a forest is either\ncontractible or a sphere. All induced strict subgraphs of G(n) are either\ncontractible or homotop to spheres. The f-vectors G(n) or G(n)^+ satisfy a\nhyper Pascal triangle relation, the total number of simplices are hyper\nFibonacci numbers. The simplex generating functions are Jacobsthal polynomials,\ngenerating functions of k-king configurations on a circular chess board. While\nthe Euler curvature of circle complements G(n) is constant by symmetry, the\ndiscrete Gauss-Bonnet curvature of path complements G(n)^+ can be expressed\nexplicitly from the generating functions. There is now a non-trivial 6 periodic\nGauss-Bonnet curvature universality in the complement of Barycentric limits.\nThe Brouwer-Lefschetz fixed point theorem produces a 12-periodicity of the\nLefschetz numbers of all graph automorphisms of G(n). There is also a\n12-periodicity of Wu characteristic. This is a 4 periodicity in dimension.These\nare manifestations of stable homotopy features, but combinatorial.\n",
			"Comment: 47 pages, 28 figures"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06873",
		"pdf_url": "http://arxiv.org/pdf/2101.06873.pdf"
	},
	"1019": {
		"title": "Transferring model structure in Bayesian transfer learning for Gaussian\n  process regression",
		"creator": [
			"Papež, Milan",
			"Quinn, Anthony"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Bayesian transfer learning (BTL) is defined in this paper as the task of\nconditioning a target probability distribution on a transferred source\ndistribution. The target globally models the interaction between the source and\ntarget, and conditions on a probabilistic data predictor made available by an\nindependent local source modeller. Fully probabilistic design is adopted to\nsolve this optimal decision-making problem in the target. By successfully\ntransferring higher moments of the source, the target can reject unreliable\nsource knowledge (i.e. it achieves robust transfer). This dual-modeller\nframework means that the source's local processing of raw data into a\ntransferred predictive distribution -- with compressive possibilities -- is\nenriched by (the possible expertise of) the local source model. In addition,\nthe introduction of the global target modeller allows correlation between the\nsource and target tasks -- if known to the target -- to be accounted for.\nImportant consequences emerge. Firstly, the new scheme attains the performance\nof fully modelled (i.e. conventional) multitask learning schemes in (those\nrare) cases where target model misspecification is avoided. Secondly, and more\nimportantly, the new dual-modeller framework is robust to the model\nmisspecification that undermines conventional multitask learning. We thoroughly\nexplore these issues in the key context of interacting Gaussian process\nregression tasks. Experimental evidence from both synthetic and real data\nsettings validates our technical findings: that the proposed BTL framework\nenjoys robustness in transfer while also being robust to model\nmisspecification.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06884",
		"pdf_url": "http://arxiv.org/pdf/2101.06884.pdf"
	},
	"1020": {
		"title": "Cooperative and Competitive Biases for Multi-Agent Reinforcement\n  Learning",
		"creator": [
			"Ryu, Heechang",
			"Shin, Hayong",
			"Park, Jinkyoo"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Multiagent Systems"
		],
		"description": [
			"  Training a multi-agent reinforcement learning (MARL) algorithm is more\nchallenging than training a single-agent reinforcement learning algorithm,\nbecause the result of a multi-agent task strongly depends on the complex\ninteractions among agents and their interactions with a stochastic and dynamic\nenvironment. We propose an algorithm that boosts MARL training using the biased\naction information of other agents based on a friend-or-foe concept. For a\ncooperative and competitive environment, there are generally two groups of\nagents: cooperative-agents and competitive-agents. In the proposed algorithm,\neach agent updates its value function using its own action and the biased\naction information of other agents in the two groups. The biased joint action\nof cooperative agents is computed as the sum of their actual joint action and\nthe imaginary cooperative joint action, by assuming all the cooperative agents\njointly maximize the target agent's value function. The biased joint action of\ncompetitive agents can be computed similarly. Each agent then updates its own\nvalue function using the biased action information, resulting in a biased value\nfunction and corresponding biased policy. Subsequently, the biased policy of\neach agent is inevitably subjected to recommend an action to cooperate and\ncompete with other agents, thereby introducing more active interactions among\nagents and enhancing the MARL policy learning. We empirically demonstrate that\nour algorithm outperforms existing algorithms in various mixed\ncooperative-competitive environments. Furthermore, the introduced biases\ngradually decrease as the training proceeds and the correction based on the\nimaginary assumption vanishes.\n",
			"Comment: Accepted as a full paper at the Twentieth International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS-21), Virtual Conference"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06890",
		"pdf_url": "http://arxiv.org/pdf/2101.06890.pdf"
	},
	"1021": {
		"title": "DeepPayload: Black-box Backdoor Attack on Deep Learning Models through\n  Neural Payload Injection",
		"creator": [
			"Li, Yuanchun",
			"Hua, Jiayi",
			"Wang, Haoyu",
			"Chen, Chunyang",
			"Liu, Yunxin"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Software Engineering"
		],
		"description": [
			"  Deep learning models are increasingly used in mobile applications as critical\ncomponents. Unlike the program bytecode whose vulnerabilities and threats have\nbeen widely-discussed, whether and how the deep learning models deployed in the\napplications can be compromised are not well-understood since neural networks\nare usually viewed as a black box. In this paper, we introduce a highly\npractical backdoor attack achieved with a set of reverse-engineering techniques\nover compiled deep learning models. The core of the attack is a neural\nconditional branch constructed with a trigger detector and several operators\nand injected into the victim model as a malicious payload. The attack is\neffective as the conditional logic can be flexibly customized by the attacker,\nand scalable as it does not require any prior knowledge from the original\nmodel. We evaluated the attack effectiveness using 5 state-of-the-art deep\nlearning models and real-world samples collected from 30 users. The results\ndemonstrated that the injected backdoor can be triggered with a success rate of\n93.5%, while only brought less than 2ms latency overhead and no more than 1.4%\naccuracy decrease. We further conducted an empirical study on real-world mobile\ndeep learning apps collected from Google Play. We found 54 apps that were\nvulnerable to our attack, including popular and security-critical ones. The\nresults call for the awareness of deep learning application developers and\nauditors to enhance the protection of deployed models.\n",
			"Comment: ICSE 2021"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06896",
		"pdf_url": "http://arxiv.org/pdf/2101.06896.pdf"
	},
	"1022": {
		"title": "Soft Constrained Autonomous Vehicle Navigation using Gaussian Processes\n  and Instance Segmentation",
		"creator": [
			"Barbosa, Bruno H. Groenner",
			"Bhatt, Neel P.",
			"Khajepour, Amir",
			"Hashemi, Ehsan"
		],
		"subject": [
			"Computer Science - Robotics",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": "  This paper presents a generic feature-based navigation framework for\nautonomous vehicles using a soft constrained Particle Filter. Selected map\nfeatures, such as road and landmark locations, and vehicle states are used for\ndesigning soft constraints. After obtaining features of mapped landmarks in\ninstance-based segmented images acquired from a monocular camera,\nvehicle-to-landmark distances are predicted using Gaussian Process Regression\n(GPR) models in a mixture of experts approach. Both mean and variance outputs\nof GPR models are used for implementing adaptive constraints. Experimental\nresults confirm that the use of image segmentation features improves the\nvehicle-to-landmark distance prediction notably, and that the proposed soft\nconstrained approach reliably localizes the vehicle even with reduced number of\nlandmarks and noisy observations.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06901",
		"pdf_url": "http://arxiv.org/pdf/2101.06901.pdf"
	},
	"1023": {
		"title": "Stable deep reinforcement learning method by predicting uncertainty in\n  rewards as a subtask",
		"creator": [
			"Suzuki, Kanata",
			"Ogata, Tetsuya"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  In recent years, a variety of tasks have been accomplished by deep\nreinforcement learning (DRL). However, when applying DRL to tasks in a\nreal-world environment, designing an appropriate reward is difficult. Rewards\nobtained via actual hardware sensors may include noise, misinterpretation, or\nfailed observations. The learning instability caused by these unstable signals\nis a problem that remains to be solved in DRL. In this work, we propose an\napproach that extends existing DRL models by adding a subtask to directly\nestimate the variance contained in the reward signal. The model then takes the\nfeature map learned by the subtask in a critic network and sends it to the\nactor network. This enables stable learning that is robust to the effects of\npotential noise. The results of experiments in the Atari game domain with\nunstable reward signals show that our method stabilizes training convergence.\nWe also discuss the extensibility of the model by visualizing feature maps.\nThis approach has the potential to make DRL more practical for use in noisy,\nreal-world scenarios.\n",
			"Comment: Published as a conference paper at ICONIP 2020"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06906",
		"pdf_url": "http://arxiv.org/pdf/2101.06906.pdf"
	},
	"1024": {
		"title": "Quartic Perturbation-based Outage-constrained Robust Design in Two-hop\n  One-way Relay Networks",
		"creator": [
			"Wu, Sissi Xiaoxiao",
			"Ni, Sherry Xue-Ying",
			"Li, Jiaying",
			"So, Anthony Man-Cho"
		],
		"subject": "Computer Science - Information Theory",
		"description": "  In this work, we study a classic robust design problem in two-hop one-way\nrelay system. We are particularly interested in the scenario where channel\nuncertainty exists in both the transmitter-to-relay and relay-to-receiver\nlinks. By considering the problem design that minimizes the average\namplify-and-forward power budget at the relay side while satisfying SNR outage\nrequirements, an outage-constrained robust design problem involving quartic\nperturbations is formulated to guarantee the robustness during transmission.\nThis problem is in general difficult as it involves constraints on the tail\nprobability of a high-order polynomial. Herein, we resort to moment inequality\nand Bernstein-type inequality to tackle this problem, which provide convex\nrestrictions, or safe approximations, of the original design. We also analyze\nthe relative tightness of the two safe approximations for a quadratic\nperturbation-based outage constrained problem. Our analysis shows that the\nBernstein-type inequality approach is less conservative than the moment\ninequality approach when the outage rate is within some prescribed regime. To\nour best knowledge, this is the first provable tightness result for these two\nsafe approximations. Our numerical simulations verify the superiority of the\nrobust design and corroborate the tightness results.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06907",
		"pdf_url": "http://arxiv.org/pdf/2101.06907.pdf"
	},
	"1025": {
		"title": "DFOGraph: An I/O- and Communication-Efficient System for Distributed\n  Fully-out-of-Core Graph Processing",
		"creator": [
			"Yu, Jiping",
			"Qin, Wei",
			"Zhu, Xiaowei",
			"Sun, Zhenbo",
			"Huang, Jianqiang",
			"Li, Xiaohan",
			"Chen, Wenguang"
		],
		"subject": "Computer Science - Distributed, Parallel, and Cluster Computing",
		"description": [
			"  With the magnitude of graph-structured data continually increasing, graph\nprocessing systems that can scale-out and scale-up are needed to handle\nextreme-scale datasets. While existing distributed out-of-core solutions have\nmade it possible, they suffer from limited performance due to excessive I/O and\ncommunication costs. We present DFOGraph, a distributed fully-out-of-core graph\nprocessing system that applies and assembles multiple techniques to enable I/O-\nand communication-efficient processing. DFOGraph builds upon two-level\ncolumn-oriented partition with adaptive compressed representations to allow\nfine-grained selective computation and communication, and it only issues\nnecessary disk and network requests. Our evaluation shows DFOGraph achieves\nperformance comparable to GridGraph and FlashGraph (>2.52x and 1.06x) on a\nsingle machine and outperforms Chaos and HybridGraph significantly (>12.94x and\n>10.82x) when scaling out.\n",
			"Comment: 12 pages, 5 figures, 7 tables"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06911",
		"pdf_url": "http://arxiv.org/pdf/2101.06911.pdf"
	},
	"1026": {
		"title": "Capitol (Pat)riots: A comparative study of Twitter and Parler",
		"creator": [
			"Hitkul",
			"Prabhu, Avinash",
			"Guhathakurta, Dipanwita",
			"jain, Jivitesh",
			"Subramanian, Mallika",
			"Reddy, Manvith",
			"Sehgal, Shradha",
			"Karandikar, Tanvi",
			"Gulati, Amogh",
			"Arora, Udit",
			"Shah, Rajiv Ratn",
			"Kumaraguru, Ponnurangam"
		],
		"subject": [
			"Computer Science - Computers and Society",
			"Computer Science - Social and Information Networks"
		],
		"description": "  On 6 January 2021, a mob of right-wing conservatives stormed the USA Capitol\nHill interrupting the session of congress certifying 2020 Presidential election\nresults. Immediately after the start of the event, posts related to the riots\nstarted to trend on social media. A social media platform which stood out was a\nfree speech endorsing social media platform Parler; it is being claimed as the\nplatform on which the riots were planned and talked about. Our report presents\na contrast between the trending content on Parler and Twitter around the time\nof riots. We collected data from both platforms based on the trending hashtags\nand draw comparisons based on what are the topics being talked about, who are\nthe people active on the platforms and how organic is the content generated on\nthe two platforms. While the content trending on Twitter had strong resentments\ntowards the event and called for action against rioters and inciters, Parler\ncontent had a strong conservative narrative echoing the ideas of voter fraud\nsimilar to the attacking mob. We also find a disproportionately high\nmanipulation of traffic on Parler when compared to Twitter.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06914",
		"pdf_url": "http://arxiv.org/pdf/2101.06914.pdf"
	},
	"1027": {
		"title": "TLU-Net: A Deep Learning Approach for Automatic Steel Surface Defect\n  Detection",
		"creator": [
			"Damacharla, Praveen",
			"V., Achuth Rao M.",
			"Ringenberg, Jordan",
			"Javaid, Ahmad Y"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": "  Visual steel surface defect detection is an essential step in steel sheet\nmanufacturing. Several machine learning-based automated visual inspection (AVI)\nmethods have been studied in recent years. However, most steel manufacturing\nindustries still use manual visual inspection due to training time and\ninaccuracies involved with AVI methods. Automatic steel defect detection\nmethods could be useful in less expensive and faster quality control and\nfeedback. But preparing the annotated training data for segmentation and\nclassification could be a costly process. In this work, we propose to use the\nTransfer Learning-based U-Net (TLU-Net) framework for steel surface defect\ndetection. We use a U-Net architecture as the base and explore two kinds of\nencoders: ResNet and DenseNet. We compare these nets' performance using random\ninitialization and the pre-trained networks trained using the ImageNet data\nset. The experiments are performed using Severstal data. The results\ndemonstrate that the transfer learning performs 5% (absolute) better than that\nof the random initialization in defect classification. We found that the\ntransfer learning performs 26% (relative) better than that of the random\ninitialization in defect segmentation. We also found the gain of transfer\nlearning increases as the training data decreases, and the convergence rate\nwith transfer learning is better than that of the random initialization.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06915",
			"International Conference on Applied Artificial Intelligence\n  (ICAPAI 2021), Halden, Norway, May 19-21, 2021"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06915.pdf"
	},
	"1028": {
		"title": "Detection of Insider Attacks in Distributed Projected Subgradient\n  Algorithms",
		"creator": [
			"Wu, Sissi Xiaoxiao",
			"Li, Gangqiang",
			"Zhang, Shengli",
			"Lin, Xiaohui"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Information Theory"
		],
		"description": "  The gossip-based distributed algorithms are widely used to solve\ndecentralized optimization problems in various multi-agent applications, while\nthey are generally vulnerable to data injection attacks by internal malicious\nagents as each agent locally estimates its decent direction without an\nauthorized supervision. In this work, we explore the application of artificial\nintelligence (AI) technologies to detect internal attacks. We show that a\ngeneral neural network is particularly suitable for detecting and localizing\nthe malicious agents, as they can effectively explore nonlinear relationship\nunderlying the collected data. Moreover, we propose to adopt one of the\nstate-of-art approaches in federated learning, i.e., a collaborative\npeer-to-peer machine learning protocol, to facilitate training our neural\nnetwork models by gossip exchanges. This advanced approach is expected to make\nour model more robust to challenges with insufficient training data, or\nmismatched test data. In our simulations, a least-squared problem is considered\nto verify the feasibility and effectiveness of AI-based methods. Simulation\nresults demonstrate that the proposed AI-based methods are beneficial to\nimprove performance of detecting and localizing malicious agents over\nscore-based methods, and the peer-to-peer neural network model is indeed robust\nto target issues.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06917",
		"pdf_url": "http://arxiv.org/pdf/2101.06917.pdf"
	},
	"1029": {
		"title": "Privacy Impact on Generalized Nash Equilibrium in Peer-to-Peer\n  Electricity Market",
		"creator": [
			"Shilov, Ilia",
			"Cadre, Hélène Le",
			"Bušic, Ana"
		],
		"subject": [
			"Computer Science - Computer Science and Game Theory",
			"Mathematics - Optimization and Control"
		],
		"description": "  We consider a peer-to-peer electricity market, where agents hold private\ninformation that they might not want to share. The problem is modeled as a\nnoncooperative communication game, which takes the form of a Generalized Nash\nEquilibrium Problem, where the agents determine their randomized reports to\nshare with the other market players, while anticipating the form of the\npeer-to-peer market equilibrium. In the noncooperative game, each agent decides\non the deterministic and random parts of the report, such that (a) the distance\nbetween the deterministic part of the report and the truthful private\ninformation is bounded and (b) the expectation of the privacy loss random\nvariable is bounded. This allows each agent to change her privacy level. We\ncharacterize the equilibrium of the game, prove the uniqueness of the\nVariational Equilibria and provide a closed form expression of the privacy\nprice. In addition, we provide a closed form expression to measure the impact\nof the privacy preservation caused by inclusion of random noise and\ndeterministic deviation from agents' true values. Numerical illustrations are\npresented on the 14-bus IEEE network.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06922",
		"pdf_url": "http://arxiv.org/pdf/2101.06922.pdf"
	},
	"1030": {
		"title": "Generative Counterfactuals for Neural Networks via Attribute-Informed\n  Perturbation",
		"creator": [
			"Yang, Fan",
			"Liu, Ninghao",
			"Du, Mengnan",
			"Hu, Xia"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  With the wide use of deep neural networks (DNN), model interpretability has\nbecome a critical concern, since explainable decisions are preferred in\nhigh-stake scenarios. Current interpretation techniques mainly focus on the\nfeature attribution perspective, which are limited in indicating why and how\nparticular explanations are related to the prediction. To this end, an\nintriguing class of explanations, named counterfactuals, has been developed to\nfurther explore the \"what-if\" circumstances for interpretation, and enables the\nreasoning capability on black-box models. However, generating counterfactuals\nfor raw data instances (i.e., text and image) is still in the early stage due\nto its challenges on high data dimensionality and unsemantic raw features. In\nthis paper, we design a framework to generate counterfactuals specifically for\nraw data instances with the proposed Attribute-Informed Perturbation (AIP). By\nutilizing generative models conditioned with different attributes,\ncounterfactuals with desired labels can be obtained effectively and\nefficiently. Instead of directly modifying instances in the data space, we\niteratively optimize the constructed attribute-informed latent space, where\nfeatures are more robust and semantic. Experimental results on real-world texts\nand images demonstrate the effectiveness, sample quality as well as efficiency\nof our designed framework, and show the superiority over other alternatives.\nBesides, we also introduce some practical applications based on our framework,\nindicating its potential beyond the model interpretability aspect.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06930",
		"pdf_url": "http://arxiv.org/pdf/2101.06930.pdf"
	},
	"1031": {
		"title": "Incremental Knowledge Based Question Answering",
		"creator": [
			"Li, Yongqi",
			"Li, Wenjie",
			"Nie, Liqiang"
		],
		"subject": "Computer Science - Computation and Language",
		"description": "  In the past years, Knowledge-Based Question Answering (KBQA), which aims to\nanswer natural language questions using facts in a knowledge base, has been\nwell developed. Existing approaches often assume a static knowledge base.\nHowever, the knowledge is evolving over time in the real world. If we directly\napply a fine-tuning strategy on an evolving knowledge base, it will suffer from\na serious catastrophic forgetting problem. In this paper, we propose a new\nincremental KBQA learning framework that can progressively expand learning\ncapacity as humans do. Specifically, it comprises a margin-distilled loss and a\ncollaborative exemplar selection method, to overcome the catastrophic\nforgetting problem by taking advantage of knowledge distillation. We reorganize\nthe SimpleQuestion dataset to evaluate the proposed incremental learning\nsolution to KBQA. The comprehensive experiments demonstrate its effectiveness\nand efficiency when working with the evolving knowledge base.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06938",
		"pdf_url": "http://arxiv.org/pdf/2101.06938.pdf"
	},
	"1032": {
		"title": "Learning DNN networks using un-rectifying ReLU with compressed sensing\n  application",
		"creator": [
			"Hwang, Wen-Liang",
			"Tung, Shih-Shuo"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Signal Processing",
			"Mathematics - Optimization and Control"
		],
		"description": [
			"  The un-rectifying technique expresses a non-linear point-wise activation\nfunction as a data-dependent variable, which means that the activation variable\nalong with its input and output can all be employed in optimization. The ReLU\nnetwork in this study was un-rectified means that the activation functions\ncould be replaced with data-dependent activation variables in the form of\nequations and constraints. The discrete nature of activation variables\nassociated with un-rectifying ReLUs allows the reformulation of deep learning\nproblems as problems of combinatorial optimization. However, we demonstrate\nthat the optimal solution to a combinatorial optimization problem can be\npreserved by relaxing the discrete domains of activation variables to closed\nintervals. This makes it easier to learn a network using methods developed for\nreal-domain constrained optimization. We also demonstrate that by introducing\ndata-dependent slack variables as constraints, it is possible to optimize a\nnetwork based on the augmented Lagrangian approach. This means that our method\ncould theoretically achieve global convergence and all limit points are\ncritical points of the learning problem. In experiments, our novel approach to\nsolving the compressed sensing recovery problem achieved state-of-the-art\nperformance when applied to the MNIST database and natural images.\n",
			"Comment: 35 pages, 6 figures"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06940",
		"pdf_url": "http://arxiv.org/pdf/2101.06940.pdf"
	},
	"1033": {
		"title": "HinFlair: pre-trained contextual string embeddings for pos tagging and\n  text classification in the Hindi language",
		"creator": "Patel, Harsh",
		"subject": "Computer Science - Computation and Language",
		"description": "  Recent advancements in language models based on recurrent neural networks and\ntransformers architecture have achieved state-of-the-art results on a wide\nrange of natural language processing tasks such as pos tagging, named entity\nrecognition, and text classification. However, most of these language models\nare pre-trained in high resource languages like English, German, Spanish.\nMulti-lingual language models include Indian languages like Hindi, Telugu,\nBengali in their training corpus, but they often fail to represent the\nlinguistic features of these languages as they are not the primary language of\nthe study. We introduce HinFlair, which is a language representation model\n(contextual string embeddings) pre-trained on a large monolingual Hindi corpus.\nExperiments were conducted on 6 text classification datasets and a Hindi\ndependency treebank to analyze the performance of these contextualized string\nembeddings for the Hindi language. Results show that HinFlair outperforms\nprevious state-of-the-art publicly available pre-trained embeddings for\ndownstream tasks like text classification and pos tagging. Also, HinFlair when\ncombined with FastText embeddings outperforms many transformers-based language\nmodels trained particularly for the Hindi language.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06949",
		"pdf_url": "http://arxiv.org/pdf/2101.06949.pdf"
	},
	"1034": {
		"title": "Modeling Heterogeneous Relations across Multiple Modes for Potential\n  Crowd Flow Prediction",
		"creator": [
			"Zhou, Qiang",
			"Gu, Jingjing",
			"Lu, Xinjiang",
			"Zhuang, Fuzhen",
			"Zhao, Yanchao",
			"Wang, Qiuhong",
			"Zhang, Xiao"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  Potential crowd flow prediction for new planned transportation sites is a\nfundamental task for urban planners and administrators. Intuitively, the\npotential crowd flow of the new coming site can be implied by exploring the\nnearby sites. However, the transportation modes of nearby sites (e.g. bus\nstations, bicycle stations) might be different from the target site (e.g.\nsubway station), which results in severe data scarcity issues. To this end, we\npropose a data driven approach, named MOHER, to predict the potential crowd\nflow in a certain mode for a new planned site. Specifically, we first identify\nthe neighbor regions of the target site by examining the geographical proximity\nas well as the urban function similarity. Then, to aggregate these\nheterogeneous relations, we devise a cross-mode relational GCN, a novel\nrelation-specific transformation model, which can learn not only the\ncorrelations but also the differences between different transportation modes.\nAfterward, we design an aggregator for inductive potential flow representation.\nFinally, an LTSM module is used for sequential flow prediction. Extensive\nexperiments on real-world data sets demonstrate the superiority of the MOHER\nframework compared with the state-of-the-art algorithms.\n",
			"Comment: Accepted by the 35th AAAI Conference on Artificial Intelligence (AAAI\n  2021)"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06954",
		"pdf_url": "http://arxiv.org/pdf/2101.06954.pdf"
	},
	"1035": {
		"title": "Covid-19 classification with deep neural network and belief functions",
		"creator": [
			"Huang, Ling",
			"Ruan, Su",
			"Denoeux, Thierry"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  Computed tomography (CT) image provides useful information for radiologists\nto diagnose Covid-19. However, visual analysis of CT scans is time-consuming.\nThus, it is necessary to develop algorithms for automatic Covid-19 detection\nfrom CT images. In this paper, we propose a belief function-based convolutional\nneural network with semi-supervised training to detect Covid-19 cases. Our\nmethod first extracts deep features, maps them into belief degree maps and\nmakes the final classification decision. Our results are more reliable and\nexplainable than those of traditional deep learning-based classification\nmodels. Experimental results show that our approach is able to achieve a good\nperformance with an accuracy of 0.81, an F1 of 0.812 and an AUC of 0.875.\n",
			"Comment: medical image, Covid-19, belief function, BIHI conference"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06958",
		"pdf_url": "http://arxiv.org/pdf/2101.06958.pdf"
	},
	"1036": {
		"title": "Social cohesion V.S. task cohesion: An evolutionary game theory study",
		"creator": [
			"Qu, Xinglong",
			"Kurokawa, Shun",
			"Han, The Anh"
		],
		"subject": [
			"Physics - Physics and Society",
			"Computer Science - Multiagent Systems",
			"Nonlinear Sciences - Adaptation and Self-Organizing Systems",
			"Nonlinear Sciences - Chaotic Dynamics"
		],
		"description": "  Using methods from evolutionary game theory, this paper investigates the\ndifference between social cohesion and task cohesion in promoting the evolution\nof cooperation in group interactions. Players engage in public goods games and\nare allowed to leave their groups if too many defections occur. Both social\ncohesion and task cohesion may prevent players from leaving. While a higher\nlevel of social cohesion increases a player's tolerance towards defections,\ntask cohesion is associated with her group performance in the past. With a\nhigher level of task cohesion, it is more likely that a dissatisfied player\nwill refer to the history and remains in her group if she was satisfied in the\npast. Our results reveal that social cohesion is detrimental to the evolution\nof cooperation while task cohesion facilitates it. This is because social\ncohesion hinders the conditional dissociation mechanism but task cohesion\nimproves the robustness of cooperative groups which are usually vulnerable to\nmistakes. We also discuss other potential aspects of cohesion and how they can\nbe investigated through our modelling. Overall, our analysis provides novel\ninsights into the relationship between group cohesion and group performance\nthrough studying the group dynamics and suggests further application of\nevolutionary game theory in this area.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06961",
		"pdf_url": "http://arxiv.org/pdf/2101.06961.pdf"
	},
	"1037": {
		"title": "Computer Aided Formal Design of Swarm Robotics Algorithms",
		"creator": [
			"Balabonski, Thibaut",
			"Courtieu, Pierre",
			"Pelle, Robin",
			"Rieg, Lionel",
			"Tixeuil, Sébastien",
			"Urbain, Xavier"
		],
		"subject": [
			"Computer Science - Computational Geometry",
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Discrete Mathematics"
		],
		"description": "  Previous works on formally studying mobile robotic swarms consider necessary\nand sufficient system hypotheses enabling to solve theoretical benchmark\nproblems (geometric pattern formation, gathering, scattering, etc.). We argue\nthat formal methods can also help in the early stage of mobile robotic swarms\nprotocol design, to obtain protocols that are correct-by-design, even for\nproblems arising from real-world use cases, not previously studied\ntheoretically. Our position is supported by a concrete case study. Starting\nfrom a real-world case scenario, we jointly design the formal problem\nspecification, a family of protocols that are able to solve the problem, and\ntheir corresponding proof of correctness, all expressed with the same formal\nframework. The concrete framework we use for our development is the PACTOLE\nlibrary based on the COQ proof assistant.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06966",
		"pdf_url": "http://arxiv.org/pdf/2101.06966.pdf"
	},
	"1038": {
		"title": "On Data-Augmentation and Consistency-Based Semi-Supervised Learning",
		"creator": [
			"Ghosh, Atin",
			"Thiery, Alexandre H."
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning",
			"Statistics - Applications"
		],
		"description": "  Recently proposed consistency-based Semi-Supervised Learning (SSL) methods\nsuch as the $\\Pi$-model, temporal ensembling, the mean teacher, or the virtual\nadversarial training, have advanced the state of the art in several SSL tasks.\nThese methods can typically reach performances that are comparable to their\nfully supervised counterparts while using only a fraction of labelled examples.\nDespite these methodological advances, the understanding of these methods is\nstill relatively limited. In this text, we analyse (variations of) the\n$\\Pi$-model in settings where analytically tractable results can be obtained.\nWe establish links with Manifold Tangent Classifiers and demonstrate that the\nquality of the perturbations is key to obtaining reasonable SSL performances.\nImportantly, we propose a simple extension of the Hidden Manifold Model that\nnaturally incorporates data-augmentation schemes and offers a framework for\nunderstanding and experimenting with SSL methods.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.06967",
			"ICLR 2021"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.06967.pdf"
	},
	"1039": {
		"title": "On the Generalizability of Motion Models for Road Users in Heterogeneous\n  Shared Traffic Spaces",
		"creator": [
			"Johora, Fatema T.",
			"Yang, Dongfang",
			"Müller, Jörg P.",
			"Özgüner, Ümit"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computer Science and Game Theory"
		],
		"description": "  Modeling mixed-traffic motion and interactions is crucial to assess safety,\nefficiency, and feasibility of future urban areas. The lack of traffic\nregulations, diverse transport modes, and the dynamic nature of mixed-traffic\nzones like shared spaces make realistic modeling of such environments\nchallenging. This paper focuses on the generalizability of the motion model,\ni.e., its ability to generate realistic behavior in different environmental\nsettings, an aspect which is lacking in existing works. Specifically, our first\ncontribution is a novel and systematic process of formulating general motion\nmodels and application of this process is to extend our Game-Theoretic Social\nForce Model (GSFM) towards a general model for generating a large variety of\nmotion behaviors of pedestrians and cars from different shared spaces. Our\nsecond contribution is to consider different motion patterns of pedestrians by\ncalibrating motion-related features of individual pedestrian and clustering\nthem into groups. We analyze two clustering approaches. The calibration and\nevaluation of our model are performed on three different shared space data\nsets. The results indicate that our model can realistically simulate a wide\nrange of motion behaviors and interaction scenarios, and that adding different\nmotion patterns of pedestrians into our model improves its performance.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06974",
		"pdf_url": "http://arxiv.org/pdf/2101.06974.pdf"
	},
	"1040": {
		"title": "Comparing Deep Learning strategies for paired but unregistered\n  multimodal segmentation of the liver in T1 and T2-weighted MRI",
		"creator": [
			"Couteaux, Vincent",
			"Trintignac, Mathilde",
			"Nempont, Olivier",
			"Pizaine, Guillaume",
			"Vlachomitrou, Anna Sesilia",
			"Valette, Pierre-Jean",
			"Milot, Laurent",
			"Bloch, Isabelle"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"I.4.6"
		],
		"description": [
			"  We address the problem of multimodal liver segmentation in paired but\nunregistered T1 and T2-weighted MR images. We compare several strategies\ndescribed in the literature, with or without multi-task training, with or\nwithout pre-registration. We also compare different loss functions\n(cross-entropy, Dice loss, and three adversarial losses). All methods achieved\ncomparable performances with the exception of a multi-task setting that\nperforms both segmentations at once, which performed poorly.\n",
			"Comment: 4 pages, 3 figures and 3 tables. Conference paper"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06979",
		"pdf_url": "http://arxiv.org/pdf/2101.06979.pdf"
	},
	"1041": {
		"title": "Mitigating the Position Bias of Transformer Models in Passage Re-Ranking",
		"creator": [
			"Hofstätter, Sebastian",
			"Lipani, Aldo",
			"Althammer, Sophia",
			"Zlabinger, Markus",
			"Hanbury, Allan"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Computation and Language"
		],
		"description": [
			"  Supervised machine learning models and their evaluation strongly depends on\nthe quality of the underlying dataset. When we search for a relevant piece of\ninformation it may appear anywhere in a given passage. However, we observe a\nbias in the position of the correct answer in the text in two popular Question\nAnswering datasets used for passage re-ranking. The excessive favoring of\nearlier positions inside passages is an unwanted artefact. This leads to three\ncommon Transformer-based re-ranking models to ignore relevant parts in unseen\npassages. More concerningly, as the evaluation set is taken from the same\nbiased distribution, the models overfitting to that bias overestimate their\ntrue effectiveness. In this work we analyze position bias on datasets, the\ncontextualized representations, and their effect on retrieval results. We\npropose a debiasing method for retrieval datasets. Our results show that a\nmodel trained on a position-biased dataset exhibits a significant decrease in\nre-ranking effectiveness when evaluated on a debiased dataset. We demonstrate\nthat by mitigating the position bias, Transformer-based re-ranking models are\nequally effective on a biased and debiased dataset, as well as more effective\nin a transfer-learning setting between two differently biased datasets.\n",
			"Comment: Accepted at ECIR 2021 (Full paper track)"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06980",
		"pdf_url": "http://arxiv.org/pdf/2101.06980.pdf"
	},
	"1042": {
		"title": "Screening for Sparse Online Learning",
		"creator": [
			"Liang, Jingwei",
			"Poon, Clarice"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Mathematics - Optimization and Control"
		],
		"description": "  Sparsity promoting regularizers are widely used to impose low-complexity\nstructure (e.g. l1-norm for sparsity) to the regression coefficients of\nsupervised learning. In the realm of deterministic optimization, the sequence\ngenerated by iterative algorithms (such as proximal gradient descent) exhibit\n\"finite activity identification\", namely, they can identify the low-complexity\nstructure in a finite number of iterations. However, most online algorithms\n(such as proximal stochastic gradient descent) do not have the property owing\nto the vanishing step-size and non-vanishing variance. In this paper, by\ncombining with a screening rule, we show how to eliminate useless features of\nthe iterates generated by online algorithms, and thereby enforce finite\nactivity identification. One consequence is that when combined with any\nconvergent online algorithm, sparsity properties imposed by the regularizer can\nbe exploited for computational gains. Numerically, significant acceleration can\nbe obtained.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06982",
		"pdf_url": "http://arxiv.org/pdf/2101.06982.pdf"
	},
	"1043": {
		"title": "Studying Catastrophic Forgetting in Neural Ranking Models",
		"creator": [
			"Lovon-Melgarejo, Jesus",
			"Soulier, Laure",
			"Pinel-Sauvagnat, Karen",
			"Tamine, Lynda"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  Several deep neural ranking models have been proposed in the recent IR\nliterature. While their transferability to one target domain held by a dataset\nhas been widely addressed using traditional domain adaptation strategies, the\nquestion of their cross-domain transferability is still under-studied. We study\nhere in what extent neural ranking models catastrophically forget old knowledge\nacquired from previously observed domains after acquiring new knowledge,\nleading to performance decrease on those domains. Our experiments show that the\neffectiveness of neuralIR ranking models is achieved at the cost of\ncatastrophic forgetting and that a lifelong learning strategy using a\ncross-domain regularizer success-fully mitigates the problem. Using an\nexplanatory approach built on a regression model, we also show the effect of\ndomain characteristics on the rise of catastrophic forgetting. We believe that\nthe obtained results can be useful for both theoretical and practical future\nwork in neural IR.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06984",
		"pdf_url": "http://arxiv.org/pdf/2101.06984.pdf"
	},
	"1044": {
		"title": "Simple Stochastic Games with Almost-Sure Energy-Parity Objectives are in\n  NP and coNP",
		"creator": [
			"Mayr, Richard",
			"Schewe, Sven",
			"Totzke, Patrick",
			"Wojtczak, Dominik"
		],
		"subject": [
			"Computer Science - Computer Science and Game Theory",
			"Computer Science - Logic in Computer Science"
		],
		"description": "  We study stochastic games with energy-parity objectives, which combine\nquantitative rewards with a qualitative $\\omega$-regular condition: The\nmaximizer aims to avoid running out of energy while simultaneously satisfying a\nparity condition. We show that the corresponding almost-sure problem, i.e.,\nchecking whether there exists a maximizer strategy that achieves the\nenergy-parity objective with probability $1$ when starting at a given energy\nlevel $k$, is decidable and in $NP \\cap coNP$. The same holds for checking if\nsuch a $k$ exists and if a given $k$ is minimal.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06989",
		"pdf_url": "http://arxiv.org/pdf/2101.06989.pdf"
	},
	"1045": {
		"title": "Deep Compression of Neural Networks for Fault Detection on Tennessee\n  Eastman Chemical Processes",
		"creator": [
			"Li, Mingxuan",
			"Shao, Yuanxun"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Artificial neural network has achieved the state-of-art performance in fault\ndetection on the Tennessee Eastman process, but it often requires enormous\nmemory to fund its massive parameters. In order to implement online real-time\nfault detection, three deep compression techniques (pruning, clustering, and\nquantization) are applied to reduce the computational burden. We have\nextensively studied 7 different combinations of compression techniques, all\nmethods achieve high model compression rates over 64% while maintain high fault\ndetection accuracy. The best result is applying all three techniques, which\nreduces the model sizes by 91.5% and remains a high accuracy over 94%. This\nresult leads to a smaller storage requirement in production environments, and\nmakes the deployment smoother in real world.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.06993",
		"pdf_url": "http://arxiv.org/pdf/2101.06993.pdf"
	},
	"1046": {
		"title": "Least resolved trees for two-colored best match graphs",
		"creator": [
			"Schaller, David",
			"Geiß, Manuela",
			"Hellmuth, Marc",
			"Stadler, Peter F."
		],
		"subject": [
			"Quantitative Biology - Populations and Evolution",
			"Computer Science - Computational Complexity",
			"Computer Science - Discrete Mathematics",
			"Mathematics - Combinatorics"
		],
		"description": "  2-colored best match graphs (2-BMGs) form a subclass of sink-free\nbi-transitive graphs that appears in phylogenetic combinatorics. There, 2-BMGs\ndescribe evolutionarily most closely related genes between a pair of species.\nThey are explained by a unique least resolved tree (LRT). Introducing the\nconcept of support vertices we derive an $O(|V|+|E|\\log^2|V|)$-time algorithm\nto recognize 2-BMGs and to construct its LRT. The approach can be extended to\nalso recognize binary-explainable 2-BMGs with the same complexity. An empirical\ncomparison emphasizes the efficiency of the new algorithm.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07000",
		"pdf_url": "http://arxiv.org/pdf/2101.07000.pdf"
	},
	"1047": {
		"title": "A Spiking Central Pattern Generator for the control of a simulated\n  lamprey robot running on SpiNNaker and Loihi neuromorphic boards",
		"creator": [
			"Angelidis, Emmanouil",
			"Buchholz, Emanuel",
			"O'Neil, Jonathan Patrick Arreguit",
			"Rougè, Alexis",
			"Stewart, Terrence",
			"von Arnim, Axel",
			"Knoll, Alois",
			"Ijspeert, Auke"
		],
		"subject": [
			"Computer Science - Neural and Evolutionary Computing",
			"Computer Science - Robotics"
		],
		"description": [
			"  Central Pattern Generators (CPGs) models have been long used to investigate\nboth the neural mechanisms that underlie animal locomotion as well as a tool\nfor robotic research. In this work we propose a spiking CPG neural network and\nits implementation on neuromorphic hardware as a means to control a simulated\nlamprey model. To construct our CPG model, we employ the naturally emerging\ndynamical systems that arise through the use of recurrent neural populations in\nthe Neural Engineering Framework (NEF). We define the mathematical formulation\nbehind our model, which consists of a system of coupled abstract oscillators\nmodulated by high-level signals, capable of producing a variety of output\ngaits. We show that with this mathematical formulation of the Central Pattern\nGenerator model, the model can be turned into a Spiking Neural Network (SNN)\nthat can be easily simulated with Nengo, an SNN simulator. The spiking CPG\nmodel is then used to produce the swimming gaits of a simulated lamprey robot\nmodel in various scenarios. We show that by modifying the input to the network,\nwhich can be provided by sensory information, the robot can be controlled\ndynamically in direction and pace. The proposed methodology can be generalized\nto other types of CPGs suitable for both engineering applications and\nscientific research. We test our system on two neuromorphic platforms,\nSpiNNaker and Loihi. Finally, we show that this category of spiking algorithms\nshows a promising potential to exploit the theoretical advantages of\nneuromorphic hardware in terms of energy efficiency and computational speed.\n",
			"Comment: 25 pages, 15 figures"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07001",
		"pdf_url": "http://arxiv.org/pdf/2101.07001.pdf"
	},
	"1048": {
		"title": "Machine Learning-Enabled Joint Antenna Selection and Precoding Design:\n  From Offline Complexity to Online Performance",
		"creator": [
			"Vu, Thang X.",
			"Chatzinotas, Symeon",
			"Nguyen, Van-Dinh",
			"Hoang, Dinh Thai",
			"Nguyen, Diep N.",
			"Di Renzo, Marco",
			"Ottersten, Bjorn"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  We investigate the performance of multi-user multiple-antenna downlink\nsystems in which a BS serves multiple users via a shared wireless medium. In\norder to fully exploit the spatial diversity while minimizing the passive\nenergy consumed by radio frequency (RF) components, the BS is equipped with M\nRF chains and N antennas, where M < N. Upon receiving pilot sequences to obtain\nthe channel state information, the BS determines the best subset of M antennas\nfor serving the users. We propose a joint antenna selection and precoding\ndesign (JASPD) algorithm to maximize the system sum rate subject to a transmit\npower constraint and QoS requirements. The JASPD overcomes the non-convexity of\nthe formulated problem via a doubly iterative algorithm, in which an inner loop\nsuccessively optimizes the precoding vectors, followed by an outer loop that\ntries all valid antenna subsets. Although approaching the (near) global\noptimality, the JASPD suffers from a combinatorial complexity, which may limit\nits application in real-time network operations. To overcome this limitation,\nwe propose a learning-based antenna selection and precoding design algorithm\n(L-ASPA), which employs a DNN to establish underlaying relations between the\nkey system parameters and the selected antennas. The proposed L-ASPD is robust\nagainst the number of users and their locations, BS's transmit power, as well\nas the small-scale channel fading. With a well-trained learning model, it is\nshown that the L-ASPD significantly outperforms baseline schemes based on the\nblock diagonalization and a learning-assisted solution for broadcasting systems\nand achieves higher effective sum rate than that of the JASPA under limited\nprocessing time. In addition, we observed that the proposed L-ASPD can reduce\nthe computation complexity by 95% while retaining more than 95% of the optimal\nperformance.\n",
			"Comment: accepted to the IEEE Transactions on Wireless Communications"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07004",
		"pdf_url": "http://arxiv.org/pdf/2101.07004.pdf"
	},
	"1049": {
		"title": "An attention model to analyse the risk of agitation and urinary tract\n  infections in people with dementia",
		"creator": [
			"Li, Honglin",
			"Rezvani, Roonak",
			"Kolanko, Magdalena Anita",
			"Sharp, David J.",
			"Wairagkar, Maitreyee",
			"Vaidyanathan, Ravi",
			"Nilforooshan, Ramin",
			"Barnaghi, Payam"
		],
		"subject": "Computer Science - Artificial Intelligence",
		"description": [
			"  Behavioural symptoms and urinary tract infections (UTI) are among the most\ncommon problems faced by people with dementia. One of the key challenges in the\nmanagement of these conditions is early detection and timely intervention in\norder to reduce distress and avoid unplanned hospital admissions. Using in-home\nsensing technologies and machine learning models for sensor data integration\nand analysis provides opportunities to detect and predict clinically\nsignificant events and changes in health status. We have developed an\nintegrated platform to collect in-home sensor data and performed an\nobservational study to apply machine learning models for agitation and UTI risk\nanalysis. We collected a large dataset from 88 participants with a mean age of\n82 and a standard deviation of 6.5 (47 females and 41 males) to evaluate a new\ndeep learning model that utilises attention and rational mechanism. The\nproposed solution can process a large volume of data over a period of time and\nextract significant patterns in a time-series data (i.e. attention) and use the\nextracted features and patterns to train risk analysis models (i.e. rational).\nThe proposed model can explain the predictions by indicating which time-steps\nand features are used in a long series of time-series data. The model provides\na recall of 91\\% and precision of 83\\% in detecting the risk of agitation and\nUTIs. This model can be used for early detection of conditions such as UTIs and\nmanaging of neuropsychiatric symptoms such as agitation in association with\ninitial treatment and early intervention approaches. In our study we have\ndeveloped a set of clinical pathways for early interventions using the alerts\ngenerated by the proposed model and a clinical monitoring team has been set up\nto use the platform and respond to the alerts according to the created\nintervention plans.\n",
			"Comment: 11 pages"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07007",
		"pdf_url": "http://arxiv.org/pdf/2101.07007.pdf"
	},
	"1050": {
		"title": "Covering rational surfaces with rational parametrization images",
		"creator": [
			"Caravantes, Jorge",
			"Sendra, J. Rafael",
			"Sevilla, David",
			"Villarino, Carlos"
		],
		"subject": [
			"Mathematics - Algebraic Geometry",
			"Computer Science - Symbolic Computation",
			"14Q10 (Primary) 68W30 (Secondary)"
		],
		"description": [
			"  Let $S$ be a rational projective surface given by means of a projective\nrational parametrization whose base locus satisfies a mild assumption. In this\npaper we present an algorithm that provides three rational maps\n$f,g,h:\\mathbb{A}^2 --\\to S\\subset \\mathbb{P}^n$ such that the union of the\nthree images covers $S$. As a consequence, we present a second algorithm that\ngenerates two rational maps $f,\\tilde{g}:\\mathbb{A}^2 --\\to S$, such that the\nunion of their images covers the affine surface $S\\cap \\mathbb{A}^n$. In the\naffine case, the number of rational maps involved in the cover is in general\noptimal.\n",
			"Comment: 16 pages. Submitted"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07011",
		"pdf_url": "http://arxiv.org/pdf/2101.07011.pdf"
	},
	"1051": {
		"title": "Regularized Policies are Reward Robust",
		"creator": [
			"Husain, Hisham",
			"Ciosek, Kamil",
			"Tomioka, Ryota"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  Entropic regularization of policies in Reinforcement Learning (RL) is a\ncommonly used heuristic to ensure that the learned policy explores the\nstate-space sufficiently before overfitting to a local optimal policy. The\nprimary motivation for using entropy is for exploration and disambiguating\noptimal policies; however, the theoretical effects are not entirely understood.\nIn this work, we study the more general regularized RL objective and using\nFenchel duality; we derive the dual problem which takes the form of an\nadversarial reward problem. In particular, we find that the optimal policy\nfound by a regularized objective is precisely an optimal policy of a\nreinforcement learning problem under a worst-case adversarial reward. Our\nresult allows us to reinterpret the popular entropic regularization scheme as a\nform of robustification. Furthermore, due to the generality of our results, we\napply to other existing regularization schemes. Our results thus give insights\ninto the effects of regularization of policies and deepen our understanding of\nexploration through robust rewards at large.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07012",
		"pdf_url": "http://arxiv.org/pdf/2101.07012.pdf"
	},
	"1052": {
		"title": "Deep Universal Blind Image Denoising",
		"creator": [
			"Soh, Jae Woong",
			"Cho, Nam Ik"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Image denoising is an essential part of many image processing and computer\nvision tasks due to inevitable noise corruption during image acquisition.\nTraditionally, many researchers have investigated image priors for the\ndenoising, within the Bayesian perspective based on image properties and\nstatistics. Recently, deep convolutional neural networks (CNNs) have shown\ngreat success in image denoising by incorporating large-scale synthetic\ndatasets. However, they both have pros and cons. While the deep CNNs are\npowerful for removing the noise with known statistics, they tend to lack\nflexibility and practicality for the blind and real-world noise. Moreover, they\ncannot easily employ explicit priors. On the other hand, traditional\nnon-learning methods can involve explicit image priors, but they require\nconsiderable computation time and cannot exploit large-scale external datasets.\nIn this paper, we present a CNN-based method that leverages the advantages of\nboth methods based on the Bayesian perspective. Concretely, we divide the blind\nimage denoising problem into sub-problems and conquer each inference problem\nseparately. As the CNN is a powerful tool for inference, our method is rooted\nin CNNs and propose a novel design of network for efficient inference. With our\nproposed method, we can successfully remove blind and real-world noise, with a\nmoderate number of parameters of universal CNN.\n",
			"Comment: Presented in ICPR 2020 (Oral)"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07017",
		"pdf_url": "http://arxiv.org/pdf/2101.07017.pdf"
	},
	"1053": {
		"title": "Deep neural network surrogates for non-smooth quantities of interest in\n  shape uncertainty quantification",
		"creator": "Scarabosio, Laura",
		"subject": [
			"Mathematics - Numerical Analysis",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  We consider the point evaluation of the solution to interface problems with\ngeometric uncertainties, where the uncertainty in the obstacle is described by\na high-dimensional parameter $\\boldsymbol{y}\\in[-1,1]^d$, $d\\in\\mathbb{N}$. We\nfocus in particular on an elliptic interface problem and a Helmholtz\ntransmission problem. Point values of the solution in the physical domain\ndepend in general non-smoothly on the high-dimensional parameter, posing a\nchallenge when one is interested in building surrogates. Indeed, high-order\nmethods show poor convergence rates, while methods which are able to track\ndiscontinuities usually suffer from the so-called curse of dimensionality. For\nthis reason, in this work we propose to build surrogates for point evaluation\nusing deep neural networks. We provide a theoretical justification for why we\nexpect neural networks to provide good surrogates. Furthermore, we present\nextensive numerical experiments showing their good performance in practice. We\nobserve in particular that neural networks do not suffer from the curse of\ndimensionality, and we study the dependence of the error on the number of point\nevaluations (that is, the number of discontinuities in the parameter space), as\nwell as on several modeling parameters, such as the contrast between the two\nmaterials and, for the Helmholtz transmission problem, the wavenumber.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07023",
		"pdf_url": "http://arxiv.org/pdf/2101.07023.pdf"
	},
	"1054": {
		"title": "Time-Efficient and High-Quality Graph Partitioning for Graph Dynamic\n  Scaling",
		"creator": [
			"Hanai, Masatoshi",
			"Tziritas, Nikos",
			"Suzumura, Toyotaro",
			"Cai, Wentong",
			"Theodoropoulos, Georgios"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Databases",
			"Computer Science - Discrete Mathematics",
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Social and Information Networks"
		],
		"description": [
			"  The dynamic scaling of distributed computations plays an important role in\nthe utilization of elastic computational resources, such as the cloud. It\nenables the provisioning and de-provisioning of resources to match dynamic\nresource availability and demands. In the case of distributed graph processing,\nchanging the number of the graph partitions while maintaining high partitioning\nquality imposes serious computational overheads as typically a time-consuming\ngraph partitioning algorithm needs to execute each time repartitioning is\nrequired. In this paper, we propose a dynamic scaling method that can\nefficiently change the number of graph partitions while keeping its quality\nhigh. Our idea is based on two techniques: preprocessing and very fast edge\npartitioning, called graph edge ordering and chunk-based edge partitioning,\nrespectively. The former converts the graph data into an ordered edge list in\nsuch a way that edges with high locality are closer to each other. The latter\nimmediately divides the ordered edge list into an arbitrary number of\nhigh-quality partitions. The evaluation with the real-world billion-scale\ngraphs demonstrates that our proposed approach significantly reduces the\nrepartitioning time, while the partitioning quality it achieves is on par with\nthat of the best existing static method.\n",
			"Comment: 21 pages, 15 figures. Under review"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07026",
		"pdf_url": "http://arxiv.org/pdf/2101.07026.pdf"
	},
	"1055": {
		"title": "Analysis of key flavors of event-driven predictive maintenance using\n  logs of phenomena described by Weibull distributions",
		"creator": [
			"Petsinis, Petros",
			"Naskos, Athanasios",
			"Gounaris, Anastasios"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  This work explores two approaches to event-driven predictive maintenance in\nIndustry 4.0 that cast the problem at hand as a classification or a regression\none, respectively, using as a starting point two state-of-the-art solutions.\nFor each of the two approaches, we examine different data preprocessing\ntechniques, different prediction algorithms and the impact of ensemble and\nsampling methods. Through systematic experiments regarding the aspectsmentioned\nabove,we aimto understand the strengths of the alternatives, and more\nimportantly, shed light on how to navigate through the vast number of such\nalternatives in an informed manner. Our work constitutes a key step towards\nunderstanding the true potential of this type of data-driven predictive\nmaintenance as of to date, and assist practitioners in focusing on the aspects\nthat have the greatest impact.\n",
			"Comment: 13 pages"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07033",
		"pdf_url": "http://arxiv.org/pdf/2101.07033.pdf"
	},
	"1056": {
		"title": "Online Caching with Optimal Switching Regret",
		"creator": [
			"Mukhopadhyay, Samrat",
			"Sinha, Abhishek"
		],
		"subject": [
			"Computer Science - Information Theory",
			"Computer Science - Machine Learning",
			"Computer Science - Performance"
		],
		"description": [
			"  We consider the classical uncoded caching problem from an online learning\npoint-of-view. A cache of limited storage capacity can hold $C$ files at a time\nfrom a large catalog. A user requests an arbitrary file from the catalog at\neach time slot. Before the file request from the user arrives, a caching policy\npopulates the cache with any $C$ files of its choice. In the case of a\ncache-hit, the policy receives a unit reward and zero rewards otherwise. In\naddition to that, there is a cost associated with fetching files to the cache,\nwhich we refer to as the switching cost. The objective is to design a caching\npolicy that incurs minimal regret while considering both the rewards due to\ncache-hits and the switching cost due to the file fetches. The main\ncontribution of this paper is the switching regret analysis of a Follow the\nPerturbed Leader-based anytime caching policy, which is shown to have an order\noptimal switching regret. In this pursuit, we improve the best-known switching\nregret bound for this problem by a factor of $\\Theta(\\sqrt{C}).$ We conclude\nthe paper by comparing the performance of different popular caching policies\nusing a publicly available trace from a commercial CDN server.\n",
			"Comment: 11 pages, 3 figures, to be submitted to ISIT, 2021"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07043",
		"pdf_url": "http://arxiv.org/pdf/2101.07043.pdf"
	},
	"1057": {
		"title": "Deadeye: A Novel Preattentive Visualization Technique Based on Dichoptic\n  Presentation",
		"creator": [
			"Krekhov, Andrey",
			"Krueger, Jens"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": [
			"  Preattentive visual features such as hue or flickering can effectively draw\nattention to an object of interest -- for instance, an important feature in a\nscientific visualization. These features appear to pop out and can be\nrecognized by our visual system, independently from the number of distractors.\nMost cues do not take advantage of the fact that most humans have two eyes. In\ncases where binocular vision is applied, it is almost exclusively used to\nconvey depth by exposing stereo pairs. We present Deadeye, a novel preattentive\nvisualization technique based on presenting different stimuli to each eye. The\ntarget object is rendered for one eye only and is instantly detected by our\nvisual system. In contrast to existing cues, Deadeye does not modify any visual\nproperties of the target and, thus, is particularly suited for visualization\napplications. Our evaluation confirms that Deadeye is indeed perceived\npreattentively. We also explore a conjunction search based on our technique and\nshow that, in contrast to 3D depth, the task cannot be processed in parallel.\n",
			"Comment: 10 pages, 8 figures, journal"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07048",
			"IEEE Transactions on Visualization and Computer Graphics, vol. 25,\n  no. 1, pp. 936-945, Jan. 2019",
			"doi:10.1109/TVCG.2018.2864498"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07048.pdf"
	},
	"1058": {
		"title": "A Distributed Chunk Calculation Approach for Self-scheduling of Parallel\n  Applications on Distributed-memory Systems",
		"creator": [
			"Eleliemy, Ahmed",
			"Ciorba, Florina M."
		],
		"subject": "Computer Science - Distributed, Parallel, and Cluster Computing",
		"description": "  Loop scheduling techniques aim to achieve load-balanced executions of\nscientific applications. Dynamic loop self-scheduling (DLS) libraries for\ndistributed-memory systems are typically MPI-based and employ a centralized\nchunk calculation approach (CCA) to assign variably-sized chunks of loop\niterations. We present a distributed chunk calculation approach (DCA) that\nsupports various types of DLS techniques. Using both CCA and DCA, twelve DLS\ntechniques are implemented and evaluated in different CPU slowdown scenarios.\nThe results show that the DLS techniques implemented using DCA outperform their\ncorresponding ones implemented with CCA, especially in extreme system slowdown\nscenarios.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07050",
		"pdf_url": "http://arxiv.org/pdf/2101.07050.pdf"
	},
	"1059": {
		"title": "A Passive Online Technique for Learning Hybrid Automata from\n  Input/Output Traces",
		"creator": [
			"Saberi, Iman",
			"Faghih, Fathiyeh",
			"Bavil, Farzad Sobhi"
		],
		"subject": [
			"Computer Science - Formal Languages and Automata Theory",
			"Computer Science - Machine Learning",
			"Computer Science - Software Engineering"
		],
		"description": [
			"  Specification synthesis is the process of deriving a model from the\ninput-output traces of a system. It is used extensively in test design, reverse\nengineering, and system identification. One type of the resulting artifact of\nthis process for cyber-physical systems is hybrid automata. They are intuitive,\nprecise, tool independent, and at a high level of abstraction, and can model\nsystems with both discrete and continuous variables. In this paper, we propose\na new technique for synthesizing hybrid automaton from the input-output traces\nof a non-linear cyber-physical system. Similarity detection in non-linear\nbehaviors is the main challenge for extracting such models. We address this\nproblem by utilizing the Dynamic Time Warping technique. Our approach is\npassive, meaning that it does not need interaction with the system during\nautomata synthesis from the logged traces; and online, which means that each\ninput/output trace is used only once in the procedure. In other words, each new\ntrace can be used to improve the already synthesized automaton. We evaluated\nour algorithm in two industrial and simulated case studies. The accuracy of the\nderived automata show promising results.\n",
			"Comment: 10 pages, 15 figures"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07053",
		"pdf_url": "http://arxiv.org/pdf/2101.07053.pdf"
	},
	"1060": {
		"title": "Explicit continuation methods with L-BFGS updating formulas for linearly\n  constrained optimization problems",
		"creator": [
			"Luo, Xin-long",
			"Lv, Jia-hui",
			"Xiao, Hang"
		],
		"subject": [
			"Mathematics - Optimization and Control",
			"Mathematics - Dynamical Systems",
			"Mathematics - Numerical Analysis"
		],
		"description": [
			"  This paper considers an explicit continuation method with the trusty\ntime-stepping scheme and the limited-memory BFGS (L-BFGS) updating formula\n(Eptctr) for the linearly constrained optimization problem. At every iteration,\nEptctr only involves three pairs of the inner product of vector and one\nmatrix-vector product, other than the traditional and representative\noptimization method such as the sequential quadratic programming (SQP) or the\nlatest continuation method such as Ptctr \\cite{LLS2020}, which needs to solve a\nquadratic programming subproblem (SQP) or a linear system of equations (Ptctr).\nThus, Eptctr can save much more computational time than SQP or Ptctr. Numerical\nresults also show that the consumed time of EPtctr is about one tenth of that\nof Ptctr or one fifteenth to 0.4 percent of that of SQP. Furthermore, Eptctr\ncan save the storage space of an $(n+m) \\times (n+m)$ large-scale matrix, in\ncomparison to SQP. The required memory of Eptctr is about one fifth of that of\nSQP. Finally, we also give the global convergence analysis of the new method\nunder the standard assumptions.\n",
			"Comment: arXiv admin note: substantial text overlap with arXiv:2012.14808;\n  text overlap with arXiv:2005.05965"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07055",
		"pdf_url": "http://arxiv.org/pdf/2101.07055.pdf"
	},
	"1061": {
		"title": "Deep Inertial Odometry with Accurate IMU Preintegration",
		"creator": [
			"Khorrambakht, Rooholla",
			"Lu, Chris Xiaoxuan",
			"Damirchi, Hamed",
			"Chen, Zhenghua",
			"Li, Zhengguo"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Inertial Measurement Units (IMUs) are interceptive modalities that provide\nego-motion measurements independent of the environmental factors. They are\nwidely adopted in various autonomous systems. Motivated by the limitations in\nprocessing the noisy measurements from these sensors using their mathematical\nmodels, researchers have recently proposed various deep learning architectures\nto estimate inertial odometry in an end-to-end manner. Nevertheless, the\nhigh-frequency and redundant measurements from IMUs lead to long raw sequences\nto be processed. In this study, we aim to investigate the efficacy of accurate\npreintegration as a more realistic solution to the IMU motion model for deep\ninertial odometry (DIO) and the resultant DIO is a fusion of model-driven and\ndata-driven approaches. The accurate IMU preintegration has the potential to\noutperform numerical approximation of the continuous IMU model used in the\nexisting DIOs. Experimental results validate the proposed DIO.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07061",
		"pdf_url": "http://arxiv.org/pdf/2101.07061.pdf"
	},
	"1062": {
		"title": "Reversible Computation in Petri Nets",
		"creator": "Psara, Kyriaki",
		"subject": "Computer Science - Logic in Computer Science",
		"description": [
			"  Reversible computation is an unconventional form of computing that extends\nthe standard forward-only mode of computation with the ability to execute a\nsequence of operations in reverse at any point during computation. As such, in\nthis thesis we propose a reversible approach to Petri nets by introducing\nmachinery and associated operational semantics to tackle the challenges of the\nmain forms of reversibility. Our proposal concerns a variation of cyclic Petri\nnets, called Reversing Petri Nets (RPNs) where tokens are persistent and\ndistinguished from each other by an identity. An immediate extension of the\noriginal model includes allowing multiple tokens of the same base/type to occur\nin a model. Specifically, we explore the individual token interpretation where\none distinguishes different tokens residing in the same place by keeping track\nof where they come from. We also propose the collective token interpretation,\nas the opposite approach to token ambiguity, which considers all tokens of a\ncertain type to be identical, disregarding their history during execution. Both\nof the proposed models of RPNs (with single or multi tokens) implement the\nnotion of uncontrolled reversibility, meaning that it specifies how to reverse\nan execution and allows to do so freely, yet it places no restrictions as to\nwhen and whether to prefer backward execution over forward execution or vice\nversa. In this respect, a further aim is to control reversibility by extending\nour formal semantics where transitions are associated with conditions whose\nsatisfaction allows the execution of transitions in the forward/reversed\ndirection.\n",
			"Comment: PhD dissertation"
		],
		"date": "2021-01-04",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07066",
		"pdf_url": "http://arxiv.org/pdf/2101.07066.pdf"
	},
	"1063": {
		"title": "Emotional EEG Classification using Connectivity Features and\n  Convolutional Neural Networks",
		"creator": [
			"Moon, Seong-Eun",
			"Chen, Chun-Jui",
			"Hsieh, Cho-Jui",
			"Wang, Jane-Ling",
			"Lee, Jong-Seok"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Human-Computer Interaction"
		],
		"description": "  Convolutional neural networks (CNNs) are widely used to recognize the user's\nstate through electroencephalography (EEG) signals. In the previous studies,\nthe EEG signals are usually fed into the CNNs in the form of high-dimensional\nraw data. However, this approach makes it difficult to exploit the brain\nconnectivity information that can be effective in describing the functional\nbrain network and estimating the perceptual state of the user. We introduce a\nnew classification system that utilizes brain connectivity with a CNN and\nvalidate its effectiveness via the emotional video classification by using\nthree different types of connectivity measures. Furthermore, two data-driven\nmethods to construct the connectivity matrix are proposed to maximize\nclassification performance. Further analysis reveals that the level of\nconcentration of the brain connectivity related to the emotional property of\nthe target video is correlated with classification performance.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07069",
			"Neural Networks, vol. 132, pp. 96-107, Dec. 2020",
			"doi:10.1016/j.neunet.2020.08.009"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07069.pdf"
	},
	"1064": {
		"title": "Online detection of failures generated by storage simulator",
		"creator": [
			"Arzymatov, Kenenbek",
			"Hushchyn, Mikhail",
			"Sapronov, Andrey",
			"Belavin, Vladislav",
			"Gremyachikh, Leonid",
			"Karpov, Maksim",
			"Ustyuzhanin, Andrey"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Modern large-scale data-farms consist of hundreds of thousands of storage\ndevices that span distributed infrastructure. Devices used in modern data\ncenters (such as controllers, links, SSD- and HDD-disks) can fail due to\nhardware as well as software problems. Such failures or anomalies can be\ndetected by monitoring the activity of components using machine learning\ntechniques. In order to use these techniques, researchers need plenty of\nhistorical data of devices in normal and failure mode for training algorithms.\nIn this work, we challenge two problems: 1) lack of storage data in the methods\nabove by creating a simulator and 2) applying existing online algorithms that\ncan faster detect a failure occurred in one of the components.\n  We created a Go-based (golang) package for simulating the behavior of modern\nstorage infrastructure. The software is based on the discrete-event modeling\nparadigm and captures the structure and dynamics of high-level storage system\nbuilding blocks. The package's flexible structure allows us to create a model\nof a real-world storage system with a configurable number of components. The\nprimary area of interest is exploring the storage machine's behavior under\nstress testing or exploitation in the medium- or long-term for observing\nfailures of its components.\n  To discover failures in the time series distribution generated by the\nsimulator, we modified a change point detection algorithm that works in online\nmode. The goal of the change-point detection is to discover differences in time\nseries distribution. This work describes an approach for failure detection in\ntime series data based on direct density ratio estimation via binary\nclassifiers.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07100",
		"pdf_url": "http://arxiv.org/pdf/2101.07100.pdf"
	},
	"1065": {
		"title": "Uplink Beam Management for Millimeter Wave Cellular MIMO Systems with\n  Hybrid Beamforming",
		"creator": [
			"Alexandropoulos, George C.",
			"Vinieratou, Ioanna",
			"Rebato, Mattia",
			"Rose, Luca",
			"Zorzi, Michele"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  Hybrid analog and digital BeamForming (HBF) is one of the enabling\ntransceiver technologies for millimeter Wave (mmWave) Multiple Input Multiple\nOutput (MIMO) systems. This technology offers highly directional communication,\nwhich is able to confront the intrinsic characteristics of mmWave signal\npropagation. However, the small coherence time in mmWave systems, especially\nunder mobility conditions, renders efficient Beam Management (BM) in standalone\nmmWave communication a very difficult task. In this paper, we consider HBF\ntransceivers with planar antenna panels and design a multi-level beam codebook\nfor the analog beamformer comprising flat top beams with variable widths. These\nbeams exhibit an almost constant array gain for the whole desired angle width,\nthereby facilitating efficient hierarchical BM. Focusing on the uplink\ncommunication, we present a novel beam training algorithm with dynamic beam\nordering, which is suitable for the stringent latency requirements of the\nlatest mmWave standard discussions. Our simulation results showcase the latency\nperformance improvement and received signal-to-noise ratio with different\nvariations of the proposed scheme over the optimum beam training scheme based\non exhaustive narrow beam search.\n",
			"Comment: 7 pages; 6 figures; accepted to an IEEE conference"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07106",
		"pdf_url": "http://arxiv.org/pdf/2101.07106.pdf"
	},
	"1066": {
		"title": "Efficient Monitoring of Hyperproperties using Prefix Trees",
		"creator": [
			"Finkbeiner, Bernd",
			"Hahn, Christopher",
			"Stenger, Marvin",
			"Tentrup, Leander"
		],
		"subject": "Computer Science - Logic in Computer Science",
		"description": [
			"  Hyperproperties, such as non-interference and observational determinism,\nrelate multiple computation traces with each other and are thus not monitorable\nby tools that consider computations in isolation. We present the monitoring\napproach implemented in the latest version of RVHyper, a runtime verification\ntool for hyperproperties. The input to the tool are specifications given in the\ntemporal logic HyperLTL, which extends linear-time temporal logic (LTL) with\ntrace quantifiers and trace variables. RVHyper processes execution traces\nsequentially until a violation of the specification is detected. In this case,\na counter example, in the form of a set of traces, is returned. RVHyper employs\na range of optimizations: a preprocessing analysis of the specification and a\nprocedure that minimizes the traces that need to be stored during the\nmonitoring process. In this article, we introduce a novel trace storage\ntechnique that arranges the traces in a tree-like structure to exploit\npartially equal traces. We evaluate RVhyper on existing benchmarks on secure\ninformation-flow control, error correcting codes and symmetry in hardware\ndesigns. As an example application outside of security, we show how RVHyper can\nbe used to detect spurious dependencies in hardware designs.\n",
			"Comment: arXiv admin note: text overlap with arXiv:1807.00758,\n  arXiv:1906.00798"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07109",
		"pdf_url": "http://arxiv.org/pdf/2101.07109.pdf"
	},
	"1067": {
		"title": "Applying High-Performance Bioinformatics Tools for Outlier Detection in\n  Log Data",
		"creator": [
			"Wurzenberger, Markus",
			"Skopik, Florian",
			"Fiedler, Roman",
			"Kastner, Wolfgang"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": "  Most of today's security solutions, such as security information and event\nmanagement (SIEM) and signature based IDS, require the operator to evaluate\npotential attack vectors and update detection signatures and rules in a timely\nmanner. However, today's sophisticated and tailored advanced persistent threats\n(APT), malware, ransomware and rootkits, can be so complex and diverse, and\noften use zero day exploits, that a pure signature-based blacklisting approach\nwould not be sufficient to detect them. Therefore, we could observe a major\nparadigm shift towards anomaly-based detection mechanisms, which try to\nestablish a system behavior baseline -- either based on netflow data or system\nlogging data -- and report any deviations from this baseline. While these\napproaches look promising, they usually suffer from scalability issues. As the\namount of log data generated during IT operations is exponentially growing,\nhigh-performance analysis methods are required that can handle this huge amount\nof data in real-time. In this paper, we demonstrate how high-performance\nbioinformatics tools can be applied to tackle this issue. We investigate their\napplication to log data for outlier detection to timely reveal anomalous system\nbehavior that points to cyber attacks. Finally, we assess the detection\ncapability and run-time performance of the proposed approach.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07113",
		"pdf_url": "http://arxiv.org/pdf/2101.07113.pdf"
	},
	"1068": {
		"title": "LNSMM: Eye Gaze Estimation With Local Network Share Multiview Multitask",
		"creator": [
			"Huang, Yong",
			"Chen, Ben",
			"Qu, Daiming"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  Eye gaze estimation has become increasingly significant in computer vision.In\nthis paper,we systematically study the mainstream of eye gaze estimation\nmethods,propose a novel methodology to estimate eye gaze points and eye gaze\ndirections simultaneously.First,we construct a local sharing network for\nfeature extraction of gaze points and gaze directions estimation,which can\nreduce network computational parameters and converge quickly;Second,we propose\na Multiview Multitask Learning (MTL) framework,for gaze directions,a coplanar\nconstraint is proposed for the left and right eyes,for gaze points,three views\ndata input indirectly introduces eye position information,a cross-view pooling\nmodule is designed, propose joint loss which handle both gaze points and gaze\ndirections estimation.Eventually,we collect a dataset to use of gaze\npoints,which have three views to exist public dataset.The experiment show our\nmethod is state-of-the-art the current mainstream methods on two indicators of\ngaze points and gaze directions.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07116",
		"pdf_url": "http://arxiv.org/pdf/2101.07116.pdf"
	},
	"1069": {
		"title": "Neural Abstractive Text Summarizer for Telugu Language",
		"creator": [
			"B, Mohan Bharath",
			"B, Aravindh Gowtham",
			"M, Akhil"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Abstractive Text Summarization is the process of constructing semantically\nrelevant shorter sentences which captures the essence of the overall meaning of\nthe source text. It is actually difficult and very time consuming for humans to\nsummarize manually large documents of text. Much of work in abstractive text\nsummarization is being done in English and almost no significant work has been\nreported in Telugu abstractive text summarization. So, we would like to propose\nan abstractive text summarization approach for Telugu language using Deep\nlearning. In this paper we are proposing an abstractive text summarization Deep\nlearning model for Telugu language. The proposed architecture is based on\nencoder-decoder sequential models with attention mechanism. We have applied\nthis model on manually created dataset to generate a one sentence summary of\nthe source text and have got good results measured qualitatively.\n",
			"Comment: 11 pages, 2 figures. Presented the paper at Third International\n  Conference on Soft Computing and Signal Processing (ICSCSP 2020) and is\n  currently in production. It will soon be published in springer Advances in\n  Intelligent Systems and Computing (AISC) series"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07120",
		"pdf_url": "http://arxiv.org/pdf/2101.07120.pdf"
	},
	"1070": {
		"title": "Learning Successor States and Goal-Dependent Values: A Mathematical\n  Viewpoint",
		"creator": [
			"Blier, Léonard",
			"Tallec, Corentin",
			"Ollivier, Yann"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  In reinforcement learning, temporal difference-based algorithms can be\nsample-inefficient: for instance, with sparse rewards, no learning occurs until\na reward is observed. This can be remedied by learning richer objects, such as\na model of the environment, or successor states. Successor states model the\nexpected future state occupancy from any given state for a given policy and are\nrelated to goal-dependent value functions, which learn how to reach arbitrary\nstates. We formally derive the temporal difference algorithm for successor\nstate and goal-dependent value function learning, either for discrete or for\ncontinuous environments with function approximation. Especially, we provide\nfinite-variance estimators even in continuous environments, where the reward\nfor exactly reaching a goal state becomes infinitely sparse. Successor states\nsatisfy more than just the Bellman equation: a backward Bellman operator and a\nBellman-Newton (BN) operator encode path compositionality in the environment.\nThe BN operator is akin to second-order gradient descent methods and provides\nthe true update of the value function when acquiring more observations, with\nexplicit tabular bounds. In the tabular case and with infinitesimal learning\nrates, mixing the usual and backward Bellman operators provably improves\neigenvalues for asymptotic convergence, and the asymptotic convergence of the\nBN operator is provably better than TD, with a rate independent from the\nenvironment. However, the BN method is more complex and less robust to sampling\nnoise. Finally, a forward-backward (FB) finite-rank parameterization of\nsuccessor states enjoys reduced variance and improved samplability, provides a\ndirect model of the value function, has fully understood fixed points\ncorresponding to long-range dependencies, approximates the BN method, and\nprovides two canonical representations of states as a byproduct.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07123",
		"pdf_url": "http://arxiv.org/pdf/2101.07123.pdf"
	},
	"1071": {
		"title": "Tip of the Tongue Known-Item Retrieval: A Case Study in Movie\n  Identification",
		"creator": [
			"Arguello, Jaime",
			"Ferguson, Adam",
			"Fine, Emery",
			"Mitra, Bhaskar",
			"Zamani, Hamed",
			"Diaz, Fernando"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Human-Computer Interaction"
		],
		"description": "  While current information retrieval systems are effective for known-item\nretrieval where the searcher provides a precise name or identifier for the item\nbeing sought, systems tend to be much less effective for cases where the\nsearcher is unable to express a precise name or identifier. We refer to this as\ntip of the tongue (TOT) known-item retrieval, named after the cognitive state\nof not being able to retrieve an item from memory. Using movie search as a case\nstudy, we explore the characteristics of questions posed by searchers in TOT\nstates in a community question answering website. We analyze how searchers\nexpress their information needs during TOT states in the movie domain.\nSpecifically, what information do searchers remember about the item being\nsought and how do they convey this information? Our results suggest that\nsearchers use a combination of information about: (1) the content of the item\nsought, (2) the context in which they previously engaged with the item, and (3)\nprevious attempts to find the item using other resources (e.g., search\nengines). Additionally, searchers convey information by sometimes expressing\nuncertainty (i.e., hedging), opinions, emotions, and by performing relative\n(vs. absolute) comparisons with attributes of the item. As a result of our\nanalysis, we believe that searchers in TOT states may require specialized query\nunderstanding methods or document representations. Finally, our preliminary\nretrieval experiments show the impact of each information type presented in\ninformation requests on retrieval performance.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07124",
		"pdf_url": "http://arxiv.org/pdf/2101.07124.pdf"
	},
	"1072": {
		"title": "A simple geometric proof for the benefit of depth in ReLU networks",
		"creator": [
			"Amrami, Asaf",
			"Goldberg, Yoav"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  We present a simple proof for the benefit of depth in multi-layer feedforward\nnetwork with rectified activation (\"depth separation\"). Specifically we present\na sequence of classification problems indexed by $m$ such that (a) for any\nfixed depth rectified network there exist an $m$ above which classifying\nproblem $m$ correctly requires exponential number of parameters (in $m$); and\n(b) for any problem in the sequence, we present a concrete neural network with\nlinear depth (in $m$) and small constant width ($\\leq 4$) that classifies the\nproblem with zero error.\n  The constructive proof is based on geometric arguments and a space folding\nconstruction.\n  While stronger bounds and results exist, our proof uses substantially simpler\ntools and techniques, and should be accessible to undergraduate students in\ncomputer science and people with similar backgrounds.\n",
			"Comment: 9 pages, 5 figures"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07126",
		"pdf_url": "http://arxiv.org/pdf/2101.07126.pdf"
	},
	"1073": {
		"title": "Fundamental Limits of Demand-Private Coded Caching",
		"creator": [
			"Gurjarpadhye, Chinmay",
			"Ravi, Jithin",
			"Kamath, Sneha",
			"Dey, Bikash Kumar",
			"Karamchandani, Nikhil"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  We consider the coded caching problem with an additional privacy constraint\nthat a user should not get any information about the demands of the other\nusers. We first show that a demand-private scheme for $N$ files and $K$ users\ncan be obtained from a non-private scheme that serves only a subset of the\ndemands for the $N$ files and $NK$ users problem. We further use this fact to\nconstruct a demand-private scheme for $N$ files and $K$ users from a particular\nknown non-private scheme for $N$ files and $NK-K+1$ users. It is then\ndemonstrated that, the memory-rate pair $(M,\\min \\{N,K\\}(1-M/N))$, which is\nachievable for non-private schemes with uncoded transmissions, is also\nachievable under demand privacy. We further propose a scheme that improves on\nthese ideas by removing some redundant transmissions. The memory-rate trade-off\nachieved using our schemes is shown to be within a multiplicative factor of 3\nfrom the optimal when $K < N$ and of 8 when $N\\leq K$. Finally, we give the\nexact memory-rate trade-off for demand-private coded caching problems with\n$N\\geq K=2$.\n",
			"Comment: 43 pages, 6 figures"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07127",
		"pdf_url": "http://arxiv.org/pdf/2101.07127.pdf"
	},
	"1074": {
		"title": "Classification of fNIRS Data Under Uncertainty: A Bayesian Neural\n  Network Approach",
		"creator": [
			"Siddique, Talha",
			"Mahmud, Md Shaad"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Functional Near-Infrared Spectroscopy (fNIRS) is a non-invasive form of\nBrain-Computer Interface (BCI). It is used for the imaging of brain\nhemodynamics and has gained popularity due to the certain pros it poses over\nother similar technologies. The overall functionalities encompass the capture,\nprocessing and classification of brain signals. Since hemodynamic responses are\ncontaminated by physiological noises, several methods have been implemented in\nthe past literature to classify the responses in focus from the unwanted ones.\nHowever, the methods, thus far does not take into consideration the uncertainty\nin the data or model parameters. In this paper, we use a Bayesian Neural\nNetwork (BNN) to carry out a binary classification on an open-access dataset,\nconsisting of unilateral finger tapping (left- and right-hand finger tapping).\nA BNN uses Bayesian statistics to assign a probability distribution to the\nnetwork weights instead of a point estimate. In this way, it takes data and\nmodel uncertainty into consideration while carrying out the classification. We\nused Variational Inference (VI) to train our model. Our model produced an\noverall classification accuracy of 86.44% over 30 volunteers. We illustrated\nhow the evidence lower bound (ELBO) function of the model converges over\niterations. We further illustrated the uncertainty that is inherent during the\nsampling of the posterior distribution of the weights. We also generated a ROC\ncurve for our BNN classifier using test data from a single volunteer and our\nmodel has an AUC score of 0.855.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07128",
		"pdf_url": "http://arxiv.org/pdf/2101.07128.pdf"
	},
	"1075": {
		"title": "Verifiable Failure Localization in Smart Grid under Cyber-Physical\n  Attacks",
		"creator": [
			"Huang, Yudi",
			"He, Ting",
			"Chaudhuri, Nilanjan Ray",
			"La Porta, Thomas"
		],
		"subject": "Computer Science - Performance",
		"description": "  Cyber-physical attacks impose a significant threat to the smart grid, as the\ncyber attack makes it difficult to identify the actual damage caused by the\nphysical attack. To defend against such attacks, various inference-based\nsolutions have been proposed to estimate the states of grid elements (e.g.,\ntransmission lines) from measurements outside the attacked area, out of which a\nfew have provided theoretical conditions for guaranteed accuracy. However,\nthese conditions are usually based on the ground truth states and thus not\nverifiable in practice. To solve this problem, we develop (i) verifiable\nconditions that can be tested based on only observable information, and (ii)\nefficient algorithms for verifying the states of links (i.e., transmission\nlines) within the attacked area based on these conditions. Our numerical\nevaluations based on the Polish power grid and IEEE 300-bus system demonstrate\nthat the proposed algorithms are highly successful in verifying the states of\ntruly failed links, and can thus greatly help in prioritizing repairs during\nthe recovery process.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07129",
		"pdf_url": "http://arxiv.org/pdf/2101.07129.pdf"
	},
	"1076": {
		"title": "SD-Regular Transducer Expressions for Aperiodic Transformations",
		"creator": [
			"Dartois, Luc",
			"Gastin, Paul",
			"Krishna, Shankara Narayanan"
		],
		"subject": [
			"Computer Science - Formal Languages and Automata Theory",
			"F.4.3"
		],
		"description": "  FO transductions, aperiodic deterministic two-way transducers, as well as\naperiodic streaming string transducers are all equivalent models for first\norder definable functions. In this paper, we solve the long standing open\nproblem of expressions capturing first order definable functions, thereby\ngeneralizing the seminal SF=AP (star free expressions = aperiodic languages)\nresult of Sch\\\"utzenberger. Our result also generalizes a lesser known\ncharacterization by Sch\\\"utzenberger of aperiodic languages by SD-regular\nexpressions (SD=AP). We show that every first order definable function over\nfinite words captured by an aperiodic deterministic two-way transducer can be\ndescribed with an SD-regular transducer expression (SDRTE). An SDRTE is a\nregular expression where Kleene stars are used in a restricted way: they can\nappear only on aperiodic languages which are prefix codes of bounded\nsynchronization delay. SDRTEs are constructed from simple functions using the\ncombinators unambiguous sum (deterministic choice), Hadamard product, and\nunambiguous versions of the Cauchy product and the k-chained Kleene-star, where\nthe star is restricted as mentioned. In order to construct an SDRTE associated\nwith an aperiodic deterministic two-way transducer, (i) we concretize\nSch\\\"utzenberger's SD=AP result, by proving that aperiodic languages are\ncaptured by SD-regular expressions which are unambiguous and stabilising; (ii)\nby structural induction on the unambiguous, stabilising SD-regular expressions\ndescribing the domain of the transducer, we construct SDRTEs. Finally, we also\nlook at various formalisms equivalent to SDRTEs which use the function\ncomposition, allowing to trade the k-chained star for a 1-star.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07130",
		"pdf_url": "http://arxiv.org/pdf/2101.07130.pdf"
	},
	"1077": {
		"title": "Trav-SHACL: Efficiently Validating Networks of SHACL Constraints",
		"creator": [
			"Figuera, Mónica",
			"Rohde, Philipp D.",
			"Vidal, Maria-Esther"
		],
		"subject": "Computer Science - Databases",
		"description": "  Knowledge graphs have emerged as expressive data structures for Web data.\nKnowledge graph potential and the demand for ecosystems to facilitate their\ncreation, curation, and understanding, is testified in diverse domains, e.g.,\nbiomedicine. The Shapes Constraint Language (SHACL) is the W3C recommendation\nlanguage for integrity constraints over RDF knowledge graphs. Enabling quality\nassements of knowledge graphs, SHACL is rapidly gaining attention in real-world\nscenarios. SHACL models integrity constraints as a network of shapes, where a\nshape contains the constraints to be fullfiled by the same entities. The\nvalidation of a SHACL shape schema can face the issue of tractability during\nvalidation. To facilitate full adoption, efficient computational methods are\nrequired. We present Trav-SHACL, a SHACL engine capable of planning the\ntraversal and execution of a shape schema in a way that invalid entities are\ndetected early and needless validations are minimized. Trav-SHACL reorders the\nshapes in a shape schema for efficient validation and rewrites target and\nconstraint queries for the fast detection of invalid entities. Trav-SHACL is\nempirically evaluated on 27 testbeds executed against knowledge graphs of up to\n34M triples. Our experimental results suggest that Trav-SHACL exhibits high\nperformance gradually and reduces validation time by a factor of up to 28.93\ncompared to the state of the art.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07136",
		"pdf_url": "http://arxiv.org/pdf/2101.07136.pdf"
	},
	"1078": {
		"title": "Teach me how to Label: Labeling Functions from Natural Language with\n  Text-to-text Transformers",
		"creator": "Papanikolaou, Yannis",
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning"
		],
		"description": "  Annotated data has become the most important bottleneck in training accurate\nmachine learning models, especially for areas that require domain expertise. A\nrecent approach to deal with the above issue proposes using natural language\nexplanations instead of labeling individual data points, thereby increasing\nhuman annotators' efficiency as well as decreasing costs substantially. This\npaper focuses on the task of turning these natural language descriptions into\nPython labeling functions by following a novel approach to semantic parsing\nwith pre-trained text-to-text Transformers. In a series of experiments our\napproach achieves a new state of the art on the semantic parsing benchmark\nCoNaLa, surpassing the previous best approach by 3.7 BLEU points. Furthermore,\non a manually constructed dataset of natural language descriptions-labeling\nfunctions pairs we achieve a BLEU of 0.39. Our approach can be regarded as a\nstepping stone towards models that are taught how to label in natural language,\ninstead of being provided specific labeled samples. Our code, constructed\ndataset and models are available at\nhttps://github.com/ypapanik/t5-for-code-generation.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07138",
		"pdf_url": "http://arxiv.org/pdf/2101.07138.pdf"
	},
	"1079": {
		"title": "Designing a mobile game to generate player data -- lessons learned",
		"creator": [
			"Wallis, William",
			"Kavanagh, William",
			"Miller, Alice",
			"Storer, Tim"
		],
		"subject": [
			"Computer Science - Multimedia",
			"Computer Science - Computers and Society",
			"Computer Science - Software Engineering"
		],
		"description": "  User friendly tools have lowered the requirements of high-quality game design\nto the point where researchers without development experience can release their\nown games. However, there is no established best-practice as few games have\nbeen produced for research purposes. Having developed a mobile game without the\nguidance of similar projects, we realised the need to share our experience so\nfuture researchers have a path to follow. Research into game balancing and\nsystem simulation required an experimental case study, which inspired the\ncreation of \"RPGLite\", a multiplayer mobile game. In creating RPGLitewith no\ndevelopment expertise we learned a series of lessons about effective amateur\ngame development for research purposes. In this paper we reflect on the entire\ndevelopment process and present these lessons.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07144",
		"pdf_url": "http://arxiv.org/pdf/2101.07144.pdf"
	},
	"1080": {
		"title": "Provably Constant-time Planning and Replanning for Real-time Grasping\n  Objects off a Conveyor Belt",
		"creator": [
			"Islam, Fahad",
			"Salzman, Oren",
			"Agarwal, Aditya",
			"Likhachev, Maxim"
		],
		"subject": "Computer Science - Robotics",
		"description": [
			"  In warehouse and manufacturing environments, manipulation platforms are\nfrequently deployed at conveyor belts to perform pick and place tasks. Because\nobjects on the conveyor belts are moving, robots have limited time to pick them\nup. This brings the requirement for fast and reliable motion planners that\ncould provide provable real-time planning guarantees, which the existing\nalgorithms do not provide. Besides the planning efficiency, the success of\nmanipulation tasks relies heavily on the accuracy of the perception system\nwhich is often noisy, especially if the target objects are perceived from a\ndistance. For fast moving conveyor belts, the robot cannot wait for a perfect\nestimate before it starts executing its motion. In order to be able to reach\nthe object in time, it must start moving early on (relying on the initial noisy\nestimates) and adjust its motion on-the-fly in response to the pose updates\nfrom perception. We propose a planning framework that meets these requirements\nby providing provable constant-time planning and replanning guarantees. To this\nend, we first introduce and formalize a new class of algorithms called\nConstant-Time Motion Planning algorithms (CTMP) that guarantee to plan in\nconstant time and within a user-defined time bound. We then present our\nplanning framework for grasping objects off a conveyor belt as an instance of\nthe CTMP class of algorithms.\n",
			"Comment: arXiv admin note: substantial text overlap with arXiv:2003.08517"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07148",
		"pdf_url": "http://arxiv.org/pdf/2101.07148.pdf"
	},
	"1081": {
		"title": "Deterministic Decremental SSSP and Approximate Min-Cost Flow in\n  Almost-Linear Time",
		"creator": [
			"Bernstein, Aaron",
			"Gutenberg, Maximilian Probst",
			"Saranurak, Thatchaphol"
		],
		"subject": "Computer Science - Data Structures and Algorithms",
		"description": "  In the decremental single-source shortest paths problem, the goal is to\nmaintain distances from a fixed source $s$ to every vertex $v$ in an $m$-edge\ngraph undergoing edge deletions. In this paper, we conclude a long line of\nresearch on this problem by showing a near-optimal deterministic data structure\nthat maintains $(1+\\epsilon)$-approximate distance estimates and runs in\n$m^{1+o(1)}$ total update time.\n  Our result, in particular, removes the oblivious adversary assumption\nrequired by the previous breakthrough result by Henzinger et al. [FOCS'14],\nwhich leads to our second result: the first almost-linear time algorithm for\n$(1-\\epsilon)$-approximate min-cost flow in undirected graphs where capacities\nand costs can be taken over edges and vertices. Previously, algorithms for max\nflow with vertex capacities, or min-cost flow with any capacities required\nsuper-linear time. Our result essentially completes the picture for approximate\nflow in undirected graphs.\n  The key technique of the first result is a novel framework that allows us to\ntreat low-diameter graphs like expanders. This allows us to harness expander\nproperties while bypassing shortcomings of expander decomposition, which almost\nall previous expander-based algorithms needed to deal with. For the second\nresult, we break the notorious flow-decomposition barrier from the\nmultiplicative-weight-update framework using randomization.\n",
		"date": [
			"2021-01-18",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07149",
		"pdf_url": "http://arxiv.org/pdf/2101.07149.pdf"
	},
	"1082": {
		"title": "Stable Recovery of Entangled Weights: Towards Robust Identification of\n  Deep Neural Networks from Minimal Samples",
		"creator": [
			"Fiedler, Christian",
			"Fornasier, Massimo",
			"Klock, Timo",
			"Rauchensteiner, Michael"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"65D15, 68T07, 90C26"
		],
		"description": "  In this paper we approach the problem of unique and stable identifiability of\ngeneric deep artificial neural networks with pyramidal shape and smooth\nactivation functions from a finite number of input-output samples. More\nspecifically we introduce the so-called entangled weights, which compose\nweights of successive layers intertwined with suitable diagonal and invertible\nmatrices depending on the activation functions and their shifts. We prove that\nentangled weights are completely and stably approximated by an efficient and\nrobust algorithm as soon as $\\mathcal O(D^2 \\times m)$ nonadaptive input-output\nsamples of the network are collected, where $D$ is the input dimension and $m$\nis the number of neurons of the network. Moreover, we empirically observe that\nthe approach applies to networks with up to $\\mathcal O(D \\times m_L)$ neurons,\nwhere $m_L$ is the number of output neurons at layer $L$. Provided knowledge of\nlayer assignments of entangled weights and of remaining scaling and shift\nparameters, which may be further heuristically obtained by least squares, the\nentangled weights identify the network completely and uniquely. To highlight\nthe relevance of the theoretical result of stable recovery of entangled\nweights, we present numerical experiments, which demonstrate that multilayered\nnetworks with generic weights can be robustly identified and therefore\nuniformly approximated by the presented algorithmic pipeline. In contrast\nbackpropagation cannot generalize stably very well in this setting, being\nalways limited by relatively large uniform error. In terms of practical impact,\nour study shows that we can relate input-output information uniquely and stably\nto network parameters, providing a form of explainability. Moreover, our method\npaves the way for compression of overparametrized networks and for the training\nof minimal complexity networks.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07150",
		"pdf_url": "http://arxiv.org/pdf/2101.07150.pdf"
	},
	"1083": {
		"title": "PRESTO: Simple and Scalable Sampling Techniques for the Rigorous\n  Approximation of Temporal Motif Counts",
		"creator": [
			"Sarpe, Ilie",
			"Vandin, Fabio"
		],
		"subject": [
			"Computer Science - Social and Information Networks",
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  The identification and counting of small graph patterns, called network\nmotifs, is a fundamental primitive in the analysis of networks, with\napplication in various domains, from social networks to neuroscience. Several\ntechniques have been designed to count the occurrences of motifs in static\nnetworks, with recent work focusing on the computational challenges provided by\nlarge networks. Modern networked datasets contain rich information, such as the\ntime at which the events modeled by the networks edges happened, which can\nprovide useful insights into the process modeled by the network. The analysis\nof motifs in temporal networks, called temporal motifs, is becoming an\nimportant component in the analysis of modern networked datasets. Several\nmethods have been recently designed to count the number of instances of\ntemporal motifs in temporal networks, which is even more challenging than its\ncounterpart for static networks. Such methods are either exact, and not\napplicable to large networks, or approximate, but provide only weak guarantees\non the estimates they produce and do not scale to very large networks. In this\nwork we present an efficient and scalable algorithm to obtain rigorous\napproximations of the count of temporal motifs. Our algorithm is based on a\nsimple but effective sampling approach, which renders our algorithm practical\nfor very large datasets. Our extensive experimental evaluation shows that our\nalgorithm provides estimates of temporal motif counts which are more accurate\nthan the state-of-the-art sampling algorithms, with significantly lower running\ntime than exact approaches, enabling the study of temporal motifs, of size\nlarger than the ones considered in previous works, on billion edges networks.\n",
			"Comment: 19 pages, 5 figures, to appear in SDM 2021"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07152",
		"pdf_url": "http://arxiv.org/pdf/2101.07152.pdf"
	},
	"1084": {
		"title": "Revisiting the Auction Algorithm for Weighted Bipartite Perfect\n  Matchings",
		"creator": [
			"Khosla, Megha",
			"Anand, Avishek"
		],
		"subject": [
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Discrete Mathematics",
			"Mathematics - Combinatorics"
		],
		"description": "  We study the classical weighted perfect matchings problem for bipartite\ngraphs or sometimes referred to as the assignment problem, i.e., given a\nweighted bipartite graph $G = (U\\cup V,E)$ with weights $w : E \\rightarrow\n\\mathcal{R}$ we are interested to find the maximum matching in $G$ with the\nminimum/maximum weight. In this work we present a new and arguably simpler\nanalysis of one of the earliest techniques developed for solving the assignment\nproblem, namely the auction algorithm. Using our analysis technique we present\ntighter and improved bounds on the runtime complexity for finding an\napproximate minumum weight perfect matching in $k$-left regular sparse\nbipartite graphs.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07155",
		"pdf_url": "http://arxiv.org/pdf/2101.07155.pdf"
	},
	"1085": {
		"title": "Maximizing approximately k-submodular functions",
		"creator": [
			"Zheng, Leqian",
			"Chan, Hau",
			"Loukides, Grigorios",
			"Li, Minming"
		],
		"subject": [
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  We introduce the problem of maximizing approximately $k$-submodular functions\nsubject to size constraints. In this problem, one seeks to select $k$-disjoint\nsubsets of a ground set with bounded total size or individual sizes, and\nmaximum utility, given by a function that is \"close\" to being $k$-submodular.\nThe problem finds applications in tasks such as sensor placement, where one\nwishes to install $k$ types of sensors whose measurements are noisy, and\ninfluence maximization, where one seeks to advertise $k$ topics to users of a\nsocial network whose level of influence is uncertain. To deal with the problem,\nwe first provide two natural definitions for approximately $k$-submodular\nfunctions and establish a hierarchical relationship between them. Next, we show\nthat simple greedy algorithms offer approximation guarantees for different\ntypes of size constraints. Last, we demonstrate experimentally that the greedy\nalgorithms are effective in sensor placement and influence maximization\nproblems.\n",
			"Comment: To be published in SIAM International Conference on Data Mining (SDM)\n  2021"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07157",
		"pdf_url": "http://arxiv.org/pdf/2101.07157.pdf"
	},
	"1086": {
		"title": "Realizing Omega-regular Hyperproperties",
		"creator": [
			"Finkbeiner, Bernd",
			"Hahn, Christopher",
			"Hofmann, Jana",
			"Tentrup, Leander"
		],
		"subject": "Computer Science - Logic in Computer Science",
		"description": [
			"  We studied the hyperlogic HyperQPTL, which combines the concepts of trace\nrelations and $\\omega$-regularity. We showed that HyperQPTL is very expressive,\nit can express properties like promptness, bounded waiting for a grant,\nepistemic properties, and, in particular, any $\\omega$-regular property. Those\nproperties are not expressible in previously studied hyperlogics like HyperLTL.\nAt the same time, we argued that the expressiveness of HyperQPTL is optimal in\na sense that a more expressive logic for $\\omega$-regular hyperproperties would\nhave an undecidable model checking problem. We furthermore studied the\nrealizability problem of HyperQPTL. We showed that realizability is decidable\nfor HyperQPTL fragments that contain properties like promptness. But still, in\ncontrast to the satisfiability problem, propositional quantification does make\nthe realizability problem of hyperlogics harder. More specifically, the\nHyperQPTL fragment of formulas with a universal-existential propositional\nquantifier alternation followed by a single trace quantifier is undecidable in\ngeneral, even though the projection of the fragment to HyperLTL has a decidable\nrealizability problem. Lastly, we implemented the bounded synthesis problem for\nHyperQPTL in the prototype tool BoSy. Using BoSy with HyperQPTL specifications,\nwe have been able to synthesize several resource arbiters. The synthesis\nproblem of non-linear-time hyperlogics is still open. For example, it is not\nyet known how to synthesize systems from specifications given in branching-time\nhyperlogics like HyperCTL$^*$.\n",
			"Comment: International Conference on Computer Aided Verification (CAV 2020)"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07161",
			"=In: Lahiri S., Wang C. (eds) Computer Aided Verification. CAV\n  2020. Lecture Notes in Computer Science, vol 12225",
			"doi:10.1007/978-3-030-53291-8_4"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07161.pdf"
	},
	"1087": {
		"title": "Generation of GelSight Tactile Images for Sim2Real Learning",
		"creator": [
			"Gomes, Daniel Fernandes",
			"Paoletti, Paolo",
			"Luo, Shan"
		],
		"subject": "Computer Science - Robotics",
		"description": "  Most current works in Sim2Real learning for robotic manipulation tasks\nleverage camera vision that may be significantly occluded by robot hands during\nthe manipulation. Tactile sensing offers complementary information to vision\nand can compensate for the information loss caused by the occlusion. However,\nthe use of tactile sensing is restricted in the Sim2Real research due to no\nsimulated tactile sensors being available. To mitigate the gap, we introduce a\nnovel approach for simulating a GelSight tactile sensor in the commonly used\nGazebo simulator. Similar to the real GelSight sensor, the simulated sensor can\nproduce high-resolution images by an optical sensor from the interaction\nbetween the touched object and an opaque soft membrane. It can indirectly sense\nforces, geometry, texture and other properties of the object and enables\nSim2Real learning with tactile sensing. Preliminary experimental results have\nshown that the simulated sensor could generate realistic outputs similar to the\nones captured by a real GelSight sensor. All the materials used in this paper\nare available at https://danfergo.github.io/gelsight-simulation.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07169",
		"pdf_url": "http://arxiv.org/pdf/2101.07169.pdf"
	},
	"1088": {
		"title": "HarDNet-MSEG: A Simple Encoder-Decoder Polyp Segmentation Neural Network\n  that Achieves over 0.9 Mean Dice and 86 FPS",
		"creator": [
			"Huang, Chien-Hsiang",
			"Wu, Hung-Yu",
			"Lin, Youn-Long"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  We propose a new convolution neural network called HarDNet-MSEG for polyp\nsegmentation. It achieves SOTA in both accuracy and inference speed on five\npopular datasets. For Kvasir-SEG, HarDNet-MSEG delivers 0.904 mean Dice running\nat 86.7 FPS on a GeForce RTX 2080 Ti GPU. It consists of a backbone and a\ndecoder. The backbone is a low memory traffic CNN called HarDNet68, which has\nbeen successfully applied to various CV tasks including image classification,\nobject detection, multi-object tracking and semantic segmentation, etc. The\ndecoder part is inspired by the Cascaded Partial Decoder, known for fast and\naccurate salient object detection. We have evaluated HarDNet-MSEG using those\nfive popular datasets. The code and all experiment details are available at\nGithub. https://github.com/james128333/HarDNet-MSEG\n",
		"date": [
			"2021-01-18",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07172",
		"pdf_url": "http://arxiv.org/pdf/2101.07172.pdf"
	},
	"1089": {
		"title": "The Broadcast Approach in Communication Networks",
		"creator": [
			"Tajer, Ali",
			"Steiner, Avi",
			"Shamai, Shlomo"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  This paper reviews the theoretical and practical principles of the broadcast\napproach to communication over state-dependent channels and networks in which\nthe transmitters have access to only the probabilistic description of the\ntime-varying states while remaining oblivious to their instantaneous\nrealizations. When the temporal variations are frequent enough, an effective\nlong-term strategy is adapting the transmission strategies to the system's\nergodic behavior. However, when the variations are infrequent, their temporal\naverage can deviate significantly from the channel's ergodic mode, rendering a\nlack of instantaneous performance guarantees. To circumvent a lack of\nshort-term guarantees, the {\\em broadcast approach} provides principles for\ndesigning transmission schemes that benefit from both short- and long-term\nperformance guarantees. This paper provides an overview of how to apply the\nbroadcast approach to various channels and network models under various\noperational constraints.\n",
			"Comment: 149 pages, 37 figures"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07173",
			"doi:10.3390/e23010120"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07173.pdf"
	},
	"1090": {
		"title": "Formal FT-based Cause-Consequence Reliability Analysis using Theorem\n  Proving",
		"creator": [
			"Abdelghany, Mohamed",
			"Tahar, Sofiene"
		],
		"subject": "Computer Science - Formal Languages and Automata Theory",
		"description": [
			"  Cause-consequence Diagram (CCD) is widely used as a deductive safety analysis\ntechnique for decision-making at the critical-system design stage. This\napproach models the causes of subsystem failures in a highly-critical system\nand their potential consequences using Fault Tree (FT) and Event Tree (ET)\nmethods, which are well-known dependability modeling techniques.\nPaper-and-pencil-based approaches and simulation tools, such as the Monte-Carlo\napproach, are commonly used to carry out CCD analysis, but lack the ability to\nrigorously verify essential system reliability properties. In this work, we\npropose to use formal techniques based on theorem proving for the formal\nmodeling and step-analysis of CCDs to overcome the inaccuracies of the\nsimulation-based analysis and the error-proneness of informal reasoning by\nmathematical proofs. In particular, we use the HOL4 theorem prover, which is a\ncomputer-based mathematical reasoning tool. To this end, we developed a\nformalization of CCDs in Higher-Order Logic (HOL), based on the algebraic\napproach, using HOL4. We demonstrate the practical effectiveness of the\nproposed CCD formalization by performing the formal reliability analysis of the\nIEEE 39-bus electrical power network. Also, we formally determine the Forced\nOutage Rate (FOR) of the power generation units and the network reliability\nindex, i.e., System Average Interruption Duration Index (SAIDI). To assess the\naccuracy of our proposed approach, we compare our results with those obtained\nwith MATLAB Monte-Carlo Simulation (MCS) as well as other state-of-the-art\napproaches for subsystem-level reliability analysis.\n",
			"Comment: 41 pages, 17 figures, 8 tables"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07174",
		"pdf_url": "http://arxiv.org/pdf/2101.07174.pdf"
	},
	"1091": {
		"title": "Partial Observability Approach for the Optimal Transparency Problem in\n  Multi-agent Systems",
		"creator": [
			"Arefizadeh, Sadegh",
			"Ozgoli, Sadjaad",
			"Bolouki, Sadegh",
			"Başar, Tamer"
		],
		"subject": [
			"Mathematics - Dynamical Systems",
			"Electrical Engineering and Systems Science - Systems and Control",
			"Mathematics - Optimization and Control"
		],
		"description": [
			"  This paper considers a network of agents, where each agent is assumed to take\nactions optimally with respect to a predefined payoff function involving the\nlatest actions of the agent's neighbors. Neighborhood relationships stem from\npayoff functions rather than actual communication channels between the agents.\nA principal is tasked to optimize the network's performance by controlling the\ninformation available to each agent with regard to other agents' latest\nactions. The information control by the principal is done via a partial\nobservability approach, which comprises a static partitioning of agents into\nblocks and making the mean of agents' latest actions within each block publicly\navailable. While the problem setup is general in terms of the payoff functions\nand the network's performance metric, this paper has a narrower focus to\nilluminate the problem and how it can be addressed in practice. In particular,\nthe performance metric is assumed to be a function of the steady-state behavior\nof the agents. After conducting a comprehensive steady-state analysis of the\nnetwork, an efficient algorithm finding optimal partitions with respect to\nvarious performance metrics is presented and validated via numerical examples.\n",
			"Comment: 14 pages"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07178",
		"pdf_url": "http://arxiv.org/pdf/2101.07178.pdf"
	},
	"1092": {
		"title": "Incorporating Coincidental Water Data into Non-intrusive Load Monitoring",
		"creator": [
			"Keramati, Mohammad-Mehdi",
			"Azizi, Elnaz",
			"Momeni, Hamidreza",
			"Bolouki, Sadegh"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Non-intrusive load monitoring (NILM) as the process of extracting the usage\npattern of appliances from the aggregated power signal is among successful\napproaches aiding residential energy management. In recent years, high volume\ndatasets on power profiles have become available, which has helped make\nclassification methods employed for the NILM purpose more effective and more\naccurate. However, the presence of multi-mode appliances and appliances with\nclose power values have remained influential in worsening the computational\ncomplexity and diminishing the accuracy of these algorithms. To tackle these\nchallenges, we propose an event-based classification process, in the first\nphase of which the $K$-nearest neighbors method, as a fast classification\ntechnique, is employed to extract power signals of appliances with exclusive\nnon-overlapping power values. Then, two deep learning models, which consider\nthe water consumption of some appliances as a novel signature in the network,\nare utilized to distinguish between appliances with overlapping power values.\nIn addition to power disaggregation, the proposed process as well extracts the\nwater consumption profiles of specific appliances. To illustrate the proposed\nprocess and validate its efficiency, seven appliances of the AMPds are\nconsidered, with the numerical classification results showing marked\nimprovement with respect to the existing classification-based NILM techniques.\n",
			"Comment: 13 pages"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07190",
		"pdf_url": "http://arxiv.org/pdf/2101.07190.pdf"
	},
	"1093": {
		"title": "Quantification of Disaggregation Difficulty with Respect to the Number\n  of Meters",
		"creator": [
			"Azizi, Elnaz",
			"Beheshti, Mohammad T H",
			"Bolouki, Sadegh"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  A promising approach toward efficient energy management is non-intrusive load\nmonitoring (NILM), that is to extract the consumption profiles of appliances\nwithin a residence by analyzing the aggregated consumption signal. Among\nefficient NILM methods are event-based algorithms in which events of the\naggregated signal are detected and classified in accordance with the appliances\ncausing them. The large number of appliances and the presence of appliances\nwith close consumption values are known to limit the performance of event-based\nNILM methods. To tackle these challenges, one could enhance the feature space\nwhich in turn results in extra hardware costs, installation complexity, and\nconcerns regarding the consumer's comfort and privacy. This has led to the\nemergence of an alternative approach, namely semi-intrusive load monitoring\n(SILM), where appliances are partitioned into blocks and the consumption of\neach block is monitored via separate power meters.\n  While a greater number of meters can result in more accurate disaggregation,\nit increases the monetary cost of load monitoring, indicating a trade-off that\nrepresents an important gap in this field. In this paper, we take a\ncomprehensive approach to close this gap by establishing a so-called notion of\n\"disaggregation difficulty metric (DDM),\" which quantifies how difficult it is\nto monitor the events of any given group of appliances based on both their\npower values and the consumer's usage behavior. Thus, DDM in essence quantifies\nhow much is expected to be gained in terms of disaggregation accuracy of a\ngeneric event-based algorithm by installing meters on the blocks of any\npartition of the appliances. Experimental results based on the REDD dataset\nillustrate the practicality of the proposed approach in addressing the\naforementioned trade-off.\n",
			"Comment: 13 pages"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07191",
		"pdf_url": "http://arxiv.org/pdf/2101.07191.pdf"
	},
	"1094": {
		"title": "A New Approach for Automatic Segmentation and Evaluation of Pigmentation\n  Lesion by using Active Contour Model and Speeded Up Robust Features",
		"creator": [
			"Mardanisamani, Sara",
			"Karimi, Zahra",
			"Jamshidzadeh, Akram",
			"Yazdi, Mehran",
			"Farshad, Melika",
			"Farshad, Amirmehdi"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  Digital image processing techniques have wide applications in different\nscientific fields including the medicine. By use of image processing\nalgorithms, physicians have been more successful in diagnosis of different\ndiseases and have achieved much better treatment results. In this paper, we\npropose an automatic method for segmenting the skin lesions and extracting\nfeatures that are associated to them. At this aim, a combination of Speeded-Up\nRobust Features (SURF) and Active Contour Model (ACM), is used. In the\nsuggested method, at first region of skin lesion is segmented from the whole\nskin image, and then some features like the mean, variance, RGB and HSV\nparameters are extracted from the segmented region. Comparing the segmentation\nresults, by use of Otsu thresholding, our proposed method, shows the\nsuperiority of our procedure over the Otsu theresholding method. Segmentation\nof the skin lesion by the proposed method and Otsu thresholding compared the\nresults with physician's manual method. The proposed method for skin lesion\nsegmentation, which is a combination of SURF and ACM, gives the best result.\nFor empirical evaluation of our method, we have applied it on twenty different\nskin lesion images. Obtained results confirm the high performance, speed and\naccuracy of our method.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07195",
		"pdf_url": "http://arxiv.org/pdf/2101.07195.pdf"
	},
	"1095": {
		"title": "Generative Dynamics of Supreme Court Citations: Analysis with a New\n  Statistical Network Model",
		"creator": [
			"Schmid, Christian S.",
			"Chen, Ted Hsuan Yun",
			"Desmarais, Bruce A."
		],
		"subject": [
			"Statistics - Applications",
			"Computer Science - Digital Libraries",
			"Physics - Physics and Society"
		],
		"description": [
			"  The significance and influence of US Supreme Court majority opinions derive\nin large part from opinions' roles as precedents for future opinions. A growing\nbody of literature seeks to understand what drives the use of opinions as\nprecedents through the study of Supreme Court case citation patterns. We raise\ntwo limitations of existing work on Supreme Court citations. First, dyadic\ncitations are typically aggregated to the case level before they are analyzed.\nSecond, citations are treated as if they arise independently. We present a\nmethodology for studying citations between Supreme Court opinions at the dyadic\nlevel, as a network, that overcomes these limitations. This methodology -- the\ncitation exponential random graph model, for which we provide user-friendly\nsoftware -- enables researchers to account for the effects of case\ncharacteristics and complex forms of network dependence in citation formation.\nWe then analyze a network that includes all Supreme Court cases decided between\n1950 and 2015. We find evidence for dependence processes, including\nreciprocity, transitivity, and popularity. The dependence effects are as\nsubstantively and statistically significant as the effects of exogenous\ncovariates, indicating that models of Supreme Court citation should incorporate\nboth the effects of case characteristics and the structure of past citations.\n",
			"Comment: 34 pages, 10 figures"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07197",
		"pdf_url": "http://arxiv.org/pdf/2101.07197.pdf"
	},
	"1096": {
		"title": "Tuning the Frequency of Periodic Data Movements over Hybrid Memory\n  Systems",
		"creator": [
			"Doudali, Thaleia Dimitra",
			"Zahka, Daniel",
			"Gavrilovska, Ada"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Operating Systems"
		],
		"description": "  Emerging hybrid memory systems that comprise technologies such as Intel's\nOptane DC Persistent Memory, exhibit disparities in the access speeds and\ncapacity ratios of their heterogeneous memory components. This breaks many\nassumptions and heuristics designed for traditional DRAM-only platforms. High\napplication performance is feasible via dynamic data movement across memory\nunits, which maximizes the capacity use of DRAM while ensuring efficient use of\nthe aggregate system resources. Newly proposed solutions use performance models\nand machine intelligence to optimize which and how much data to move\ndynamically; however, the decision of when to move this data is based on\nempirical selection of time intervals, or left to the applications. Our\nexperimental evaluation shows that failure to properly configure the data\nmovement frequency can lead to 10%-100% slowdown for a given data movement\npolicy; yet, there is no established methodology on how to properly configure\nthis value for a given workload, platform and policy. We propose Cori, a\nsystem-level tuning solution that identifies and extracts the necessary\napplication-level data reuse information, and guides the selection of data\nmovement frequency to deliver gains in application performance and system\nresource efficiency. Experimental evaluation shows that Cori configures data\nmovement frequencies that provide application performance within 3% of the\noptimal one, and that it can achieve this up to 5x more quickly than random or\nbrute-force approaches. System-level validation of Cori on a platform with DRAM\nand Intel's Optane DC PMEM confirms its practicality and tuning efficiency.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07200",
		"pdf_url": "http://arxiv.org/pdf/2101.07200.pdf"
	},
	"1097": {
		"title": "DeepGreen: Deep Learning of Green's Functions for Nonlinear Boundary\n  Value Problems",
		"creator": [
			"Gin, Craig R.",
			"Shea, Daniel E.",
			"Brunton, Steven L.",
			"Kutz, J. Nathan"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"Computer Science - Machine Learning",
			"Physics - Computational Physics"
		],
		"description": "  Boundary value problems (BVPs) play a central role in the mathematical\nanalysis of constrained physical systems subjected to external forces.\nConsequently, BVPs frequently emerge in nearly every engineering discipline and\nspan problem domains including fluid mechanics, electromagnetics, quantum\nmechanics, and elasticity. The fundamental solution, or Green's function, is a\nleading method for solving linear BVPs that enables facile computation of new\nsolutions to systems under any external forcing. However, fundamental Green's\nfunction solutions for nonlinear BVPs are not feasible since linear\nsuperposition no longer holds. In this work, we propose a flexible deep\nlearning approach to solve nonlinear BVPs using a dual-autoencoder\narchitecture. The autoencoders discover an invertible coordinate transform that\nlinearizes the nonlinear BVP and identifies both a linear operator $L$ and\nGreen's function $G$ which can be used to solve new nonlinear BVPs. We find\nthat the method succeeds on a variety of nonlinear systems including nonlinear\nHelmholtz and Sturm--Liouville problems, nonlinear elasticity, and a 2D\nnonlinear Poisson equation. The method merges the strengths of the universal\napproximation capabilities of deep learning with the physics knowledge of\nGreen's functions to yield a flexible tool for identifying fundamental\nsolutions to a variety of nonlinear systems.\n",
		"date": "2020-12-31",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07206",
		"pdf_url": "http://arxiv.org/pdf/2101.07206.pdf"
	},
	"1098": {
		"title": "Learning Visual Representations with Optimum-Path Forest and its\n  Applications to Barrett's Esophagus and Adenocarcinoma Diagnosis",
		"creator": [
			"Souza Jr., Luis A. de",
			"Afonso, Luis C. S.",
			"Ebigbo, Alanna",
			"Probst, Andreas",
			"Messmann, Helmut",
			"Mendel, Robert",
			"Palm, Christoph",
			"Papa, João P."
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  In this work, we introduce the unsupervised Optimum-Path Forest (OPF)\nclassifier for learning visual dictionaries in the context of Barrett's\nesophagus (BE) and automatic adenocarcinoma diagnosis. The proposed approach\nwas validated in two datasets (MICCAI 2015 and Augsburg) using three different\nfeature extractors (SIFT, SURF, and the not yet applied to the BE context\nA-KAZE), as well as five supervised classifiers, including two variants of the\nOPF, Support Vector Machines with Radial Basis Function and Linear kernels, and\na Bayesian classifier. Concerning MICCAI 2015 dataset, the best results were\nobtained using unsupervised OPF for dictionary generation using supervised OPF\nfor classification purposes and using SURF feature extractor with accuracy\nnearly to 78% for distinguishing BE patients from adenocarcinoma ones.\nRegarding the Augsburg dataset, the most accurate results were also obtained\nusing both OPF classifiers but with A-KAZE as the feature extractor with\naccuracy close to 73%. The combination of feature extraction and\nbag-of-visual-words techniques showed results that outperformed others obtained\nrecently in the literature, as well as we highlight new advances in the related\nresearch area. Reinforcing the significance of this work, to the best of our\nknowledge, this is the first one that aimed at addressing computer-aided BE\nidentification using bag-of-visual-words and OPF classifiers, being this\napplication of unsupervised technique in the BE feature calculation the major\ncontribution of this work. It is also proposed a new BE and adenocarcinoma\ndescription using the A-KAZE features, not yet applied in the literature.\n",
		"date": [
			"2021-01-18",
			"2021-01-19"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07209",
			"doi:10.1007/s00521-018-03982-0"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07209.pdf"
	},
	"1099": {
		"title": "Challenges in the application of a mortality prediction model for\n  COVID-19 patients on an Indian cohort",
		"creator": [
			"Makhija, Yukti",
			"Bhatia, Samarth",
			"Singh, Shalendra",
			"Jayaswal, Sneha Kumar",
			"Malik, Prabhat Singh",
			"Gupta, Pallavi",
			"Samaga, Shreyas N.",
			"Johri, Shreya",
			"Venigalla, Sri Krishna",
			"Hota, Rabi Narayan",
			"Bhatia, Surinder Singh",
			"Gupta, Ishaan"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  Many countries are now experiencing the third wave of the COVID-19 pandemic\nstraining the healthcare resources with an acute shortage of hospital beds and\nventilators for the critically ill patients. This situation is especially worse\nin India with the second largest load of COVID-19 cases and a relatively\nresource-scarce medical infrastructure. Therefore, it becomes essential to\ntriage the patients based on the severity of their disease and devote resources\ntowards critically ill patients. Yan et al. 1 have published a very pertinent\nresearch that uses Machine learning (ML) methods to predict the outcome of\nCOVID-19 patients based on their clinical parameters at the day of admission.\nThey used the XGBoost algorithm, a type of ensemble model, to build the\nmortality prediction model. The final classifier is built through the\nsequential addition of multiple weak classifiers. The clinically operable\ndecision rule was obtained from a 'single-tree XGBoost' and used lactic\ndehydrogenase (LDH), lymphocyte and high-sensitivity C-reactive protein\n(hs-CRP) values. This decision tree achieved a 100% survival prediction and 81%\nmortality prediction. However, these models have several technical challenges\nand do not provide an out of the box solution that can be deployed for other\npopulations as has been reported in the \"Matters Arising\" section of Yan et al.\nHere, we show the limitations of this model by deploying it on one of the\nlargest datasets of COVID-19 patients containing detailed clinical parameters\ncollected from India.\n",
			"Comment: 8 pages, 1 figure, 1 table Study designed by: IG, SB, YM, SJ. Data\n  collected and curated by: SKJ, PG, SNS, RNH, SSB, PSM, SKV and SS. Data\n  analysis performed by: SB, YM. Manuscript was written by: IG, SS, SB, YM .\n  All authors read and approved the final manuscript. The first two authors\n  have contributed equally"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07215",
		"pdf_url": "http://arxiv.org/pdf/2101.07215.pdf"
	},
	"1100": {
		"title": "Reservoir Computers Modal Decomposition and Optimization",
		"creator": [
			"Nathe, Chad",
			"Del Frate, Enrico",
			"Carroll, Thomas",
			"Pecora, Louis",
			"Shirin, Afroza",
			"Sorrentino, Francesco"
		],
		"subject": [
			"Condensed Matter - Disordered Systems and Neural Networks",
			"Computer Science - Machine Learning"
		],
		"description": "  The topology of a network associated with a reservoir computer is often taken\nso that the connectivity and the weights are chosen randomly. Optimization is\nhardly considered as the parameter space is typically too large. Here we\ninvestigate this problem for a class of reservoir computers for which we obtain\na decomposition of the reservoir dynamics into modes, which can be computed\nindependently of one another. Each mode depends on an eigenvalue of the network\nadjacency matrix. We then take a parametric approach in which the eigenvalues\nare parameters that can be appropriately designed and optimized. In addition,\nwe introduce the application of a time shift to each individual mode. We show\nthat manipulations of the individual modes, either in terms of the eigenvalues\nor the time shifts, can lead to dramatic reductions in the training error.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07219",
		"pdf_url": "http://arxiv.org/pdf/2101.07219.pdf"
	},
	"1101": {
		"title": "A Tensor-Based Formulation of Hetero-functional Graph Theory",
		"creator": [
			"Farid, Amro M.",
			"Thompson, Dakota",
			"Hegde, Prabhat",
			"Schoonenberg, Wester"
		],
		"subject": "Computer Science - Artificial Intelligence",
		"description": "  Recently, hetero-functional graph theory (HFGT) has developed as a means to\nmathematically model the structure of large flexible engineering systems. In\nthat regard, it intellectually resembles a fusion of network science and\nmodel-based systems engineering. With respect to the former, it relies on\nmultiple graphs as data structures so as to support matrix-based quantitative\nanalysis. In the meantime, HFGT explicitly embodies the heterogeneity of\nconceptual and ontological constructs found in model-based systems engineering\nincluding system form, system function, and system concept. At their\nfoundation, these disparate conceptual constructs suggest multi-dimensional\nrather than two-dimensional relationships. This paper provides the first\ntensor-based treatment of some of the most important parts of hetero-functional\ngraph theory. In particular, it addresses the \"system concept\", the\nhetero-functional adjacency matrix, and the hetero-functional incidence tensor.\nThe tensor-based formulation described in this work makes a stronger tie\nbetween HFGT and its ontological foundations in MBSE. Finally, the tensor-based\nformulation facilitates an understanding of the relationships between HFGT and\nmulti-layer networks.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07220",
		"pdf_url": "http://arxiv.org/pdf/2101.07220.pdf"
	},
	"1102": {
		"title": "Leveraging AI to optimize website structure discovery during Penetration\n  Testing",
		"creator": [
			"Antonelli, Diego",
			"Cascella, Roberta",
			"Perrone, Gaetano",
			"Romano, Simon Pietro",
			"Schiano, Antonio"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": "  Dirbusting is a technique used to brute force directories and file names on\nweb servers while monitoring HTTP responses, in order to enumerate server\ncontents. Such a technique uses lists of common words to discover the hidden\nstructure of the target website. Dirbusting typically relies on response codes\nas discovery conditions to find new pages. It is widely used in web application\npenetration testing, an activity that allows companies to detect websites\nvulnerabilities. Dirbusting techniques are both time and resource consuming and\ninnovative approaches have never been explored in this field. We hence propose\nan advanced technique to optimize the dirbusting process by leveraging\nArtificial Intelligence. More specifically, we use semantic clustering\ntechniques in order to organize wordlist items in different groups according to\ntheir semantic meaning. The created clusters are used in an ad-hoc implemented\nnext-word intelligent strategy. This paper demonstrates that the usage of\nclustering techniques outperforms the commonly used brute force methods.\nPerformance is evaluated by testing eight different web applications. Results\nshow a performance increase that is up to 50% for each of the conducted\nexperiments.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07223",
		"pdf_url": "http://arxiv.org/pdf/2101.07223.pdf"
	},
	"1103": {
		"title": "Device Variability Analysis for Memristive Material Implication",
		"creator": [
			"Laube, Simon Michael",
			"TaheriNejad, Nima"
		],
		"subject": "Computer Science - Emerging Technologies",
		"description": "  Currently, memristor devices suffer from variability between devices and from\ncycle to cycle. In this work, we study the impact of device variations on\nmemristive Material Implication (IMPLY). New constraints for different\nparameters and variables are analytically derived and compared to extensive\nsimulation results, covering single gate and 1T1R crossbar structures. We show\nthat a static analysis based on switching conditions is not sufficient for an\noverall assessment of robustness against device variability. Furthermore, we\noutline parameter ranges within which the IMPLY gate is predicted to produce\ncorrect output values. Our study shows that threshold voltage is the most\ncritical parameter. This work helps scientists and engineers to understand the\npitfalls of designing reliable IMPLY-based calculation units better and design\nthem with more ease. Moreover, these analyses can be used to determine whether\na certain memristor technology is suitable for implementation of IMPLY-based\ncircuits and systems.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07231",
		"pdf_url": "http://arxiv.org/pdf/2101.07231.pdf"
	},
	"1104": {
		"title": "Syntroids: Synthesizing a Game for FPGAs using Temporal Logic\n  Specifications",
		"creator": [
			"Geier, Gideon",
			"Heim, Philippe",
			"Klein, Felix",
			"Finkbeiner, Bernd"
		],
		"subject": [
			"Computer Science - Logic in Computer Science",
			"Computer Science - Hardware Architecture"
		],
		"description": "  We present Syntroids, a case study for the automatic synthesis of hardware\nfrom a temporal logic specification. Syntroids is a space shooter arcade game\nrealized on an FPGA, where the control flow architecture has been completely\nspecified in Temporal Stream Logic (TSL) and implemented using reactive\nsynthesis. TSL is a recently introduced temporal logic that separates control\nand data. This leads to scalable synthesis, because the cost of the synthesis\nprocess is independent of the complexity of the handled data.\n  In this case study, we report on our experience with the TSL-based\ndevelopment of the Syntroids game and on the implementation quality obtained\nwith synthesis in comparison to manual programming. We also discuss solved and\nopen challenges with respect to currently available synthesis tools.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07232",
		"pdf_url": "http://arxiv.org/pdf/2101.07232.pdf"
	},
	"1105": {
		"title": "Transverse Wave: an impartial color-propagation game inspired by Social\n  Influence and Quantum Nim",
		"creator": [
			"Burke, Kyle",
			"Ferland, Matthew",
			"Teng, Shanghua"
		],
		"subject": [
			"Computer Science - Computational Complexity",
			"Mathematics - Combinatorics",
			"91A46",
			"G.2.1",
			"G.2.2",
			"F.1.3"
		],
		"description": [
			"  In this paper, we study a colorful, impartial combinatorial game played on a\ntwo-dimensional grid, Transverse Wave. We are drawn to this game because of its\napparent simplicity, contrasting intractability, and intrinsic connection to\ntwo other combinatorial games, one inspired by social influence and another\ninspired by quantum superpositions.\n  More precisely, we show that Transverse Wave is at the intersection of\nsocial-influence-inspired Friend Circle and superposition-based Demi-Quantum\nNim. Transverse Wave is also connected with Schaefer's logic game Avoid True.\nIn addition to analyzing the mathematical structures and computational\ncomplexity of Transverse Wave, we provide a web-based version of the game,\nplayable at\nhttps://turing.plymouth.edu/~kgb1013/DB/combGames/transverseWave.html.\nFurthermore, we formulate a basic network-influence inspired game, called\nDemographic Influence, which simultaneously generalizes Node-Kyles and\nDemi-Quantum Nim (which in turn contains as special cases Nim, Avoid True, and\nTransverse Wave). These connections illuminate the lattice order, induced by\nspecial-case/generalization relationships over mathematical games, fundamental\nto both the design and comparative analyses of combinatorial games.\n",
			"Comment: 29 Pages"
		],
		"date": [
			"2021-01-18",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07237",
		"pdf_url": "http://arxiv.org/pdf/2101.07237.pdf"
	},
	"1106": {
		"title": "Alignment and stability of embeddings: measurement and inference\n  improvement",
		"creator": [
			"Gürsoy, Furkan",
			"Haddad, Mounir",
			"Bothorel, Cécile"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Social and Information Networks"
		],
		"description": "  Representation learning (RL) methods learn objects' latent embeddings where\ninformation is preserved by distances. Since distances are invariant to certain\nlinear transformations, one may obtain different embeddings while preserving\nthe same information. In dynamic systems, a temporal difference in embeddings\nmay be explained by the stability of the system or by the misalignment of\nembeddings due to arbitrary transformations. In the literature, embedding\nalignment has not been defined formally, explored theoretically, or analyzed\nempirically. Here, we explore the embedding alignment and its parts, provide\nthe first formal definitions, propose novel metrics to measure alignment and\nstability, and show their suitability through synthetic experiments. Real-world\nexperiments show that both static and dynamic RL methods are prone to produce\nmisaligned embeddings and such misalignment worsens the performance of dynamic\nnetwork inference tasks. By ensuring alignment, the prediction accuracy raises\nby up to 90% in static and by 40% in dynamic RL methods.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07251",
		"pdf_url": "http://arxiv.org/pdf/2101.07251.pdf"
	},
	"1107": {
		"title": "Guided parallelized stochastic gradient descent for delay compensation",
		"creator": "Sharma, Anuraganand",
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Neural and Evolutionary Computing"
		],
		"description": [
			"  Stochastic gradient descent (SGD) algorithm and its variations have been\neffectively used to optimize neural network models. However, with the rapid\ngrowth of big data and deep learning, SGD is no longer the most suitable choice\ndue to its natural behavior of sequential optimization of the error function.\nThis has led to the development of parallel SGD algorithms, such as\nasynchronous SGD (ASGD) and synchronous SGD (SSGD) to train deep neural\nnetworks. However, it introduces a high variance due to the delay in parameter\n(weight) update. We address this delay in our proposed algorithm and try to\nminimize its impact. We employed guided SGD (gSGD) that encourages consistent\nexamples to steer the convergence by compensating the unpredictable deviation\ncaused by the delay. Its convergence rate is also similar to A/SSGD, however,\nsome additional (parallel) processing is required to compensate for the delay.\nThe experimental results demonstrate that our proposed approach has been able\nto mitigate the impact of delay for the quality of classification accuracy. The\nguided approach with SSGD clearly outperforms sequential SGD and even achieves\nthe accuracy close to sequential SGD for some benchmark datasets.\n",
			"Comment: This is a preprint version"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07259",
			"Applied Soft Computing (2021)",
			"doi:10.1016/j.asoc.2021.107084"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07259.pdf"
	},
	"1108": {
		"title": "Proceedings of the 18th International Overture Workshop",
		"creator": [
			"Fitzgerald, John",
			"Oda, Tomohiro",
			"Macedo, Hugo Daniel"
		],
		"subject": "Computer Science - Software Engineering",
		"description": "  This volume contains the papers presented at the 18th International Overture\nWorkshop, held online on 7th December 2020. This event was the latest in a\nseries of workshops around the Vienna Development Method (VDM), the open-source\nproject Overture, and related tools and formalisms. VDM is one of the longest\nestablished formal methods for systems development. A lively community of\nresearchers and practitioners has grown up in academia and industry has grown\naround the modelling languages (VDM-SL, VDM++, VDM-RT, CML) and tools\n(VDMTools, Overture, Crescendo, Symphony, the INTO-CPS chain, and ViennaTalk).\nTogether, these provide a platform for work on modelling and analysis\ntechnology that includes static and dynamic analysis, test generation,\nexecution support, and model checking. This workshop provided updates on the\nemerging technology of VDM/Overture, including collaboration infrastructure,\ncollaborative modelling and co-simulation for Cyber-Physical Systems.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07261",
		"pdf_url": "http://arxiv.org/pdf/2101.07261.pdf"
	},
	"1109": {
		"title": "How Long to Estimate Sparse MIMO Channels",
		"creator": [
			"Shabara, Yahia",
			"Koksal, C. Emre",
			"Ekici, Eylem"
		],
		"subject": "Computer Science - Information Theory",
		"description": "  Large MIMO transceivers are integral components of next-generation wireless\nnetworks. However, for such systems to be practical, their channel estimation\nprocess needs to be fast and reliable. Although several solutions for fast\nestimation of sparse channels do exist, there is still a gap in understanding\nthe fundamental limits governing this problem. Specifically, we need to better\nunderstand the lower bound on the number of measurements under which accurate\nchannel estimates can be obtained. This work bridges that knowledge gap by\nderiving a tight asymptotic lower bound on the number of measurements. This not\nonly helps develop a better understanding for the sparse MIMO channel\nestimation problem, but it also provides a benchmark for evaluating current and\nfuture solutions.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07287",
		"pdf_url": "http://arxiv.org/pdf/2101.07287.pdf"
	},
	"1110": {
		"title": "Cross-Layer Network Codes for Content Delivery in Cache-Enabled D2D\n  Networks",
		"creator": [
			"Al-Abiad, Mohammed S.",
			"Hassan, Md. Zoheb",
			"Hossain, Md. Jahangir"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  In this paper, we consider the use of cross-layer network coding (CLNC),\ncaching, and device-to-device (D2D) communications to jointly optimize the\ndelivery of a set of popular contents to a set of user devices (UDs). In the\nconsidered D2D network, a group of near-by UDs cooperate with each other and\nuse NC to combine their cached files, so as the completion time required for\ndelivering all requested contents to all UDs is minimized. Unlike the previous\nwork that considers only one transmitting UD at a time, our work allows\nmultiple UDs to transmit simultaneously given the interference among the active\nlinks is small. Such configuration brings a new trade-off among scheduling UDs\nto transmitting UDs, selecting the coding decisions and the transmission\nrate/power. Therefore, we consider the completion time minimization problem\nthat involves scheduling multiple transmitting UDs, determining their\ntransmission rates/powers and file combinations. The problem is shown to be\nintractable because it involves all future coding decisions. To tackle the\nproblem at each transmission slot, we first design a graph called herein the\nD2D Rate-Aware IDNC graph where its vertices have weights that judiciously\nbalance between the rates/powers of the transmitting UDs and the number of\ntheir scheduled UDs. Then, we propose an innovative and efficient CLNC solution\nthat iteratively selects a set of transmitting UDs only if the interference\ncaused by the transmissions of the newly selected UDs does not significantly\nimpact the overall completion time. Simulation results show that the proposed\nsolution offers significant completion time reduction compared with the\nexisting algorithms.\n",
			"Comment: 12 pages, 5 figures, paper"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07291",
		"pdf_url": "http://arxiv.org/pdf/2101.07291.pdf"
	},
	"1111": {
		"title": "Data Protection Impact Assessment for the Corona App",
		"creator": [
			"Bock, Kirsten",
			"Kühne, Christian R.",
			"Mühlhoff, Rainer",
			"Ost, Měto R.",
			"Pohle, Jörg",
			"Rehak, Rainer"
		],
		"subject": [
			"Computer Science - Computers and Society",
			"Computer Science - Cryptography and Security",
			"Computer Science - Social and Information Networks",
			"68P27 (Primary), 68-00 (Secondary)",
			"K.4.1",
			"K.4.2",
			"K.4.3",
			"H.4.m",
			"H.1.m",
			"C.5.m"
		],
		"description": [
			"  Since SARS-CoV-2 started spreading in Europe in early 2020, there has been a\nstrong call for technical solutions to combat or contain the pandemic, with\ncontact tracing apps at the heart of the debates. The EU's General Daten\nProtection Regulation (GDPR) requires controllers to carry out a data\nprotection impact assessment (DPIA) where their data processing is likely to\nresult in a high risk to the rights and freedoms (Art. 35 GDPR). A DPIA is a\nstructured risk analysis that identifies and evaluates possible consequences of\ndata processing relevant to fundamental rights and describes the measures\nenvisaged to address these risks or expresses the inability to do so. Based on\nthe Standard Data Protection Model (SDM), we present a scientific DPIA which\nthoroughly examines three published contact tracing app designs that are\nconsidered to be the most \"privacy-friendly\": PEPP-PT, DP-3T and a concept\nsummarized by Chaos Computer Club member Linus Neumann, all of which process\npersonal health data. The DPIA starts with an analysis of the processing\ncontext and some expected use cases. Then, the processing activities are\ndescribed by defining a realistic processing purpose. This is followed by the\nlegal assessment and threshold analysis. Finally, we analyse the weak points,\nthe risks and determine appropriate protective measures. We show that even\ndecentralized implementations involve numerous serious weaknesses and risks.\nLegally, consent is unfit as legal ground hence data must be processed based on\na law. We also found that measures to realize the rights of data subjects and\naffected people are not sufficient. Last but not least, we show that\nanonymization must be understood as a continuous process, which aims at\nseparating the personal reference and is based on a mix of legal,\norganizational and technical measures. All currently available proposals lack\nsuch an explicit separation process.\n",
			"Comment: 97 pages, German version here: https://www.fiff.de/dsfa-corona"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07292",
		"pdf_url": "http://arxiv.org/pdf/2101.07292.pdf"
	},
	"1112": {
		"title": "Diagnostic Captioning: A Survey",
		"creator": [
			"Pavlopoulos, John",
			"Kougia, Vasiliki",
			"Androutsopoulos, Ion",
			"Papamichail, Dimitris"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Diagnostic Captioning (DC) concerns the automatic generation of a diagnostic\ntext from a set of medical images of a patient collected during an examination.\nDC can assist inexperienced physicians, reducing clinical errors. It can also\nhelp experienced physicians produce diagnostic reports faster. Following the\nadvances of deep learning, especially in generic image captioning, DC has\nrecently attracted more attention, leading to several systems and datasets.\nThis article is an extensive overview of DC. It presents relevant datasets,\nevaluation measures, and up to date systems. It also highlights shortcomings\nthat hinder DC's progress and proposes future directions.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07299",
		"pdf_url": "http://arxiv.org/pdf/2101.07299.pdf"
	},
	"1113": {
		"title": "Buying Data Over Time: Approximately Optimal Strategies for Dynamic\n  Data-Driven Decisions",
		"creator": [
			"Immorlica, Nicole",
			"Kash, Ian",
			"Lucier, Brendan"
		],
		"subject": "Computer Science - Computer Science and Game Theory",
		"description": "  We consider a model where an agent has a repeated decision to make and wishes\nto maximize their total payoff. Payoffs are influenced by an action taken by\nthe agent, but also an unknown state of the world that evolves over time.\nBefore choosing an action each round, the agent can purchase noisy samples\nabout the state of the world. The agent has a budget to spend on these samples,\nand has flexibility in deciding how to spread that budget across rounds. We\ninvestigate the problem of choosing a sampling algorithm that optimizes total\nexpected payoff. For example: is it better to buy samples steadily over time,\nor to buy samples in batches? We solve for the optimal policy, and show that it\nis a natural instantiation of the latter. Under a more general model that\nincludes per-round fixed costs, we prove that a variation on this batching\npolicy is a 2-approximation.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07304",
		"pdf_url": "http://arxiv.org/pdf/2101.07304.pdf"
	},
	"1114": {
		"title": "Component Importance and Interdependence Analysis for Transmission,\n  Distribution and Communication Systems",
		"creator": [
			"Fu, Tao",
			"Wang, Dexin",
			"Fan, Xiaoyuan",
			"Huang, Qiuhua"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  For critical infrastructure restoration planning, the real-time scheduling\nand coordination of system restoration efforts, the key in decision-making is\nto prioritize those critical components that are out of service during the\nrestoration. For this purpose, there is a need for component importance\nanalysis. While it has been investigated extensively for individual systems,\ncomponent importance considering interdependence among transmission,\ndistribution and communication (T&D&C) systems has not been systematically\nanalyzed and widely adopted. In this study, we propose a component importance\nassessment method in the context of interdependence between T&D&C networks.\nAnalytic methods for multilayer networks and a set of metrics have been applied\nfor assessing the component importance and interdependence between T&D&C\nnetworks based on their physical characteristics. The proposed methodology is\nfurther validated with integrated synthetic Illinois regional transmission,\ndistribution, and communication (T&D&C) systems, the results reveal the unique\ncharacteristics of component/node importance, which may be strongly affected by\nthe network topology and cross-domain node mapping.\n",
			"Comment: 11 pages"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07306",
		"pdf_url": "http://arxiv.org/pdf/2101.07306.pdf"
	},
	"1115": {
		"title": "Knowledge Distillation Methods for Efficient Unsupervised Adaptation\n  Across Multiple Domains",
		"creator": [
			"Nguyen-Meidine, Le Thanh",
			"Belal, Atif",
			"Kiran, Madhu",
			"Dolz, Jose",
			"Blais-Morin, Louis-Antoine",
			"Granger, Eric"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Beyond the complexity of CNNs that require training on large annotated\ndatasets, the domain shift between design and operational data has limited the\nadoption of CNNs in many real-world applications. For instance, in person\nre-identification, videos are captured over a distributed set of cameras with\nnon-overlapping viewpoints. The shift between the source (e.g. lab setting) and\ntarget (e.g. cameras) domains may lead to a significant decline in recognition\naccuracy. Additionally, state-of-the-art CNNs may not be suitable for such\nreal-time applications given their computational requirements. Although several\ntechniques have recently been proposed to address domain shift problems through\nunsupervised domain adaptation (UDA), or to accelerate/compress CNNs through\nknowledge distillation (KD), we seek to simultaneously adapt and compress CNNs\nto generalize well across multiple target domains. In this paper, we propose a\nprogressive KD approach for unsupervised single-target DA (STDA) and\nmulti-target DA (MTDA) of CNNs. Our method for KD-STDA adapts a CNN to a single\ntarget domain by distilling from a larger teacher CNN, trained on both target\nand source domain data in order to maintain its consistency with a common\nrepresentation. Our proposed approach is compared against state-of-the-art\nmethods for compression and STDA of CNNs on the Office31 and ImageClef-DA image\nclassification datasets. It is also compared against state-of-the-art methods\nfor MTDA on Digits, Office31, and OfficeHome. In both settings -- KD-STDA and\nKD-MTDA -- results indicate that our approach can achieve the highest level of\naccuracy across target domains, while requiring a comparable or lower CNN\ncomplexity.\n",
			"Comment: This is the extended journal version of arXiv:2005.07839"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07308",
			"doi:10.1016/j.imavis.2021.104096"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07308.pdf"
	},
	"1116": {
		"title": "Coverage Evaluation for 5G Reduced Capability New Radio (NR-RedCap)",
		"creator": [
			"Moloudi, Saeedeh",
			"Mozaffari, Mohammad",
			"Veedu, Sandeep Narayanan Kadan",
			"Kittichokechai, Kittipong",
			"Wang, Y. -P. Eric",
			"Bergman, Johan",
			"Höglund, Andreas"
		],
		"subject": "Computer Science - Information Theory",
		"description": "  The fifth generation (5G) wireless technology is primarily designed to\naddress a wide range of use cases categorized into the enhanced mobile\nbroadband (eMBB), ultra-reliable and low latency communication (URLLC), and\nmassive machine-type communication (mMTC). Nevertheless, there are a few other\nuse cases which are in-between these main use cases such as industrial wireless\nsensor networks, video surveillance, or wearables. In order to efficiently\nserve such use cases, in Release 17, the 3rd generation partnership project\n(3GPP) introduced the reduced capability NR devices (NR-RedCap) with lower cost\nand complexity, smaller form factor and longer battery life compared to regular\nNR devices. However, one key potential consequence of device cost and\ncomplexity reduction is the coverage loss. In this paper, we provide a\ncomprehensive evaluation of NR RedCap coverage for different physical channels\nand initial access messages to identify the channels/messages that are\npotentially coverage limiting for RedCap UEs. We perform the coverage\nevaluations for RedCap UEs operating in three different scenarios, namely\nRural, Urban and Indoor with carrier frequencies 700 MHz, 2.6 GHz and 28 GHz,\nrespectively. Our results confirm that for all the considered scenarios, the\namounts of required coverage recovery for RedCap channels are either less than\n1 dB or can be compensated by considering smaller data rate targets for RedCap\nuse cases.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07310",
		"pdf_url": "http://arxiv.org/pdf/2101.07310.pdf"
	},
	"1117": {
		"title": "Classification of Pedagogical content using conventional machine\n  learning and deep learning model",
		"creator": [
			"Apuk, Vedat",
			"Nuçi, Krenare Pireva"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Information Retrieval",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  The advent of the Internet and a large number of digital technologies has\nbrought with it many different challenges. A large amount of data is found on\nthe web, which in most cases is unstructured and unorganized, and this\ncontributes to the fact that the use and manipulation of this data is quite a\ndifficult process. Due to this fact, the usage of different machine and deep\nlearning techniques for Text Classification has gained its importance, which\nimproved this discipline and made it more interesting for scientists and\nresearchers for further study. This paper aims to classify the pedagogical\ncontent using two different models, the K-Nearest Neighbor (KNN) from the\nconventional models and the Long short-term memory (LSTM) recurrent neural\nnetwork from the deep learning models. The result indicates that the accuracy\nof classifying the pedagogical content reaches 92.52 % using KNN model and\n87.71 % using LSTM model.\n",
			"Comment: 11 pages"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07321",
		"pdf_url": "http://arxiv.org/pdf/2101.07321.pdf"
	},
	"1118": {
		"title": "OpenUVR: an Open-Source System Framework for Untethered Virtual Reality\n  Applications",
		"creator": [
			"Rohloff, Alec",
			"Allen, Zackary",
			"Lin, Kung-Min",
			"Okrend, Joshua",
			"Nie, Chengyi",
			"Liu, Yu-Chia",
			"Tseng, Hung-Wei"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Operating Systems"
		],
		"description": "  Advancements in heterogeneous computing technologies enable the significant\npotential of virtual reality (VR) applications. To offer the best user\nexperience (UX), a system should adopt an untethered, wireless-network-based\narchitecture to transfer VR content between the user and the content generator.\nHowever, modern wireless network technologies make implementing such an\narchitecture challenging, as VR applications require superior video quality --\nwith high resolution, high frame rates, and very low latency.\n  This paper presents OpenUVR, an open-source framework that uses commodity\nhardware components to satisfy the demands of interactive, real-time VR\napplications. OpenUVR significantly improves UX through a redesign of the\nsystem stack and addresses the most time-sensitive issues associated with\nredundant memory copying in modern computing systems. OpenUVR presents a\ncross-layered VR datapath to avoid redundant data operations and computation\namong system components, OpenUVR customizes the network stack to eliminate\nunnecessary memory operations incurred by mismatching data formats in each\nlayer, and OpenUVR uses feedback from mobile devices to remove memory buffers.\n  Together, these modifications allow OpenUVR to reduce VR application delays\nto 14.32 ms, meeting the 20 ms minimum latency in avoiding motion sickness. As\nan open-source system that is fully compatible with commodity hardware, OpenUVR\noffers the research community an opportunity to develop, investigate, and\noptimize applications for untethered, high-performance VR architectures.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07327",
		"pdf_url": "http://arxiv.org/pdf/2101.07327.pdf"
	},
	"1119": {
		"title": "MIMOSA: Reducing Malware Analysis Overhead with Coverings",
		"creator": [
			"Ahmadi, Mohsen",
			"Leach, Kevin",
			"Dougherty, Ryan",
			"Forrest, Stephanie",
			"Weimer, Westley"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": "  There is a growing body of malware samples that evade automated analysis and\ndetection tools. Malware may measure fingerprints (\"artifacts\") of the\nunderlying analysis tool or environment and change their behavior when\nartifacts are detected. While analysis tools can mitigate artifacts to reduce\nexposure, such concealment is expensive. However, not every sample checks for\nevery type of artifact-analysis efficiency can be improved by mitigating only\nthose artifacts most likely to be used by a sample. Using that insight, we\npropose MIMOSA, a system that identifies a small set of \"covering\" tool\nconfigurations that collectively defeat most malware samples with increased\nefficiency. MIMOSA identifies a set of tool configurations that maximize\nanalysis throughput and detection accuracy while minimizing manual effort,\nenabling scalable automation to analyze stealthy malware. We evaluate our\napproach against a benchmark of 1535 labeled stealthy malware samples. Our\napproach increases analysis throughput over state of the art on over 95% of\nthese samples. We also investigate cost-benefit tradeoffs between the fraction\nof successfully-analyzed samples and computing resources required. MIMOSA\nprovides a practical, tunable method for efficiently deploying analysis\nresources.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07328",
		"pdf_url": "http://arxiv.org/pdf/2101.07328.pdf"
	},
	"1120": {
		"title": "Dissonance Between Human and Machine Understanding",
		"creator": [
			"Zhang, Zijian",
			"Singh, Jaspreet",
			"Gadiraju, Ujwal",
			"Anand, Avishek"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"I.2.10"
		],
		"description": [
			"  Complex machine learning models are deployed in several critical domains\nincluding healthcare and autonomous vehicles nowadays, albeit as functional\nblack boxes. Consequently, there has been a recent surge in interpreting\ndecisions of such complex models in order to explain their actions to humans.\nModels that correspond to human interpretation of a task are more desirable in\ncertain contexts and can help attribute liability, build trust, expose biases\nand in turn build better models. It is, therefore, crucial to understand how\nand which models conform to human understanding of tasks. In this paper, we\npresent a large-scale crowdsourcing study that reveals and quantifies the\ndissonance between human and machine understanding, through the lens of an\nimage classification task. In particular, we seek to answer the following\nquestions: Which (well-performing) complex ML models are closer to humans in\ntheir use of features to make accurate predictions? How does task difficulty\naffect the feature selection capability of machines in comparison to humans?\nAre humans consistently better at selecting features that make image\nrecognition more accurate? Our findings have important implications on\nhuman-machine collaboration, considering that a long term goal in the field of\nartificial intelligence is to make machines capable of learning and reasoning\nlike humans.\n",
			"Comment: 23 pages, 5 figures"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07337",
			"[J]. Proceedings of the ACM on Human-Computer Interaction, 2019,\n  3(CSCW): 1-23",
			"doi:10.1145/3359158"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07337.pdf"
	},
	"1121": {
		"title": "MONAH: Multi-Modal Narratives for Humans to analyze conversations",
		"creator": [
			"Kim, Joshua Y.",
			"Kim, Greyson Y.",
			"Liu, Chunfeng",
			"Calvo, Rafael A.",
			"Taylor, Silas C. R.",
			"Yacef, Kalina"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"I.7.2"
		],
		"description": [
			"  In conversational analyses, humans manually weave multimodal information into\nthe transcripts, which is significantly time-consuming. We introduce a system\nthat automatically expands the verbatim transcripts of video-recorded\nconversations using multimodal data streams. This system uses a set of\npreprocessing rules to weave multimodal annotations into the verbatim\ntranscripts and promote interpretability. Our feature engineering contributions\nare two-fold: firstly, we identify the range of multimodal features relevant to\ndetect rapport-building; secondly, we expand the range of multimodal\nannotations and show that the expansion leads to statistically significant\nimprovements in detecting rapport-building.\n",
			"Comment: 14 pages"
		],
		"date": [
			"2021-01-18",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07339",
		"pdf_url": "http://arxiv.org/pdf/2101.07339.pdf"
	},
	"1122": {
		"title": "Automatic punctuation restoration with BERT models",
		"creator": [
			"Nagy, Attila",
			"Bial, Bence",
			"Ács, Judit"
		],
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  We present an approach for automatic punctuation restoration with BERT models\nfor English and Hungarian. For English, we conduct our experiments on Ted\nTalks, a commonly used benchmark for punctuation restoration, while for\nHungarian we evaluate our models on the Szeged Treebank dataset. Our best\nmodels achieve a macro-averaged $F_1$-score of 79.8 in English and 82.2 in\nHungarian. Our code is publicly available.\n",
			"Comment: 11 pages, 6 figures, source code at\n  https://github.com/attilanagy234/neural-punctuator"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07343",
		"pdf_url": "http://arxiv.org/pdf/2101.07343.pdf"
	},
	"1123": {
		"title": "Accelerating Deep Learning Inference via Learned Caches",
		"creator": [
			"Balasubramanian, Arjun",
			"Kumar, Adarsh",
			"Liu, Yuhan",
			"Cao, Han",
			"Venkataraman, Shivaram",
			"Akella, Aditya"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Performance"
		],
		"description": "  Deep Neural Networks (DNNs) are witnessing increased adoption in multiple\ndomains owing to their high accuracy in solving real-world problems. However,\nthis high accuracy has been achieved by building deeper networks, posing a\nfundamental challenge to the low latency inference desired by user-facing\napplications. Current low latency solutions trade-off on accuracy or fail to\nexploit the inherent temporal locality in prediction serving workloads.\n  We observe that caching hidden layer outputs of the DNN can introduce a form\nof late-binding where inference requests only consume the amount of computation\nneeded. This enables a mechanism for achieving low latencies, coupled with an\nability to exploit temporal locality. However, traditional caching approaches\nincur high memory overheads and lookup latencies, leading us to design learned\ncaches - caches that consist of simple ML models that are continuously updated.\nWe present the design of GATI, an end-to-end prediction serving system that\nincorporates learned caches for low-latency DNN inference. Results show that\nGATI can reduce inference latency by up to 7.69X on realistic workloads.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07344",
		"pdf_url": "http://arxiv.org/pdf/2101.07344.pdf"
	},
	"1124": {
		"title": "Object Detection and Pose Estimation from RGB and Depth Data for\n  Real-time, Adaptive Robotic Grasping",
		"creator": [
			"Paul, S. K.",
			"Chowdhury, M. T.",
			"Nicolescu, M.",
			"Nicolescu, M."
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Computer Vision and Pattern Recognition",
			"I.4.8",
			"I.4.9",
			"I.2.9"
		],
		"description": "  In recent times, object detection and pose estimation have gained significant\nattention in the context of robotic vision applications. Both the\nidentification of objects of interest as well as the estimation of their pose\nremain important capabilities in order for robots to provide effective\nassistance for numerous robotic applications ranging from household tasks to\nindustrial manipulation. This problem is particularly challenging because of\nthe heterogeneity of objects having different and potentially complex shapes,\nand the difficulties arising due to background clutter and partial occlusions\nbetween objects. As the main contribution of this work, we propose a system\nthat performs real-time object detection and pose estimation, for the purpose\nof dynamic robot grasping. The robot has been pre-trained to perform a small\nset of canonical grasps from a few fixed poses for each object. When presented\nwith an unknown object in an arbitrary pose, the proposed approach allows the\nrobot to detect the object identity and its actual pose, and then adapt a\ncanonical grasp in order to be used with the new pose. For training, the system\ndefines a canonical grasp by capturing the relative pose of an object with\nrespect to the gripper attached to the robot's wrist. During testing, once a\nnew pose is detected, a canonical grasp for the object is identified and then\ndynamically adapted by adjusting the robot arm's joint angles, so that the\ngripper can grasp the object in its new pose. We conducted experiments using a\nhumanoid PR2 robot and showed that the proposed framework can detect\nwell-textured objects, and provide accurate pose estimation in the presence of\ntolerable amounts of out-of-plane rotation. The performance is also illustrated\nby the robot successfully grasping objects from a wide range of arbitrary\nposes.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07347",
		"pdf_url": "http://arxiv.org/pdf/2101.07347.pdf"
	},
	"1125": {
		"title": "Consistency of random-walk based network embedding algorithms",
		"creator": [
			"Zhang, Yichi",
			"Tang, Minh"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning",
			"Computer Science - Social and Information Networks"
		],
		"description": "  Random-walk based network embedding algorithms like node2vec and DeepWalk are\nwidely used to obtain Euclidean representation of the nodes in a network prior\nto performing down-stream network inference tasks. Nevertheless, despite their\nimpressive empirical performance, there is a lack of theoretical results\nexplaining their behavior. In this paper we studied the node2vec and DeepWalk\nalgorithms through the perspective of matrix factorization. We analyze these\nalgorithms in the setting of community detection for stochastic blockmodel\ngraphs; in particular we established large-sample error bounds and prove\nconsistent community recovery of node2vec/DeepWalk embedding followed by\nk-means clustering. Our theoretical results indicate a subtle interplay between\nthe sparsity of the observed networks, the window sizes of the random walks,\nand the convergence rates of the node2vec/DeepWalk embedding toward the\nembedding of the true but unknown edge probabilities matrix. More specifically,\nas the network becomes sparser, our results suggest using larger window sizes,\nor equivalently, taking longer random walks, in order to attain better\nconvergence rate for the resulting embeddings. The paper includes numerical\nexperiments corroborating these observations.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07354",
		"pdf_url": "http://arxiv.org/pdf/2101.07354.pdf"
	},
	"1126": {
		"title": "Dynamic Longest Increasing Subsequence and the Erd\\\"{o}s-Szekeres\n  Partitioning Problem",
		"creator": [
			"Mitzenmacher, Michael",
			"Seddighin, Saeed"
		],
		"subject": "Computer Science - Data Structures and Algorithms",
		"description": "  In this paper, we provide new approximation algorithms for dynamic variations\nof the longest increasing subsequence (\\textsf{LIS}) problem, and the\ncomplementary distance to monotonicity (\\textsf{DTM}) problem. In this setting,\noperations of the following form arrive sequentially: (i) add an element, (ii)\nremove an element, or (iii) substitute an element for another. At every point\nin time, the algorithm has an approximation to the longest increasing\nsubsequence (or distance to monotonicity). We present a\n$(1+\\epsilon)$-approximation algorithm for \\textsf{DTM} with polylogarithmic\nworst-case update time and a constant factor approximation algorithm for\n\\textsf{LIS} with worst-case update time $\\tilde O(n^\\epsilon)$ for any\nconstant $\\epsilon > 0$.% $n$ in the runtime denotes the size of the array at\nthe time the operation arrives.\n  Our dynamic algorithm for \\textsf{LIS} leads to an almost optimal algorithm\nfor the Erd\\\"{o}s-Szekeres partitioning problem. Erd\\\"{o}s-Szekeres\npartitioning problem was introduced by Erd\\\"{o}s and Szekeres in 1935 and was\nknown to be solvable in time $O(n^{1.5}\\log n)$. Subsequent work improve the\nruntime to $O(n^{1.5})$ only in 1998. Our dynamic \\textsf{LIS} algorithm leads\nto a solution for Erd\\\"{o}s-Szekeres partitioning problem with runtime $\\tilde\nO_{\\epsilon}(n^{1+\\epsilon})$ for any constant $\\epsilon > 0$.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07360",
		"pdf_url": "http://arxiv.org/pdf/2101.07360.pdf"
	},
	"1127": {
		"title": "Training Learned Optimizers with Randomly Initialized Learned Optimizers",
		"creator": [
			"Metz, Luke",
			"Freeman, C. Daniel",
			"Maheswaranathan, Niru",
			"Sohl-Dickstein, Jascha"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Neural and Evolutionary Computing"
		],
		"description": "  Learned optimizers are increasingly effective, with performance exceeding\nthat of hand designed optimizers such as Adam~\\citep{kingma2014adam} on\nspecific tasks \\citep{metz2019understanding}. Despite the potential gains\navailable, in current work the meta-training (or `outer-training') of the\nlearned optimizer is performed by a hand-designed optimizer, or by an optimizer\ntrained by a hand-designed optimizer \\citep{metz2020tasks}. We show that a\npopulation of randomly initialized learned optimizers can be used to train\nthemselves from scratch in an online fashion, without resorting to a hand\ndesigned optimizer in any part of the process. A form of population based\ntraining is used to orchestrate this self-training. Although the randomly\ninitialized optimizers initially make slow progress, as they improve they\nexperience a positive feedback loop, and become rapidly more effective at\ntraining themselves. We believe feedback loops of this type, where an optimizer\nimproves itself, will be important and powerful in the future of machine\nlearning. These methods not only provide a path towards increased performance,\nbut more importantly relieve research and engineering effort.\n",
		"date": "2021-01-14",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07367",
		"pdf_url": "http://arxiv.org/pdf/2101.07367.pdf"
	},
	"1128": {
		"title": "Text line extraction using fully convolutional network and energy\n  minimization",
		"creator": [
			"Barakat, Berat Kurar",
			"Droby, Ahmad",
			"Alaasam, Reem",
			"Madi, Boraq",
			"Rabaev, Irina",
			"El-Sana, Jihad"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Text lines are important parts of handwritten document images and easier to\nanalyze by further applications. Despite recent progress in text line\ndetection, text line extraction from a handwritten document remains an unsolved\ntask. This paper proposes to use a fully convolutional network for text line\ndetection and energy minimization for text line extraction. Detected text lines\nare represented by blob lines that strike through the text lines. These blob\nlines assist an energy function for text line extraction. The detection stage\ncan locate arbitrarily oriented text lines. Furthermore, the extraction stage\nis capable of finding out the pixels of text lines with various heights and\ninterline proximity independent of their orientations. Besides, it can finely\nsplit the touching and overlapping text lines without an orientation\nassumption. We evaluate the proposed method on VML-AHTE, VML-MOC, and\nDiva-HisDB datasets. The VML-AHTE dataset contains overlapping, touching and\nclose text lines with rich diacritics. The VML-MOC dataset is very challenging\nby its multiply oriented and skewed text lines. The Diva-HisDB dataset exhibits\ndistinct text line heights and touching text lines. The results demonstrate the\neffectiveness of the method despite various types of challenges, yet using the\nsame parameters in all the experiments.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07370",
		"pdf_url": "http://arxiv.org/pdf/2101.07370.pdf"
	},
	"1129": {
		"title": "Centrality with Diversity",
		"creator": [
			"Lyu, Liang",
			"Fain, Brandon",
			"Munagala, Kamesh",
			"Wang, Kangning"
		],
		"subject": "Computer Science - Social and Information Networks",
		"description": [
			"  Graph centrality measures use the structure of a network to quantify central\nor \"important\" nodes, with applications in web search, social media analysis,\nand graphical data mining generally. Traditional centrality measures such as\nthe well known PageRank interpret a directed edge as a vote in favor of the\nimportance of the linked node. We study the case where nodes may belong to\ndiverse communities or interests and investigate centrality measures that can\nidentify nodes that are simultaneously important to many such diverse\ncommunities. We propose a family of diverse centrality measures formed as fixed\npoint solutions to a generalized nonlinear eigenvalue problem. Our measure can\nbe efficiently computed on large graphs by iterated best response and we study\nits normative properties on both random graph models and real-world data. We\nfind that we are consistently and efficiently able to identify the most\nimportant diverse nodes of a graph, that is, those that are simultaneously\ncentral to multiple communities.\n",
			"Comment: Accepted by the 14th ACM International Conference on Web Search and\n  Data Mining (WSDM 2021)"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07371",
			"doi:10.1145/3437963.3441789"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07371.pdf"
	},
	"1130": {
		"title": "Panel: Humans and Technology for Inclusive Privacy and Security",
		"creator": [
			"Das, Sanchari",
			"Gutzwiller, Robert S.",
			"Roscoe, Rod D.",
			"Rajivan, Prashanth",
			"Wang, Yang",
			"Camp, L. Jean",
			"Hoyle, Roberto"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Computers and Society"
		],
		"description": "  Computer security and user privacy are critical issues and concerns in the\ndigital era due to both increasing users and threats to their data. Separate\nissues arise between generic cybersecurity guidance (i.e., protect all user\ndata from malicious threats) and the individualistic approach of privacy (i.e.,\nspecific to users and dependent on user needs and risk perceptions). Research\nhas shown that several security- and privacy-focused vulnerabilities are\ntechnological (e.g., software bugs (Streiff, Kenny, Das, Leeth, & Camp, 2018),\ninsecure authentication (Das, Wang, Tingle, & Camp, 2019)), or behavioral\n(e.g., sharing passwords (Das, Dingman, & Camp, 2018); and compliance (Das,\nDev, & Srinivasan, 2018) (Dev, Das, Rashidi, & Camp, 2019)). This panel\nproposal addresses a third category of sociotechnical vulnerabilities that can\nand sometimes do arise from non-inclusive design of security and privacy. In\nthis panel, we will address users' needs and desires for privacy. The panel\nwill engage in in-depth discussions about value-sensitive design while focusing\non potentially vulnerable populations, such as older adults, teens, persons\nwith disabilities, and others who are not typically emphasized in general\nsecurity and privacy concerns. Human factors have a stake in and ability to\nfacilitate improvements in these areas.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07377",
		"pdf_url": "http://arxiv.org/pdf/2101.07377.pdf"
	},
	"1131": {
		"title": "A Comparison of Question Rewriting Methods for Conversational Passage\n  Retrieval",
		"creator": [
			"Vakulenko, Svitlana",
			"Voskarides, Nikos",
			"Tu, Zhucheng",
			"Longpre, Shayne"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Computation and Language"
		],
		"description": [
			"  Conversational passage retrieval relies on question rewriting to modify the\noriginal question so that it no longer depends on the conversation history.\nSeveral methods for question rewriting have recently been proposed, but they\nwere compared under different retrieval pipelines. We bridge this gap by\nthoroughly evaluating those question rewriting methods on the TREC CAsT 2019\nand 2020 datasets under the same retrieval pipeline. We analyze the effect of\ndifferent types of question rewriting methods on retrieval performance and show\nthat by combining question rewriting methods of different types we can achieve\nstate-of-the-art performance on both datasets.\n",
			"Comment: ECIR 2021 short paper"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07382",
		"pdf_url": "http://arxiv.org/pdf/2101.07382.pdf"
	},
	"1132": {
		"title": "Work Online, Welfare Calls, and Wine Night: Effects of the COVID-19\n  Pandemic on Individuals' Technology Use",
		"creator": [
			"Tomlinson, Bill",
			"Black, Rebecca W."
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Computers and Society"
		],
		"description": [
			"  The COVID-19 pandemic has changed the ways many people use computational\nsystems. We conducted an empirical study, using qualitative and quantitative\nanalyses of free-response surveys completed by 62 US residents, to explore how\nCOVID-19 affected their computer use across work, education, home life, and\nsocial life. Nearly all participants experienced an increase in computer usage\nfor themselves or a family member in one or more of the four domains. The\nincreases involved both increasing frequency of existing uses as well as the\nadoption of new types of use. Changes in usage impacted many aspects of\npeople's lives, including relationships, affective experiences, and life\ntrajectories. Understanding these changes is important to the future of HCI, as\nthe field adapts to COVID-19 and potential future pandemics.\n",
			"Comment: 20 pages, 1 figure"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07388",
		"pdf_url": "http://arxiv.org/pdf/2101.07388.pdf"
	},
	"1133": {
		"title": "IRS-Empowered Wireless Communications: State-of-the-Art, Key Techniques,\n  and Open Issues",
		"creator": [
			"Zeng, Ming",
			"Bedeer, Ebrahim",
			"Li, Xingwang",
			"Pham, Quoc-Viet",
			"Dobre, Octavia A.",
			"Fortier, Paul",
			"Rusch, Leslie A."
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  In this article, we overview intelligent reflecting surface (IRS)-empowered\nwireless communication systems. We first present the fundamentals of\nIRS-assisted wireless transmission. On this basis, we explore the integration\nof IRS with various advanced transmission technologies, such as millimeter\nwave, non-orthogonal multiple access, and physical layer security. Following\nthis, we discuss the effects of hardware impairments and imperfect\nchannel-state-information on the IRS system performance. Finally, we highlight\nseveral open issues to be addressed.\n",
			"Comment: submitted to IEEE Magazines, Intelligent reflecting surface (IRS),\n  millimeter wave, non-orthogonal multiple access, physical layer security,\n  hardware impairments"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07394",
		"pdf_url": "http://arxiv.org/pdf/2101.07394.pdf"
	},
	"1134": {
		"title": "ArtEmis: Affective Language for Visual Art",
		"creator": [
			"Achlioptas, Panos",
			"Ovsjanikov, Maks",
			"Haydarov, Kilichbek",
			"Elhoseiny, Mohamed",
			"Guibas, Leonidas"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Computation and Language"
		],
		"description": [
			"  We present a novel large-scale dataset and accompanying machine learning\nmodels aimed at providing a detailed understanding of the interplay between\nvisual content, its emotional effect, and explanations for the latter in\nlanguage. In contrast to most existing annotation datasets in computer vision,\nwe focus on the affective experience triggered by visual artworks and ask the\nannotators to indicate the dominant emotion they feel for a given image and,\ncrucially, to also provide a grounded verbal explanation for their emotion\nchoice. As we demonstrate below, this leads to a rich set of signals for both\nthe objective content and the affective impact of an image, creating\nassociations with abstract concepts (e.g., \"freedom\" or \"love\"), or references\nthat go beyond what is directly visible, including visual similes and\nmetaphors, or subjective references to personal experiences. We focus on visual\nart (e.g., paintings, artistic photographs) as it is a prime example of imagery\ncreated to elicit emotional responses from its viewers. Our dataset, termed\nArtEmis, contains 439K emotion attributions and explanations from humans, on\n81K artworks from WikiArt. Building on this data, we train and demonstrate a\nseries of captioning systems capable of expressing and explaining emotions from\nvisual stimuli. Remarkably, the captions produced by these systems often\nsucceed in reflecting the semantic and abstract content of the image, going\nwell beyond systems trained on existing datasets. The collected dataset and\ndeveloped methods are available at https://artemisdataset.org.\n",
			"Comment: https://artemisdataset.org"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07396",
		"pdf_url": "http://arxiv.org/pdf/2101.07396.pdf"
	},
	"1135": {
		"title": "Initialization Using Perlin Noise for Training Networks with a Limited\n  Amount of Data",
		"creator": [
			"Inoue, Nakamasa",
			"Yamagata, Eisuke",
			"Kataoka, Hirokatsu"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  We propose a novel network initialization method using Perlin noise for\ntraining image classification networks with a limited amount of data. Our main\nidea is to initialize the network parameters by solving an artificial noise\nclassification problem, where the aim is to classify Perlin noise samples into\ntheir noise categories. Specifically, the proposed method consists of two\nsteps. First, it generates Perlin noise samples with category labels defined\nbased on noise complexity. Second, it solves a classification problem, in which\nnetwork parameters are optimized to classify the generated noise samples. This\nmethod produces a reasonable set of initial weights (filters) for image\nclassification. To the best of our knowledge, this is the first work to\ninitialize networks by solving an artificial optimization problem without using\nany real-world images. Our experiments show that the proposed method\noutperforms conventional initialization methods on four image classification\ndatasets.\n",
			"Comment: Accepted to ICPR2020"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07406",
		"pdf_url": "http://arxiv.org/pdf/2101.07406.pdf"
	},
	"1136": {
		"title": "Improved parallel WaveGAN vocoder with perceptually weighted spectrogram\n  loss",
		"creator": [
			"Song, Eunwoo",
			"Yamamoto, Ryuichi",
			"Hwang, Min-Jae",
			"Kim, Jin-Seob",
			"Kwon, Ohsung",
			"Kim, Jae-Min"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Audio and Speech Processing",
			"Computer Science - Sound"
		],
		"description": [
			"  This paper proposes a spectral-domain perceptual weighting technique for\nParallel WaveGAN-based text-to-speech (TTS) systems. The recently proposed\nParallel WaveGAN vocoder successfully generates waveform sequences using a fast\nnon-autoregressive WaveNet model. By employing multi-resolution short-time\nFourier transform (MR-STFT) criteria with a generative adversarial network, the\nlight-weight convolutional networks can be effectively trained without any\ndistillation process. To further improve the vocoding performance, we propose\nthe application of frequency-dependent weighting to the MR-STFT loss function.\nThe proposed method penalizes perceptually-sensitive errors in the frequency\ndomain; thus, the model is optimized toward reducing auditory noise in the\nsynthesized speech. Subjective listening test results demonstrate that our\nproposed method achieves 4.21 and 4.26 TTS mean opinion scores for female and\nmale Korean speakers, respectively.\n",
			"Comment: To appear in SLT 2021"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07412",
		"pdf_url": "http://arxiv.org/pdf/2101.07412.pdf"
	},
	"1137": {
		"title": "SOSD-Net: Joint Semantic Object Segmentation and Depth Estimation from\n  Monocular images",
		"creator": [
			"He, Lei",
			"Lu, Jiwen",
			"Wang, Guanghui",
			"Song, Shiyu",
			"Zhou, Jie"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Depth estimation and semantic segmentation play essential roles in scene\nunderstanding. The state-of-the-art methods employ multi-task learning to\nsimultaneously learn models for these two tasks at the pixel-wise level. They\nusually focus on sharing the common features or stitching feature maps from the\ncorresponding branches. However, these methods lack in-depth consideration on\nthe correlation of the geometric cues and the scene parsing. In this paper, we\nfirst introduce the concept of semantic objectness to exploit the geometric\nrelationship of these two tasks through an analysis of the imaging process,\nthen propose a Semantic Object Segmentation and Depth Estimation Network\n(SOSD-Net) based on the objectness assumption. To the best of our knowledge,\nSOSD-Net is the first network that exploits the geometry constraint for\nsimultaneous monocular depth estimation and semantic segmentation. In addition,\nconsidering the mutual implicit relationship between these two tasks, we\nexploit the iterative idea from the expectation-maximization algorithm to train\nthe proposed network more effectively. Extensive experimental results on the\nCityscapes and NYU v2 dataset are presented to demonstrate the superior\nperformance of the proposed approach.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07422",
		"pdf_url": "http://arxiv.org/pdf/2101.07422.pdf"
	},
	"1138": {
		"title": "Submodular Maximization via Taylor Series Approximation",
		"creator": [
			"Özcan, Gözde",
			"Moharrer, Armin",
			"Ioannidis, Stratis"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  We study submodular maximization problems with matroid constraints, in\nparticular, problems where the objective can be expressed via compositions of\nanalytic and multilinear functions. We show that for functions of this form,\nthe so-called continuous greedy algorithm attains a ratio arbitrarily close to\n$(1-1/e) \\approx 0.63$ using a deterministic estimation via Taylor series\napproximation. This drastically reduces execution time over prior art that uses\nsampling.\n",
			"Comment: 15 pages, 2 figures, to be published in the SIAM International\n  Conference on Data Mining proceedings (SDM 2021)"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07423",
		"pdf_url": "http://arxiv.org/pdf/2101.07423.pdf"
	},
	"1139": {
		"title": "Dynamic Planning of Bicycle Stations in Dockless Public Bicycle-sharing\n  System Using Gated Graph Neural Network",
		"creator": [
			"Chen, Jianguo",
			"Li, Kenli",
			"Li, Keqin",
			"Yu, Philip S.",
			"Zeng, Zeng"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  Benefiting from convenient cycling and flexible parking locations, the\nDockless Public Bicycle-sharing (DL-PBS) network becomes increasingly popular\nin many countries. However, redundant and low-utility stations waste public\nurban space and maintenance costs of DL-PBS vendors. In this paper, we propose\na Bicycle Station Dynamic Planning (BSDP) system to dynamically provide the\noptimal bicycle station layout for the DL-PBS network. The BSDP system contains\nfour modules: bicycle drop-off location clustering, bicycle-station graph\nmodeling, bicycle-station location prediction, and bicycle-station layout\nrecommendation. In the bicycle drop-off location clustering module, candidate\nbicycle stations are clustered from each spatio-temporal subset of the\nlarge-scale cycling trajectory records. In the bicycle-station graph modeling\nmodule, a weighted digraph model is built based on the clustering results and\ninferior stations with low station revenue and utility are filtered. Then,\ngraph models across time periods are combined to create a graph sequence model.\nIn the bicycle-station location prediction module, the GGNN model is used to\ntrain the graph sequence data and dynamically predict bicycle stations in the\nnext period. In the bicycle-station layout recommendation module, the predicted\nbicycle stations are fine-tuned according to the government urban management\nplan, which ensures that the recommended station layout is conducive to city\nmanagement, vendor revenue, and user convenience. Experiments on actual DL-PBS\nnetworks verify the effectiveness, accuracy and feasibility of the proposed\nBSDP system.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07425",
		"pdf_url": "http://arxiv.org/pdf/2101.07425.pdf"
	},
	"1140": {
		"title": "Learning Efficient, Explainable and Discriminative Representations for\n  Pulmonary Nodules Classification",
		"creator": [
			"Jiang, Hanliang",
			"Shen, Fuhao",
			"Gao, Fei",
			"Han, Weidong"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  Automatic pulmonary nodules classification is significant for early diagnosis\nof lung cancers. Recently, deep learning techniques have enabled remarkable\nprogress in this field. However, these deep models are typically of high\ncomputational complexity and work in a black-box manner. To combat these\nchallenges, in this work, we aim to build an efficient and (partially)\nexplainable classification model. Specially, we use \\emph{neural architecture\nsearch} (NAS) to automatically search 3D network architectures with excellent\naccuracy/speed trade-off. Besides, we use the convolutional block attention\nmodule (CBAM) in the networks, which helps us understand the reasoning process.\nDuring training, we use A-Softmax loss to learn angularly discriminative\nrepresentations. In the inference stage, we employ an ensemble of diverse\nneural networks to improve the prediction accuracy and robustness. We conduct\nextensive experiments on the LIDC-IDRI database. Compared with previous\nstate-of-the-art, our model shows highly comparable performance by using less\nthan 1/40 parameters. Besides, empirical study shows that the reasoning process\nof learned networks is in conformity with physicians' diagnosis. Related code\nand results have been released at: https://github.com/fei-hdu/NAS-Lung.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07429",
			"Pattern Recognition, 2021"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07429.pdf"
	},
	"1141": {
		"title": "A Surrogate-Assisted Variable Grouping Algorithm for General Large Scale\n  Global Optimization Problems",
		"creator": [
			"Chen, An",
			"Ren, Zhigang",
			"Wang, Muyi",
			"Liang, Yongsheng",
			"Liu, Hanqing",
			"Du, Wenhao"
		],
		"subject": "Computer Science - Neural and Evolutionary Computing",
		"description": "  Problem decomposition plays a vital role when applying cooperative\ncoevolution (CC) to large scale global optimization problems. However, most\nlearning-based decomposition algorithms either only apply to additively\nseparable problems or face the issue of false separability detections.\nDirecting against these limitations, this study proposes a novel decomposition\nalgorithm called surrogate-assisted variable grouping (SVG). SVG first designs\na general-separability-oriented detection criterion according to whether the\noptimum of a variable changes with other variables. This criterion is\nconsistent with the separability definition and thus endows SVG with broad\napplicability and high accuracy. To reduce the fitness evaluation requirement,\nSVG seeks the optimum of a variable with the help of a surrogate model rather\nthan the original expensive high-dimensional model. Moreover, it converts the\nvariable grouping process into a dynamic-binary-tree search one, which\nfacilitates reutilizing historical separability detection information and thus\nreducing detection times. To evaluate the performance of SVG, a suite of\nbenchmark functions with up to 2000 dimensions, including additively and\nnon-additively separable ones, were designed. Experimental results on these\nfunctions indicate that, compared with six state-of-the-art decomposition\nalgorithms, SVG possesses broader applicability and competitive efficiency.\nFurthermore, it can significantly enhance the optimization performance of CC.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07430",
		"pdf_url": "http://arxiv.org/pdf/2101.07430.pdf"
	},
	"1142": {
		"title": "Dynamic Bicycle Dispatching of Dockless Public Bicycle-sharing Systems\n  using Multi-objective Reinforcement Learning",
		"creator": [
			"Chen, Jianguo",
			"Li, Kenli",
			"Li, Keqin",
			"Yu, Philip S.",
			"Zeng, Zeng"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": "  As a new generation of Public Bicycle-sharing Systems (PBS), the dockless PBS\n(DL-PBS) is an important application of cyber-physical systems and intelligent\ntransportation. How to use AI to provide efficient bicycle dispatching\nsolutions based on dynamic bicycle rental demand is an essential issue for\nDL-PBS. In this paper, we propose a dynamic bicycle dispatching algorithm based\non multi-objective reinforcement learning (MORL-BD) to provide the optimal\nbicycle dispatching solution for DL-PBS. We model the DL-PBS system from the\nperspective of CPS and use deep learning to predict the layout of bicycle\nparking spots and the dynamic demand of bicycle dispatching. We define the\nmulti-route bicycle dispatching problem as a multi-objective optimization\nproblem by considering the optimization objectives of dispatching costs,\ndispatch truck's initial load, workload balance among the trucks, and the\ndynamic balance of bicycle supply and demand. On this basis, the collaborative\nmulti-route bicycle dispatching problem among multiple dispatch trucks is\nmodeled as a multi-agent MORL model. All dispatch paths between parking spots\nare defined as state spaces, and the reciprocal of dispatching costs is defined\nas a reward. Each dispatch truck is equipped with an agent to learn the optimal\ndispatch path in the dynamic DL-PBS network. We create an elite list to store\nthe Pareto optimal solutions of bicycle dispatch paths found in each action,\nand finally, get the Pareto frontier. Experimental results on the actual DL-PBS\nsystems show that compared with existing methods, MORL-BD can find a higher\nquality Pareto frontier with less execution time.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07437",
		"pdf_url": "http://arxiv.org/pdf/2101.07437.pdf"
	},
	"1143": {
		"title": "Ambiguity of Objective Image Quality Metrics: A New Methodology for\n  Performance Evaluation",
		"creator": [
			"Cheon, Manri",
			"Vigier, Toinon",
			"Krasula, Lukáš",
			"Lee, Junghyuk",
			"Callet, Patrick Le",
			"Lee, Jong-Seok"
		],
		"subject": [
			"Computer Science - Multimedia",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": "  Objective image quality metrics try to estimate the perceptual quality of the\ngiven image by considering the characteristics of the human visual system.\nHowever, it is possible that the metrics produce different quality scores even\nfor two images that are perceptually indistinguishable by human viewers, which\nhave not been considered in the existing studies related to objective quality\nassessment. In this paper, we address the issue of ambiguity of objective image\nquality assessment. We propose an approach to obtain an ambiguity interval of\nan objective metric, within which the quality score difference is not\nperceptually significant. In particular, we use the visual difference\npredictor, which can consider viewing conditions that are important for visual\nquality perception. In order to demonstrate the usefulness of the proposed\napproach, we conduct experiments with 33 state-of-the-art image quality metrics\nin the viewpoint of their accuracy and ambiguity for three image quality\ndatabases. The results show that the ambiguity intervals can be applied as an\nadditional figure of merit when conventional performance measurement does not\ndetermine superiority between the metrics. The effect of the viewing distance\non the ambiguity interval is also shown.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07439",
			"Signal Processing: Image Communication (2021)",
			"doi:10.1016/j.image.2021.116150"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07439.pdf"
	},
	"1144": {
		"title": "Fast Convergence of DETR with Spatially Modulated Co-Attention",
		"creator": [
			"Gao, Peng",
			"Zheng, Minghang",
			"Wang, Xiaogang",
			"Dai, Jifeng",
			"Li, Hongsheng"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  The recently proposed Detection Transformer (DETR) model successfully applies\nTransformer to objects detection and achieves comparable performance with\ntwo-stage object detection frameworks, such as Faster-RCNN. However, DETR\nsuffers from its slow convergence. Training DETR \\cite{carion2020end} from\nscratch needs 500 epochs to achieve a high accuracy. To accelerate its\nconvergence, we propose a simple yet effective scheme for improving the DETR\nframework, namely Spatially Modulated Co-Attention (SMCA) mechanism. The core\nidea of SMCA is to conduct regression-aware co-attention in DETR by\nconstraining co-attention responses to be high near initially estimated\nbounding box locations. Our proposed SMCA increases DETR's convergence speed by\nreplacing the original co-attention mechanism in the decoder while keeping\nother operations in DETR unchanged. Furthermore, by integrating multi-head and\nscale-selection attention designs into SMCA, our fully-fledged SMCA can achieve\nbetter performance compared to DETR with a dilated convolution-based backbone\n(45.6 mAP at 108 epochs vs. 43.3 mAP at 500 epochs). We perform extensive\nablation studies on COCO dataset to validate the effectiveness of the proposed\nSMCA.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07448",
		"pdf_url": "http://arxiv.org/pdf/2101.07448.pdf"
	},
	"1145": {
		"title": "Single versus Multiple Annotation for Named Entity Recognition of\n  Mutations",
		"creator": [
			"Iraola, David Martinez",
			"Yepes, Antonio Jimeno"
		],
		"subject": "Computer Science - Computation and Language",
		"description": "  The focus of this paper is to address the knowledge acquisition bottleneck\nfor Named Entity Recognition (NER) of mutations, by analysing different\napproaches to build manually-annotated data. We address first the impact of\nusing a single annotator vs two annotators, in order to measure whether\nmultiple annotators are required. Once we evaluate the performance loss when\nusing a single annotator, we apply different methods to sample the training\ndata for second annotation, aiming at improving the quality of the dataset\nwithout requiring a full pass. We use held-out double-annotated data to build\ntwo scenarios with different types of rankings: similarity-based and confidence\nbased. We evaluate both approaches on: (i) their ability to identify training\ninstances that are erroneous (cases where single-annotator labels differ from\ndouble-annotation after discussion), and (ii) on Mutation NER performance for\nstate-of-the-art classifiers after integrating the fixes at different\nthresholds.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07450",
		"pdf_url": "http://arxiv.org/pdf/2101.07450.pdf"
	},
	"1146": {
		"title": "Wide Color Gamut Image Content Characterization: Method, Evaluation, and\n  Applications",
		"creator": [
			"Lee, Junghyuk",
			"Vigier, Toinon",
			"Callet, Patrick Le",
			"Lee, Jong-Seok"
		],
		"subject": [
			"Computer Science - Multimedia",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": "  In this paper, we propose a novel framework to characterize a wide color\ngamut image content based on perceived quality due to the processes that change\ncolor gamut, and demonstrate two practical use cases where the framework can be\napplied. We first introduce the main framework and implementation details.\nThen, we provide analysis for understanding of existing wide color gamut\ndatasets with quantitative characterization criteria on their characteristics,\nwhere four criteria, i.e., coverage, total coverage, uniformity, and total\nuniformity, are proposed. Finally, the framework is applied to content\nselection in a gamut mapping evaluation scenario in order to enhance\nreliability and robustness of the evaluation results. As a result, the\nframework fulfils content characterization for studies where quality of\nexperience of wide color gamut stimuli is involved.\n",
		"date": "2021-01-18",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07451",
			"IEEE Transactions on Multimedia (2020)",
			"doi:10.1109/TMM.2020.3032026"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07451.pdf"
	},
	"1147": {
		"title": "Learning Control of Quantum Systems",
		"creator": "Dong, Daoyi",
		"subject": [
			"Quantum Physics",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": [
			"  This paper provides a brief introduction to learning control of quantum\nsystems. In particular, the following aspects are outlined, including\ngradient-based learning for optimal control of quantum systems, evolutionary\ncomputation for learning control of quantum systems, learning-based quantum\nrobust control, and reinforcement learning for quantum control.\n",
			"Comment: 9 pages"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07461",
			"In: Baillieul J., Samad T. (eds) Encyclopedia of Systems and\n  Control. Springer, London (2020)",
			"doi:10.1007/978-1-4471-5102-9_100161-1"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07461.pdf"
	},
	"1148": {
		"title": "Deep Reinforcement Learning for Producing Furniture Layout in Indoor\n  Scenes",
		"creator": [
			"Di, Xinhan",
			"Yu, Pengqian"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  In the industrial interior design process, professional designers plan the\nsize and position of furniture in a room to achieve a satisfactory design for\nselling. In this paper, we explore the interior scene design task as a Markov\ndecision process (MDP), which is solved by deep reinforcement learning. The\ngoal is to produce an accurate position and size of the furniture\nsimultaneously for the indoor layout task. In particular, we first formulate\nthe furniture layout task as a MDP problem by defining the state, action, and\nreward function. We then design the simulated environment and train\nreinforcement learning agents to produce the optimal layout for the MDP\nformulation. We conduct our experiments on a large-scale real-world interior\nlayout dataset that contains industrial designs from professional designers.\nOur numerical results demonstrate that the proposed model yields higher-quality\nlayouts as compared with the state-of-art model. The developed simulator and\ncodes are available at \\url{https://github.com/CODE-SUBMIT/simulator1}.\n",
			"Comment: computer vision reinforcement learning. arXiv admin note: text\n  overlap with arXiv:2012.08514, arXiv:2012.08131"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07462",
		"pdf_url": "http://arxiv.org/pdf/2101.07462.pdf"
	},
	"1149": {
		"title": "Computer Science Communities: Who is Speaking, and Who is Listening to\n  the Women? Using an Ethics of Care to Promote Diverse Voices",
		"creator": [
			"Cheong, Marc",
			"Leins, Kobi",
			"Coghlan, Simon"
		],
		"subject": "Computer Science - Computers and Society",
		"description": [
			"  Those working on policy, digital ethics and governance often refer to issues\nin `computer science', that includes, but is not limited to, common subfields\nof Artificial Intelligence (AI), Computer Science (CS) Computer Security\n(InfoSec), Computer Vision (CV), Human Computer Interaction (HCI), Information\nSystems, (IS), Machine Learning (ML), Natural Language Processing (NLP) and\nSystems Architecture. Within this framework, this paper is a preliminary\nexploration of two hypotheses, namely 1) Each community has differing inclusion\nof minoritised groups (using women as our test case); and 2) Even where women\nexist in a community, they are not published representatively. Using data from\n20,000 research records, totalling 503,318 names, preliminary data supported\nour hypothesis. We argue that ACM has an ethical duty of care to its community\nto increase these ratios, and to hold individual computing communities to\naccount in order to do so, by providing incentives and a regular reporting\nsystem, in order to uphold its own Code.\n",
			"Comment: Accepted to ACM FAccT 2021. 10 pages, 1 figure. This arXiv copy is a\n  working draft only and not the final version"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07463",
		"pdf_url": "http://arxiv.org/pdf/2101.07463.pdf"
	},
	"1150": {
		"title": "Density-Ratio Based Personalised Ranking from Implicit Feedback",
		"creator": [
			"Togashi, Riku",
			"Kato, Masahiro",
			"Otani, Mayu",
			"Satoh, Shin'ichi"
		],
		"subject": "Computer Science - Information Retrieval",
		"description": [
			"  Learning from implicit user feedback is challenging as we can only observe\npositive samples but never access negative ones. Most conventional methods cope\nwith this issue by adopting a pairwise ranking approach with negative sampling.\nHowever, the pairwise ranking approach has a severe disadvantage in the\nconvergence time owing to the quadratically increasing computational cost with\nrespect to the sample size; it is problematic, particularly for large-scale\ndatasets and complex models such as neural networks. By contrast, a pointwise\napproach does not directly solve a ranking problem, and is therefore inferior\nto a pairwise counterpart in top-K ranking tasks; however, it is generally\nadvantageous in regards to the convergence time. This study aims to establish\nan approach to learn personalised ranking from implicit feedback, which\nreconciles the training efficiency of the pointwise approach and ranking\neffectiveness of the pairwise counterpart. The key idea is to estimate the\nranking of items in a pointwise manner; we first reformulate the conventional\npointwise approach based on density ratio estimation and then incorporate the\nessence of ranking-oriented approaches (e.g. the pairwise approach) into our\nformulation. Through experiments on three real-world datasets, we demonstrate\nthat our approach not only dramatically reduces the convergence time (one to\ntwo orders of magnitude faster) but also significantly improving the ranking\nperformance.\n",
			"Comment: Accepted by WWW 2021"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07481",
		"pdf_url": "http://arxiv.org/pdf/2101.07481.pdf"
	},
	"1151": {
		"title": "Unsupervised Deep Learning for Handwritten Page Segmentation",
		"creator": [
			"Droby, Ahmad",
			"Barakat, Berat Kurar",
			"Madi, Borak",
			"Alaasam, Reem",
			"El-Sana, Jihad"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Segmenting handwritten document images into regions with homogeneous patterns\nis an important pre-processing step for many document images analysis tasks.\nHand-labeling data to train a deep learning model for layout analysis requires\nsignificant human effort. In this paper, we present an unsupervised deep\nlearning method for page segmentation, which revokes the need for annotated\nimages. A siamese neural network is trained to differentiate between patches\nusing their measurable properties such as number of foreground pixels, and\naverage component height and width. The network is trained that spatially\nnearby patches are similar. The network's learned features are used for page\nsegmentation, where patches are classified as main and side text based on the\nextracted features. We tested the method on a dataset of handwritten document\nimages with quite complex layouts. Our experiments show that the proposed\nunsupervised method is as effective as typical supervised methods.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07487",
		"pdf_url": "http://arxiv.org/pdf/2101.07487.pdf"
	},
	"1152": {
		"title": "Optimizing Hyperparameters in CNNs using Bilevel Programming in Time\n  Series Data",
		"creator": [
			"Seth, Taniya",
			"Muhuri, Pranab K."
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Hyperparameter optimization has remained a central topic within the machine\nlearning community due to its ability to produce state-of-the-art results. With\nthe recent interest growing in the usage of CNNs for time series prediction, we\npropose the notion of optimizing Hyperparameters in CNNs for the purpose of\ntime series prediction. In this position paper, we give away the idea of\nmodeling the concerned hyperparameter optimization problem using bilevel\nprogramming.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07492",
		"pdf_url": "http://arxiv.org/pdf/2101.07492.pdf"
	},
	"1153": {
		"title": "Disentangled Recurrent Wasserstein Autoencoder",
		"creator": [
			"Han, Jun",
			"Min, Martin Renqiang",
			"Han, Ligong",
			"Li, Li Erran",
			"Zhang, Xuan"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Learning disentangled representations leads to interpretable models and\nfacilitates data generation with style transfer, which has been extensively\nstudied on static data such as images in an unsupervised learning framework.\nHowever, only a few works have explored unsupervised disentangled sequential\nrepresentation learning due to challenges of generating sequential data. In\nthis paper, we propose recurrent Wasserstein Autoencoder (R-WAE), a new\nframework for generative modeling of sequential data. R-WAE disentangles the\nrepresentation of an input sequence into static and dynamic factors (i.e.,\ntime-invariant and time-varying parts). Our theoretical analysis shows that,\nR-WAE minimizes an upper bound of a penalized form of the Wasserstein distance\nbetween model distribution and sequential data distribution, and simultaneously\nmaximizes the mutual information between input data and different disentangled\nlatent factors, respectively. This is superior to (recurrent) VAE which does\nnot explicitly enforce mutual information maximization between input data and\ndisentangled latent representations. When the number of actions in sequential\ndata is available as weak supervision information, R-WAE is extended to learn a\ncategorical latent representation of actions to improve its disentanglement.\nExperiments on a variety of datasets show that our models outperform other\nbaselines with the same settings in terms of disentanglement and unconditional\nvideo generation both quantitatively and qualitatively.\n",
			"Comment: ICLR 2021"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07496",
		"pdf_url": "http://arxiv.org/pdf/2101.07496.pdf"
	},
	"1154": {
		"title": "Paraconsistent Foundations for Quantum Probability",
		"creator": "Goertzel, Ben",
		"subject": "Computer Science - Artificial Intelligence",
		"description": "  It is argued that a fuzzy version of 4-truth-valued paraconsistent logic\n(with truth values corresponding to True, False, Both and Neither) can be\napproximately isomorphically mapped into the complex-number algebra of quantum\nprobabilities. I.e., p-bits (paraconsistent bits) can be transformed into close\napproximations of qubits. The approximation error can be made arbitrarily\nsmall, at least in a formal sense, and can be related to the degree of\nirreducible \"evidential error\" assumed to plague an observer's observations.\nThis logical correspondence manifests itself in program space via an\napproximate mapping between probabilistic and quantum types in programming\nlanguages.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07498",
		"pdf_url": "http://arxiv.org/pdf/2101.07498.pdf"
	},
	"1155": {
		"title": "COVID-19 and Digital Transformation -- Developing an Open Experimental\n  Testbed for Sustainable and Innovative Environments (ETSIE) using Fuzzy\n  Cognitive Maps",
		"creator": "Höhl, Wolfgang",
		"subject": "Computer Science - Computers and Society",
		"description": [
			"  This paper sketches a new approach using Fuzzy Cognitive Maps (FCMs) to\noperably map and simulate digital transformation in architecture and urban\nplanning. Today these processes are poorly understood. Many current studies on\ndigital transformation are only treating questions of economic efficiency.\nSustainability and social impact only play a minor role. Decisive definitions,\nconcepts and terms stay unclear. Therefore this paper develops an open\nexperimental testbed for sustainable and innovative environments (ETSIE) for\nthree different digital transformation scenarios using FCMs. A traditional\ngrowth-oriented scenario, a COVID-19 scenario and an innovative and sustainable\nCOVID-19 scenario are modeled and tested. All three scenarios have the same\nnumber of components, connections and the same driver components. Only the\ninitial state vectors are different and the internal correlations are weighted\ndifferently. This allows for comparing all three scenarios on an equal basis.\nThe mental modeler software is used (Gray et al. 2013). This paper presents one\nof the first applications of FCMs in the context of digital transformation. It\nis shown, that the traditional growth-oriented scenario is structurally very\nsimilar to the current COVID-19 scenario. The current pandemic is able to\naccelerate digital transformation to a certain extent. But the pandemic does\nnot guarantee for a distinct sustainable and innovative future development.\nOnly by changing the initial state vectors and the weights of the connections\nan innovative and sustainable turnaround in a third scenario becomes possible.\n",
			"Comment: 21 pages, 11 figures and 17 tables; keywords: soft computing; fuzzy\n  cognitive maps; digital transformation; COVID-19; decision making;\n  sustainability; integrated world system modeling"
		],
		"date": [
			"2021-01-19",
			"2021-01-20"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07509",
		"pdf_url": "http://arxiv.org/pdf/2101.07509.pdf"
	},
	"1156": {
		"title": "Collaborative Federated Learning For Healthcare: Multi-Modal COVID-19\n  Diagnosis at the Edge",
		"creator": [
			"Qayyum, Adnan",
			"Ahmad, Kashif",
			"Ahsan, Muhammad Ahtazaz",
			"Al-Fuqaha, Ala",
			"Qadir, Junaid"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Distributed, Parallel, and Cluster Computing"
		],
		"description": [
			"  Despite significant improvements over the last few years, cloud-based\nhealthcare applications continue to suffer from poor adoption due to their\nlimitations in meeting stringent security, privacy, and quality of service\nrequirements (such as low latency). The edge computing trend, along with\ntechniques for distributed machine learning such as federated learning, have\ngained popularity as a viable solution in such settings. In this paper, we\nleverage the capabilities of edge computing in medicine by analyzing and\nevaluating the potential of intelligent processing of clinical visual data at\nthe edge allowing the remote healthcare centers, lacking advanced diagnostic\nfacilities, to benefit from the multi-modal data securely. To this aim, we\nutilize the emerging concept of clustered federated learning (CFL) for an\nautomatic diagnosis of COVID-19. Such an automated system can help reduce the\nburden on healthcare systems across the world that has been under a lot of\nstress since the COVID-19 pandemic emerged in late 2019. We evaluate the\nperformance of the proposed framework under different experimental setups on\ntwo benchmark datasets. Promising results are obtained on both datasets\nresulting in comparable results against the central baseline where the\nspecialized models (i.e., each on a specific type of COVID-19 imagery) are\ntrained with central data, and improvements of 16\\% and 11\\% in overall\nF1-Scores have been achieved over the multi-modal model trained in the\nconventional Federated Learning setup on X-ray and Ultrasound datasets,\nrespectively. We also discuss in detail the associated challenges,\ntechnologies, tools, and techniques available for deploying ML at the edge in\nsuch privacy and delay-sensitive applications.\n",
			"Comment: preprint version"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07511",
		"pdf_url": "http://arxiv.org/pdf/2101.07511.pdf"
	},
	"1157": {
		"title": "Mapping and Describing Geospatial Data to Generalize Complex Mapping and\n  Describing Geospatial Data to Generalize Complex Models: The Case of\n  LittoSIM-GEN Models",
		"creator": [
			"Laatabi, Ahmed",
			"Becu, Nicolas",
			"Marilleau, Nicolas",
			"Pignon-Mussaud, Cécilia",
			"Amalric, Marion",
			"Bertin, X.",
			"Anselme, Brice",
			"Beck, Elise"
		],
		"subject": "Computer Science - Artificial Intelligence",
		"description": "  For some scientific questions, empirical data are essential to develop\nreliable simulation models. These data usually come from different sources with\ndiverse and heterogeneous formats. The design of complex data-driven models is\noften shaped by the structure of the data available in research projects.\nHence, applying such models to other case studies requires either to get\nsimilar data or to transform new data to fit the model inputs. It is the case\nof agent-based models (ABMs) that use advanced data structures such as\nGeographic Information Systems data. We faced this problem in the LittoSIM-GEN\nproject when generalizing our participatory flooding model (LittoSIM) to new\nterritories. From this experience, we provide a mapping approach to structure,\ndescribe, and automatize the integration of geospatial data into ABMs.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07523",
			"International Journal of Geospatial and Environmental Research,\n  KAGES, 2020"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07523.pdf"
	},
	"1158": {
		"title": "Momentum^2 Teacher: Momentum Teacher with Momentum Statistics for\n  Self-Supervised Learning",
		"creator": [
			"Li, Zeming",
			"Liu, Songtao",
			"Sun, Jian"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  In this paper, we present a novel approach, Momentum$^2$ Teacher, for\nstudent-teacher based self-supervised learning. The approach performs momentum\nupdate on both network weights and batch normalization (BN) statistics. The\nteacher's weight is a momentum update of the student, and the teacher's BN\nstatistics is a momentum update of those in history. The Momentum$^2$ Teacher\nis simple and efficient. It can achieve the state of the art results (74.5\\%)\nunder ImageNet linear evaluation protocol using small-batch size(\\eg, 128),\nwithout requiring large-batch training on special hardware like TPU or\ninefficient across GPU operation (\\eg, shuffling BN, synced BN). Our\nimplementation and pre-trained models will be given on\nGitHub\\footnote{https://github.com/zengarden/momentum2-teacher}.\n",
			"Comment: 11 pages, Tech report"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07525",
		"pdf_url": "http://arxiv.org/pdf/2101.07525.pdf"
	},
	"1159": {
		"title": "The Unreasonable Effectiveness of Patches in Deep Convolutional Kernels\n  Methods",
		"creator": [
			"Thiry, Louis",
			"Arbel, Michael",
			"Belilovsky, Eugene",
			"Oyallon, Edouard"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  A recent line of work showed that various forms of convolutional kernel\nmethods can be competitive with standard supervised deep convolutional networks\non datasets like CIFAR-10, obtaining accuracies in the range of 87-90% while\nbeing more amenable to theoretical analysis. In this work, we highlight the\nimportance of a data-dependent feature extraction step that is key to the\nobtain good performance in convolutional kernel methods. This step typically\ncorresponds to a whitened dictionary of patches, and gives rise to a\ndata-driven convolutional kernel methods. We extensively study its effect,\ndemonstrating it is the key ingredient for high performance of these methods.\nSpecifically, we show that one of the simplest instances of such kernel\nmethods, based on a single layer of image patches followed by a linear\nclassifier is already obtaining classification accuracies on CIFAR-10 in the\nsame range as previous more sophisticated convolutional kernel methods. We\nscale this method to the challenging ImageNet dataset, showing such a simple\napproach can exceed all existing non-learned representation methods. This is a\nnew baseline for object recognition without representation learning methods,\nthat initiates the investigation of convolutional kernel models on ImageNet. We\nconduct experiments to analyze the dictionary that we used, our ablations\nshowing they exhibit low-dimensional properties.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07528",
			"International Conference on Learning Representation (ICLR 2021),\n  2021, Vienna (online), Austria"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07528.pdf"
	},
	"1160": {
		"title": "Hidden Markov Model-Based Encoding for Time-Correlated IoT Sources",
		"creator": [
			"Chandak, Siddharth",
			"Chiariotti, Federico",
			"Popovski, Petar"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"94A05 (Primary), 94B35, 62M05 (Secondary)",
			"E.4",
			"H.1.1"
		],
		"description": [
			"  As the use of Internet of Things (IoT) devices for monitoring purposes\nbecomes ubiquitous, the efficiency of sensor communication is a major issue for\nthe modern Internet. Channel coding is less efficient for extremely short\npackets, and traditional techniques that rely on source compression require\nextensive signaling or pre-existing knowledge of the source dynamics. In this\nwork, we propose an encoding and decoding scheme that learns source dynamics\nonline using a Hidden Markov Model (HMM), puncturing a short packet code to\noutperform existing compression-based approaches. Our approach shows\nsignificant performance improvements for sources that are highly correlated in\ntime, with no additional complexity on the sender side.\n",
			"Comment: Preprint version of the paper published in IEEE Communications\n  Letters"
		],
		"date": [
			"2021-01-19",
			"2021-01-20"
		],
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07534",
			"doi:10.1109/LCOMM.2020.3044210"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07534.pdf"
	},
	"1161": {
		"title": "Electrocardiogram Classification and Visual Diagnosis of Atrial\n  Fibrillation with DenseECG",
		"creator": [
			"Chen, Dacheng",
			"Li, Dan",
			"Xu, Xiuqin",
			"Yang, Ruizhi",
			"Ng, See-Kiong"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Signal Processing",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": "  Atrial Fibrillation (AF) is a common cardiac arrhythmia affecting a large\nnumber of people around the world. If left undetected, it will develop into\nchronic disability or even early mortality. However, patients who have this\nproblem can barely feel its presence, especially in its early stage. A\nnon-invasive, automatic, and effective detection method is therefore needed to\nhelp early detection so that medical intervention can be implemented in time to\nprevent its progression.\n  Electrocardiogram (ECG), which records the electrical activities of the\nheart, has been widely used for detecting the presence of AF. However, due to\nthe subtle patterns of AF, the performance of detection models have largely\ndepended on complicated data pre-processing and expertly engineered features.\nIn our work, we developed DenseECG, an end-to-end model based on 5 layers 1D\ndensely connected convolutional neural network. We trained our model using the\npublicly available dataset from 2017 PhysioNet Computing in Cardiology(CinC)\nChallenge containing 8528 single-lead ECG recordings of short-term heart\nrhythms (9-61s). Our trained model was able to outperform the other\nstate-of-the-art AF detection models on this dataset without complicated data\npre-processing and expert-supervised feature engineering.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07535",
		"pdf_url": "http://arxiv.org/pdf/2101.07535.pdf"
	},
	"1162": {
		"title": "PICA: A Pixel Correlation-based Attentional Black-box Adversarial Attack",
		"creator": [
			"Wang, Jie",
			"Yin, Zhaoxia",
			"Tang, Jin",
			"Jiang, Jing",
			"Luo, Bin"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  The studies on black-box adversarial attacks have become increasingly\nprevalent due to the intractable acquisition of the structural knowledge of\ndeep neural networks (DNNs). However, the performance of emerging attacks is\nnegatively impacted when fooling DNNs tailored for high-resolution images. One\nof the explanations is that these methods usually focus on attacking the entire\nimage, regardless of its spatial semantic information, and thereby encounter\nthe notorious curse of dimensionality. To this end, we propose a pixel\ncorrelation-based attentional black-box adversarial attack, termed as PICA.\nFirstly, we take only one of every two neighboring pixels in the salient region\nas the target by leveraging the attentional mechanism and pixel correlation of\nimages, such that the dimension of the black-box attack reduces. After that, a\ngeneral multiobjective evolutionary algorithm is employed to traverse the\nreduced pixels and generate perturbations that are imperceptible by the human\nvision. Extensive experimental results have verified the effectiveness of the\nproposed PICA on the ImageNet dataset. More importantly, PICA is\ncomputationally more efficient to generate high-resolution adversarial examples\ncompared with the existing black-box attacks.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07538",
		"pdf_url": "http://arxiv.org/pdf/2101.07538.pdf"
	},
	"1163": {
		"title": "A synthetic biology approach for the design of genetic algorithms with\n  bacterial agents",
		"creator": [
			"Becerra, A. Gargantilla",
			"Gutiérrez, M.",
			"Lahoz-Beltra, R."
		],
		"subject": [
			"Computer Science - Neural and Evolutionary Computing",
			"Computer Science - Multiagent Systems"
		],
		"description": "  Bacteria have been a source of inspiration for the design of evolutionary\nalgorithms. At the beginning of the 20th century synthetic biology was born, a\ndiscipline whose goal is the design of biological systems that do not exist in\nnature, for example, programmable synthetic bacteria. In this paper, we\nintroduce as a novelty the designing of evolutionary algorithms where all the\nsteps are conducted by synthetic bacteria. To this end, we designed a genetic\nalgorithm, which we have named BAGA, illustrating its utility solving simple\ninstances of optimization problems such as function optimization, 0/1 knapsack\nproblem, Hamiltonian path problem. The results obtained open the possibility of\nconceiving evolutionary algorithms inspired by principles, mechanisms and\ngenetic circuits from synthetic biology. In summary, we can conclude that\nsynthetic biology is a source of inspiration either for the design of\nevolutionary algorithms or for some of their steps, as shown by the results\nobtained in our simulation experiments.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07540",
		"pdf_url": "http://arxiv.org/pdf/2101.07540.pdf"
	},
	"1164": {
		"title": "Sniffing Multi-hop Multi-channel Wireless Sensor Networks",
		"creator": [
			"Kovač, Jelena",
			"Crnogorac, Jovan",
			"Kočan, Enis",
			"Vucinic, Malisa"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": [
			"  As wireless sensor networks grow larger, more complex and their role more\nsignificant, it becomes necessary to have an insight into the network traffic.\nFor this purpose, sniffers play an irreplaceable role. Since a sniffer is a\ndevice of limited range, to cover a multi-hop network it is necessary to\nconsider the deployment of multiple sniffers. This motivates the research on\nthe optimal number and position of sniffers in the network. We present a\nsolution based on a minimal dominant set from graph theory. We evaluate the\nproposed solution and implement it as an extension of the 6TiSCH simulator. Our\nsolution assumes a 50-nodes scenario, deployed in 2x2 km outdoor area, with 10%\nof packet drops over all channels, when 10 sniffers are used.\n",
			"Comment: 2020 28th Telecommunications Forum (TELFOR), Nov 2020, Belgrade,\n  Serbia"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07541",
		"pdf_url": "http://arxiv.org/pdf/2101.07541.pdf"
	},
	"1165": {
		"title": "VML-MOC: Segmenting a multiply oriented and curved handwritten text\n  lines dataset",
		"creator": [
			"Barakat, Berat Kurar",
			"Cohen, Rafi",
			"Rabaev, Irina",
			"El-Sana, Jihad"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  This paper publishes a natural and very complicated dataset of handwritten\ndocuments with multiply oriented and curved text lines, namely VML-MOC dataset.\nThese text lines were written as remarks on the page margins by different\nwriters over the years. They appear at different locations within the\norientations that range between 0 and 180 or as curvilinear forms. We evaluate\na multi-oriented Gaussian based method to segment these handwritten text lines\nthat are skewed or curved in any orientation. It achieves a mean pixel\nIntersection over Union score of 80.96% on the test documents. The results are\ncompared with the results of a single-oriented Gaussian based text line\nsegmentation method.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07542",
		"pdf_url": "http://arxiv.org/pdf/2101.07542.pdf"
	},
	"1166": {
		"title": "Subspace exploration: Bounds on Projected Frequency Estimation",
		"creator": [
			"Cormode, Graham",
			"Dickens, Charlie",
			"Woodruff, David P."
		],
		"subject": [
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Computational Complexity"
		],
		"description": "  Given an $n \\times d$ dimensional dataset $A$, a projection query specifies a\nsubset $C \\subseteq [d]$ of columns which yields a new $n \\times |C|$ array. We\nstudy the space complexity of computing data analysis functions over such\nsubspaces, including heavy hitters and norms, when the subspaces are revealed\nonly after observing the data. We show that this important class of problems is\ntypically hard: for many problems, we show $2^{\\Omega(d)}$ lower bounds.\nHowever, we present upper bounds which demonstrate space dependency better than\n$2^d$. That is, for $c,c' \\in (0,1)$ and a parameter $N=2^d$ an\n$N^c$-approximation can be obtained in space $\\min(N^{c'},n)$, showing that it\nis possible to improve on the na\\\"{i}ve approach of keeping information for all\n$2^d$ subsets of $d$ columns. Our results are based on careful constructions of\ninstances using coding theory and novel combinatorial reductions that exhibit\nsuch space-approximation tradeoffs.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07546",
		"pdf_url": "http://arxiv.org/pdf/2101.07546.pdf"
	},
	"1167": {
		"title": "Multiobjective Multitasking Optimization Based on Decomposition with\n  Dual Neighborhoods",
		"creator": [
			"Wang, Xianpeng",
			"Dong, Zhiming",
			"Tang, Lixin",
			"Zhang, Qingfu"
		],
		"subject": "Computer Science - Computational Engineering, Finance, and Science",
		"description": "  This paper proposes a multiobjective multitasking optimization evolutionary\nalgorithm based on decomposition with dual neighborhood. In our proposed\nalgorithm, each subproblem not only maintains a neighborhood based on the\nEuclidean distance among weight vectors within its own task, but also keeps a\nneighborhood with subproblems of other tasks. Gray relation analysis is used to\ndefine neighborhood among subproblems of different tasks. In such a way,\nrelationship among different subproblems can be effectively exploited to guide\nthe search. Experimental results show that our proposed algorithm outperforms\nfour state-of-the-art multiobjective multitasking evolutionary algorithms and a\ntraditional decomposition-based multiobjective evolutionary algorithm on a set\nof test problems.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07548",
		"pdf_url": "http://arxiv.org/pdf/2101.07548.pdf"
	},
	"1168": {
		"title": "Object Tracking by Detection with Visual and Motion Cues",
		"creator": "Salscheider, Niels Ole",
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Self-driving cars and other autonomous vehicles need to detect and track\nobjects in camera images. We present a simple online tracking algorithm that is\nbased on a constant velocity motion model with a Kalman filter, and an\nassignment heuristic. The assignment heuristic relies on four metrics: An\nembedding vector that describes the appearance of objects and can be used to\nre-identify them, a displacement vector that describes the object movement\nbetween two consecutive video frames, the Mahalanobis distance between the\nKalman filter states and the new detections, and a class distance. These\nmetrics are combined with a linear SVM, and then the assignment problem is\nsolved by the Hungarian algorithm. We also propose an efficient CNN\narchitecture that estimates these metrics. Our multi-frame model accepts two\nconsecutive video frames which are processed individually in the backbone, and\nthen optical flow is estimated on the resulting feature maps. This allows the\nnetwork heads to estimate the displacement vectors. We evaluate our approach on\nthe challenging BDD100K tracking dataset. Our multi-frame model achieves a good\nMOTA value of 39.1% with low localization error of 0.206 in MOTP. Our fast\nsingle-frame model achieves an even lower localization error of 0.202 in MOTP,\nand a MOTA value of 36.8%.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07549",
		"pdf_url": "http://arxiv.org/pdf/2101.07549.pdf"
	},
	"1169": {
		"title": "Upper Dominating Set: Tight Algorithms for Pathwidth and Sub-Exponential\n  Approximation",
		"creator": [
			"Dublois, Louis",
			"Lampis, Michael",
			"Paschos, Vangelis Th."
		],
		"subject": [
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Computational Complexity"
		],
		"description": [
			"  An upper dominating set is a minimal dominating set in a graph. In the\n\\textsc{Upper Dominating Set} problem, the goal is to find an upper dominating\nset of maximum size. We study the complexity of parameterized algorithms for\n\\textsc{Upper Dominating Set}, as well as its sub-exponential approximation.\nFirst, we prove that, under ETH, \\textsc{$k$-Upper Dominating Set} cannot be\nsolved in time $O(n^{o(k)})$ (improving on $O(n^{o(\\sqrt{k})})$), and in the\nsame time we show under the same complexity assumption that for any constant\nratio $r$ and any $\\varepsilon > 0$, there is no $r$-approximation algorithm\nrunning in time $O(n^{k^{1-\\varepsilon}})$. Then, we settle the problem's\ncomplexity parameterized by pathwidth by giving an algorithm running in time\n$O^*(6^{pw})$ (improving the current best $O^*(7^{pw})$), and a lower bound\nshowing that our algorithm is the best we can get under the SETH. Furthermore,\nwe obtain a simple sub-exponential approximation algorithm for this problem: an\nalgorithm that produces an $r$-approximation in time $n^{O(n/r)}$, for any\ndesired approximation ratio $r < n$. We finally show that this\ntime-approximation trade-off is tight, up to an arbitrarily small constant in\nthe second exponent: under the randomized ETH, and for any ratio $r > 1$ and\n$\\varepsilon > 0$, no algorithm can output an $r$-approximation in time\n$n^{(n/r)^{1-\\varepsilon}}$. Hence, we completely characterize the\napproximability of the problem in sub-exponential time.\n",
			"Comment: This paper has been accepted to CIAC 2021"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07550",
		"pdf_url": "http://arxiv.org/pdf/2101.07550.pdf"
	},
	"1170": {
		"title": "Local Complexity of Polygons",
		"creator": [
			"Klute, Fabian",
			"Reddy, Meghana M.",
			"Miltzow, Tillmann"
		],
		"subject": [
			"Computer Science - Computational Geometry",
			"Computer Science - Discrete Mathematics",
			"Computer Science - Data Structures and Algorithms"
		],
		"description": [
			"  Many problems in Discrete and Computational Geometry deal with simple\npolygons or polygonal regions. Many algorithms and data-structures perform\nconsiderably faster, if the underlying polygonal region has low local\ncomplexity. One obstacle to make this intuition rigorous, is the lack of a\nformal definition of local complexity. Here, we give two possible definitions\nand show how they are related in a combinatorial sense. We say that a polygon\n$P$ has point visibility width $w=pvw$, if there is no point $q\\in P$ that sees\nmore than $w$ reflex vertices. We say that a polygon $P$ has chord visibility\nwidth $w=cvw $, if there is no chord $c=\\textrm{seg}(a,b)\\subset P$ that sees\nmore than w reflex vertices. We show that \\[ cvw \\leq pvw ^{O( pvw )},\\] for\nany simple polygon. Furthermore, we show that there exists a simple polygon\nwith \\[ cvw \\geq 2^{\\Omega( pvw )}.\\]\n",
			"Comment: 7 pages, 5 figures"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07554",
		"pdf_url": "http://arxiv.org/pdf/2101.07554.pdf"
	},
	"1171": {
		"title": "Single-RF Multi-User Communication Through Reconfigurable Intelligent\n  Surfaces: An Information-Theoretic Analysis",
		"creator": [
			"Karasik, Roy",
			"Simeone, Osvaldo",
			"Di Renzo, Marco",
			"Shamai, Shlomo"
		],
		"subject": [
			"Computer Science - Information Theory",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": [
			"  Reconfigurable intelligent surfaces (RISs) are typically used in multi-user\nsystems to mitigate interference among active transmitters. In contrast, this\npaper studies a setting with a conventional active encoder as well as a passive\nencoder that modulates the reflection pattern of the RIS. The RIS hence serves\nthe dual purpose of improving the rate of the active encoder and of enabling\ncommunication from the second encoder. The capacity region is characterized,\nand information-theoretic insights regarding the trade-offs between the rates\nof the two encoders are derived by focusing on the high- and low-power regimes.\n",
			"Comment: Submitted for possible conference publication. arXiv admin note: text\n  overlap with arXiv:2012.00407"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07556",
		"pdf_url": "http://arxiv.org/pdf/2101.07556.pdf"
	},
	"1172": {
		"title": "Modelling Downlink Packet Aggregation in Paced 802.11ac WLANs",
		"creator": [
			"Gringoli, Francesco",
			"Leith, Douglas J."
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": [
			"  We derive an analytic model of packet aggregation on the the downlink of an\n802.11ac WLAN when packet arrivals are paced. The model is closed-form and so\nsuitable for both analysis and design of next generation edge architectures\nthat aim to achieve high rate and low delay. The model is validated against\nboth simulations and experimental measurements and found to be remarkably\naccurate despite its simplicity.\n",
			"Comment: arXiv admin note: substantial text overlap with arXiv:1910.09651"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07562",
		"pdf_url": "http://arxiv.org/pdf/2101.07562.pdf"
	},
	"1173": {
		"title": "Using StyleGAN for Visual Interpretability of Deep Learning Models on\n  Medical Images",
		"creator": [
			"Schutte, Kathryn",
			"Moindrot, Olivier",
			"Hérent, Paul",
			"Schiratti, Jean-Baptiste",
			"Jégou, Simon"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  As AI-based medical devices are becoming more common in imaging fields like\nradiology and histology, interpretability of the underlying predictive models\nis crucial to expand their use in clinical practice. Existing heatmap-based\ninterpretability methods such as GradCAM only highlight the location of\npredictive features but do not explain how they contribute to the prediction.\nIn this paper, we propose a new interpretability method that can be used to\nunderstand the predictions of any black-box model on images, by showing how the\ninput image would be modified in order to produce different predictions. A\nStyleGAN is trained on medical images to provide a mapping between latent\nvectors and images. Our method identifies the optimal direction in the latent\nspace to create a change in the model prediction. By shifting the latent\nrepresentation of an input image along this direction, we can produce a series\nof new synthetic images with changed predictions. We validate our approach on\nhistology and radiology images, and demonstrate its ability to provide\nmeaningful explanations that are more informative than GradCAM heatmaps. Our\nmethod reveals the patterns learned by the model, which allows clinicians to\nbuild trust in the model's predictions, discover new biomarkers and eventually\nreveal potential biases.\n",
			"Comment: Accepted for oral session of Medical Imaging meets NeurIPS 2020\n  workshop:\n  http://www.cse.cuhk.edu.hk/~qdou/public/medneurips2020/70_neurips2020_cameraready_opt.pdf"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07563",
		"pdf_url": "http://arxiv.org/pdf/2101.07563.pdf"
	},
	"1174": {
		"title": "Creation and Evaluation of a Pre-tertiary Artificial Intelligence (AI)\n  Curriculum",
		"creator": [
			"Chiu, Thomas K. F.",
			"Meng, Helen",
			"Chai, Ching-Sing",
			"King, Irwin",
			"Wong, Savio",
			"Yam, Yeung"
		],
		"subject": "Computer Science - Artificial Intelligence",
		"description": [
			"  Contributions: The Chinese University of Hong Kong (CUHK)-Jockey Club AI for\nthe Future Project (AI4Future) co-created an AI curriculum for pre-tertiary\neducation and evaluated its efficacy. While AI is conventionally taught in\ntertiary level education, our co-creation process successfully developed the\ncurriculum that has been used in secondary school teaching in Hong Kong and\nreceived positive feedback. Background: AI4Future is a cross-sector project\nthat engages five major partners - CUHK Faculty of Engineering and Faculty of\nEducation, Hong Kong secondary schools, the government and the AI industry. A\nteam of 14 professors with expertise in engineering and education collaborated\nwith 17 principals and teachers from 6 secondary schools to co-create the\ncurriculum. This team formation bridges the gap between researchers in\nengineering and education, together with practitioners in education context.\nResearch Questions: What are the main features of the curriculum content\ndeveloped through the co-creation process? Would the curriculum significantly\nimprove the students perceived competence in, as well as attitude and\nmotivation towards AI? What are the teachers perceptions of the co-creation\nprocess that aims to accommodate and foster teacher autonomy? Methodology: This\nstudy adopted a mix of quantitative and qualitative methods and involved 335\nstudent participants. Findings: 1) two main features of learning resources, 2)\nthe students perceived greater competence, and developed more positive attitude\nto learn AI, and 3) the co-creation process generated a variety of resources\nwhich enhanced the teachers knowledge in AI, as well as fostered teachers\nautonomy in bringing the subject matter into their classrooms.\n",
			"Comment: 8 pages 5 figures"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07570",
		"pdf_url": "http://arxiv.org/pdf/2101.07570.pdf"
	},
	"1175": {
		"title": "An Improvement of Object Detection Performance using Multi-step Machine\n  Learnings",
		"creator": [
			"Kishimoto, Tomoe",
			"Saito, Masahiko",
			"Tanaka, Junichi",
			"Iiyama, Yutaro",
			"Sawada, Ryu",
			"Terashi, Koji"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Connecting multiple machine learning models into a pipeline is effective for\nhandling complex problems. By breaking down the problem into steps, each\ntackled by a specific component model of the pipeline, the overall solution can\nbe made accurate and explainable. This paper describes an enhancement of object\ndetection based on this multi-step concept, where a post-processing step called\nthe calibration model is introduced. The calibration model consists of a\nconvolutional neural network, and utilizes rich contextual information based on\nthe domain knowledge of the input. Improvements of object detection performance\nby 0.8-1.9 in average precision metric over existing object detectors have been\nobserved using the new model.\n",
			"Comment: Submitted to ICIP 2021"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07571",
		"pdf_url": "http://arxiv.org/pdf/2101.07571.pdf"
	},
	"1176": {
		"title": "Collaboration among Image and Object Level Features for Image\n  Colourisation",
		"creator": [
			"Pucci, Rita",
			"Micheloni, Christian",
			"Martinel, Niki"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  Image colourisation is an ill-posed problem, with multiple correct solutions\nwhich depend on the context and object instances present in the input datum.\nPrevious approaches attacked the problem either by requiring intense user\ninteractions or by exploiting the ability of convolutional neural networks\n(CNNs) in learning image level (context) features. However, obtaining human\nhints is not always feasible and CNNs alone are not able to learn object-level\nsemantics unless multiple models pretrained with supervision are considered. In\nthis work, we propose a single network, named UCapsNet, that separate\nimage-level features obtained through convolutions and object-level features\ncaptured by means of capsules. Then, by skip connections over different layers,\nwe enforce collaboration between such disentangling factors to produce high\nquality and plausible image colourisation. We pose the problem as a\nclassification task that can be addressed by a fully self-supervised approach,\nthus requires no human effort. Experimental results on three benchmark datasets\nshow that our approach outperforms existing methods on standard quality metrics\nand achieves a state of the art performances on image colourisation. A large\nscale user study shows that our method is preferred over existing solutions.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07576",
		"pdf_url": "http://arxiv.org/pdf/2101.07576.pdf"
	},
	"1177": {
		"title": "Spatial Assembly: Generative Architecture With Reinforcement Learning,\n  Self Play and Tree Search",
		"creator": [
			"Tigas, Panagiotis",
			"Hosmer, Tyson"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Graphics",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  With this work, we investigate the use of Reinforcement Learning (RL) for the\ngeneration of spatial assemblies, by combining ideas from Procedural Generation\nalgorithms (Wave Function Collapse algorithm (WFC)) and RL for Game Solving.\nWFC is a Generative Design algorithm, inspired by Constraint Solving. In WFC,\none defines a set of tiles/blocks and constraints and the algorithm generates\nan assembly that satisfies these constraints. Casting the problem of generation\nof spatial assemblies as a Markov Decision Process whose states transitions are\ndefined by WFC, we propose an algorithm that uses Reinforcement Learning and\nSelf-Play to learn a policy that generates assemblies that maximize objectives\nset by the designer. Finally, we demonstrate the use of our Spatial Assembly\nalgorithm in Architecture Design.\n",
			"Comment: Workshop on Machine Learning for Creativity and Design at the 34rd\n  Conference on Neural Information Processing Systems (NeurIPS 2020)"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07579",
		"pdf_url": "http://arxiv.org/pdf/2101.07579.pdf"
	},
	"1178": {
		"title": "Continual Deterioration Prediction for Hospitalized COVID-19 Patients",
		"creator": [
			"Liu, Jiacheng",
			"Singh, Meghna",
			"Hill, Catherine ST.",
			"Raj, Vino",
			"Kirkland, Lisa",
			"Srivastava, Jaideep"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  Leading up to August 2020, COVID-19 has spread to almost every country in the\nworld, causing millions of infected and hundreds of thousands of deaths. In\nthis paper, we first verify the assumption that clinical variables could have\ntime-varying effects on COVID-19 outcomes. Then, we develop a temporal\nstratification approach to make daily predictions on patients' outcome at the\nend of hospital stay. Training data is segmented by the remaining length of\nstay, which is a proxy for the patient's overall condition. Based on this, a\nsequence of predictive models are built, one for each time segment. Thanks to\nthe publicly shared data, we were able to build and evaluate prototype models.\nPreliminary experiments show 0.98 AUROC, 0.91 F1 score and 0.97 AUPR on\ncontinuous deterioration prediction, encouraging further development of the\nmodel as well as validations on different datasets. We also verify the key\nassumption which motivates our method. Clinical variables could have\ntime-varying effects on COVID-19 outcomes. That is to say, the feature\nimportance of a variable in the predictive model varies at different disease\nstages.\n",
			"Comment: 8 pages, 11 figures. Submitted to JAMIA in OCT, 2020"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07581",
		"pdf_url": "http://arxiv.org/pdf/2101.07581.pdf"
	},
	"1179": {
		"title": "Fast Distributed Algorithms for Girth, Cycles and Small Subgraphs",
		"creator": [
			"Censor-Hillel, Keren",
			"Fischer, Orr",
			"Gonen, Tzlil",
			"Gall, François Le",
			"Leitersdorf, Dean",
			"Oshman, Rotem"
		],
		"subject": [
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Distributed, Parallel, and Cluster Computing"
		],
		"description": "  In this paper we give fast distributed graph algorithms for detecting and\nlisting small subgraphs, and for computing or approximating the girth. Our\nalgorithms improve upon the state of the art by polynomial factors, and for\ngirth, we obtain an constant-time algorithm for additive +1 approximation in\nthe Congested Clique, and the first parametrized algorithm for exact\ncomputation in CONGEST.\n  In the Congested Clique, we develop a technique for learning small\nneighborhoods, and apply it to obtain an $O(1)$-round algorithm that computes\nthe girth with only an additive +1 error. Next, we introduce a new technique\n(the partition tree technique) allowing for efficiently and deterministically\nlisting all copies of any subgraph, improving upon the state-of the-art for\nnon-dense graphs. We give two applications of this technique: First we show\nthat for constant $k$, $C_{2k}$-detection can be solved in $O(1)$ rounds in the\nCongested Clique, improving on prior work which used matrix multiplication and\nhad polynomial round complexity. Second, we show that in triangle-free graphs,\nthe girth can be exactly computed in time polynomially faster than the best\nknown bounds for general graphs.\n  In CONGEST, we describe a new approach for finding cycles, and apply it in\ntwo ways: first we show a fast parametrized algorithm for girth with round\ncomplexity $\\tilde{O}(\\min(g\\cdot n^{1-1/\\Theta(g)},n))$ for any girth $g$; and\nsecond, we show how to find small even-length cycles $C_{2k}$ for $k = 3,4,5$\nin $O(n^{1-1/k})$ rounds, which is a polynomial improvement upon the previous\nrunning times.\n  Finally, using our improved $C_6$-freeness algorithm and the barrier on\nproving lower bounds on triangle-freeness of Eden et al., we show that\nimproving the current $\\tilde\\Omega(\\sqrt{n})$ lower bound for $C_6$-freeness\nof Korhonen et al. by any polynomial factor would imply strong circuit\ncomplexity lower bounds.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07590",
		"pdf_url": "http://arxiv.org/pdf/2101.07590.pdf"
	},
	"1180": {
		"title": "Real-Time Limited-View CT Inpainting and Reconstruction with Dual Domain\n  Based on Spatial Information",
		"creator": [
			"Deng, Ken",
			"Sun, Chang",
			"Liu, Yitong",
			"Yang, Hongwen"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  Low-dose Computed Tomography is a common issue in reality. Current reduction,\nsparse sampling and limited-view scanning can all cause it. Between them,\nlimited-view CT is general in the industry due to inevitable mechanical and\nphysical limitation. However, limited-view CT can cause serious imaging problem\non account of its massive information loss. Thus, we should effectively utilize\nthe scant prior information to perform completion. It is an undeniable fact\nthat CT imaging slices are extremely dense, which leads to high continuity\nbetween successive images. We realized that fully exploit the spatial\ncorrelation between consecutive frames can significantly improve restoration\nresults in video inpainting. Inspired by this, we propose a deep learning-based\nthree-stage algorithm that hoist limited-view CT imaging quality based on\nspatial information. In stage one, to better utilize prior information in the\nRadon domain, we design an adversarial autoencoder to complement the Radon\ndata. In the second stage, a model is built to perform inpainting based on\nspatial continuity in the image domain. At this point, we have roughly restored\nthe imaging, while its texture still needs to be finely repaired. Hence, we\npropose a model to accurately restore the image in stage three, and finally\nachieve an ideal inpainting result. In addition, we adopt FBP instead of\nSART-TV to make our algorithm more suitable for real-time use. In the\nexperiment, we restore and reconstruct the Radon data that has been cut the\nrear one-third part, they achieve PSNR of 40.209, SSIM of 0.943, while\nprecisely present the texture.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07594",
		"pdf_url": "http://arxiv.org/pdf/2101.07594.pdf"
	},
	"1181": {
		"title": "Analysis and tuning of hierarchical topic models based on Renyi entropy\n  approach",
		"creator": [
			"Koltcov, Sergei",
			"Ignatenko, Vera",
			"Terpilovskii, Maxim",
			"Rosso, Paolo"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": "  Hierarchical topic modeling is a potentially powerful instrument for\ndetermining the topical structure of text collections that allows constructing\na topical hierarchy representing levels of topical abstraction. However, tuning\nof parameters of hierarchical models, including the number of topics on each\nhierarchical level, remains a challenging task and an open issue. In this\npaper, we propose a Renyi entropy-based approach for a partial solution to the\nabove problem. First, we propose a Renyi entropy-based metric of quality for\nhierarchical models. Second, we propose a practical concept of hierarchical\ntopic model tuning tested on datasets with human mark-up. In the numerical\nexperiments, we consider three different hierarchical models, namely,\nhierarchical latent Dirichlet allocation (hLDA) model, hierarchical Pachinko\nallocation model (hPAM), and hierarchical additive regularization of topic\nmodels (hARTM). We demonstrate that hLDA model possesses a significant level of\ninstability and, moreover, the derived numbers of topics are far away from the\ntrue numbers for labeled datasets. For hPAM model, the Renyi entropy approach\nallows us to determine only one level of the data structure. For hARTM model,\nthe proposed approach allows us to estimate the number of topics for two\nhierarchical levels.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07598",
		"pdf_url": "http://arxiv.org/pdf/2101.07598.pdf"
	},
	"1182": {
		"title": "Meta-Reinforcement Learning for Adaptive Motor Control in Changing Robot\n  Dynamics and Environments",
		"creator": [
			"Anne, Timothée",
			"Wilkinson, Jack",
			"Li, Zhibin"
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  This work developed a meta-learning approach that adapts the control policy\non the fly to different changing conditions for robust locomotion. The proposed\nmethod constantly updates the interaction model, samples feasible sequences of\nactions of estimated the state-action trajectories, and then applies the\noptimal actions to maximize the reward. To achieve online model adaptation, our\nproposed method learns different latent vectors of each training condition,\nwhich are selected online given the newly collected data. Our work designs\nappropriate state space and reward functions, and optimizes feasible actions in\nan MPC fashion which are then sampled directly in the joint space considering\nconstraints, hence requiring no prior design of specific walking gaits. We\nfurther demonstrate the robot's capability of detecting unexpected changes\nduring interaction and adapting control policies quickly. The extensive\nvalidation on the SpotMicro robot in a physics simulation shows adaptive and\nrobust locomotion skills under varying ground friction, external pushes, and\ndifferent robot models including hardware faults and changes.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07599",
		"pdf_url": "http://arxiv.org/pdf/2101.07599.pdf"
	},
	"1183": {
		"title": "Interpretable Models for Granger Causality Using Self-explaining Neural\n  Networks",
		"creator": [
			"Marcinkevičs, Ričards",
			"Vogt, Julia E."
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Exploratory analysis of time series data can yield a better understanding of\ncomplex dynamical systems. Granger causality is a practical framework for\nanalysing interactions in sequential data, applied in a wide range of domains.\nIn this paper, we propose a novel framework for inferring multivariate Granger\ncausality under nonlinear dynamics based on an extension of self-explaining\nneural networks. This framework is more interpretable than other\nneural-network-based techniques for inferring Granger causality, since in\naddition to relational inference, it also allows detecting signs of\nGranger-causal effects and inspecting their variability over time. In\ncomprehensive experiments on simulated data, we show that our framework\nperforms on par with several powerful baseline methods at inferring Granger\ncausality and that it achieves better performance at inferring interaction\nsigns. The results suggest that our framework is a viable and more\ninterpretable alternative to sparse-input neural networks for inferring Granger\ncausality.\n",
			"Comment: ICLR 2021"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07600",
		"pdf_url": "http://arxiv.org/pdf/2101.07600.pdf"
	},
	"1184": {
		"title": "Deep Learning Models for Calculation of Cardiothoracic Ratio from Chest\n  Radiographs for Assisted Diagnosis of Cardiomegaly",
		"creator": [
			"Gupte, Tanveer",
			"Niljikar, Mrunmai",
			"Gawali, Manish",
			"Kulkarni, Viraj",
			"Kharat, Amit",
			"Pant, Aniruddha"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  We propose an automated method based on deep learning to compute the\ncardiothoracic ratio and detect the presence of cardiomegaly from chest\nradiographs. We develop two separate models to demarcate the heart and chest\nregions in an X-ray image using bounding boxes and use their outputs to\ncalculate the cardiothoracic ratio. We obtain a sensitivity of 0.96 at a\nspecificity of 0.81 with a mean absolute error of 0.0209 on a held-out test\ndataset and a sensitivity of 0.84 at a specificity of 0.97 with a mean absolute\nerror of 0.018 on an independent dataset from a different hospital. We also\ncompare three different segmentation model architectures for the proposed\nmethod and observe that Attention U-Net yields better results than SE-Resnext\nU-Net and EfficientNet U-Net. By providing a numeric measurement of the\ncardiothoracic ratio, we hope to mitigate human subjectivity arising out of\nvisual assessment in the detection of cardiomegaly.\n",
			"Comment: 6 pages"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07606",
		"pdf_url": "http://arxiv.org/pdf/2101.07606.pdf"
	},
	"1185": {
		"title": "Chronological Citation Recommendation with Time Preference",
		"creator": [
			"Ma, Shutian",
			"Zhang, Heng",
			"Zhang, Chengzhi",
			"Liu, Xiaozhong"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Computation and Language",
			"H.3.3"
		],
		"description": "  Citation recommendation is an important task to assist scholars in finding\ncandidate literature to cite. Traditional studies focus on static models of\nrecommending citations, which do not explicitly distinguish differences between\npapers that are caused by temporal variations. Although, some researchers have\ninvestigated chronological citation recommendation by adding time related\nfunction or modeling textual topics dynamically. These solutions can hardly\ncope with function generalization or cold-start problems when there is no\ninformation for user profiling or there are isolated papers never being cited.\nWith the rise and fall of science paradigms, scientific topics tend to change\nand evolve over time. People would have the time preference when citing papers,\nsince most of the theoretical basis exist in classical readings that published\nin old time, while new techniques are proposed in more recent papers. To\nexplore chronological citation recommendation, this paper wants to predict the\ntime preference based on user queries, which is a probability distribution of\nciting papers published in different time slices. Then, we use this time\npreference to re-rank the initial citation list obtained by content-based\nfiltering. Experimental results demonstrate that task performance can be\nfurther enhanced by time preference and it's flexible to be added in other\ncitation recommendation frameworks.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07609",
		"pdf_url": "http://arxiv.org/pdf/2101.07609.pdf"
	},
	"1186": {
		"title": "Comparative Evaluation of 3D and 2D Deep Learning Techniques for\n  Semantic Segmentation in CT Scans",
		"creator": [
			"Shivdeo, Abhishek",
			"Lokwani, Rohit",
			"Kulkarni, Viraj",
			"Kharat, Amit",
			"Pant, Aniruddha"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Image segmentation plays a pivotal role in several medical-imaging\napplications by assisting the segmentation of the regions of interest. Deep\nlearning-based approaches have been widely adopted for semantic segmentation of\nmedical data. In recent years, in addition to 2D deep learning architectures,\n3D architectures have been employed as the predictive algorithms for 3D medical\nimage data. In this paper, we propose a 3D stack-based deep learning technique\nfor segmenting manifestations of consolidation and ground-glass opacities in 3D\nComputed Tomography (CT) scans. We also present a comparison based on the\nsegmentation results, the contextual information retained, and the inference\ntime between this 3D technique and a traditional 2D deep learning technique. We\nalso define the area-plot, which represents the peculiar pattern observed in\nthe slice-wise areas of the pathology regions predicted by these deep learning\nmodels. In our exhaustive evaluation, 3D technique performs better than the 2D\ntechnique for the segmentation of CT scans. We get dice scores of 79% and 73%\nfor the 3D and the 2D techniques respectively. The 3D technique results in a 5X\nreduction in the inference time compared to the 2D technique. Results also show\nthat the area-plots predicted by the 3D model are more similar to the ground\ntruth than those predicted by the 2D model. We also show how increasing the\namount of contextual information retained during the training can improve the\n3D model's performance.\n",
			"Comment: 9 pages"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07612",
		"pdf_url": "http://arxiv.org/pdf/2101.07612.pdf"
	},
	"1187": {
		"title": "A Lightweight Structure Aimed to Utilize Spatial Correlation for\n  Sparse-View CT Reconstruction",
		"creator": [
			"Liu, Yitong",
			"Deng, Ken",
			"Sun, Chang",
			"Yang, Hongwen"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  Sparse-view computed tomography (CT) is known as a widely used approach to\nreduce radiation dose while accelerating imaging through lowered projection\nviews and correlated calculations. However, its severe imaging noise and\nstreaking artifacts turn out to be a major issue in the low dose protocol. In\nthis paper, we propose a dual-domain deep learning-based method that breaks\nthrough the limitations of currently prevailing algorithms that merely process\nsingle image slices. Since the scanned object usually contains a high degree of\nspatial continuity, the obtained consecutive imaging slices embody rich\ninformation that is largely unexplored. Therefore, we establish a cascade model\nnamed LS-AAE which aims to tackle the above problem. In addition, in order to\nadapt to the social trend of lightweight medical care, our model adopts the\ninverted residual with linear bottleneck in the module design to make it mobile\nand lightweight (reduce model parameters to one-eighth of its original) without\nsacrificing its performance. In our experiments, sparse sampling is conducted\nat intervals of 4{\\deg}, 8{\\deg} and 16{\\deg}, which appears to be a\nchallenging sparsity that few scholars have attempted before. Nevertheless, our\nmethod still exhibits its robustness and achieves the state-of-the-art\nperformance by reaching the PSNR of 40.305 and the SSIM of 0.948, while\nensuring high model mobility. Particularly, it still exceeds other current\nmethods when the sampling rate is one-fourth of them, thereby demonstrating its\nremarkable superiority.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07613",
		"pdf_url": "http://arxiv.org/pdf/2101.07613.pdf"
	},
	"1188": {
		"title": "Characterizing References from Different Disciplines: A Perspective of\n  Citation Content Analysis",
		"creator": [
			"Zhang, Chengzhi",
			"Liu, Lifan",
			"Wang, Yuzhuo"
		],
		"subject": [
			"Computer Science - Digital Libraries",
			"Computer Science - Computation and Language",
			"H.3.7"
		],
		"description": "  Multidisciplinary cooperation is now common in research since social issues\ninevitably involve multiple disciplines. In research articles, reference\ninformation, especially citation content, is an important representation of\ncommunication among different disciplines. Analyzing the distribution\ncharacteristics of references from different disciplines in research articles\nis basic to detecting the sources of referred information and identifying\ncontributions of different disciplines. This work takes articles in PLoS as the\ndata and characterizes the references from different disciplines based on\nCitation Content Analysis (CCA). First, we download 210,334 full-text articles\nfrom PLoS and collect the information of the in-text citations. Then, we\nidentify the discipline of each reference in these academic articles. To\ncharacterize the distribution of these references, we analyze three\ncharacteristics, namely, the number of citations, the average cited intensity\nand the average citation length. Finally, we conclude that the distributions of\nreferences from different disciplines are significantly different. Although\nmost references come from Natural Science, Humanities and Social Sciences play\nimportant roles in the Introduction and Background sections of the articles.\nBasic disciplines, such as Mathematics, mainly provide research methods in the\narticles in PLoS. Citations mentioned in the Results and Discussion sections of\narticles are mainly in-discipline citations, such as citations from Nursing and\nMedicine in PLoS.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07614",
		"pdf_url": "http://arxiv.org/pdf/2101.07614.pdf"
	},
	"1189": {
		"title": "Human Action Recognition Based on Multi-scale Feature Maps from Depth\n  Video Sequences",
		"creator": [
			"Li, Chang",
			"Huang, Qian",
			"Li, Xing",
			"Wu, Qianhan"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Multimedia"
		],
		"description": [
			"  Human action recognition is an active research area in computer vision.\nAlthough great process has been made, previous methods mostly recognize actions\nbased on depth data at only one scale, and thus they often neglect multi-scale\nfeatures that provide additional information action recognition in practical\napplication scenarios. In this paper, we present a novel framework focusing on\nmulti-scale motion information to recognize human actions from depth video\nsequences. We propose a multi-scale feature map called Laplacian pyramid depth\nmotion images(LP-DMI). We employ depth motion images (DMI) as the templates to\ngenerate the multi-scale static representation of actions. Then, we caculate\nLP-DMI to enhance multi-scale dynamic information of motions and reduces\nredundant static information in human bodies. We further extract the\nmulti-granularity descriptor called LP-DMI-HOG to provide more discriminative\nfeatures. Finally, we utilize extreme learning machine (ELM) for action\nclassification. The proposed method yeilds the recognition accuracy of 93.41%,\n85.12%, 91.94% on public MSRAction3D dataset, UTD-MHAD and DHA dataset. Through\nextensive experiments, we prove that our method outperforms state-of-the-art\nbenchmarks.\n",
			"Comment: 20 pages, 7 figures"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07618",
		"pdf_url": "http://arxiv.org/pdf/2101.07618.pdf"
	},
	"1190": {
		"title": "Knowledge Graph for Microdata of Statistics Netherlands",
		"creator": "Sun, Chang",
		"subject": [
			"Computer Science - Digital Libraries",
			"Computer Science - Databases"
		],
		"description": "  Statistics Netherlands (CBS) hosted a huge amount of data not only on the\nstatistical level but also on the individual level. With the development of\ndata science technologies, more and more researchers request to conduct their\nresearch by using high-quality individual data from CBS (called CBS Microdata)\nor combining them with other data sources. Making great use of these data for\nresearch and scientific purposes can tremendously benefit the whole society.\nHowever, CBS Microdata has been collected and maintained in different ways by\ndifferent departments in and out of CBS. The representation, quality, metadata\nof datasets are not sufficiently harmonized. The project converts the\ndescriptions of all CBS microdata sets into one knowledge graph with\ncomprehensive metadata in Dutch and English using text mining and semantic web\ntechnologies. Researchers can easily query the metadata, explore the relations\namong multiple datasets, and find the needed variables. For example, if a\nresearcher searches a dataset about \"Age at Death\" in the Health and Well-being\ncategory, all information related to this dataset will appear including\nkeywords and variable names. \"Age at Death\" dataset has a keyword - \"Death\".\nThis keyword will lead to other datasets such as \"Date of Death\". \"Cause of\nDeath\", \"Production statistics Health and welfare\" from Population, Business\ncategories, and Health and well-being categories. This will tremendously save\ntime and costs for the data requester but also data maintainers.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07622",
		"pdf_url": "http://arxiv.org/pdf/2101.07622.pdf"
	},
	"1191": {
		"title": "Mirror-Descent Inverse Kinematics for Box-constrained Joint Space",
		"creator": "Kobayashi, Taisuke",
		"subject": "Computer Science - Robotics",
		"description": [
			"  This paper proposes a new Jacobian-based inverse kinematics (IK) explicitly\nconsidering box-constrained joint space. To control humanoid robots, the\nreference pose of end effector(s) is planned in task space, then mapped into\nthe reference joints by IK. Due to the limited analytical solutions for IK,\niterative numerical IK solvers based on Jacobian between task and joint spaces\nhave become popular. However, the conventional Jacobian-based IK does not\nexplicitly consider the joint constraints, and therefore, they usually clamp\nthe obtained joints during iteration according to the constraints in practice.\nThe problem in clamping operation has been pointed out that it causes numerical\ninstability due to non-smoothed objective function. To alleviate the clamping\nproblem, this study explicitly considers the joint constraints, especially the\nbox constraints in this paper, inside the new IK solver. Specifically, instead\nof clamping, a mirror descent (MD) method with box-constrained real joint space\nand no-constrained mirror space is integrated with the conventional\nJacobian-based IK methods, so-called MD-IK. In addition, to escape local optima\nnearly on the boundaries of constraints, a heuristic technique, called\n$\\epsilon$-clamping, is implemented as margin in software level. As a result,\nMD-IK achieved more stable and enough fast i) regulation on the random\nreference poses and ii) tracking to the random trajectories compared to the\nconventional IK solvers.\n",
			"Comment: 7 pages, 6 figures"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07625",
		"pdf_url": "http://arxiv.org/pdf/2101.07625.pdf"
	},
	"1192": {
		"title": "Self-Organizing Intelligent Matter: A blueprint for an AI generating\n  algorithm",
		"creator": [
			"Gregor, Karol",
			"Besse, Frederic"
		],
		"subject": "Computer Science - Neural and Evolutionary Computing",
		"description": [
			"  We propose an artificial life framework aimed at facilitating the emergence\nof intelligent organisms. In this framework there is no explicit notion of an\nagent: instead there is an environment made of atomic elements. These elements\ncontain neural operations and interact through exchanges of information and\nthrough physics-like rules contained in the environment. We discuss how an\nevolutionary process can lead to the emergence of different organisms made of\nmany such atomic elements which can coexist and thrive in the environment. We\ndiscuss how this forms the basis of a general AI generating algorithm. We\nprovide a simplified implementation of such system and discuss what advances\nneed to be made to scale it up further.\n",
			"Comment: 13 pages, 2 figures"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07627",
		"pdf_url": "http://arxiv.org/pdf/2101.07627.pdf"
	},
	"1193": {
		"title": "A family of codes with locality containing optimal codes",
		"creator": [
			"Andrade, Bruno",
			"Carvalho, Cícero",
			"Neumann, Victor G. L.",
			"Veiga, Antônio C. P."
		],
		"subject": [
			"Computer Science - Information Theory",
			"Mathematics - Algebraic Geometry",
			"11T71, 94B27, 14G50"
		],
		"description": "  Locally recoverable codes were introduced by Gopalan et al. in 2012, and in\nthe same year Prakash et al. introduced the concept of codes with locality,\nwhich are a type of locally recoverable codes. In this work we introduce a new\nfamily of codes with locality, which are subcodes of a certain family of\nevaluation codes. We determine the dimension of these codes, and also bounds\nfor the minimum distance. We present the true values of the minimum distance in\nspecial cases, and also show that elements of this family are \"optimal codes\",\nas defined by Prakash et al.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07629",
		"pdf_url": "http://arxiv.org/pdf/2101.07629.pdf"
	},
	"1194": {
		"title": "A Note on Order and Index Reduction for Descriptor Systems",
		"creator": [
			"Corless, Martin",
			"Shorten, Robert"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  We present order reduction results for linear time invariant descriptor\nsystems. Results are given for both forced and unforced systems as well methods\nfor constructing the reduced order systems. Our results establish a precise\nconnection between classical and new results on this topic, and lead to an\nelementary construction of quasi-Weierstrass forms for a descriptor system.\nExamples are given to illustrate the usefulness of our results.\n",
			"Comment: None"
		],
		"date": "2021-01-18",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07649",
		"pdf_url": "http://arxiv.org/pdf/2101.07649.pdf"
	},
	"1195": {
		"title": "Improve Global Glomerulosclerosis Classification with Imbalanced Data\n  using CircleMix Augmentation",
		"creator": [
			"Lu, Yuzhe",
			"Yang, Haichun",
			"Zhu, Zheyu",
			"Deng, Ruining",
			"Fogo, Agnes B.",
			"Huo, Yuankai"
		],
		"subject": [
			"Quantitative Biology - Quantitative Methods",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": "  The classification of glomerular lesions is a routine and essential task in\nrenal pathology. Recently, machine learning approaches, especially deep\nlearning algorithms, have been used to perform computer-aided lesion\ncharacterization of glomeruli. However, one major challenge of developing such\nmethods is the naturally imbalanced distribution of different lesions. In this\npaper, we propose CircleMix, a novel data augmentation technique, to improve\nthe accuracy of classifying globally sclerotic glomeruli with a hierarchical\nlearning strategy. Different from the recently proposed CutMix method, the\nCircleMix augmentation is optimized for the ball-shaped biomedical objects,\nsuch as glomeruli. 6,861 glomeruli with five classes (normal, periglomerular\nfibrosis, obsolescent glomerulosclerosis, solidified glomerulosclerosis, and\ndisappearing glomerulosclerosis) were employed to develop and evaluate the\nproposed methods. From five-fold cross-validation, the proposed CircleMix\naugmentation achieved superior performance (Balanced Accuracy=73.0%) compared\nwith the EfficientNet-B0 baseline (Balanced Accuracy=69.4%)\n",
		"date": "2021-01-16",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07654",
		"pdf_url": "http://arxiv.org/pdf/2101.07654.pdf"
	},
	"1196": {
		"title": "A Novel Cluster Classify Regress Model Predictive Controller\n  Formulation; CCR-MPC",
		"creator": [
			"Etienam, Clement",
			"Shen, Siying",
			"O'Dwyer, Edward J",
			"Sykes, Joshua"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Computer Science - Machine Learning"
		],
		"description": "  In this work, we develop a novel data-driven model predictive controller\nusing advanced techniques in the field of machine learning. The objective is to\nregulate control signals to adjust the desired internal room setpoint\ntemperature, affected indirectly by the external weather states. The\nmethodology involves developing a time-series machine learning model with\neither a Long Short Term Memory model (LSTM) or a Gradient Boosting Algorithm\n(XGboost), capable of forecasting this weather states for any desired time\nhorizon and concurrently optimising the control signals to the desired set\npoint. The supervised learning model for mapping the weather states together\nwith the control signals to the room temperature is constructed using a\npreviously developed methodology called Cluster Classify regress (CCR), which\nis similar in style but scales better to high dimensional dataset than the\nwell-known Mixture-of-Experts. The overall method called CCR-MPC involves a\ncombination of a time series model for weather states prediction, CCR for\nforwarding and any numerical optimisation method for solving the inverse\nproblem. Forward uncertainty quantification (Forward-UQ) leans towards the\nregression model in the CCR and is attainable using a Bayesian deep neural\nnetwork or a Gaussian process (GP). For this work, in the CCR modulation, we\nemploy K-means clustering for Clustering, XGboost classifier for Classification\nand 5th order polynomial regression for Regression. Inverse UQ can also be\nobtained by using an I-ES approach for solving the inverse problem or even the\nwell-known Markov chain Monte Carlo (MCMC) approach. The developed CCR-MPC is\nelegant, and as seen on the numerical experiments is able to optimise the\ncontroller to attain the desired setpoint temperature.\n",
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07655",
		"pdf_url": "http://arxiv.org/pdf/2101.07655.pdf"
	},
	"1197": {
		"title": "Analysis of Moral Judgement on Reddit",
		"creator": [
			"Botzer, Nicholas",
			"Gu, Shawn",
			"Weninger, Tim"
		],
		"subject": "Computer Science - Social and Information Networks",
		"description": [
			"  Moral outrage has become synonymous with social media in recent years.\nHowever, the preponderance of academic analysis on social media websites has\nfocused on hate speech and misinformation. This paper focuses on analyzing\nmoral judgements rendered on social media by capturing the moral judgements\nthat are passed in the subreddit /r/AmITheAsshole on Reddit. Using the labels\nassociated with each judgement we train a classifier that can take a comment\nand determine whether it judges the user who made the original post to have\npositive or negative moral valence. Then, we use this classifier to investigate\nan assortment of website traits surrounding moral judgements in ten other\nsubreddits, including where negative moral users like to post and their posting\npatterns. Our findings also indicate that posts that are judged in a positive\nmanner will score higher.\n",
			"Comment: Submitted to ICWSM 2021, 9 pages and 6 figures"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07664",
		"pdf_url": "http://arxiv.org/pdf/2101.07664.pdf"
	},
	"1198": {
		"title": "Few-Shot Bayesian Optimization with Deep Kernel Surrogates",
		"creator": [
			"Wistuba, Martin",
			"Grabocka, Josif"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  Hyperparameter optimization (HPO) is a central pillar in the automation of\nmachine learning solutions and is mainly performed via Bayesian optimization,\nwhere a parametric surrogate is learned to approximate the black box response\nfunction (e.g. validation error). Unfortunately, evaluating the response\nfunction is computationally intensive. As a remedy, earlier work emphasizes the\nneed for transfer learning surrogates which learn to optimize hyperparameters\nfor an algorithm from other tasks. In contrast to previous work, we propose to\nrethink HPO as a few-shot learning problem in which we train a shared deep\nsurrogate model to quickly adapt (with few response evaluations) to the\nresponse function of a new task. We propose the use of a deep kernel network\nfor a Gaussian process surrogate that is meta-learned in an end-to-end fashion\nin order to jointly approximate the response functions of a collection of\ntraining data sets. As a result, the novel few-shot optimization of our deep\nkernel surrogate leads to new state-of-the-art results at HPO compared to\nseveral recent methods on diverse metadata sets.\n",
			"Comment: Published as a conference paper at ICLR 2021"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07667",
		"pdf_url": "http://arxiv.org/pdf/2101.07667.pdf"
	},
	"1199": {
		"title": "Challenges for Computational Lexical Semantic Change",
		"creator": [
			"Hengchen, Simon",
			"Tahmasebi, Nina",
			"Schlechtweg, Dominik",
			"Dubossarsky, Haim"
		],
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  The computational study of lexical semantic change (LSC) has taken off in the\npast few years and we are seeing increasing interest in the field, from both\ncomputational sciences and linguistics. Most of the research so far has focused\non methods for modelling and detecting semantic change using large diachronic\ntextual data, with the majority of the approaches employing neural embeddings.\nWhile methods that offer easy modelling of diachronic text are one of the main\nreasons for the spiking interest in LSC, neural models leave many aspects of\nthe problem unsolved. The field has several open and complex challenges. In\nthis chapter, we aim to describe the most important of these challenges and\noutline future directions.\n",
			"Comment: To appear in: Nina Tahmasebi, Lars Borin, Adam Jatowt, Yang Xu, Simon\n  Hengchen (eds). Computational Approaches to Semantic Change. Berlin: Language\n  Science Press. [preliminary page numbering]"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07668",
		"pdf_url": "http://arxiv.org/pdf/2101.07668.pdf"
	},
	"1200": {
		"title": "A framework to compare music generative models using automatic\n  evaluation metrics extended to rhythm",
		"creator": [
			"Garcia-Valencia, Sebastian",
			"Betancourt, Alejandro",
			"Lalinde-Pulido, Juan G."
		],
		"subject": [
			"Computer Science - Sound",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Audio and Speech Processing"
		],
		"description": [
			"  To train a machine learning model is necessary to take numerous decisions\nabout many options for each process involved, in the field of sequence\ngeneration and more specifically of music composition, the nature of the\nproblem helps to narrow the options but at the same time, some other options\nappear for specific challenges. This paper takes the framework proposed in a\nprevious research that did not consider rhythm to make a series of design\ndecisions, then, rhythm support is added to evaluate the performance of two RNN\nmemory cells in the creation of monophonic music. The model considers the\nhandling of music transposition and the framework evaluates the quality of the\ngenerated pieces using automatic quantitative metrics based on geometry which\nhave rhythm support added as well.\n",
			"Comment: arXiv admin note: substantial text overlap with arXiv:2012.01231"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07669",
		"pdf_url": "http://arxiv.org/pdf/2101.07669.pdf"
	},
	"1201": {
		"title": "Edge-Featured Graph Attention Network",
		"creator": [
			"Chen, Jun",
			"Chen, Haopeng"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  Lots of neural network architectures have been proposed to deal with learning\ntasks on graph-structured data. However, most of these models concentrate on\nonly node features during the learning process. The edge features, which\nusually play a similarly important role as the nodes, are often ignored or\nsimplified by these models. In this paper, we present edge-featured graph\nattention networks, namely EGATs, to extend the use of graph neural networks to\nthose tasks learning on graphs with both node and edge features. These models\ncan be regarded as extensions of graph attention networks (GATs). By reforming\nthe model structure and the learning process, the new models can accept node\nand edge features as inputs, incorporate the edge information into feature\nrepresentations, and iterate both node and edge features in a parallel but\nmutual way. The results demonstrate that our work is highly competitive against\nother node classification approaches, and can be well applied in edge-featured\ngraph learning tasks.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07671",
		"pdf_url": "http://arxiv.org/pdf/2101.07671.pdf"
	},
	"1202": {
		"title": "COTORRA: COntext-aware Testbed fOR Robotic Applications",
		"creator": [
			"Groshev, Milan",
			"Martín-Pérez, Jorge",
			"Antevski, Kiril",
			"de la Oliva, Antonio",
			"Bernardos, Carlos J."
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Networking and Internet Architecture"
		],
		"description": [
			"  Edge & Fog computing have received considerable attention as promising\ncandidates for the evolution of robotic systems. In this letter, we propose\nCOTORRA, an Edge & Fog driven robotic testbed that combines context information\nwith robot sensor data to validate innovative concepts for robotic systems\nprior to being applied in a production environment. In lab/university, we\nestablished COTORRA as an easy applicable and modular testbed on top of\nheterogeneous network infrastructure. COTORRA is open for pluggable robotic\napplications. To verify its feasibility and assess its performance, we ran set\nof experiments that show how autonomous navigation applications can achieve\ntarget latencies bellow 15ms or perform an inter-domain (DLT) federation within\n19 seconds.\n",
			"Comment: 4 pages, 4 figures, submitted to IEEE Communications Letters"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07676",
		"pdf_url": "http://arxiv.org/pdf/2101.07676.pdf"
	},
	"1203": {
		"title": "The Six Hug Commandments: Design and Evaluation of a Human-Sized Hugging\n  Robot with Visual and Haptic Perception",
		"creator": [
			"Block, Alexis E.",
			"Christen, Sammy",
			"Gassert, Roger",
			"Hilliges, Otmar",
			"Kuchenbecker, Katherine J."
		],
		"subject": "Computer Science - Robotics",
		"description": [
			"  Receiving a hug is one of the best ways to feel socially supported, and the\nlack of social touch can have severe negative effects on an individual's\nwell-being. Based on previous research both within and outside of HRI, we\npropose six tenets (\"commandments\") of natural and enjoyable robotic hugging: a\nhugging robot should be soft, be warm, be human sized, visually perceive its\nuser, adjust its embrace to the user's size and position, and reliably release\nwhen the user wants to end the hug. Prior work validated the first two tenets,\nand the final four are new. We followed all six tenets to create a new robotic\nplatform, HuggieBot 2.0, that has a soft, warm, inflated body (HuggieChest) and\nuses visual and haptic sensing to deliver closed-loop hugging. We first\nverified the outward appeal of this platform in comparison to the previous\nPR2-based HuggieBot 1.0 via an online video-watching study involving 117 users.\nWe then conducted an in-person experiment in which 32 users each exchanged\neight hugs with HuggieBot 2.0, experiencing all combinations of visual hug\ninitiation, haptic sizing, and haptic releasing. The results show that adding\nhaptic reactivity definitively improves user perception a hugging robot,\nlargely verifying our four new tenets and illuminating several interesting\nopportunities for further improvement.\n",
			"Comment: 9 pages, 6 Figures, 2 Tables, ACM/IEEE Human-Robot Interaction (HRI)\n  Conference 2021"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07679",
			"doi:10.1145/3434073.3444656"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07679.pdf"
	},
	"1204": {
		"title": "Utilizing Import Vector Machines to Identify Dangerous Pro-active\n  Traffic Conditions",
		"creator": [
			"Yang, Kui",
			"Zhao, Wenjing",
			"Antoniou, Constantinos"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning",
			"Statistics - Applications"
		],
		"description": [
			"  Traffic accidents have been a severe issue in metropolises with the\ndevelopment of traffic flow. This paper explores the theory and application of\na recently developed machine learning technique, namely Import Vector Machines\n(IVMs), in real-time crash risk analysis, which is a hot topic to reduce\ntraffic accidents. Historical crash data and corresponding traffic data from\nShanghai Urban Expressway System were employed and matched. Traffic conditions\nare labelled as dangerous (i.e. probably leading to a crash) and safe (i.e. a\nnormal traffic condition) based on 5-minute measurements of average speed,\nvolume and occupancy. The IVM algorithm is trained to build the classifier and\nits performance is compared to the popular and successfully applied technique\nof Support Vector Machines (SVMs). The main findings indicate that IVMs could\nsuccessfully be employed in real-time identification of dangerous pro-active\ntraffic conditions. Furthermore, similar to the \"support points\" of the SVM,\nthe IVM model uses only a fraction of the training data to index kernel basis\nfunctions, typically a much smaller fraction than the SVM, and its\nclassification rates are similar to those of SVMs. This gives the IVM a\ncomputational advantage over the SVM, especially when the size of the training\ndata set is large.\n",
			"Comment: 6 pages, 3 figures, 2020 IEEE 23rd International Conference on\n  Intelligent Transportation Systems (ITSC)"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07683",
			"In 2020 IEEE 23rd International Conference on Intelligent\n  Transportation Systems (ITSC) (pp. 1-6). IEEE",
			"doi:10.1109/ITSC45102.2020.9294284"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07683.pdf"
	},
	"1205": {
		"title": "Choice Set Misspecification in Reward Inference",
		"creator": [
			"Freedman, Rachel",
			"Shah, Rohin",
			"Dragan, Anca"
		],
		"subject": [
			"Computer Science - Artificial Intelligence",
			"Computer Science - Human-Computer Interaction"
		],
		"description": [
			"  Specifying reward functions for robots that operate in environments without a\nnatural reward signal can be challenging, and incorrectly specified rewards can\nincentivise degenerate or dangerous behavior. A promising alternative to\nmanually specifying reward functions is to enable robots to infer them from\nhuman feedback, like demonstrations or corrections. To interpret this feedback,\nrobots treat as approximately optimal a choice the person makes from a choice\nset, like the set of possible trajectories they could have demonstrated or\npossible corrections they could have made. In this work, we introduce the idea\nthat the choice set itself might be difficult to specify, and analyze choice\nset misspecification: what happens as the robot makes incorrect assumptions\nabout the set of choices from which the human selects their feedback. We\npropose a classification of different kinds of choice set misspecification, and\nshow that these different classes lead to meaningful differences in the\ninferred reward and resulting performance. While we would normally expect\nmisspecification to hurt, we find that certain kinds of misspecification are\nneither helpful nor harmful (in expectation). However, in other situations,\nmisspecification can be extremely harmful, leading the robot to believe the\nopposite of what it should believe. We hope our results will allow for better\nprediction and response to the effects of misspecification in real-world reward\ninference.\n",
			"Comment: Presented at the IJCAI-PRICAI 2020 Workshop on Artificial\n  Intelligence Safety"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07691",
		"pdf_url": "http://arxiv.org/pdf/2101.07691.pdf"
	},
	"1206": {
		"title": "Twitter Subjective Well-Being Indicator During COVID-19 Pandemic: A\n  Cross-Country Comparative Study",
		"creator": [
			"Carpi, Tiziana",
			"Hino, Airo",
			"Iacus, Stefano Maria",
			"Porro, Giuseppe"
		],
		"subject": [
			"Economics - General Economics",
			"Computer Science - Computation and Language",
			"Statistics - Applications"
		],
		"description": "  This study analyzes the impact of the COVID-19 pandemic on the subjective\nwell-being as measured through Twitter data indicators for Japan and Italy. It\nturns out that, overall, the subjective well-being dropped by 11.7% for Italy\nand 8.3% for Japan in the first nine months of 2020 compared to the last two\nmonths of 2019 and even more compared to the historical mean of the indexes.\nThrough a data science approach we try to identify the possible causes of this\ndrop down by considering several explanatory variables including, climate and\nair quality data, number of COVID-19 cases and deaths, Facebook Covid and flu\nsymptoms global survey, Google Trends data and coronavirus-related searches,\nGoogle mobility data, policy intervention measures, economic variables and\ntheir Google Trends proxies, as well as health and stress proxy variables based\non big data. We show that a simple static regression model is not able to\ncapture the complexity of well-being and therefore we propose a dynamic elastic\nnet approach to show how different group of factors may impact the well-being\nin different periods, even over a short time length, and showing further\ncountry-specific aspects. Finally, a structural equation modeling analysis\ntries to address the causal relationships among the COVID-19 factors and\nsubjective well-being showing that, overall, prolonged mobility\nrestrictions,flu and Covid-like symptoms, economic uncertainty, social\ndistancing and news about the pandemic have negative effects on the subjective\nwell-being.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07695",
		"pdf_url": "http://arxiv.org/pdf/2101.07695.pdf"
	},
	"1207": {
		"title": "Proof Automation in the Theory of Finite Sets and Finite Set Relation\n  Algebra",
		"creator": [
			"Cristiá, Maximiliano",
			"Katz, Ricardo D.",
			"Rossi, Gianfranco"
		],
		"subject": "Computer Science - Logic in Computer Science",
		"description": "  {log} ('setlog') is a satisfiability solver for formulas of the theory of\nfinite sets and finite set relation algebra (FSTRA). As such, it can be used as\nan automated theorem prover (ATP) for this theory. {log} is able to\nautomatically prove a number of FSTRA theorems, but not all of them.\nNevertheless, we have observed that many theorems that {log} cannot\nautomatically prove can be divided into a few subgoals automatically\ndischargeable by {log}. The purpose of this work is to present a prototype\ninteractive theorem prover (ITP), called {log}-ITP, providing evidence that a\nproper integration of {log} into world-class ITP's can deliver a great deal of\nproof automation concerning FSTRA. An empirical evaluation based on 210\ntheorems from the TPTP and Coq's SSReflect libraries shows a noticeable\nreduction in the size and complexity of the proofs with respect to Coq.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07700",
		"pdf_url": "http://arxiv.org/pdf/2101.07700.pdf"
	},
	"1208": {
		"title": "Computing the exact number of periodic orbits for planar flows",
		"creator": [
			"Graça, Daniel S.",
			"Zhong, Ning"
		],
		"subject": [
			"Mathematics - Dynamical Systems",
			"Computer Science - Logic in Computer Science",
			"Mathematics - Logic",
			"03D78 (Primary) 34C07 (Secondary)",
			"F.1.1",
			"F.4.1"
		],
		"description": "  In this paper, we consider the problem of determining the \\emph{exact} number\nof periodic orbits for polynomial planar flows. This problem is a variant of\nHilbert's 16th problem. Using a natural definition of computability, we show\nthat the problem is noncomputable on the one hand and, on the other hand,\ncomputable uniformly on the set of all structurally stable systems defined on\nthe unit disk. We also prove that there is a family of polynomial planar\nsystems which does not have a computable sharp upper bound on the number of its\nperiodic orbits.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07701",
		"pdf_url": "http://arxiv.org/pdf/2101.07701.pdf"
	},
	"1209": {
		"title": "Communication-Efficient Sampling for Distributed Training of Graph\n  Convolutional Networks",
		"creator": [
			"Jiang, Peng",
			"Rumi, Masuma Akter"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Training Graph Convolutional Networks (GCNs) is expensive as it needs to\naggregate data recursively from neighboring nodes. To reduce the computation\noverhead, previous works have proposed various neighbor sampling methods that\nestimate the aggregation result based on a small number of sampled neighbors.\nAlthough these methods have successfully accelerated the training, they mainly\nfocus on the single-machine setting. As real-world graphs are large, training\nGCNs in distributed systems is desirable. However, we found that the existing\nneighbor sampling methods do not work well in a distributed setting.\nSpecifically, a naive implementation may incur a huge amount of communication\nof feature vectors among different machines. To address this problem, we\npropose a communication-efficient neighbor sampling method in this work. Our\nmain idea is to assign higher sampling probabilities to the local nodes so that\nremote nodes are accessed less frequently. We present an algorithm that\ndetermines the local sampling probabilities and makes sure our skewed neighbor\nsampling does not affect much the convergence of the training. Our experiments\nwith node classification benchmarks show that our method significantly reduces\nthe communication overhead for distributed GCN training with little accuracy\nloss.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07706",
		"pdf_url": "http://arxiv.org/pdf/2101.07706.pdf"
	},
	"1210": {
		"title": "Leveraging Peer Review in Visualization Education: A Proposal for a New\n  Model",
		"creator": [
			"Friedman, Alon",
			"Rosen, Paul"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": "  In visualization education, both science and humanities, the literature is\noften divided into two parts: the design aspect and the analysis of the\nvisualization. However, we find limited discussion on how to motivate and\nengage visualization students in the classroom. In the field of Writing\nStudies, researchers develop tools and frameworks for student peer review of\nwriting. Based on the literature review from the field of Writing Studies, this\npaper proposes a new framework to implement visualization peer review in the\nclassroom to engage today's students. This framework can be customized for\nincremental and double-blind review to inspire students and reinforce critical\nthinking about visualization.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07708",
			"Pedagogy Data Visualization Workshop @ IEEE VIS, 2017"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07708.pdf"
	},
	"1211": {
		"title": "Image Denoising using Attention-Residual Convolutional Neural Networks",
		"creator": [
			"Pires, Rafael G.",
			"Santos, Daniel F. S.",
			"Santana, Marcos C. S.",
			"Santos, Claudio F. G.",
			"Papa, Joao P."
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  During the image acquisition process, noise is usually added to the data\nmainly due to physical limitations of the acquisition sensor, and also\nregarding imprecisions during the data transmission and manipulation. In that\nsense, the resultant image needs to be processed to attenuate its noise without\nlosing details. Non-learning-based strategies such as filter-based and noise\nprior modeling have been adopted to solve the image denoising problem.\nNowadays, learning-based denoising techniques showed to be much more effective\nand flexible approaches, such as Residual Convolutional Neural Networks. Here,\nwe propose a new learning-based non-blind denoising technique named Attention\nResidual Convolutional Neural Network (ARCNN), and its extension to blind\ndenoising named Flexible Attention Residual Convolutional Neural Network\n(FARCNN). The proposed methods try to learn the underlying noise expectation\nusing an Attention-Residual mechanism. Experiments on public datasets corrupted\nby different levels of Gaussian and Poisson noise support the effectiveness of\nthe proposed approaches against some state-of-the-art image denoising methods.\nARCNN achieved an overall average PSNR results of around 0.44dB and 0.96dB for\nGaussian and Poisson denoising, respectively FARCNN presented very consistent\nresults, even with slightly worsen performance compared to ARCNN.\n",
			"Comment: Published in: 2020 33rd SIBGRAPI Conference on Graphics, Patterns and\n  Images (SIBGRAPI)"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07713",
			"doi:10.1109/SIBGRAPI51738.2020.00022"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07713.pdf"
	},
	"1212": {
		"title": "Meningioma segmentation in T1-weighted MRI leveraging global context and\n  attention mechanisms",
		"creator": [
			"Bouget, David",
			"Pedersen, André",
			"Hosainey, Sayied Abdol Mohieb",
			"Solheim, Ole",
			"Reinertsen, Ingerid"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"I.4.6",
			"J.3"
		],
		"description": [
			"  Meningiomas are the most common type of primary brain tumor, accounting for\napproximately 30% of all brain tumors. A substantial number of these tumors are\nnever surgically removed but rather monitored over time. Automatic and precise\nmeningioma segmentation is therefore beneficial to enable reliable growth\nestimation and patient-specific treatment planning. In this study, we propose\nthe inclusion of attention mechanisms over a U-Net architecture: (i)\nAttention-gated U-Net (AGUNet) and (ii) Dual Attention U-Net (DAUNet), using a\n3D MRI volume as input. Attention has the potential to leverage the global\ncontext and identify features' relationships across the entire volume. To limit\nspatial resolution degradation and loss of detail inherent to encoder-decoder\narchitectures, we studied the impact of multi-scale input and deep supervision\ncomponents. The proposed architectures are trainable end-to-end and each\nconcept can be seamlessly disabled for ablation studies. The validation studies\nwere performed using a 5-fold cross validation over 600 T1-weighted MRI volumes\nfrom St. Olavs University Hospital, Trondheim, Norway. For the best performing\narchitecture, an average Dice score of 81.6% was reached for an F1-score of\n95.6%. With an almost perfect precision of 98%, meningiomas smaller than 3ml\nwere occasionally missed hence reaching an overall recall of 93%. Leveraging\nglobal context from a 3D MRI volume provided the best performances, even if the\nnative volume resolution could not be processed directly. Overall, near-perfect\ndetection was achieved for meningiomas larger than 3ml which is relevant for\nclinical use. In the future, the use of multi-scale designs and refinement\nnetworks should be further investigated to improve the performance. A larger\nnumber of cases with meningiomas below 3ml might also be needed to improve the\nperformance for the smallest tumors.\n",
			"Comment: 16 pages, 5 figures, 3 tables. Submitted to Artificial Intelligence\n  in Medicine"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07715",
		"pdf_url": "http://arxiv.org/pdf/2101.07715.pdf"
	},
	"1213": {
		"title": "Predicting Pneumonia and Region Detection from X-Ray Images using Deep\n  Neural Network",
		"creator": [
			"Hossain, Sheikh Md Hanif",
			"Raju, S M",
			"Ismail, Amelia Ritahani"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"68T07 (Primary), 68T45 (Secondary)",
			"I.2.6",
			"I.2.10"
		],
		"description": [
			"  Biomedical images are increasing drastically. Along the way, many machine\nlearning algorithms have been proposed to predict and identify various kinds of\ndiseases. One such disease is Pneumonia which is an infection caused by both\nbacteria and viruses through the inflammation of a person's lung air sacs. In\nthis paper, an algorithm was proposed that receives x-ray images as input and\nverifies whether this patient is infected by Pneumonia as well as specific\nregion of the lungs that the inflammation has occurred at. The algorithm is\nbased on the transfer learning mechanism where pre-trained ResNet-50\n(Convolutional Neural Network) was used followed by some custom layer for\nmaking the prediction. The model has achieved an accuracy of 90.6 percent which\nconfirms that the model is effective and can be implemented for the detection\nof Pneumonia in patients. Furthermore, a class activation map is used for the\ndetection of the infected region in the lungs. Also, PneuNet was developed so\nthat users can access more easily and use the services.\n",
			"Comment: 5 figures, 4 pages"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07717",
		"pdf_url": "http://arxiv.org/pdf/2101.07717.pdf"
	},
	"1214": {
		"title": "Deep Feedback Inverse Problem Solver",
		"creator": [
			"Ma, Wei-Chiu",
			"Wang, Shenlong",
			"Gu, Jiayuan",
			"Manivasagam, Sivabalan",
			"Torralba, Antonio",
			"Urtasun, Raquel"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Robotics"
		],
		"description": [
			"  We present an efficient, effective, and generic approach towards solving\ninverse problems. The key idea is to leverage the feedback signal provided by\nthe forward process and learn an iterative update model. Specifically, at each\niteration, the neural network takes the feedback as input and outputs an update\non the current estimation. Our approach does not have any restrictions on the\nforward process; it does not require any prior knowledge either. Through the\nfeedback information, our model not only can produce accurate estimations that\nare coherent to the input observation but also is capable of recovering from\nearly incorrect predictions. We verify the performance of our approach over a\nwide range of inverse problems, including 6-DOF pose estimation, illumination\nestimation, as well as inverse kinematics. Comparing to traditional\noptimization-based methods, we can achieve comparable or better performance\nwhile being two to three orders of magnitude faster. Compared to deep\nlearning-based approaches, our model consistently improves the performance on\nall metrics. Please refer to the project page for videos, animations,\nsupplementary materials, etc.\n",
			"Comment: ECCV 2020 Spotlight"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07719",
		"pdf_url": "http://arxiv.org/pdf/2101.07719.pdf"
	},
	"1215": {
		"title": "Hyperdimensional computing as a framework for systematic aggregation of\n  image descriptors",
		"creator": [
			"Neubert, Peer",
			"Schubert, Stefan"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Robotics"
		],
		"description": "  Image and video descriptors are an omnipresent tool in computer vision and\nits application fields like mobile robotics. Many hand-crafted and in\nparticular learned image descriptors are numerical vectors with a potentially\n(very) large number of dimensions. Practical considerations like memory\nconsumption or time for comparisons call for the creation of compact\nrepresentations. In this paper, we use hyperdimensional computing (HDC) as an\napproach to systematically combine information from a set of vectors in a\nsingle vector of the same dimensionality. HDC is a known technique to perform\nsymbolic processing with distributed representation in numerical vectors with\nthousands of dimensions. We present a HDC implementation that is suitable for\nprocessing the output of existing and future (deep-learning based) image\ndescriptors. We discuss how this can be used as a framework to process\ndescriptors together with additional knowledge by simple and fast vector\noperations. A concrete outcome is a novel HDC-based approach to aggregate a set\nof local image descriptors together with their image positions in a single\nholistic descriptor. The comparison to available holistic descriptors and\naggregation methods on a series of standard mobile robotics place recognition\nexperiments shows a 20% improvement in average performance compared to\nrunner-up and 3.6x better worst-case performance.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07720",
		"pdf_url": "http://arxiv.org/pdf/2101.07720.pdf"
	},
	"1216": {
		"title": "A survey on shape-constraint deep learning for medical image\n  segmentation",
		"creator": [
			"Bohlender, Simon",
			"Oksuz, Ilkay",
			"Mukhopadhyay, Anirban"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  Since the advent of U-Net, fully convolutional deep neural networks and its\nmany variants have completely changed the modern landscape of deep learning\nbased medical image segmentation. However, the over dependence of these methods\non pixel level classification and regression has been identified early on as a\nproblem. Especially when trained on medical databases with sparse available\nannotation, these methods are prone to generate segmentation artifacts such as\nfragmented structures, topological inconsistencies and islands of pixel. These\nartefacts are especially problematic in medical imaging since segmentation is\nalmost always a pre-processing step for some downstream evaluation. The range\nof possible downstream evaluations is rather big, for example surgical\nplanning, visualization, shape analysis, prognosis, treatment planning etc.\nHowever, one common thread across all these downstream tasks is the demand of\nanatomical consistency. To ensure the segmentation result is anatomically\nconsistent, approaches based on Markov/ Conditional Random Fields, Statistical\nShape Models are becoming increasingly popular over the past 5 years. In this\nreview paper, a broad overview of recent literature on bringing anatomical\nconstraints for medical image segmentation is given, the shortcomings and\nopportunities of the proposed methods are thoroughly discussed and potential\nfuture work is elaborated. We review the most relevant papers published until\nthe submission date. For quick access, important details such as the underlying\nmethod, datasets and performance are tabulated.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07721",
		"pdf_url": "http://arxiv.org/pdf/2101.07721.pdf"
	},
	"1217": {
		"title": "DeepTrust: A Deep Learning Approach for Measuring Social Media Users\n  Trustworthiness",
		"creator": [
			"Alrubaian, Majed",
			"Al-Qurishi, Muhammad",
			"Omar, Sherif",
			"Mostafa, Mohamed A."
		],
		"subject": "Computer Science - Social and Information Networks",
		"description": [
			"  Veracity of data posted on the microblog platforms has in recent years been a\nsubject of intensive study by professionals specializing in various fields of\ninformatics as well as sociology, particularly in the light of increasing\nimportance of online tools for news spreading. On Twitter and similar sites, it\nis possible to report on ongoing situations globally with minimal delay, while\nthe cost of such reporting remains negligible. One of the most important\nfeatures of this social network is that content delivery can be customized to\nallow users to focus only on news items covering subject matters they find\ninteresting. With this in mind, it becomes necessary to create verification\nmechanisms that can ascertain whether the claims made on Twitter can be taken\nseriously and prevent false content from spreading too far. This study\ndemonstrates an innovative System for verification of information that can\nfulfill the role described above. The System is comprised of four mutually\nconnected modules: a legacy module, a trustworthiness classifier; a module\nmanaging user authority, and a ranking procedure. All of the modules function\nwithin an integrated framework and jointly contribute to an accurate\nclassification of messages and authors. Effectiveness of the solution was\nevaluated empirically on a sample of Twitter users, with a strict 10-fold\nevaluation procedure applied for each module. The findings indicate that the\nsolution successfully meets the primary objectives of the study and performs\nits function as expected.\n",
			"Comment: 18 pages,6 figures"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07725",
		"pdf_url": "http://arxiv.org/pdf/2101.07725.pdf"
	},
	"1218": {
		"title": "TC-DTW: Accelerating Multivariate Dynamic Time Warping Through Triangle\n  Inequality and Point Clustering",
		"creator": [
			"Shen, Daniel",
			"Chi, Min"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Databases"
		],
		"description": "  Dynamic time warping (DTW) plays an important role in analytics on time\nseries. Despite the large body of research on speeding up univariate DTW, the\nmethod for multivariate DTW has not been improved much in the last two decades.\nThe most popular algorithm used today is still the one developed seventeen\nyears ago. This paper presents a solution that, as far as we know, for the\nfirst time consistently outperforms the classic multivariate DTW algorithm\nacross dataset sizes, series lengths, data dimensions, temporal window sizes,\nand machines. The new solution, named TC-DTW, introduces Triangle Inequality\nand Point Clustering into the algorithm design on lower bound calculations for\nmultivariate DTW. In experiments on DTW-based nearest neighbor finding, the new\nsolution avoids as much as 98% (60% average) DTW distance calculations and\nyields as much as 25X (7.5X average) speedups.\n",
		"date": [
			"2021-01-15",
			"2021-01-19"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07731",
		"pdf_url": "http://arxiv.org/pdf/2101.07731.pdf"
	},
	"1219": {
		"title": "Metadata Analysis of Open Educational Resources",
		"creator": [
			"Tavakoli, Mohammadreza",
			"Elias, Mirette",
			"Kismihók, Gábor",
			"Auer, Sören"
		],
		"subject": "Computer Science - Computers and Society",
		"description": [
			"  Open Educational Resources (OERs) are openly licensed educational materials\nthat are widely used for learning. Nowadays, many online learning repositories\nprovide millions of OERs. Therefore, it is exceedingly difficult for learners\nto find the most appropriate OER among these resources. Subsequently, the\nprecise OER metadata is critical for providing high-quality services such as\nsearch and recommendation. Moreover, metadata facilitates the process of\nautomatic OER quality control as the continuously increasing number of OERs\nmakes manual quality control extremely difficult. This work uses the metadata\nof 8,887 OERs to perform an exploratory data analysis on OER metadata.\nAccordingly, this work proposes metadata-based scoring and prediction models to\nanticipate the quality of OERs. Based on the results, our analysis demonstrated\nthat OER metadata and OER content qualities are closely related, as we could\ndetect high-quality OERs with an accuracy of 94.6%. Our model was also\nevaluated on 884 educational videos from Youtube to show its applicability on\nother educational repositories.\n",
			"Comment: This paper has been accepted to be published in the 11th\n  International Learning Analytics and Knowledge (LAK'2021), April 12--16,\n  2021. ACM. arXiv admin note: text overlap with arXiv:2005.10542"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07735",
		"pdf_url": "http://arxiv.org/pdf/2101.07735.pdf"
	},
	"1220": {
		"title": "Information Theoretic Secure Aggregation with User Dropouts",
		"creator": [
			"Zhao, Yizhou",
			"Sun, Hua"
		],
		"subject": [
			"Computer Science - Information Theory",
			"Computer Science - Cryptography and Security",
			"Computer Science - Machine Learning"
		],
		"description": "  In the robust secure aggregation problem, a server wishes to learn and only\nlearn the sum of the inputs of a number of users while some users may drop out\n(i.e., may not respond). The identity of the dropped users is not known a\npriori and the server needs to securely recover the sum of the remaining\nsurviving users. We consider the following minimal two-round model of secure\naggregation. Over the first round, any set of no fewer than $U$ users out of\n$K$ users respond to the server and the server wants to learn the sum of the\ninputs of all responding users. The remaining users are viewed as dropped. Over\nthe second round, any set of no fewer than $U$ users of the surviving users\nrespond (i.e., dropouts are still possible over the second round) and from the\ninformation obtained from the surviving users over the two rounds, the server\ncan decode the desired sum. The security constraint is that even if the server\ncolludes with any $T$ users and the messages from the dropped users are\nreceived by the server (e.g., delayed packets), the server is not able to infer\nany additional information beyond the sum in the information theoretic sense.\nFor this information theoretic secure aggregation problem, we characterize the\noptimal communication cost. When $U \\leq T$, secure aggregation is not\nfeasible, and when $U > T$, to securely compute one symbol of the sum, the\nminimum number of symbols sent from each user to the server is $1$ over the\nfirst round, and $1/(U-T)$ over the second round.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07750",
		"pdf_url": "http://arxiv.org/pdf/2101.07750.pdf"
	},
	"1221": {
		"title": "A bi-directional extensible interface between Lean and Mathematica",
		"creator": [
			"Lewis, Robert Y.",
			"Wu, Minchao"
		],
		"subject": [
			"Computer Science - Logic in Computer Science",
			"Computer Science - Mathematical Software"
		],
		"description": [
			"  We implement a user-extensible ad hoc connection between the Lean proof\nassistant and the computer algebra system Mathematica. By reflecting the syntax\nof each system in the other and providing a flexible interface for extending\ntranslation, our connection allows for the exchange of arbitrary information\nbetween the two systems.\n  We show how to make use of the Lean metaprogramming framework to verify\ncertain Mathematica computations, so that the rigor of the proof assistant is\nnot compromised. We also use Mathematica as an untrusted oracle to guide proof\nsearch in the proof assistant and interact with a Mathematica notebook from\nwithin a Lean session. In the other direction, we import and process Lean\ndeclarations from within Mathematica. The proof assistant library serves as a\ndatabase of mathematical knowledge that the CAS can display and explore.\n",
			"Comment: arXiv admin note: substantial text overlap with arXiv:1712.09288"
		],
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07758",
		"pdf_url": "http://arxiv.org/pdf/2101.07758.pdf"
	},
	"1222": {
		"title": "The Coq Proof Script Visualiser (coq-psv)",
		"creator": "Frank, Mario",
		"subject": [
			"Computer Science - Logic in Computer Science",
			"Computer Science - Computers and Society",
			"K.3.0",
			"H.5.2",
			"F.3.1"
		],
		"description": [
			"  In this work, we present a visualisation tool that is able to process Coq\nproof scripts and generate a table representation of the contained proofs as\n$\\LaTeX$ or PDF files. This tool has the aim to support both education and\nreview processes as all proof steps can be visualised. Thus, there is no need\nto use Coq in order to review proofs or use them as examples in teaching. In\ncontrast to the usual approach of visualising proofs as hypertext or markdown\ndocuments, the generated files can be easily printed.\n",
			"Comment: This contribution was presented during a talk at the Coq Workshop\n  2020, affiliated with the IJCAR 2020"
		],
		"date": "2021-01-15",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07761",
		"pdf_url": "http://arxiv.org/pdf/2101.07761.pdf"
	},
	"1223": {
		"title": "Learning over Families of Sets -- Hypergraph Representation Learning for\n  Higher Order Tasks",
		"creator": [
			"Srinivasan, Balasubramaniam",
			"Zheng, Da",
			"Karypis, George"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Graph representation learning has made major strides over the past decade.\nHowever, in many relational domains, the input data are not suited for simple\ngraph representations as the relationships between entities go beyond pairwise\ninteractions. In such cases, the relationships in the data are better\nrepresented as hyperedges (set of entities) of a non-uniform hypergraph. While\nthere have been works on principled methods for learning representations of\nnodes of a hypergraph, these approaches are limited in their applicability to\ntasks on non-uniform hypergraphs (hyperedges with different cardinalities). In\nthis work, we exploit the incidence structure to develop a hypergraph neural\nnetwork to learn provably expressive representations of variable sized\nhyperedges which preserve local-isomorphism in the line graph of the\nhypergraph, while also being invariant to permutations of its constituent\nvertices. Specifically, for a given vertex set, we propose frameworks for (1)\nhyperedge classification and (2) variable sized expansion of partially observed\nhyperedges which captures the higher order interactions among vertices and\nhyperedges. We evaluate performance on multiple real-world hypergraph datasets\nand demonstrate consistent, significant improvement in accuracy, over\nstate-of-the-art models.\n",
			"Comment: Published as a conference paper at SIAM International Conference on\n  Data Mining(SDM 2021)"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07773",
		"pdf_url": "http://arxiv.org/pdf/2101.07773.pdf"
	},
	"1224": {
		"title": "Dynamic State Estimation for Radial Microgrid Protection",
		"creator": [
			"Barnes, Arthur K.",
			"Mate, Adam"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  Microgrids are localized electrical grids with control capability that are\nable to disconnect from the traditional grid to operate autonomously. They\nstrengthen grid resilience, help mitigate grid disturbances, and support a\nflexible grid by enabling the integration of distributed energy resources.\nGiven the likely presence of critical loads, the proper protection of\nmicrogrids is of vital importance; however, this is complicated in the case of\ninverter-interfaced microgrids where low fault currents preclude the use of\nconventional time-overcurrent protection. This paper introduces and\ninvestigates the application of dynamic state estimation, a generalization of\ndifferential protection, for the protection of radial portions of microgrids\n(or distribution networks); both phasor-based and dynamic approaches are\ninvestigated for protection. It is demonstrated through experiments on three\ncase-study systems that dynamic state estimation is capable of correctly\nidentifying model parameters for both normal and faulted operation.\n",
			"Comment: Accepted by the \"2021 57th IEEE Industrial and Commercial Power\n  System Conference\" for presentation and publication"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07774",
		"pdf_url": "http://arxiv.org/pdf/2101.07774.pdf"
	},
	"1225": {
		"title": "Minimax Off-Policy Evaluation for Multi-Armed Bandits",
		"creator": [
			"Ma, Cong",
			"Zhu, Banghua",
			"Jiao, Jiantao",
			"Wainwright, Martin J."
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning",
			"Mathematics - Statistics Theory"
		],
		"description": "  We study the problem of off-policy evaluation in the multi-armed bandit model\nwith bounded rewards, and develop minimax rate-optimal procedures under three\nsettings. First, when the behavior policy is known, we show that the Switch\nestimator, a method that alternates between the plug-in and importance sampling\nestimators, is minimax rate-optimal for all sample sizes. Second, when the\nbehavior policy is unknown, we analyze performance in terms of the competitive\nratio, thereby revealing a fundamental gap between the settings of known and\nunknown behavior policies. When the behavior policy is unknown, any estimator\nmust have mean-squared error larger -- relative to the oracle estimator\nequipped with the knowledge of the behavior policy -- by a multiplicative\nfactor proportional to the support size of the target policy. Moreover, we\ndemonstrate that the plug-in approach achieves this worst-case competitive\nratio up to a logarithmic factor. Third, we initiate the study of the partial\nknowledge setting in which it is assumed that the minimum probability taken by\nthe behavior policy is known. We show that the plug-in estimator is optimal for\nrelatively large values of the minimum probability, but is sub-optimal when the\nminimum probability is low. In order to remedy this gap, we propose a new\nestimator based on approximation by Chebyshev polynomials that provably\nachieves the optimal estimation error. Numerical experiments on both simulated\nand real data corroborate our theoretical findings.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07781",
		"pdf_url": "http://arxiv.org/pdf/2101.07781.pdf"
	},
	"1226": {
		"title": "Implementing Admittance Relaying for Microgrid Protection",
		"creator": [
			"Barnes, Arthur K.",
			"Mate, Adam"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  The rapid increase of distributed energy resources has led to the widespread\ndeployment of microgrids. These flexible and efficient local energy grids are\nable to operate in both grid-connected mode and islanded mode; they are\ninterfaced to the main power system by a fast semiconductor switch and commonly\nmake use of inverter-interfaced generation. This paper focuses on inverter\ninterfaced microgrids, which present a challenge for protection as they do not\nprovide the high short-circuit current necessary for conventional\ntime-overcurrent protection. The application of admittance relaying for the\nprotection of inverter-interfaced microgrids is investigated as a potential\nsolution. The comparison of analytical and simulated results of performed four\nexperiments prove the suitability of admittance relaying for microgrids\nprotection.\n",
			"Comment: Accepted by the \"2021 57th IEEE Industrial and Commercial Power\n  System Conference\" for presentation and publication"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07783",
		"pdf_url": "http://arxiv.org/pdf/2101.07783.pdf"
	},
	"1227": {
		"title": "Solving Quadratic Unconstrained Binary Optimization with\n  divide-and-conquer and quantum algorithms",
		"creator": "Guerreschi, Gian Giacomo",
		"subject": [
			"Quantum Physics",
			"Computer Science - Data Structures and Algorithms"
		],
		"description": "  Quadratic Unconstrained Binary Optimization (QUBO) is a broad class of\noptimization problems with many practical applications. To solve its hard\ninstances in an exact way, known classical algorithms require exponential time\nand several approximate methods have been devised to reduce such cost. With the\ngrowing maturity of quantum computing, quantum algorithms have been proposed to\nspeed up the solution by using either quantum annealers or universal quantum\ncomputers. Here we apply the divide-and-conquer approach to reduce the original\nproblem to a collection of smaller problems whose solutions can be assembled to\nform a single Polynomial Binary Unconstrained Optimization instance with fewer\nvariables. This technique can be applied to any QUBO instance and leads to\neither an all-classical or a hybrid quantum-classical approach. When quantum\nheuristics like the Quantum Approximate Optimization Algorithm (QAOA) are used,\nour proposal leads to a double advantage: a substantial reduction of quantum\nresources, specifically an average of ~42% fewer qubits to solve MaxCut on\nrandom 3-regular graphs, together with an improvement in the quality of the\napproximate solutions reached.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07813",
		"pdf_url": "http://arxiv.org/pdf/2101.07813.pdf"
	},
	"1228": {
		"title": "Internet of Predictable Things (IoPT) Framework to Increase\n  Cyber-Physical System Resiliency",
		"creator": [
			"Cali, Umit",
			"Kuzlu, Murat",
			"Sharma, Vinayak",
			"Pipattanasomporn, Manisa",
			"Catak, Ferhat Ozgur"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  During the last two decades, distributed energy systems, especially renewable\nenergy sources (RES), have become more economically viable with increasing\nmarket share and penetration levels on power systems. In addition to\ndecarbonization and decentralization of energy systems, digitalization has also\nbecome very important. The use of artificial intelligence (AI), advanced\noptimization algorithms, Industrial Internet of Things (IIoT), and other\ndigitalization frameworks makes modern power system assets more intelligent,\nwhile vulnerable to cybersecurity risks. This paper proposes the concept of the\nInternet of Predictable Things (IoPT) that incorporates advanced data analytics\nand machine learning methods to increase the resiliency of cyber-physical\nsystems against cybersecurity risks. The proposed concept is demonstrated using\na cyber-physical system testbed under a variety of cyber attack scenarios as a\nproof of concept (PoC).\n",
			"Comment: 13 pages"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07816",
		"pdf_url": "http://arxiv.org/pdf/2101.07816.pdf"
	},
	"1229": {
		"title": "Machine learning applications for COVID-19: A state-of-the-art review",
		"creator": [
			"Kamalov, Firuz",
			"Cherukuri, Aswani",
			"Sulieman, Hana",
			"Thabtah, Fadi",
			"Hossain, Akbar"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  The COVID-19 pandemic has galvanized the machine learning community to create\nnew solutions that can help in the fight against the virus. The body of\nliterature related to applications of machine learning and artificial\nintelligence to COVID-19 is constantly growing. The goal of this article is to\npresent the latest advances in machine learning research applied to COVID-19.\nWe cover four major areas of research: forecasting, medical diagnostics, drug\ndevelopment, and contact tracing. We review and analyze the most successful\nstate of the art studies. In contrast to other existing surveys on the subject,\nour article presents a high level overview of the current research that is\nsufficiently detailed to provide an informed insight.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07824",
		"pdf_url": "http://arxiv.org/pdf/2101.07824.pdf"
	},
	"1230": {
		"title": "Multi-Task Network Pruning and Embedded Optimization for Real-time\n  Deployment in ADAS",
		"creator": [
			"Dellinger, Flora",
			"Boulay, Thomas",
			"Barrenechea, Diego Mendoza",
			"El-Hachimi, Said",
			"Leang, Isabelle",
			"Bürger, Fabian"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Camera-based Deep Learning algorithms are increasingly needed for perception\nin Automated Driving systems. However, constraints from the automotive industry\nchallenge the deployment of CNNs by imposing embedded systems with limited\ncomputational resources. In this paper, we propose an approach to embed a\nmulti-task CNN network under such conditions on a commercial prototype\nplatform, i.e. a low power System on Chip (SoC) processing four surround-view\nfisheye cameras at 10 FPS.\n  The first focus is on designing an efficient and compact multi-task network\narchitecture. Secondly, a pruning method is applied to compress the CNN,\nhelping to reduce the runtime and memory usage by a factor of 2 without\nlowering the performances significantly. Finally, several embedded optimization\ntechniques such as mixed-quantization format usage and efficient data transfers\nbetween different memory areas are proposed to ensure real-time execution and\navoid bandwidth bottlenecks. The approach is evaluated on the hardware\nplatform, considering embedded detection performances, runtime and memory\nbandwidth. Unlike most works from the literature that focus on classification\ntask, we aim here to study the effect of pruning and quantization on a compact\nmulti-task network with object detection, semantic segmentation and soiling\ndetection tasks.\n",
			"Comment: Accepted at workshop on Machine Learning for Autonomous Driving\n  (NeurIPS 2020)"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07831",
		"pdf_url": "http://arxiv.org/pdf/2101.07831.pdf"
	},
	"1231": {
		"title": "Implicit Bias of Linear RNNs",
		"creator": [
			"Emami, Melikasadat",
			"Sahraee-Ardakan, Mojtaba",
			"Pandit, Parthe",
			"Rangan, Sundeep",
			"Fletcher, Alyson K."
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Neural and Evolutionary Computing",
			"Electrical Engineering and Systems Science - Systems and Control",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Contemporary wisdom based on empirical studies suggests that standard\nrecurrent neural networks (RNNs) do not perform well on tasks requiring\nlong-term memory. However, precise reasoning for this behavior is still\nunknown. This paper provides a rigorous explanation of this property in the\nspecial case of linear RNNs. Although this work is limited to linear RNNs, even\nthese systems have traditionally been difficult to analyze due to their\nnon-linear parameterization. Using recently-developed kernel regime analysis,\nour main result shows that linear RNNs learned from random initializations are\nfunctionally equivalent to a certain weighted 1D-convolutional network.\nImportantly, the weightings in the equivalent model cause an implicit bias to\nelements with smaller time lags in the convolution and hence, shorter memory.\nThe degree of this bias depends on the variance of the transition kernel matrix\nat initialization and is related to the classic exploding and vanishing\ngradients problem. The theory is validated in both synthetic and real data\nexperiments.\n",
			"Comment: 30 pages, 4 figures"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07833",
		"pdf_url": "http://arxiv.org/pdf/2101.07833.pdf"
	},
	"1232": {
		"title": "Porcupine: A Synthesizing Compiler for Vectorized Homomorphic Encryption",
		"creator": [
			"Cowan, Meghan",
			"Dangwal, Deeksha",
			"Alaghi, Armin",
			"Trippel, Caroline",
			"Lee, Vincent T.",
			"Reagen, Brandon"
		],
		"subject": "Computer Science - Cryptography and Security",
		"description": "  Homomorphic encryption (HE) is a privacy-preserving technique that enables\ncomputation directly on encrypted data. Despite its promise, HE has seen\nlimited use due to performance overheads and compilation challenges. Recent\nwork has made significant advances to address the performance overheads but\nautomatic compilation of efficient HE kernels remains relatively unexplored.\n  This paper presents Porcupine, an optimizing compiler, and HE DSL named Quill\nto automatically generate HE code using program synthesis. HE poses three major\ncompilation challenges: it only supports a limited set of SIMD-like operators,\nit uses long-vector operands, and decryption can fail if ciphertext noise\ngrowth is not managed properly. Quill captures the underlying HE operator\nbehavior that enables Porcupine to reason about the complex trade-offs imposed\nby the challenges and generate optimized, verified HE kernels. To improve\nsynthesis time, we propose a series of optimizations including a sketch design\ntailored to HE and instruction restriction to narrow the program search space.\nWe evaluate Procupine using a set of kernels and show speedups of up to 51%\n(11% geometric mean) compared to heuristic-driven hand-optimized kernels.\nAnalysis of Porcupine's synthesized code reveals that optimal solutions are not\nalways intuitive, underscoring the utility of automated reasoning in this\ndomain.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07841",
		"pdf_url": "http://arxiv.org/pdf/2101.07841.pdf"
	},
	"1233": {
		"title": "Scalable Optimization for Wind Farm Control using Coordination Graphs",
		"creator": [
			"Verstraeten, Timothy",
			"Daems, Pieter-Jan",
			"Bargiacchi, Eugenio",
			"Roijers, Diederik M.",
			"Libin, Pieter J. K.",
			"Helsen, Jan"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": "  Wind farms are a crucial driver toward the generation of ecological and\nrenewable energy. Due to their rapid increase in capacity, contemporary wind\nfarms need to adhere to strict constraints on power output to ensure stability\nof the electricity grid. Specifically, a wind farm controller is required to\nmatch the farm's power production with a power demand imposed by the grid\noperator. This is a non-trivial optimization problem, as complex dependencies\nexist between the wind turbines. State-of-the-art wind farm control typically\nrelies on physics-based heuristics that fail to capture the full load spectrum\nthat defines a turbine's health status. When this is not taken into account,\nthe long-term viability of the farm's turbines is put at risk. Given the\ncomplex dependencies that determine a turbine's lifetime, learning a flexible\nand optimal control strategy requires a data-driven approach. However, as wind\nfarms are large-scale multi-agent systems, optimizing control strategies over\nthe full joint action space is intractable. We propose a new learning method\nfor wind farm control that leverages the sparse wind farm structure to\nfactorize the optimization problem. Using a Bayesian approach, based on\nmulti-agent Thompson sampling, we explore the factored joint action space for\nconfigurations that match the demand, while considering the lifetime of\nturbines. We apply our method to a grid-like wind farm layout, and evaluate\nconfigurations using a state-of-the-art wind flow simulator. Our results are\ncompetitive with a physics-based heuristic approach in terms of demand error,\nwhile, contrary to the heuristic, our method prolongs the lifetime of high-risk\nturbines.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07844",
		"pdf_url": "http://arxiv.org/pdf/2101.07844.pdf"
	},
	"1234": {
		"title": "Parallel-in-time high-order multiderivative IMEX solvers",
		"creator": [
			"Schütz, Jochen",
			"Seal, David C.",
			"Zeifang, Jonas"
		],
		"subject": "Mathematics - Numerical Analysis",
		"description": [
			"  In this work, we present a novel class of parallelizable high-order time\nintegration schemes for the approximate solution of additive ODEs. The methods\nachieve high order through a combination of a suitable quadrature formula\ninvolving multiple derivatives of the ODE's right-hand side and a\npredictor-corrector ansatz. The latter approach is designed in such a way that\nparallelism in time is made possible. We present thorough analysis as well as\nnumerical results that showcase scaling opportunities of methods from this\nclass of solvers.\n",
			"Comment: 36 pages"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07846",
		"pdf_url": "http://arxiv.org/pdf/2101.07846.pdf"
	},
	"1235": {
		"title": "The Complexity of Monitoring Hyperproperties",
		"creator": [
			"Bonakdarpour, Borzoo",
			"Finkbeiner, Bernd"
		],
		"subject": "Computer Science - Logic in Computer Science",
		"description": "  We study the runtime verification of hyperproperties, expressed in the\ntemporal logic HyperLTL, as a means to inspect a system with respect to\nsecurity polices. Runtime monitors for hyperproperties analyze trace logs that\nare organized by common prefixes in the form of a tree-shaped Kripke structure,\nor are organized both by common prefixes and by common suffixes in the form of\nan acyclic Kripke structure. Unlike runtime verification techniques for trace\nproperties, where the monitor tracks the state of the specification but usually\ndoes not need to store traces, a monitor for hyperproperties repeatedly model\nchecks the growing Kripke structure. This calls for a rigorous complexity\nanalysis of the model checking problem over tree-shaped and acyclic Kripke\nstructures. We show that for trees, the complexity in the size of the Kripke\nstructure is L-complete independently of the number of quantifier alternations\nin the HyperLTL formula. For acyclic Kripke structures, the complexity is\nPSPACE-complete (in the level of the polynomial hierarchy that corresponds to\nthe number of quantifier alternations). The combined complexity in the size of\nthe Kripke structure and the length of the HyperLTL formula is PSPACE-complete\nfor both trees and acyclic Kripke structures, and is as low as NC for the\nrelevant case of trees and alternation-free HyperLTL formulas. Thus, the size\nand shape of both the Kripke structure and the formula have significant impact\non the complexity of the model checking problem.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07847",
			"doi:10.1109/CSF.2018.00019"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07847.pdf"
	},
	"1236": {
		"title": "Rapid Convergence: The Outcomes of Making PPE during a Healthcare Crisis",
		"creator": [
			"Mack, Kelly",
			"Hofmann, Megan",
			"Lakshmi, Udaya",
			"Cao, Jerry",
			"Auradkar, Nayha",
			"Arriaga, Rosa I.",
			"Hudson, Scott E.",
			"Mankoff, Jennifer"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": "  The NIH 3D Print Exchange is a public and open source repository for\nprimarily 3D printable medical device designs with contributions from\nexpert-amateur makers, engineers from industry and academia, and clinicians. In\nresponse to the COVID-19 pandemic, a collection was formed to foster\nsubmissions of low-cost, local manufacture of personal protective equipment\n(Personal Protective Equipment (PPE)). We systematically evaluated the 623\nsubmissions in this collection to understand: what makers contributed, how they\nwere made, who made them, and key characteristics of their designs. Our\nanalysis reveals an immediate design convergence to derivatives of a few\ninitial designs affiliated with NIH partners (e.g., universities, the Veteran's\nHealth Administration, America Makes) and major for-profit groups (e.g.,\nPrusa). The NIH worked to review safe and effective designs but was quickly\noverloaded by derivative works. We found that the vast majority were never\nreviewed (81.3%) while 10.4% of those reviewed were deemed safe for clinical\n(5.6%) or community use (4.8%). Our work contributes insights into: the\noutcomes of distributed, community-based, medical making; features the\ncommunity accepted as \"safe\" making; and how platforms can support regulated\nmaker activities in high-risk domains (e.g., healthcare).\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07853",
		"pdf_url": "http://arxiv.org/pdf/2101.07853.pdf"
	},
	"1237": {
		"title": "Colouring Graphs of Bounded Diameter in the Absence of Small Cycles",
		"creator": [
			"Martin, Barnaby",
			"Paulusma, Daniel",
			"Smith, Siani"
		],
		"subject": [
			"Mathematics - Combinatorics",
			"Computer Science - Computational Complexity",
			"Computer Science - Discrete Mathematics",
			"Computer Science - Data Structures and Algorithms"
		],
		"description": "  For $k\\geq 1$, a $k$-colouring $c$ of $G$ is a mapping from $V(G)$ to\n$\\{1,2,\\ldots,k\\}$ such that $c(u)\\neq c(v)$ for any two non-adjacent vertices\n$u$ and $v$. The $k$-Colouring problem is to decide if a graph $G$ has a\n$k$-colouring. For a family of graphs ${\\cal H}$, a graph $G$ is ${\\cal\nH}$-free if $G$ does not contain any graph from ${\\cal H}$ as an induced\nsubgraph. Let $C_s$ be the $s$-vertex cycle. In previous work (MFCS 2019) we\nexamined the effect of bounding the diameter on the complexity of $3$-Colouring\nfor $(C_3,\\ldots,C_s)$-free graphs and $H$-free graphs where $H$ is some\npolyad. Here, we prove for certain small values of $s$ that $3$-Colouring is\npolynomial-time solvable for $C_s$-free graphs of diameter $2$ and\n$(C_4,C_s)$-free graphs of diameter $2$. In fact, our results hold for the more\ngeneral problem List $3$-Colouring. We complement these results with some\nhardness result for diameter $4$.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07856",
		"pdf_url": "http://arxiv.org/pdf/2101.07856.pdf"
	},
	"1238": {
		"title": "Numerical procedure for optimal control of hybrid systems with sliding\n  modes, Part II",
		"creator": [
			"Pytlak, Radoslaw",
			"Suski, Damian"
		],
		"subject": [
			"Mathematics - Optimization and Control",
			"Mathematics - Numerical Analysis"
		],
		"description": "  This paper concerns the numerical procedure for solving hybrid optimal\ncontrol problems with sliding modes. A sliding mode is coped with\ndifferential-algebraic equations (DAEs) and that guarantees accurate tracking\nof the sliding motion surface. In the second part of the paper we demonstrate\nthe correspondence between the discrete adjoint equations and the discretized\nversion of the continuous adjoint equations in the case of system equations\ndescribed by DAEs. We show that the discrete adjoint state trajectories\nconverge to their continuous counterparts. Next, we describe the application of\nthe proposed procedure to three optimal control problems. The first problem\nconcerns optimal control of a simple mechanical system with dry friction. The\nsecond problem is related to the planning of a haemodialysis process. The third\nproblem concerns the optimal steering of a racing car.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07861",
		"pdf_url": "http://arxiv.org/pdf/2101.07861.pdf"
	},
	"1239": {
		"title": "SEMULATOR: Emulating the Dynamics of Crossbar Array-based Analog Neural\n  System with Regression Neural Networks",
		"creator": [
			"Lee, Chaeun",
			"Kim, Seyoung"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Emerging Technologies",
			"Computer Science - Neural and Evolutionary Computing"
		],
		"description": [
			"  As deep neural networks require tremendous amount of computation and memory,\nanalog computing with emerging memory devices is a promising alternative to\ndigital computing for edge devices. However, because of the increasing\nsimulation time for analog computing system, it has not been explored. To\novercome this issue, analytically approximated simulators are developed, but\nthese models are inaccurate and narrow down the options for peripheral circuits\nfor multiply-accumulate operation (MAC). In this sense, we propose a\nmethodology, SEMULATOR (SiMULATOR by Emulating the analog computing block)\nwhich uses a deep neural network to emulate the behavior of crossbar-based\nanalog computing system. With the proposed neural architecture, we\nexperimentally and theoretically shows that it emulates a MAC unit for neural\ncomputation. In addition, the simulation time is incomparably reduced when it\ncompared to the circuit simulators such as SPICE.\n",
			"Comment: 10 pages, 7 figures, preprint"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07864",
		"pdf_url": "http://arxiv.org/pdf/2101.07864.pdf"
	},
	"1240": {
		"title": "A Physics-Based Finite-State Abstraction for Traffic Congestion Control",
		"creator": [
			"Rastgoftar, Hossein",
			"Jeannin, Jean-Baptiste"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  This paper offers a finite-state abstraction of traffic coordination and\ncongestion in a network of interconnected roads (NOIR). By applying mass\nconservation, we model traffic coordination as a Markov process. Model\nPredictive Control (MPC) is applied to control traffic congestion through the\nboundary of the traffic network. The optimal boundary inflow is assigned as the\nsolution of a constrained quadratic programming problem. Additionally, the\nmovement phases commanded by traffic signals are determined using receding\nhorizon optimization. In simulation, we show how traffic congestion can be\nsuccessfully controlled through optimizing boundary inflow and movement phases\nat traffic network junctions.\n",
			"Comment: 7 pages, 5 figures. arXiv admin note: text overlap with\n  arXiv:1912.00565"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07865",
		"pdf_url": "http://arxiv.org/pdf/2101.07865.pdf"
	},
	"1241": {
		"title": "Classification of COVID-19 X-ray Images Using a Combination of Deep and\n  Handcrafted Features",
		"creator": [
			"Zhang, Weihan",
			"Pogorelsky, Bryan",
			"Loveland, Mark",
			"Wolf, Trevor"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Coronavirus Disease 2019 (COVID-19) demonstrated the need for accurate and\nfast diagnosis methods for emergent viral diseases. Soon after the emergence of\nCOVID-19, medical practitioners used X-ray and computed tomography (CT) images\nof patients' lungs to detect COVID-19. Machine learning methods are capable of\nimproving the identification accuracy of COVID-19 in X-ray and CT images,\ndelivering near real-time results, while alleviating the burden on medical\npractitioners. In this work, we demonstrate the efficacy of a support vector\nmachine (SVM) classifier, trained with a combination of deep convolutional and\nhandcrafted features extracted from X-ray chest scans. We use this combination\nof features to discriminate between healthy, common pneumonia, and COVID-19\npatients. The performance of the combined feature approach is compared with a\nstandard convolutional neural network (CNN) and the SVM trained with\nhandcrafted features. We find that combining the features in our novel\nframework improves the performance of the classification task compared to the\nindependent application of convolutional and handcrafted features.\nSpecifically, we achieve an accuracy of 0.988 in the classification task with\nour combined approach compared to 0.963 and 0.983 accuracy for the handcrafted\nfeatures with SVM and CNN respectively.\n",
			"Comment: 5 pages, 5 figures"
		],
		"date": [
			"2021-01-19",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07866",
		"pdf_url": "http://arxiv.org/pdf/2101.07866.pdf"
	},
	"1242": {
		"title": "Illuminating the Space of Beatable Lode Runner Levels Produced By\n  Various Generative Adversarial Networks",
		"creator": [
			"Steckel, Kirby",
			"Schrum, Jacob"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Neural and Evolutionary Computing"
		],
		"description": "  Generative Adversarial Networks (GANs) are capable of generating convincing\nimitations of elements from a training set, but the distribution of elements in\nthe training set affects to difficulty of properly training the GAN and the\nquality of the outputs it produces. This paper looks at six different GANs\ntrained on different subsets of data from the game Lode Runner. The quality\ndiversity algorithm MAP-Elites was used to explore the set of quality levels\nthat could be produced by each GAN, where quality was defined as being beatable\nand having the longest solution path possible. Interestingly, a GAN trained on\nonly 20 levels generated the largest set of diverse beatable levels while a GAN\ntrained on 150 levels generated the smallest set of diverse beatable levels,\nthus challenging the notion that more is always better when training GANs.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07868",
		"pdf_url": "http://arxiv.org/pdf/2101.07868.pdf"
	},
	"1243": {
		"title": "Flying Robots for Safe and Efficient Parcel Delivery Within the COVID-19\n  Pandemic",
		"creator": [
			"Patchou, Manuel",
			"Sliwa, Benjamin",
			"Wietfeld, Christian"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Computer Science - Robotics"
		],
		"description": "  The integration of small-scale Unmanned Aerial Vehicles (UAVs) into\nIntelligent Transportation Systems (ITSs) will empower novel smart-city\napplications and services. After the unforeseen outbreak of the COVID-19\npandemic, the public demand for delivery services has multiplied. Mobile\nrobotic systems inherently offer the potential for minimizing the amount of\ndirect human-to-human interactions with the parcel delivery process. The\nproposed system-of-systems consists of various complex aspects such as\nassigning and distributing delivery jobs, establishing and maintaining reliable\ncommunication links between the vehicles, as well as path planning and mobility\ncontrol. In this paper, we apply a system-level perspective for identifying key\nchallenges and promising solution approaches for modeling, analysis, and\noptimization of UAV-aided parcel delivery. We present a system-of-systems model\nfor UAV-assisted parcel delivery to cope with higher capacity requirements\ninduced by the COVID-19. To demonstrate the benefits of hybrid vehicular\ndelivery, we present a case study focusing on the prioritization of\ntime-critical deliveries such as medical goods. The results further confirm\nthat the capacity of traditional delivery fleets can be upgraded with drone\nusage. Furthermore, we observe that the delay incurred by prioritizing\ntime-critical deliveries can be compensated with drone deployment. Finally,\ncentralized and decentralized communication approaches for data transmission\ninside hybrid delivery fleets are compared.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07877",
		"pdf_url": "http://arxiv.org/pdf/2101.07877.pdf"
	},
	"1244": {
		"title": "Proceedings of the 3rd Annual International Applied Category Theory\n  Conference 2020",
		"creator": [
			"Spivak, David I.",
			"Vicary, Jamie"
		],
		"subject": [
			"Computer Science - Discrete Mathematics",
			"Computer Science - Programming Languages"
		],
		"description": "  The third annual International Applied Category Theory Conference (ACT2020)\nwas planned to take place at MIT in Cambridge, Massachusetts USA. However, the\nglobal COVID-19 pandemic made the prospect of holding a large in-person meeting\nimpossible, and the event was thus held completely online. Holding the talks\nonline had the new benefits of reducing carbon footprint, being inclusive of\npeople from more parts of the world, and producing higher-quality video talks,\nwhich have been posted online for posterity.\n  The ACT2020 contributions spanned a broad spectrum of application areas,\nincluding databases, dynamical systems, functional programming, game theory,\nlenses, neuroscience, probabilistic programming, natural language processing,\nquantum mechanics, and cyberphysical systems. Papers featured a broad range of\ncategorical techniques.\n  Papers in this Proceedings volume represents about half of the talks\npresented at ACT2020. Being included in the proceedings vs. not is not an\nindication of talk quality, but instead almost exclusively the choice of the\nauthors, e.g. to present work already published elsewhere.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07888",
			"EPTCS 333, 2021",
			"doi:10.4204/EPTCS.333"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07888.pdf"
	},
	"1245": {
		"title": "A modular vision language navigation and manipulation framework for long\n  horizon compositional tasks in indoor environment",
		"creator": [
			"Saha, Homagni",
			"Fotouhif, Fateme",
			"Liu, Qisai",
			"Sarkar, Soumik"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Robotics"
		],
		"description": [
			"  In this paper we propose a new framework - MoViLan (Modular Vision and\nLanguage) for execution of visually grounded natural language instructions for\nday to day indoor household tasks. While several data-driven, end-to-end\nlearning frameworks have been proposed for targeted navigation tasks based on\nthe vision and language modalities, performance on recent benchmark data sets\nrevealed the gap in developing comprehensive techniques for long horizon,\ncompositional tasks (involving manipulation and navigation) with diverse object\ncategories, realistic instructions and visual scenarios with non-reversible\nstate changes. We propose a modular approach to deal with the combined\nnavigation and object interaction problem without the need for strictly aligned\nvision and language training data (e.g., in the form of expert demonstrated\ntrajectories). Such an approach is a significant departure from the traditional\nend-to-end techniques in this space and allows for a more tractable training\nprocess with separate vision and language data sets. Specifically, we propose a\nnovel geometry-aware mapping technique for cluttered indoor environments, and a\nlanguage understanding model generalized for household instruction following.\nWe demonstrate a significant increase in success rates for long-horizon,\ncompositional tasks over the baseline on the recently released benchmark data\nset-ALFRED.\n",
			"Comment: 16 pages"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07891",
		"pdf_url": "http://arxiv.org/pdf/2101.07891.pdf"
	},
	"1246": {
		"title": "Cross-domain few-shot learning with unlabelled data",
		"creator": "Yao, Fupin",
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  Few shot learning aims to solve the data scarcity problem. If there is a\ndomain shift between the test set and the training set, their performance will\ndecrease a lot. This setting is called Cross-domain few-shot learning. However,\nthis is very challenging because the target domain is unseen during training.\nThus we propose a new setting some unlabelled data from the target domain is\nprovided, which can bridge the gap between the source domain and the target\ndomain. A benchmark for this setting is constructed using DomainNet\n\\cite{peng2018oment}. We come up with a self-supervised learning method to\nfully utilize the knowledge in the labeled training set and the unlabelled set.\nExtensive experiments show that our methods outperforms several baseline\nmethods by a large margin. We also carefully design an episodic training\npipeline which yields a significant performance boost.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07899",
		"pdf_url": "http://arxiv.org/pdf/2101.07899.pdf"
	},
	"1247": {
		"title": "Feature Sharing Cooperative Network for Semantic Segmentation",
		"creator": [
			"Ikedo, Ryota",
			"Hotta, Kazuhiro"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  In recent years, deep neural networks have achieved high ac-curacy in the\nfield of image recognition. By inspired from human learning method, we propose\na semantic segmentation method using cooperative learning which shares the\ninformation resembling a group learning. We use two same networks and paths for\nsending feature maps between two networks. Two networks are trained\nsimultaneously. By sharing feature maps, one of two networks can obtain the\ninformation that cannot be obtained by a single network. In addition, in order\nto enhance the degree of cooperation, we propose two kinds of methods that\nconnect only the same layer and multiple layers. We evaluated our proposed idea\non two kinds of networks. One is Dual Attention Network (DANet) and the other\none is DeepLabv3+. The proposed method achieved better segmentation accuracy\nthan the conventional single network and ensemble of networks.\n",
			"Comment: computer vision and pattern recognition"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07905",
		"pdf_url": "http://arxiv.org/pdf/2101.07905.pdf"
	},
	"1248": {
		"title": "IntentNet: Learning to Predict Intention from Raw Sensor Data",
		"creator": [
			"Casas, Sergio",
			"Luo, Wenjie",
			"Urtasun, Raquel"
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  In order to plan a safe maneuver, self-driving vehicles need to understand\nthe intent of other traffic participants. We define intent as a combination of\ndiscrete high-level behaviors as well as continuous trajectories describing\nfuture motion. In this paper, we develop a one-stage detector and forecaster\nthat exploits both 3D point clouds produced by a LiDAR sensor as well as\ndynamic maps of the environment. Our multi-task model achieves better accuracy\nthan the respective separate modules while saving computation, which is\ncritical to reducing reaction time in self-driving applications.\n",
			"Comment: CoRL 2018"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07907",
		"pdf_url": "http://arxiv.org/pdf/2101.07907.pdf"
	},
	"1249": {
		"title": "A Search-Based Testing Framework for Deep Neural Networks of Source Code\n  Embedding",
		"creator": [
			"Pour, Maryam Vahdat",
			"Li, Zhuo",
			"Ma, Lei",
			"Hemmati, Hadi"
		],
		"subject": "Computer Science - Software Engineering",
		"description": [
			"  Over the past few years, deep neural networks (DNNs) have been continuously\nexpanding their real-world applications for source code processing tasks across\nthe software engineering domain, e.g., clone detection, code search, comment\ngeneration. Although quite a few recent works have been performed on testing of\nDNNs in the context of image and speech processing, limited progress has been\nachieved so far on DNN testing in the context of source code processing, that\nexhibits rather unique characteristics and challenges.\n  In this paper, we propose a search-based testing framework for DNNs of source\ncode embedding and its downstream processing tasks like Code Search. To\ngenerate new test inputs, we adopt popular source code refactoring tools to\ngenerate the semantically equivalent variants. For more effective testing, we\nleverage the DNN mutation testing to guide the testing direction. To\ndemonstrate the usefulness of our technique, we perform a large-scale\nevaluation on popular DNNs of source code processing based on multiple\nstate-of-the-art code embedding methods (i.e., Code2vec, Code2seq and\nCodeBERT). The testing results show that our generated adversarial samples can\non average reduce the performance of these DNNs from 5.41% to 9.58%. Through\nretraining the DNNs with our generated adversarial samples, the robustness of\nDNN can improve by 23.05% on average. The evaluation results also show that our\nadversarial test generation strategy has the least negative impact (median of\n3.56%), on the performance of the DNNs for regular test data, compared to the\nother methods.\n",
			"Comment: ICST 2021"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07910",
		"pdf_url": "http://arxiv.org/pdf/2101.07910.pdf"
	},
	"1250": {
		"title": "Epidemic? The Attack Surface of German Hospitals during the COVID-19\n  Pandemic",
		"creator": [
			"Klick, Johannes",
			"Koch, Robert",
			"Brandstetter, Thomas"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Computers and Society"
		],
		"description": [
			"  In our paper we analyze the attack surface of German hospitals and healthcare\nproviders in 2020 during the COVID-19 Pandemic. The analysis looked at the\npublicly visible attack surface utilizing a Distributed Cyber Recon System,\nutilizing distributed Internet scanning, Big Data methods and scan data of\n1,483 GB from more than 89 different global Internet scans. From the 1,555\nidentified German clinical entities, security posture analysis was conducted by\nlooking at more than 13,000 service banners for version identification and\nsubsequent CVE-based vulnerability identification. Primary analysis shows that\n32 percent of the analyzed services were determined as vulnerable to various\ndegrees and 36 percent of all hospitals showed numerous vulnerabilities.\nFurther resulting vulnerability statistics were mapped against size of\norganization and hospital bed count.\n",
			"Comment: Preprint for NATO CCDCOE Annual International Conference on Cyber\n  Conflict (CyCon) [Paper submitted to Peer Review Process]"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07912",
		"pdf_url": "http://arxiv.org/pdf/2101.07912.pdf"
	},
	"1251": {
		"title": "Geometric Heat Flow Method for Legged Locomotion Planning",
		"creator": [
			"Fan, Yinai",
			"Liu, Shenyu",
			"Belabbas, Mohamed-Ali"
		],
		"subject": [
			"Mathematics - Optimization and Control",
			"Computer Science - Robotics"
		],
		"description": "  We propose in this paper a motion planning method for legged robot locomotion\nbased on Geometric Heat Flow framework. The motion planning task is challenging\ndue to the hybrid nature of dynamics and contact constraints. We encode the\nhybrid dynamics and constraints into Riemannian inner product, and this inner\nproduct is defined so that short curves correspond to admissible motions for\nthe system. We rely on the affine geometric heat flow to deform an arbitrary\npath connecting the desired initial and final states to this admissible motion.\nThe method is able to automatically find the trajectory of robot's center of\nmass, feet contact positions and forces on uneven terrain.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07913",
		"pdf_url": "http://arxiv.org/pdf/2101.07913.pdf"
	},
	"1252": {
		"title": "PGT: Pseudo Relevance Feedback Using a Graph-Based Transformer",
		"creator": [
			"Yu, HongChien",
			"Dai, Zhuyun",
			"Callan, Jamie"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Most research on pseudo relevance feedback (PRF) has been done in vector\nspace and probabilistic retrieval models. This paper shows that\nTransformer-based rerankers can also benefit from the extra context that PRF\nprovides. It presents PGT, a graph-based Transformer that sparsifies attention\nbetween graph nodes to enable PRF while avoiding the high computational\ncomplexity of most Transformer architectures. Experiments show that PGT\nimproves upon non-PRF Transformer reranker, and it is at least as accurate as\nTransformer PRF models that use full attention, but with lower computational\ncosts.\n",
			"Comment: Accepted at ECIR 2021 (short paper track)"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07918",
		"pdf_url": "http://arxiv.org/pdf/2101.07918.pdf"
	},
	"1253": {
		"title": "A Guide to Design Disturbance Observer-based Motion Control Systems in\n  Discrete-time Domain",
		"creator": "Sariyildiz, Emre",
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  This paper analyses and synthesises the Disturbance Observer (DOb) based\nmotion control systems in the discrete-time domain. By employing Bode Integral\nTheorem, it is shown that continuous-time analysis methods fall-short in\nexplaining the dynamic behaviours of the DOb-based robust motion controllers\nimplemented by computers and microcontrollers. For example, continuous-time\nanalysis methods cannot explain why the robust stability and performance of the\ndigital motion controller deteriorate as the bandwidth of the DOb increases.\nTherefore, unexpected dynamic responses (e.g., poor stability and performance,\nand high-sensitivity to disturbances and noise) may be observed when the\nparameters of the digital robust motion controller are tuned by using\ncontinuous-time synthesis methods in practice. This paper also analytically\nderives the robust stability and performance constraints of the DOb-based\nmotion controllers in the discrete-time domain. The proposed design constraints\nallow one to systematically synthesise a high-performance digital robust motion\ncontroller. The validity of the proposed analysis and synthesis methods are\nverified by simulations.\n",
			"Comment: IEEE International Conference on Mechatronics (ICM2021)"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07920",
		"pdf_url": "http://arxiv.org/pdf/2101.07920.pdf"
	},
	"1254": {
		"title": "Using Full-text Content of Academic Articles to Build a Methodology\n  Taxonomy of Information Science in China",
		"creator": [
			"Zhang, Heng",
			"Zhang, Chengzhi"
		],
		"subject": [
			"Computer Science - Digital Libraries",
			"Computer Science - Computation and Language",
			"I.2.7"
		],
		"description": "  Research on the construction of traditional information science methodology\ntaxonomy is mostly conducted manually. From the limited corpus, researchers\nhave attempted to summarize some of the research methodology entities into\nseveral abstract levels (generally three levels); however, they have been\nunable to provide a more granular hierarchy. Moreover, updating the methodology\ntaxonomy is traditionally a slow process. In this study, we collected full-text\nacademic papers related to information science. First, we constructed a basic\nmethodology taxonomy with three levels by manual annotation. Then, the word\nvectors of the research methodology entities were trained using the full-text\ndata. Accordingly, the research methodology entities were clustered and the\nbasic methodology taxonomy was expanded using the clustering results to obtain\na methodology taxonomy with more levels. This study provides new concepts for\nconstructing a methodology taxonomy of information science. The proposed\nmethodology taxonomy is semi-automated; it is more detailed than conventional\nschemes and the speed of taxonomy renewal has been enhanced.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07924",
		"pdf_url": "http://arxiv.org/pdf/2101.07924.pdf"
	},
	"1255": {
		"title": "A Discrete Scheme for Computing Image's Weighted Gaussian Curvature",
		"creator": [
			"Gong, Yuanhao",
			"Tang, Wenming",
			"Zhou, Lebin",
			"Yu, Lantao",
			"Qiu, Guoping"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Electrical Engineering and Systems Science - Signal Processing",
			"Mathematics - Differential Geometry"
		],
		"description": "  Weighted Gaussian Curvature is an important measurement for images. However,\nits conventional computation scheme has low performance, low accuracy and\nrequires that the input image must be second order differentiable. To tackle\nthese three issues, we propose a novel discrete computation scheme for the\nweighted Gaussian curvature. Our scheme does not require the second order\ndifferentiability. Moreover, our scheme is more accurate, has smaller support\nregion and computationally more efficient than the conventional schemes.\nTherefore, our scheme holds promise for a large range of applications where the\nweighted Gaussian curvature is needed, for example, image smoothing, cartoon\ntexture decomposition, optical flow estimation, etc.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07927",
		"pdf_url": "http://arxiv.org/pdf/2101.07927.pdf"
	},
	"1256": {
		"title": "Impacts of Earthquakes on Electrical Grid Resilience",
		"creator": [
			"Mate, Adam",
			"Hagan, Travis",
			"Cotilla-Sanchez, Eduardo",
			"Brekken, Ted K. A.",
			"Von Jouanne, Annette"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  One of the most complex and devastating disaster scenarios that the\nU.S.~Pacific Northwest region and the state of Oregon faces is a large\nmagnitude Cascadia Subduction Zone earthquake event. The region's electrical\ngrid lacks in resilience against the destruction of a megathrust earthquake, a\npowerful tsunami, hundreds of aftershocks and increased volcanic activity, all\nof which are highly probable components of this hazard. This research seeks to\ncatalyze further understanding and improvement of resilience. By systematizing\npower system related experiences of historical earthquakes, and collecting\npractical and innovative ideas from other regions on how to enhance network\ndesign, construction, and operation, important steps are being taken toward a\nmore resilient, earthquake-resistant grid. This paper presents relevant\nfindings in an effort to be an overview and a useful guideline for those who\nare also working towards greater electrical grid resilience.\n",
			"Comment: Accepted by the \"2021 57th IEEE Industrial and Commercial Power\n  System Conference\" for presentation and publication"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07928",
		"pdf_url": "http://arxiv.org/pdf/2101.07928.pdf"
	},
	"1257": {
		"title": "Online Active Proposal Set Generation for Weakly Supervised Object\n  Detection",
		"creator": [
			"Jin, Ruibing",
			"Lin, Guosheng",
			"Wen, Changyun"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  To reduce the manpower consumption on box-level annotations, many weakly\nsupervised object detection methods which only require image-level annotations,\nhave been proposed recently. The training process in these methods is\nformulated into two steps. They firstly train a neural network under weak\nsupervision to generate pseudo ground truths (PGTs). Then, these PGTs are used\nto train another network under full supervision. Compared with fully supervised\nmethods, the training process in weakly supervised methods becomes more complex\nand time-consuming. Furthermore, overwhelming negative proposals are involved\nat the first step. This is neglected by most methods, which makes the training\nnetwork biased towards to negative proposals and thus degrades the quality of\nthe PGTs, limiting the training network performance at the second step. Online\nproposal sampling is an intuitive solution to these issues. However, lacking of\nadequate labeling, a simple online proposal sampling may make the training\nnetwork stuck into local minima. To solve this problem, we propose an Online\nActive Proposal Set Generation (OPG) algorithm. Our OPG algorithm consists of\ntwo parts: Dynamic Proposal Constraint (DPC) and Proposal Partition (PP). DPC\nis proposed to dynamically determine different proposal sampling strategy\naccording to the current training state. PP is used to score each proposal,\npart proposals into different sets and generate an active proposal set for the\nnetwork optimization. Through experiments, our proposed OPG shows consistent\nand significant improvement on both datasets PASCAL VOC 2007 and 2012, yielding\ncomparable performance to the state-of-the-art results.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07929",
		"pdf_url": "http://arxiv.org/pdf/2101.07929.pdf"
	},
	"1258": {
		"title": "Air-Ground Collaborative Mobile Edge Computing: Architecture,\n  Challenges, and Opportunities",
		"creator": [
			"Qin, Zhen",
			"Wang, Hai",
			"Qu, Yuben",
			"Dai, Haipeng",
			"Wei, Zhenhua"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": "  By pushing computation, cache, and network control to the edge, mobile edge\ncomputing (MEC) is expected to play a leading role in fifth generation (5G) and\nfuture sixth generation (6G). Nevertheless, facing ubiquitous fast-growing\ncomputational demands, it is impossible for a single MEC paradigm to\neffectively support high-quality intelligent services at end user equipments\n(UEs). To address this issue, we propose an air-ground collaborative MEC\n(AGC-MEC) architecture in this article. The proposed AGC-MEC integrates all\npotentially available MEC servers within air and ground in the envisioned 6G,\nby a variety of collaborative ways to provide computation services at their\nbest for UEs. Firstly, we introduce the AGC-MEC architecture and elaborate\nthree typical use cases. Then, we discuss four main challenges in the AGC-MEC\nas well as their potential solutions. Next, we conduct a case study of\ncollaborative service placement for AGC-MEC to validate the effectiveness of\nthe proposed collaborative service placement strategy. Finally, we highlight\nseveral potential research directions of the AGC-MEC.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07930",
		"pdf_url": "http://arxiv.org/pdf/2101.07930.pdf"
	},
	"1259": {
		"title": "MIT SafePaths Card (MiSaCa): Augmenting Paper Based Vaccination Cards\n  with Printed Codes",
		"creator": [
			"Bae, Joseph",
			"Sukumaran, Rohan",
			"Shankar, Sheshank",
			"Srivastava, Saurish",
			"Iyer, Rohan",
			"Mahindra, Aryan",
			"Mirza, Qamil",
			"Arseni, Maurizio",
			"Sharma, Anshuman",
			"Agrawal, Saras",
			"Mukhopadhyay, Orna",
			"Kang, Colin",
			"Katiyar, Priyanshi",
			"Shekhar, Apurv",
			"Hasan, Sifat",
			"Dasgupta, Krishnendu",
			"Gandhi, Darshan",
			"TV, Sethuramen",
			"Patwa, Parth",
			"Singh, Ishaan",
			"Singh, Abhishek",
			"Raskar, Ramesh"
		],
		"subject": [
			"Computer Science - Computers and Society",
			"Computer Science - Cryptography and Security"
		],
		"description": [
			"  In this early draft, we describe a user-centric, card-based system for\nvaccine distribution. Our system makes use of digitally signed QR codes and\ntheir use for phased vaccine distribution, vaccine\nadministration/record-keeping, immunization verification, and follow-up symptom\nreporting. Furthermore, we propose and describe a complementary scanner app\nsystem to be used by vaccination clinics, public health officials, and\nimmunization verification parties to effectively utilize card-based framework.\nWe believe that the proposed system provides a privacy-preserving and efficient\nframework for vaccine distribution in both developed and developing regions.\n",
			"Comment: 8 pages, 4 Figures, 1 Table"
		],
		"date": [
			"2021-01-19",
			"2021-01-21"
		],
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07931",
		"pdf_url": "http://arxiv.org/pdf/2101.07931.pdf"
	},
	"1260": {
		"title": "Quarter Laplacian Filter for Edge Aware Image Processing",
		"creator": [
			"Gong, Yuanhao",
			"Tang, Wenming",
			"Zhou, Lebin",
			"Yu, Lantao",
			"Qiu, Guoping"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": "  This paper presents a quarter Laplacian filter that can preserve corners and\nedges during image smoothing. Its support region is $2\\times2$, which is\nsmaller than the $3\\times3$ support region of Laplacian filter. Thus, it is\nmore local. Moreover, this filter can be implemented via the classical box\nfilter, leading to high performance for real time applications. Finally, we\nshow its edge preserving property in several image processing tasks, including\nimage smoothing, texture enhancement, and low-light image enhancement. The\nproposed filter can be adopted in a wide range of image processing\napplications.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07933",
		"pdf_url": "http://arxiv.org/pdf/2101.07933.pdf"
	},
	"1261": {
		"title": "Beyond Fine-tuning: Classifying High Resolution Mammograms using\n  Function-Preserving Transformations",
		"creator": [
			"Wei, Tao",
			"Aviles-Rivero, Angelica I",
			"Wang, Shuo",
			"Huang, Yuan",
			"Gilbert, Fiona J",
			"Schönlieb, Carola-Bibiane",
			"Chen, Chang Wen"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  The task of classifying mammograms is very challenging because the lesion is\nusually small in the high resolution image. The current state-of-the-art\napproaches for medical image classification rely on using the de-facto method\nfor ConvNets - fine-tuning. However, there are fundamental differences between\nnatural images and medical images, which based on existing evidence from the\nliterature, limits the overall performance gain when designed with algorithmic\napproaches. In this paper, we propose to go beyond fine-tuning by introducing a\nnovel framework called MorphHR, in which we highlight a new transfer learning\nscheme. The idea behind the proposed framework is to integrate\nfunction-preserving transformations, for any continuous non-linear activation\nneurons, to internally regularise the network for improving mammograms\nclassification. The proposed solution offers two major advantages over the\nexisting techniques. Firstly and unlike fine-tuning, the proposed approach\nallows for modifying not only the last few layers but also several of the first\nones on a deep ConvNet. By doing this, we can design the network front to be\nsuitable for learning domain specific features. Secondly, the proposed scheme\nis scalable to hardware. Therefore, one can fit high resolution images on\nstandard GPU memory. We show that by using high resolution images, one prevents\nlosing relevant information. We demonstrate, through numerical and visual\nexperiments, that the proposed approach yields to a significant improvement in\nthe classification performance over state-of-the-art techniques, and is indeed\non a par with radiology experts. Moreover and for generalisation purposes, we\nshow the effectiveness of the proposed learning scheme on another large\ndataset, the ChestX-ray14, surpassing current state-of-the-art techniques.\n",
			"Comment: 10 pages, 5 figures"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07945",
		"pdf_url": "http://arxiv.org/pdf/2101.07945.pdf"
	},
	"1262": {
		"title": "Fast linear barycentric rational interpolation for singular functions\n  via scaled transformations",
		"creator": [
			"Kong, Desong",
			"Xiang, Shuhuang"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"32E30, 41A20, 41A50, 65N35, 65M70"
		],
		"description": [
			"  In this paper, applied strictly monotonic increasing scaled maps, a kind of\nwell-conditioned linear barycentric rational interpolations are proposed to\napproximate functions of singularities at the origin, such as $x^\\alpha$ for\n$\\alpha \\in (0,1)$ and $\\log(x)$. It just takes $O(N)$ flops and can achieve\nfast convergence rates with the choice the scaled parameter, where $N$ is the\nmaximum degree of the denominator and numerator. The construction of the\nrational interpolant couples rational polynomials in the barycentric form of\nsecond kind with the transformed Jacobi-Gauss-Lobatto points. Numerical\nexperiments are considered which illustrate the accuracy and efficiency of the\nalgorithms. The convergence of the rational interpolation is also considered.\n",
			"Comment: 24 pages, 32 figures"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07949",
		"pdf_url": "http://arxiv.org/pdf/2101.07949.pdf"
	},
	"1263": {
		"title": "Convolutional conditional neural processes for local climate downscaling",
		"creator": [
			"Vaughan, Anna",
			"Tebbutt, Will",
			"Hosking, J. Scott",
			"Turner, Richard E."
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Physics - Atmospheric and Oceanic Physics",
			"J.2"
		],
		"description": [
			"  A new model is presented for multisite statistical downscaling of temperature\nand precipitation using convolutional conditional neural processes (convCNPs).\nConvCNPs are a recently developed class of models that allow deep learning\ntechniques to be applied to off-the-grid spatio-temporal data. This model has a\nsubstantial advantage over existing downscaling methods in that the trained\nmodel can be used to generate multisite predictions at an arbitrary set of\nlocations, regardless of the availability of training data. The convCNP model\nis shown to outperform an ensemble of existing downscaling techniques over\nEurope for both temperature and precipitation taken from the VALUE\nintercomparison project. The model also outperforms an approach that uses\nGaussian processes to interpolate single-site downscaling models at unseen\nlocations. Importantly, substantial improvement is seen in the representation\nof extreme precipitation events. These results indicate that the convCNP is a\nrobust downscaling model suitable for generating localised projections for use\nin climate impact studies, and motivates further research into applications of\ndeep learning techniques in statistical downscaling.\n",
			"Comment: 26 pages, 12 figures"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07950",
		"pdf_url": "http://arxiv.org/pdf/2101.07950.pdf"
	},
	"1264": {
		"title": "This photograph has been altered: Testing the effectiveness of image\n  forensic labeling on news image credibility",
		"creator": [
			"Shen, Cuihua",
			"Kasra, Mona",
			"O'Brien, James"
		],
		"subject": "Computer Science - Social and Information Networks",
		"description": "  Despite the ubiquity and proliferation of images and videos in online news\nenvironments, much of the existing research on misinformation and its\ncorrection is solely focused on textual misinformation, and little is known\nabout how ordinary users evaluate fake or manipulated images and the most\neffective ways to label and correct such falsities. We designed a visual\nforensic label of image authenticity, Picture-O-Meter, and tested the label's\nefficacy in relation to its source and placement in an experiment with 2440\nparticipants. Our findings demonstrate that, despite human beings' general\ninability to detect manipulated images on their own, image forensic labels are\nan effective tool for counteracting visual misinformation.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07951",
		"pdf_url": "http://arxiv.org/pdf/2101.07951.pdf"
	},
	"1265": {
		"title": "PyTorch-Direct: Enabling GPU Centric Data Access for Very Large Graph\n  Neural Network Training with Irregular Accesses",
		"creator": [
			"Min, Seung Won",
			"Wu, Kun",
			"Huang, Sitao",
			"Hidayetoğlu, Mert",
			"Xiong, Jinjun",
			"Ebrahimi, Eiman",
			"Chen, Deming",
			"Hwu, Wen-mei"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Performance"
		],
		"description": "  With the increasing adoption of graph neural networks (GNNs) in the machine\nlearning community, GPUs have become an essential tool to accelerate GNN\ntraining. However, training GNNs on very large graphs that do not fit in GPU\nmemory is still a challenging task. Unlike conventional neural networks,\nmini-batching input samples in GNNs requires complicated tasks such as\ntraversing neighboring nodes and gathering their feature values. While this\nprocess accounts for a significant portion of the training time, we find\nexisting GNN implementations using popular deep neural network (DNN) libraries\nsuch as PyTorch are limited to a CPU-centric approach for the entire data\npreparation step. This \"all-in-CPU\" approach has negative impact on the overall\nGNN training performance as it over-utilizes CPU resources and hinders GPU\nacceleration of GNN training. To overcome such limitations, we introduce\nPyTorch-Direct, which enables a GPU-centric data accessing paradigm for GNN\ntraining. In PyTorch-Direct, GPUs are capable of efficiently accessing\ncomplicated data structures in host memory directly without CPU intervention.\nOur microbenchmark and end-to-end GNN training results show that PyTorch-Direct\nreduces data transfer time by 47.1% on average and speeds up GNN training by up\nto 1.6x. Furthermore, by reducing CPU utilization, PyTorch-Direct also saves\nsystem power by 12.4% to 17.5% during training. To minimize programmer effort,\nwe introduce a new \"unified tensor\" type along with necessary changes to the\nPyTorch memory allocator, dispatch logic, and placement rules. As a result,\nusers need to change at most two lines of their PyTorch GNN training code for\neach tensor object to take advantage of PyTorch-Direct.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07956",
		"pdf_url": "http://arxiv.org/pdf/2101.07956.pdf"
	},
	"1266": {
		"title": "Class balanced underwater object detection dataset generated by\n  class-wise style augmentation",
		"creator": [
			"Chen, Long",
			"Dong, Junyu",
			"Zhou, Huiyu"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Underwater object detection technique is of great significance for various\napplications in underwater the scenes. However, class imbalance issue is still\nan unsolved bottleneck for current underwater object detection algorithms. It\nleads to large precision discrepancies among different classes that the\ndominant classes with more training data achieve higher detection precisions\nwhile the minority classes with fewer training data achieves much lower\ndetection precisions. In this paper, we propose a novel class-wise style\naugmentation (CWSA) algorithm to generate a class-balanced underwater dataset\nBalance18 from the public contest underwater dataset URPC2018. CWSA is a new\nkind of data augmentation technique which augments the training data for the\nminority classes by generating various colors, textures and contrasts for the\nminority classes. Compare with previous data augmentation algorithms such\nflipping, cropping and rotations, CWSA is able to generate a class balanced\nunderwater dataset with diverse color distortions and haze-effects.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07959",
		"pdf_url": "http://arxiv.org/pdf/2101.07959.pdf"
	},
	"1267": {
		"title": "HIVE-4-MAT: Advancing the Ontology Infrastructure for Materials Science",
		"creator": [
			"Greenberg, Jane",
			"Zhao, Xintong",
			"Adair, Joseph",
			"Boone, Joan",
			"Hu, Xiaohua Tony"
		],
		"subject": [
			"Computer Science - Digital Libraries",
			"Computer Science - Computation and Language",
			"I.7"
		],
		"description": [
			"  Introduces HIVE-4-MAT - Helping Interdisciplinary Vocabulary Engineering for\nMaterials Science, an automatic linked data ontology application. Covers\ncontextual background for materials science, shared ontology infrastructures,\nand reviews the knowledge extraction and indexing process. HIVE-4-MAT's\nvocabulary browsing, term search and selection, and knowledge extraction and\nindexing are reviewed, and plans to integrate named entity recognition.\nConclusion highlights next steps with relation extraction to support better\nontologies.\n",
			"Comment: 12 pages, 1 table, 7 figures, Presented at \"MTSR '20: 14th\n  International Conference on Metadata and Semantics Research,\" and forthcoming\n  in conference proceedings. Research supported by NSF OAC: #1940239"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07960",
		"pdf_url": "http://arxiv.org/pdf/2101.07960.pdf"
	},
	"1268": {
		"title": "Robust W-GAN-Based Estimation Under Wasserstein Contamination",
		"creator": [
			"Liu, Zheng",
			"Loh, Po-Ling"
		],
		"subject": [
			"Mathematics - Statistics Theory",
			"Computer Science - Information Theory",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  Robust estimation is an important problem in statistics which aims at\nproviding a reasonable estimator when the data-generating distribution lies\nwithin an appropriately defined ball around an uncontaminated distribution.\nAlthough minimax rates of estimation have been established in recent years,\nmany existing robust estimators with provably optimal convergence rates are\nalso computationally intractable. In this paper, we study several estimation\nproblems under a Wasserstein contamination model and present computationally\ntractable estimators motivated by generative adversarial networks (GANs).\nSpecifically, we analyze properties of Wasserstein GAN-based estimators for\nlocation estimation, covariance matrix estimation, and linear regression and\nshow that our proposed estimators are minimax optimal in many scenarios.\nFinally, we present numerical results which demonstrate the effectiveness of\nour estimators.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07969",
		"pdf_url": "http://arxiv.org/pdf/2101.07969.pdf"
	},
	"1269": {
		"title": "Representation Evaluation Block-based Teacher-Student Network for the\n  Industrial Quality-relevant Performance Modeling and Monitoring",
		"creator": [
			"Yang, Dan",
			"Peng, Xin",
			"Lu, Yusheng",
			"Huang, Haojie",
			"Zhong, Weimin"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Quality-relevant fault detection plays an important role in industrial\nprocesses, while the current quality-related fault detection methods based on\nneural networks main concentrate on process-relevant variables and ignore\nquality-relevant variables, which restrict the application of process\nmonitoring. Therefore, in this paper, a fault detection scheme based on the\nimproved teacher-student network is proposed for quality-relevant fault\ndetection. In the traditional teacher-student network, as the features\ndifferences between the teacher network and the student network will cause\nperformance degradation on the student network, representation evaluation block\n(REB) is proposed to quantify the features differences between the teacher and\nthe student networks, and uncertainty modeling is used to add this difference\nin modeling process, which are beneficial to reduce the features differences\nand improve the performance of the student network. Accordingly, REB and\nuncertainty modeling is applied in the teacher-student network named as\nuncertainty modeling teacher-student uncertainty autoencoder (TSUAE). Then, the\nproposed TSUAE is applied to process monitoring, which can effectively detect\nfaults in the process-relevant subspace and quality-relevant subspace\nsimultaneously. The proposed TSUAE-based fault detection method is verified in\ntwo simulation experiments illustrating that it has satisfactory fault\ndetection performance compared to other fault detection methods.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07976",
		"pdf_url": "http://arxiv.org/pdf/2101.07976.pdf"
	},
	"1270": {
		"title": "Inference under Information Constraints III: Local Privacy Constraints",
		"creator": [
			"Acharya, Jayadev",
			"Canonne, Clément L.",
			"Freitag, Cody",
			"Sun, Ziteng",
			"Tyagi, Himanshu"
		],
		"subject": [
			"Computer Science - Data Structures and Algorithms",
			"Computer Science - Cryptography and Security",
			"Computer Science - Discrete Mathematics",
			"Mathematics - Statistics Theory"
		],
		"description": [
			"  We study goodness-of-fit and independence testing of discrete distributions\nin a setting where samples are distributed across multiple users. The users\nwish to preserve the privacy of their data while enabling a central server to\nperform the tests. Under the notion of local differential privacy, we propose\nsimple, sample-optimal, and communication-efficient protocols for these two\nquestions in the noninteractive setting, where in addition users may or may not\nshare a common random seed. In particular, we show that the availability of\nshared (public) randomness greatly reduces the sample complexity. Underlying\nour public-coin protocols are privacy-preserving mappings which, when applied\nto the samples, minimally contract the distance between their respective\nprobability distributions.\n",
			"Comment: To appear in the Special Issue on Privacy and Security of Information\n  Systems of the IEEE Journal on Selected Areas in Information Theory (JSAIT),\n  2021. Journal version of the AISTATS'19 paper \"Test without Trust: Optimal\n  Locally Private Distribution Testing\" (arXiv:1808.02174), which it extends\n  and supersedes"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07981",
		"pdf_url": "http://arxiv.org/pdf/2101.07981.pdf"
	},
	"1271": {
		"title": "Cell image segmentation by Feature Random Enhancement Module",
		"creator": [
			"Ando, Takamasa",
			"Hotta, Kazuhiro"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  It is important to extract good features using an encoder to realize semantic\nsegmentation with high accuracy. Although loss function is optimized in\ntraining deep neural network, far layers from the layers for computing loss\nfunction are difficult to train. Skip connection is effective for this problem\nbut there are still far layers from the loss function. In this paper, we\npropose the Feature Random Enhancement Module which enhances the features\nrandomly in only training. By emphasizing the features at far layers from loss\nfunction, we can train those layers well and the accuracy was improved. In\nexperiments, we evaluated the proposed module on two kinds of cell image\ndatasets, and our module improved the segmentation accuracy without increasing\ncomputational cost in test phase.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07983",
		"pdf_url": "http://arxiv.org/pdf/2101.07983.pdf"
	},
	"1272": {
		"title": "Semi-supervised Keypoint Localization",
		"creator": [
			"Moskvyak, Olga",
			"Maire, Frederic",
			"Dayoub, Feras",
			"Baktashmotlagh, Mahsa"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Knowledge about the locations of keypoints of an object in an image can\nassist in fine-grained classification and identification tasks, particularly\nfor the case of objects that exhibit large variations in poses that greatly\ninfluence their visual appearance, such as wild animals. However, supervised\ntraining of a keypoint detection network requires annotating a large image\ndataset for each animal species, which is a labor-intensive task. To reduce the\nneed for labeled data, we propose to learn simultaneously keypoint heatmaps and\npose invariant keypoint representations in a semi-supervised manner using a\nsmall set of labeled images along with a larger set of unlabeled images.\nKeypoint representations are learnt with a semantic keypoint consistency\nconstraint that forces the keypoint detection network to learn similar features\nfor the same keypoint across the dataset. Pose invariance is achieved by making\nkeypoint representations for the image and its augmented copies closer together\nin feature space. Our semi-supervised approach significantly outperforms\nprevious methods on several benchmarks for human and animal body landmark\nlocalization.\n",
			"Comment: accepted to ICLR 2021"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07988",
		"pdf_url": "http://arxiv.org/pdf/2101.07988.pdf"
	},
	"1273": {
		"title": "A Visual Analytics Approach to Facilitate the Proctoring of Online Exams",
		"creator": [
			"Li, Haotian",
			"Xu, Min",
			"Wang, Yong",
			"Wei, Huan",
			"Qu, Huamin"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": [
			"  Online exams have become widely used to evaluate students' performance in\nmastering knowledge in recent years, especially during the pandemic of\nCOVID-19. However, it is challenging to conduct proctoring for online exams due\nto the lack of face-to-face interaction. Also, prior research has shown that\nonline exams are more vulnerable to various cheating behaviors, which can\ndamage their credibility. This paper presents a novel visual analytics approach\nto facilitate the proctoring of online exams by analyzing the exam video\nrecords and mouse movement data of each student. Specifically, we detect and\nvisualize suspected head and mouse movements of students in three levels of\ndetail, which provides course instructors and teachers with convenient,\nefficient and reliable proctoring for online exams. Our extensive evaluations,\nincluding usage scenarios, a carefully-designed user study and expert\ninterviews, demonstrate the effectiveness and usability of our approach.\n",
			"Comment: 17 pages, 10 figures. Accepted at CHI2021"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07990",
			"doi:10.1145/3411764.3445294"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07990.pdf"
	},
	"1274": {
		"title": "Viral Visualizations: How Coronavirus Skeptics Use Orthodox Data\n  Practices to Promote Unorthodox Science Online",
		"creator": [
			"Lee, Crystal",
			"Yang, Tanya",
			"Inchoco, Gabrielle",
			"Jones, Graham M.",
			"Satyanarayan, Arvind"
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Computers and Society"
		],
		"description": [
			"  Controversial understandings of the coronavirus pandemic have turned data\nvisualizations into a battleground. Defying public health officials,\ncoronavirus skeptics on US social media spent much of 2020 creating data\nvisualizations showing that the government's pandemic response was excessive\nand that the crisis was over. This paper investigates how pandemic\nvisualizations circulated on social media, and shows that people who mistrust\nthe scientific establishment often deploy the same rhetorics of data-driven\ndecision-making used by experts, but to advocate for radical policy changes.\nUsing a quantitative analysis of how visualizations spread on Twitter and an\nethnographic approach to analyzing conversations about COVID data on Facebook,\nwe document an epistemological gap that leads pro- and anti-mask groups to draw\ndrastically different inferences from similar data. Ultimately, we argue that\nthe deployment of COVID data visualizations reflect a deeper sociopolitical\nrift regarding the place of science in public life.\n",
			"Comment: To appear in ACM CHI 2021; 18 pages, 4 figures, 1 table"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07993",
			"doi:10.1145/3411764.3445211"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07993.pdf"
	},
	"1275": {
		"title": "FedNS: Improving Federated Learning for collaborative image\n  classification on mobile clients",
		"creator": [
			"Zhuo, Yaoxin",
			"Li, Baoxin"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Federated Learning (FL) is a paradigm that aims to support loosely connected\nclients in learning a global model collaboratively with the help of a\ncentralized server. The most popular FL algorithm is Federated Averaging\n(FedAvg), which is based on taking weighted average of the client models, with\nthe weights determined largely based on dataset sizes at the clients. In this\npaper, we propose a new approach, termed Federated Node Selection (FedNS), for\nthe server's global model aggregation in the FL setting. FedNS filters and\nre-weights the clients' models at the node/kernel level, hence leading to a\npotentially better global model by fusing the best components of the clients.\nUsing collaborative image classification as an example, we show with\nexperiments from multiple datasets and networks that FedNS can consistently\nachieve improved performance over FedAvg.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07995",
		"pdf_url": "http://arxiv.org/pdf/2101.07995.pdf"
	},
	"1276": {
		"title": "SplitSR: An End-to-End Approach to Super-Resolution on Mobile Devices",
		"creator": [
			"Liu, Xin",
			"Li, Yuang",
			"Fromm, Josh",
			"Wang, Yuntao",
			"Jiang, Ziheng",
			"Mariakakis, Alex",
			"Patel, Shwetak"
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  Super-resolution (SR) is a coveted image processing technique for mobile apps\nranging from the basic camera apps to mobile health. Existing SR algorithms\nrely on deep learning models with significant memory requirements, so they have\nyet to be deployed on mobile devices and instead operate in the cloud to\nachieve feasible inference time. This shortcoming prevents existing SR methods\nfrom being used in applications that require near real-time latency. In this\nwork, we demonstrate state-of-the-art latency and accuracy for on-device\nsuper-resolution using a novel hybrid architecture called SplitSR and a novel\nlightweight residual block called SplitSRBlock. The SplitSRBlock supports\nchannel-splitting, allowing the residual blocks to retain spatial information\nwhile reducing the computation in the channel dimension. SplitSR has a hybrid\ndesign consisting of standard convolutional blocks and lightweight residual\nblocks, allowing people to tune SplitSR for their computational budget. We\nevaluate our system on a low-end ARM CPU, demonstrating both higher accuracy\nand up to 5 times faster inference than previous approaches. We then deploy our\nmodel onto a smartphone in an app called ZoomSR to demonstrate the first-ever\ninstance of on-device, deep learning-based SR. We conducted a user study with\n15 participants to have them assess the perceived quality of images that were\npost-processed by SplitSR. Relative to bilinear interpolation -- the existing\nstandard for on-device SR -- participants showed a statistically significant\npreference when looking at both images (Z=-9.270, p<0.01) and text (Z=-6.486,\np<0.01).\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.07996",
		"pdf_url": "http://arxiv.org/pdf/2101.07996.pdf"
	},
	"1277": {
		"title": "No More Handshaking: How have COVID-19 pushed the expansion of\n  computer-mediated communication in Japanese idol culture?",
		"creator": "Yakura, Hiromu",
		"subject": "Computer Science - Human-Computer Interaction",
		"description": [
			"  In Japanese idol culture, meet-and-greet events where fans were allowed to\nhandshake with an idol member for several seconds were regarded as its\nessential component until the spread of COVID-19. Now, idol groups are\nstruggling in the transition of such events to computer-mediated communication\nbecause these events had emphasized meeting face-to-face over communicating, as\nwe can infer from their length of time. I anticipated that investigating this\nemerging transition would provide implications because their communication has\na unique characteristic that is distinct from well-studied situations, such as\nworkplace communication and intimate relationships. Therefore, I first\nconducted a quantitative survey to develop a precise understanding of the\ntransition, and based on its results, had semi-structured interviews with idol\nfans about their perceptions of the transition. The survey revealed distinctive\napproaches, including one where fans gathered at a venue but were isolated from\nthe idol member by an acrylic plate and talked via a video call. Then the\ninterviews not only provided answers to why such an approach would be\nreasonable but also suggested the existence of a large gap between conventional\noffline events and emerging online events in their perceptions. Based on the\nresults, I discussed how we can develop interaction techniques to support this\ntransition and how we can apply it to other situations outside idol culture,\nsuch as computer-mediated performing arts.\n",
			"Comment: To appear in ACM CHI Conference on Human Factors in Computing Systems\n  (CHI '21), May 8-13, 2021, Yokohama, Japan"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.07999",
			"doi:10.1145/3411764.3445252"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.07999.pdf"
	},
	"1278": {
		"title": "Macroscopic Control of Text Generation for Image Captioning",
		"creator": [
			"Zhu, Zhangzi",
			"Wang, Tianlei",
			"Qu, Hong"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Despite the fact that image captioning models have been able to generate\nimpressive descriptions for a given image, challenges remain: (1) the\ncontrollability and diversity of existing models are still far from\nsatisfactory; (2) models sometimes may produce extremely poor-quality captions.\nIn this paper, two novel methods are introduced to solve the problems\nrespectively. Specifically, for the former problem, we introduce a control\nsignal which can control the macroscopic sentence attributes, such as sentence\nquality, sentence length, sentence tense and number of nouns etc. With such a\ncontrol signal, the controllability and diversity of existing captioning models\nare enhanced. For the latter problem, we innovatively propose a strategy that\nan image-text matching model is trained to measure the quality of sentences\ngenerated in both forward and backward directions and finally choose the better\none. As a result, this strategy can effectively reduce the proportion of\npoorquality sentences. Our proposed methods can be easily applie on most image\ncaptioning models to improve their overall performance. Based on the Up-Down\nmodel, the experimental results show that our methods achieve BLEU-\n4/CIDEr/SPICE scores of 37.5/120.3/21.5 on MSCOCO Karpathy test split with\ncross-entropy training, which surpass the results of other state-of-the-art\nmethods trained by cross-entropy loss.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08000",
		"pdf_url": "http://arxiv.org/pdf/2101.08000.pdf"
	},
	"1279": {
		"title": "One-way resynchronizability of word transducers",
		"creator": [
			"Bose, Sougata",
			"Krishna, S. N.",
			"Muscholl, Anca",
			"Puppis, Gabriele"
		],
		"subject": [
			"Computer Science - Formal Languages and Automata Theory",
			"Computer Science - Logic in Computer Science",
			"68Q45",
			"F.4.1",
			"F.1.1"
		],
		"description": "  The origin semantics for transducers was proposed in 2014, and led to various\ncharacterizations and decidability results that are in contrast with the\nclassical semantics. In this paper we add a further decidability result for\ncharacterizing transducers that are close to one-way transducers in the origin\nsemantics. We show that it is decidable whether a non-deterministic two-way\nword transducer can be resynchronized by a bounded, regular resynchronizer into\nan origin-equivalent one-way transducer. The result is in contrast with the\nusual semantics, where it is undecidable to know if a non-deterministic two-way\ntransducer is equivalent to some one-way transducer.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08011",
		"pdf_url": "http://arxiv.org/pdf/2101.08011.pdf"
	},
	"1280": {
		"title": "Deep Learning for Intelligent Demand Response and Smart Grids: A\n  Comprehensive Survey",
		"creator": [
			"B, Prabadevi",
			"Pham, Quoc-Viet",
			"Liyanage, Madhusanka",
			"Deepa, N",
			"VVSS, Mounik",
			"Reddy, Shivani",
			"Maddikunta, Praveen Kumar Reddy",
			"Khare, Neelu",
			"Gadekallu, Thippa Reddy",
			"Hwang, Won-Joo"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": [
			"  Electricity is one of the mandatory commodities for mankind today. To address\nchallenges and issues in the transmission of electricity through the\ntraditional grid, the concepts of smart grids and demand response have been\ndeveloped. In such systems, a large amount of data is generated daily from\nvarious sources such as power generation (e.g., wind turbines), transmission\nand distribution (microgrids and fault detectors), load management (smart\nmeters and smart electric appliances). Thanks to recent advancements in big\ndata and computing technologies, Deep Learning (DL) can be leveraged to learn\nthe patterns from the generated data and predict the demand for electricity and\npeak hours. Motivated by the advantages of deep learning in smart grids, this\npaper sets to provide a comprehensive survey on the application of DL for\nintelligent smart grids and demand response. Firstly, we present the\nfundamental of DL, smart grids, demand response, and the motivation behind the\nuse of DL. Secondly, we review the state-of-the-art applications of DL in smart\ngrids and demand response, including electric load forecasting, state\nestimation, energy theft detection, energy sharing and trading. Furthermore, we\nillustrate the practicality of DL via various use cases and projects. Finally,\nwe highlight the challenges presented in existing research works and highlight\nimportant issues and potential directions in the use of DL for smart grids and\ndemand response.\n",
			"Comment: This work has been submitted for possible publication. Any comments\n  and suggestions are appreciated"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08013",
		"pdf_url": "http://arxiv.org/pdf/2101.08013.pdf"
	},
	"1281": {
		"title": "What are Hybrid Development Methods Made Of? An Evidence-based\n  Characterization",
		"creator": [
			"Tell, Paolo",
			"Klünder, Jil",
			"Küpper, Steffen",
			"Raffo, David",
			"MacDonell, Stephen G.",
			"Münch, Jürgen",
			"Pfahl, Dietmar",
			"Linssen, Oliver",
			"Kuhrmann, Marco"
		],
		"subject": "Computer Science - Software Engineering",
		"description": [
			"  Among the multitude of software development processes available, hardly any\nis used by the book. Regardless of company size or industry sector, a majority\nof project teams and companies use customized processes that combine different\ndevelopment methods -- so-called hybrid development methods. Even though such\nhybrid development methods are highly individualized, a common understanding of\nhow to systematically construct synergetic practices is missing. In this paper,\nwe make a first step towards devising such guidelines. Grounded in 1,467 data\npoints from a large-scale online survey among practitioners, we study the\ncurrent state of practice in process use to answer the question: What are\nhybrid development methods made of? Our findings reveal that only eight methods\nand few practices build the core of modern software development. This small set\nallows for statistically constructing hybrid development methods. Using an 85%\nagreement level in the participants' selections, we provide two examples\nillustrating how hybrid development methods are characterized by the practices\nthey are made of. Our evidence-based analysis approach lays the foundation for\ndevising hybrid development methods.\n",
			"Comment: Conference, 11 pages, 8 figures, 3 tables"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08016",
			"Proceedings of the International Conference on Software and\n  Systems Process (ICSSP2019). Montr\\'eal, Canada, IEEE Computer Society Press,\n  pp.105-114",
			"doi:10.1109/ICSSP.2019.00022"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08016.pdf"
	},
	"1282": {
		"title": "Improved Signed Distance Function for 2D Real-time SLAM and Accurate\n  Localization",
		"creator": [
			"Fu, Xingyin",
			"Fang, Zheng",
			"Xiao, Xizhen",
			"He, Yijia",
			"Liu, Xiao"
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  Accurate mapping and localization are very important for many industrial\nrobotics applications. In this paper, we propose an improved Signed Distance\nFunction (SDF) for both 2D SLAM and pure localization to improve the accuracy\nof mapping and localization. To achieve this goal, firstly we improved the\nback-end mapping to build a more accurate SDF map by extending the update range\nand building free space, etc. Secondly, to get more accurate pose estimation\nfor the front-end, we proposed a new iterative registration method to align the\ncurrent scan to the SDF submap by removing random outliers of laser scanners.\nThirdly, we merged all the SDF submaps to produce an integrated SDF map for\nhighly accurate pure localization. Experimental results show that based on the\nmerged SDF map, a localization accuracy of a few millimeters (5mm) can be\nachieved globally within the map. We believe that this method is important for\nmobile robots working in scenarios where high localization accuracy matters.\n",
			"Comment: 7 pages, 9 figures, conference paper"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08018",
		"pdf_url": "http://arxiv.org/pdf/2101.08018.pdf"
	},
	"1283": {
		"title": "NEMR: Network Embedding on Metric of Relation",
		"creator": [
			"Xie, Luodi",
			"Shen, Hong",
			"Ren, Jiaxin"
		],
		"subject": [
			"Computer Science - Social and Information Networks",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Network embedding maps the nodes of a given network into a low-dimensional\nspace such that the semantic similarities among the nodes can be effectively\ninferred. Most existing approaches use inner-product of node embedding to\nmeasure the similarity between nodes leading to the fact that they lack the\ncapacity to capture complex relationships among nodes. Besides, they take the\npath in the network just as structural auxiliary information when inferring\nnode embeddings, while paths in the network are formed with rich user\ninformations which are semantically relevant and cannot be ignored. In this\npaper, We propose a novel method called Network Embedding on the Metric of\nRelation, abbreviated as NEMR, which can learn the embeddings of nodes in a\nrelational metric space efficiently. First, our NEMR models the relationships\namong nodes in a metric space with deep learning methods including variational\ninference that maps the relationship of nodes to a gaussian distribution so as\nto capture the uncertainties. Secondly, our NEMR considers not only the\nequivalence of multiple-paths but also the natural order of a single-path when\ninferring embeddings of nodes, which makes NEMR can capture the multiple\nrelationships among nodes since multiple paths contain rich user information,\ne.g., age, hobby and profession. Experimental results on several public\ndatasets show that the NEMR outperforms the state-of-the-art methods on\nrelevant inference tasks including link prediction and node classification.\n",
			"Comment: 11 pages, 5 figures"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08020",
		"pdf_url": "http://arxiv.org/pdf/2101.08020.pdf"
	},
	"1284": {
		"title": "Bolder is Better: Raising User Awareness through Salient and Concise\n  Privacy Notices",
		"creator": [
			"Ebert, Nico",
			"Ackermann, Kurt Alexander",
			"Scheppler, Björn"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": "  This paper addresses the question whether the recently proposed approach of\nconcise privacy notices in apps and on websites is effective in raising user\nawareness. To assess the effectiveness in a realistic setting, we included\nconcise notices in a fictitious but realistic fitness tracking app and asked\nparticipants recruited from an online panel to provide their feedback on the\nusability of the app as a cover story. Importantly, after giving feedback,\nusers were also asked to recall the data practices described in the notices.\nThe experimental setup included the variation of different levels of saliency\nand riskiness of the privacy notices. Based on a total sample of 2,274\nparticipants, our findings indicate that concise privacy notices are indeed a\npromising approach to raise user awareness for privacy information when\ndisplayed in a salient way, especially in case the notices describe risky data\npractices. Our results may be helpful for regulators, user advocates and\ntransparency-oriented companies in creating or enforcing better privacy\ntransparency towards average users that do not read traditional privacy\npolicies.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08021",
		"pdf_url": "http://arxiv.org/pdf/2101.08021.pdf"
	},
	"1285": {
		"title": "Diffuse-interface blended method for the imposition of physical\n  boundaries in two-fluid flows",
		"creator": [
			"Treeratanaphitak, Tanyakarn",
			"Abukhdeir, Nasser Mohieddin"
		],
		"subject": [
			"Physics - Fluid Dynamics",
			"Mathematics - Numerical Analysis"
		],
		"description": [
			"  Multiphase flows are commonly found in chemical engineering processes such as\ndistillation columns, bubble columns, fluidized beds and heat exchangers.\nPhysical boundaries in numerical simulations of multiphase flows are generally\ndefined by a mesh that conforms to the physical boundaries of the system.\nDepending on the complexity of the physical system, generating the conformal\nmesh can be time-consuming and the resulting mesh could potentially contain a\nlarge number of skewed elements, which is undesirable. The diffuse-interface\napproach allows for a structured mesh to be used while still capturing the\ndesired solid-fluid boundaries. In this work, a diffuse-interface method for\nthe imposition of physical boundaries is developed for two-fluid incompressible\nflow systems. The diffuse-interface is used to define the physical boundaries\nand the boundary conditions are imposed by blending the conservation equations\nfrom the two-fluid model with that of the solid. The results from the\ndiffuse-interface method and mesh-defined boundaries are found to be in good\nagreement at small diffuse-interface widths.\n",
			"Comment: Submitted to International Journal of Multiphase Flow"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08022",
		"pdf_url": "http://arxiv.org/pdf/2101.08022.pdf"
	},
	"1286": {
		"title": "Adversarial Attacks for Tabular Data: Application to Fraud Detection and\n  Imbalanced Data",
		"creator": [
			"Cartella, Francesco",
			"Anunciacao, Orlando",
			"Funabiki, Yuki",
			"Yamaguchi, Daisuke",
			"Akishita, Toru",
			"Elshocht, Olivier"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Guaranteeing the security of transactional systems is a crucial priority of\nall institutions that process transactions, in order to protect their\nbusinesses against cyberattacks and fraudulent attempts. Adversarial attacks\nare novel techniques that, other than being proven to be effective to fool\nimage classification models, can also be applied to tabular data. Adversarial\nattacks aim at producing adversarial examples, in other words, slightly\nmodified inputs that induce the Artificial Intelligence (AI) system to return\nincorrect outputs that are advantageous for the attacker. In this paper we\nillustrate a novel approach to modify and adapt state-of-the-art algorithms to\nimbalanced tabular data, in the context of fraud detection. Experimental\nresults show that the proposed modifications lead to a perfect attack success\nrate, obtaining adversarial examples that are also less perceptible when\nanalyzed by humans. Moreover, when applied to a real-world production system,\nthe proposed techniques shows the possibility of posing a serious threat to the\nrobustness of advanced AI-based fraud detection procedures.\n",
			"Comment: Will be published on Proceedings of the Workshop on Artificial\n  Intelligence Safety (SafeAI 2021) co-located with 35th AAAI Conference on\n  Artificial Intelligence (AAAI 2021)"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08030",
		"pdf_url": "http://arxiv.org/pdf/2101.08030.pdf"
	},
	"1287": {
		"title": "Bias in ontologies -- a preliminary assessment",
		"creator": "Keet, C. Maria",
		"subject": [
			"Computer Science - Artificial Intelligence",
			"I.2.4"
		],
		"description": [
			"  Logical theories in the form of ontologies and similar artefacts in computing\nand IT are used for structuring, annotating, and querying data, among others,\nand therewith influence data analytics regarding what is fed into the\nalgorithms. Algorithmic bias is a well-known notion, but what does bias mean in\nthe context of ontologies that provide a structuring mechanism for an\nalgorithm's input? What are the sources of bias there and how would they\nmanifest themselves in ontologies? We examine and enumerate types of bias\nrelevant for ontologies, and whether they are explicit or implicit. These eight\ntypes are illustrated with examples from extant production-level ontologies and\nsamples from the literature. We then assessed three concurrently developed\nCOVID-19 ontologies on bias and detected different subsets of types of bias in\neach one, to a greater or lesser extent. This first characterisation aims\ncontribute to a sensitisation of ethical aspects of ontologies primarily\nregarding representation of information and knowledge.\n",
			"Comment: 10 pages, 4 figures, 2 tables, soon to be submitted to an\n  international conference"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08035",
		"pdf_url": "http://arxiv.org/pdf/2101.08035.pdf"
	},
	"1288": {
		"title": "Bridge the Vision Gap from Field to Command: A Deep Learning Network\n  Enhancing Illumination and Details",
		"creator": [
			"Jiang, Zhuqing",
			"Liu, Chang",
			"Wang, Ya'nan",
			"Li, Kai",
			"Men, Aidong",
			"Wang, Haiying",
			"Luo, Haiyong"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  With the goal of tuning up the brightness, low-light image enhancement enjoys\nnumerous applications, such as surveillance, remote sensing and computational\nphotography. Images captured under low-light conditions often suffer from poor\nvisibility and blur. Solely brightening the dark regions will inevitably\namplify the blur, thus may lead to detail loss. In this paper, we propose a\nsimple yet effective two-stream framework named NEID to tune up the brightness\nand enhance the details simultaneously without introducing many computational\ncosts. Precisely, the proposed method consists of three parts: Light\nEnhancement (LE), Detail Refinement (DR) and Feature Fusing (FF) module, which\ncan aggregate composite features oriented to multiple tasks based on channel\nattention mechanism. Extensive experiments conducted on several benchmark\ndatasets demonstrate the efficacy of our method and its superiority over\nstate-of-the-art methods.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08039",
		"pdf_url": "http://arxiv.org/pdf/2101.08039.pdf"
	},
	"1289": {
		"title": "Bayesian Optimization Assisted Meal Bolus Decision Based on Gaussian\n  Processes Learning and Risk-Sensitive Control",
		"creator": [
			"Cai, Deheng",
			"Liu, Wei",
			"Ji, Linong",
			"Shi, Dawei"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": "  Effective postprandial glucose control is important to glucose management for\nsubjects with diabetes mellitus. In this work, a data-driven meal bolus\ndecision method is proposed without the need of subject-specific glucose\nmanagement parameters. The postprandial glucose dynamics is learnt using\nGaussian process regression. Considering the asymmetric risks of hyper- and\nhypoglycemia and the uncertainties in the predicted glucose trajectories, an\nasymmetric risk-sensitive cost function is designed. Bayesian optimization is\nutilized to solve the optimization problem, since the gradient of the cost\nfunction is unavailable. The proposed approach is evaluated using the 10-adult\ncohort of the FDA-accepted UVA/Padova T1DM simulator and compared with the\nstandard insulin bolus calculator. For the case of announced meals, the\nproposed method achieves satisfactory and similar performance in terms of mean\nglucose and percentage time in [70, 180] mg/dL without increasing the risk of\nhypoglycemia. Similar results are observed for the case without the meal\ninformation (assuming that the patient follows a consistent diet) and the case\nof basal rate mismatches. In addition, advisory-mode analysis is performed\nbased on clinical data, which indicates that the method can determine safe and\nreasonable meal boluses in real clinical settings. The results verify the\neffectiveness and robustness of the proposed method and indicate the\nfeasibility of achieving improved postprandial glucose regulation through a\ndata-driven optimal control method.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08044",
		"pdf_url": "http://arxiv.org/pdf/2101.08044.pdf"
	},
	"1290": {
		"title": "Extended Reality (XR) Remote Research: a Survey of Drawbacks and\n  Opportunities",
		"creator": [
			"Ratcliffe, Jack",
			"Soave, Francesco",
			"Bryan-Kinns, Nick",
			"Tokarchuk, Laurissa",
			"Farkhatdinov, Ildar"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": "  Extended Reality (XR) technology - such as virtual and augmented reality - is\nnow widely used in Human Computer Interaction (HCI), social science and\npsychology experimentation. However, these experiments are predominantly\ndeployed in-lab with a co-present researcher. Remote experiments, without\nco-present researchers, have not flourished, despite the success of remote\napproaches for non-XR investigations. This paper summarises findings from a\n30-item survey of 46 XR researchers to understand perceived limitations and\nbenefits of remote XR experimentation. Our thematic analysis identifies\nconcerns common with non-XR remote research, such as participant recruitment,\nas well as XR-specific issues, including safety and hardware variability. We\nidentify potential positive affordances of XR technology, including leveraging\ndata collection functionalities builtin to HMDs (e.g. hand, gaze tracking) and\nthe portability and reproducibility of an experimental setting. We suggest that\nXR technology could be conceptualised as an interactive technology and a\ncapable data-collection device suited for remote experimentation.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08046",
			"doi:10.1145/3411764.3445170"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08046.pdf"
	},
	"1291": {
		"title": "Exploring Design and Governance Challenges in the Development of\n  Privacy-Preserving Computation",
		"creator": [
			"Agrawal, Nitin",
			"Binns, Reuben",
			"Van Kleek, Max",
			"Laine, Kim",
			"Shadbolt, Nigel"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": "  Homomorphic encryption, secure multi-party computation, and differential\nprivacy are part of an emerging class of Privacy Enhancing Technologies which\nshare a common promise: to preserve privacy whilst also obtaining the benefits\nof computational analysis. Due to their relative novelty, complexity, and\nopacity, these technologies provoke a variety of novel questions for design and\ngovernance. We interviewed researchers, developers, industry leaders,\npolicymakers, and designers involved in their deployment to explore\nmotivations, expectations, perceived opportunities and barriers to adoption.\nThis provided insight into several pertinent challenges facing the adoption of\nthese technologies, including: how they might make a nebulous concept like\nprivacy computationally tractable; how to make them more usable by developers;\nand how they could be explained and made accountable to stakeholders and wider\nsociety. We conclude with implications for the development, deployment, and\nresponsible governance of these privacy-preserving computation techniques.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08048",
			"doi:10.1145/3411764.3445677"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08048.pdf"
	},
	"1292": {
		"title": "Fast formation and assembly of isogeometric Galerkin matrices for\n  trimmed patches",
		"creator": "Marussig, Benjamin",
		"subject": [
			"Computer Science - Computational Engineering, Finance, and Science",
			"Mathematics - Numerical Analysis"
		],
		"description": "  This work explores the application of the fast assembly and formation\nstrategy from [8, 17] to trimmed bi-variate parameter spaces. Two concepts for\nthe treatment of basis functions cut by the trimming curve are investigated:\none employs a hybrid Gauss-point-based approach, and the other computes\ndiscontinuous weighted quadrature rules. The concepts' accuracy and efficiency\nare examined for the formation of mass matrices and their application to\nL2-projection. Significant speed-ups compared to standard element by element\nfinite element formation are observed. There is no clear preference between the\nconcepts proposed. While the discontinuous weighted scheme scales favorably\nwith the degree of the basis, it also requires additional effort for computing\nthe quadrature weights. The hybrid Gauss approach does not have this overhead,\nwhich is determined by the complexity of the trimming curve. Hence, it is\nwell-suited for moderate degrees, whereas discontinuous-weightedquadrature has\npotential for high degrees, in particular, if the related weights are computed\nin parallel.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08053",
		"pdf_url": "http://arxiv.org/pdf/2101.08053.pdf"
	},
	"1293": {
		"title": "Voltage Inference for and Coordination of Distributed Voltage Controls\n  in Extremely-High DER-Penetration Distribution Networks",
		"creator": [
			"Xu, Ying",
			"Qu, Zhihua"
		],
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": "  The unique problems and phenomena in the distributed voltage control of\nlarge-scale power distribution systems with extremely-high DER-penetration are\ntargeted in this paper. First, a DER-explicit distribution network model and\nvoltage sensitivity are derived. Based on that, a voltage inference method is\nimplemented to fill the gap of measurement insufficiency in the grid-edge\nareas. Then, autonomous Q control being implemented in each local area, a\n$\\overline{Q}$-coordinated P control is designed to coordinate the reactive and\nreal power controls. All the algorithms have been tested in standard and\nsynthetic systems, and have expected results. Moreover, an open-source software\nplatform, which integrates the modeling of communication networks, DER\ncontrols, and power networks, is developed to enable the distributed control\nand optimization algorithms in the grid simulation of the large-scale\ndistribution systems.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08054",
		"pdf_url": "http://arxiv.org/pdf/2101.08054.pdf"
	},
	"1294": {
		"title": "On the Parametrization and Statistics of Propagation Graphs",
		"creator": [
			"Prüller, Richard",
			"Blazek, Thomas",
			"Pratschner, Stefan",
			"Rupp, Markus"
		],
		"subject": [
			"Computer Science - Information Theory",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": [
			"  Propagation graphs (PGs) serve as a frequency-selective, spatially consistent\nchannel model suitable for fast channel simulations in a scattering\nenvironment. So far, however, the parametrization of the model, and its\nconsequences, have received little attention. In this contribution, we propose\na new parametrization for PGs that adheres to the doubly exponentially decaying\ncluster structure of the Saleh-Valenzuela (SV) model. We show how to compute\nthe newly proposed internal model parameters based on an approximation of the\n$K$-factor and the two decay rates from the SV model. Furthermore, via the\nsingular values of multiple-input multiple-output (MIMO) channels, we compare\nthe degrees of freedom (DoF) between our new and another frequently used\nparametrization. Specifically, we compare the DoF loss when the distance\nbetween antennas within the transmitter and receiver arrays or the average\ndistance between scatterers decreases. Based on this comparison, it is shown\nthat, in contrast to the typical parametrization, our newly proposed\nparametrization loses DoF in both scenarios, as one would expect from a\nspatially consistent channel model.\n",
			"Comment: 5 pages, 3 figures, accepted for publication at EuCAP 2021"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08056",
		"pdf_url": "http://arxiv.org/pdf/2101.08056.pdf"
	},
	"1295": {
		"title": "A Similarity Measure of Gaussian Process Predictive Distributions",
		"creator": [
			"Asencio-Martín, Lucia",
			"Garrido-Merchán, Eduardo C."
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  Some scenarios require the computation of a predictive distribution of a new\nvalue evaluated on an objective function conditioned on previous observations.\nWe are interested on using a model that makes valid assumptions on the\nobjective function whose values we are trying to predict. Some of these\nassumptions may be smoothness or stationarity. Gaussian process (GPs) are\nprobabilistic models that can be interpreted as flexible distributions over\nfunctions. They encode the assumptions through covariance functions, making\nhypotheses about new data through a predictive distribution by being fitted to\nold observations. We can face the case where several GPs are used to model\ndifferent objective functions. GPs are non-parametric models whose complexity\nis cubic on the number of observations. A measure that represents how similar\nis one GP predictive distribution with respect to another would be useful to\nstop using one GP when they are modelling functions of the same input space. We\nare really inferring that two objective functions are correlated, so one GP is\nenough to model both of them by performing a transformation of the prediction\nof the other function in case of inverse correlation. We show empirical\nevidence in a set of synthetic and benchmark experiments that GPs predictive\ndistributions can be compared and that one of them is enough to predict two\ncorrelated functions in the same input space. This similarity metric could be\nextremely useful used to discard objectives in Bayesian many-objective\noptimization.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08061",
		"pdf_url": "http://arxiv.org/pdf/2101.08061.pdf"
	},
	"1296": {
		"title": "Thread Evolution Kit for Optimizing Thread Operations on CE/IoT Devices",
		"creator": [
			"Lim, Geunsik",
			"Kang, Donghyun",
			"Eom, Young Ik"
		],
		"subject": [
			"Computer Science - Operating Systems",
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Performance"
		],
		"description": "  Most modern operating systems have adopted the one-to-one thread model to\nsupport fast execution of threads in both multi-core and single-core systems.\nThis thread model, which maps the kernel-space and user-space threads in a\none-to-one manner, supports quick thread creation and termination in\nhigh-performance server environments. However, the performance of time-critical\nthreads is degraded when multiple threads are being run in low-end CE devices\nwith limited system resources. When a CE device runs many threads to support\ndiverse application functionalities, low-level hardware specifications often\nlead to significant resource contention among the threads trying to obtain\nsystem resources. As a result, the operating system encounters challenges, such\nas excessive thread context switching overhead, execution delay of\ntime-critical threads, and a lack of virtual memory for thread stacks. This\npaper proposes a state-of-the-art Thread Evolution Kit (TEK) that consists of\nthree primary components: a CPU Mediator, Stack Tuner, and Enhanced Thread\nIdentifier. From the experiment, we can see that the proposed scheme\nsignificantly improves user responsiveness (7x faster) under high CPU\ncontention compared to the traditional thread model. Also, TEK solves the\nsegmentation fault problem that frequently occurs when a CE application\nincreases the number of threads during its execution.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08062",
			"doi:10.1109/TCE.2020.3033328"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08062.pdf"
	},
	"1297": {
		"title": "Component Tree Loss Function: Definition and Optimization",
		"creator": [
			"Perret, Benjamin",
			"Cousty, Jean"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": "  In this article, we propose a method to design loss functions based on\ncomponent trees which can be optimized by gradient descent algorithms and which\nare therefore usable in conjunction with recent machine learning approaches\nsuch as neural networks. We show how the altitudes associated to the nodes of\nsuch hierarchical image representations can be differentiated with respect to\nthe image pixel values. This feature is used to design a generic loss function\nthat can select or discard image maxima based on various attributes such as\nextinction values. The possibilities of the proposed method are demonstrated on\nsimulated and real image filtering.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08063",
		"pdf_url": "http://arxiv.org/pdf/2101.08063.pdf"
	},
	"1298": {
		"title": "Upstream mobility Finite Volumes for the Richards equation in\n  heterogenous domains",
		"creator": [
			"Bassetto, Sabrina",
			"Cancès, Clément",
			"Enchéry, Guillaume",
			"Tran, Quang-Huy"
		],
		"subject": [
			"Mathematics - Numerical Analysis",
			"65M08, 65M12, 76S05"
		],
		"description": "  This paper is concerned with the Richards equation in a heterogeneous domain,\neach subdomain of which is homogeneous and represents a rocktype. Our first\ncontribution is to rigorously prove convergence toward a weak solution of\ncell-centered finite-volume schemes with upstream mobility and without\nKirchhoff's transform. Our second contribution is to numerically demonstrate\nthe relevance of locally refining the grid at the interface between subregions,\nwhere discontinuities occur, in order to preserve an acceptable accuracy for\nthe results computed with the schemes under consideration.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08077",
		"pdf_url": "http://arxiv.org/pdf/2101.08077.pdf"
	},
	"1299": {
		"title": "A Damped Newton Algorithm for Generated Jacobian Equations",
		"creator": [
			"Gallouët, Anatole",
			"Merigot, Quentin",
			"Thibert, Boris"
		],
		"subject": [
			"Computer Science - Computational Geometry",
			"Mathematics - Analysis of PDEs",
			"Mathematics - Numerical Analysis"
		],
		"description": "  Generated Jacobian Equations have been introduced by Trudinger [Disc. cont.\ndyn. sys (2014), pp. 1663-1681] as a generalization of Monge-Amp{\\`e}re\nequations arising in optimal transport. In this paper, we introduce and study a\ndamped Newton algorithm for solving these equations in the semi-discrete\nsetting, meaning that one of the two measures involved in the problem is\nfinitely supported and the other one is absolutely continuous. We also present\na numerical application of this algorithm to the near-field parallel refractor\nproblem arising in non-imaging problems.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08080",
		"pdf_url": "http://arxiv.org/pdf/2101.08080.pdf"
	},
	"1300": {
		"title": "The Challenges of Persian User-generated Textual Content: A Machine\n  Learning-Based Approach",
		"creator": "Habib, Mohammad Kasra",
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  Over recent years a lot of research papers and studies have been published on\nthe development of effective approaches that benefit from a large amount of\nuser-generated content and build intelligent predictive models on top of them.\nThis research applies machine learning-based approaches to tackle the hurdles\nthat come with Persian user-generated textual content. Unfortunately, there is\nstill inadequate research in exploiting machine learning approaches to\nclassify/cluster Persian text. Further, analyzing Persian text suffers from a\nlack of resources; specifically from datasets and text manipulation tools.\nSince the syntax and semantics of the Persian language is different from\nEnglish and other languages, the available resources from these languages are\nnot instantly usable for Persian. In addition, recognition of nouns and\npronouns, parts of speech tagging, finding words' boundary, stemming or\ncharacter manipulations for Persian language are still unsolved issues that\nrequire further studying. Therefore, efforts have been made in this research to\naddress some of the challenges. This presented approach uses a\nmachine-translated datasets to conduct sentiment analysis for the Persian\nlanguage. Finally, the dataset has been rehearsed with different classifiers\nand feature engineering approaches. The results of the experiments have shown\npromising state-of-the-art performance in contrast to the previous efforts; the\nbest classifier was Support Vector Machines which achieved a precision of\n91.22%, recall of 91.71%, and F1 score of 91.46%.\n",
			"Comment: 12 Pages bib inc., 5 Figures and 5 Tables"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08087",
		"pdf_url": "http://arxiv.org/pdf/2101.08087.pdf"
	},
	"1301": {
		"title": "Automatic Differentiation via Effects and Handlers: An Implementation in\n  Frank",
		"creator": "Sigal, Jesse",
		"subject": [
			"Computer Science - Programming Languages",
			"Computer Science - Machine Learning",
			"F.3.2",
			"F.3.3",
			"G.1.4"
		],
		"description": [
			"  Automatic differentiation (AD) is an important family of algorithms which\nenables derivative based optimization. We show that AD can be simply\nimplemented with effects and handlers by doing so in the Frank language. By\nconsidering how our implementation behaves in Frank's operational semantics, we\nshow how our code performs the dynamic creation of programs during evaluation.\n",
			"Comment: Appeared as short paper in PEPM'21, see\n  https://www.youtube.com/watch?v=BmBSJFkfL2M for associated talk"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08095",
		"pdf_url": "http://arxiv.org/pdf/2101.08095.pdf"
	},
	"1302": {
		"title": "A Generalized Weisfeiler-Lehman Graph Kernel",
		"creator": [
			"Schulz, Till Hendrik",
			"Horváth, Tamás",
			"Welke, Pascal",
			"Wrobel, Stefan"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  The Weisfeiler-Lehman graph kernels are among the most prevalent graph\nkernels due to their remarkable time complexity and predictive performance.\nTheir key concept is based on an implicit comparison of neighborhood\nrepresenting trees with respect to equality (i.e., isomorphism). This binary\nvalued comparison is, however, arguably too rigid for defining suitable\nsimilarity measures over graphs. To overcome this limitation, we propose a\ngeneralization of Weisfeiler-Lehman graph kernels which takes into account the\nsimilarity between trees rather than equality. We achieve this using a\nspecifically fitted variation of the well-known tree edit distance which can\nefficiently be calculated. We empirically show that our approach significantly\noutperforms state-of-the-art methods in terms of predictive performance on\ndatasets containing structurally more complex graphs beyond the typically\nconsidered molecular graphs.\n",
			"Comment: n/a"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08104",
		"pdf_url": "http://arxiv.org/pdf/2101.08104.pdf"
	},
	"1303": {
		"title": "Classifying Scientific Publications with BERT -- Is Self-Attention a\n  Feature Selection Method?",
		"creator": [
			"Garcia-Silva, Andres",
			"Gomez-Perez, Jose Manuel"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Digital Libraries"
		],
		"description": [
			"  We investigate the self-attention mechanism of BERT in a fine-tuning scenario\nfor the classification of scientific articles over a taxonomy of research\ndisciplines. We observe how self-attention focuses on words that are highly\nrelated to the domain of the article. Particularly, a small subset of\nvocabulary words tends to receive most of the attention. We compare and\nevaluate the subset of the most attended words with feature selection methods\nnormally used for text classification in order to characterize self-attention\nas a possible feature selection approach. Using ConceptNet as ground truth, we\nalso find that attended words are more related to the research fields of the\narticles. However, conventional feature selection methods are still a better\noption to learn classifiers from scratch. This result suggests that, while\nself-attention identifies domain-relevant terms, the discriminatory information\nin BERT is encoded in the contextualized outputs and the classification layer.\nIt also raises the question whether injecting feature selection methods in the\nself-attention mechanism could further optimize single sequence classification\nusing transformers.\n",
			"Comment: Paper accepted for publication at ECIR2021"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08114",
		"pdf_url": "http://arxiv.org/pdf/2101.08114.pdf"
	},
	"1304": {
		"title": "Technological Competence is a Precondition for Effective Implementation\n  of Virtual Reality Head Mounted Displays in Human Neuroscience: A\n  Technological Review and Meta-analysis",
		"creator": [
			"Kourtesis, Panagiotis",
			"Collina, Simona",
			"Doumas, Leonidas A. A.",
			"MacPherson, Sarah E."
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Computers and Society",
			"Computer Science - Multimedia",
			"B.8",
			"C.4",
			"D.0",
			"J.4"
		],
		"description": [
			"  Immersive virtual reality (VR) emerges as a promising research and clinical\ntool. However, several studies suggest that VR induced adverse symptoms and\neffects (VRISE) may undermine the health and safety standards, and the\nreliability of the scientific results. In the current literature review, the\ntechnical reasons for the adverse symptomatology are investigated to provide\nsuggestions and technological knowledge for the implementation of VR\nhead-mounted display (HMD) systems in cognitive neuroscience. The technological\nsystematic literature indicated features pertinent to display, sound, motion\ntracking, navigation, ergonomic interactions, user experience, and computer\nhardware that should be considered by the researchers. Subsequently, a\nmeta-analysis of 44 neuroscientific or neuropsychological studies involving VR\nHMD systems was performed. The meta-analysis of the VR studies demonstrated\nthat new generation HMDs induced significantly less VRISE and marginally fewer\ndropouts.Importantly, the commercial versions of the new generation HMDs with\nergonomic interactions had zero incidents of adverse symptomatology and\ndropouts. HMDs equivalent to or greater than the commercial versions of\ncontemporary HMDs accompanied with ergonomic interactions are suitable for\nimplementation in cognitive neuroscience. In conclusion, researchers\ntechnological competency, along with meticulous methods and reports pertinent\nto software, hardware, and VRISE, are paramount to ensure the health and safety\nstandards and the reliability of neuroscientific results.\n",
			"Comment: Published in Frontiers in Human Neuroscience, 4 Figures, 4 Tables"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08123",
			"2019,Frontiers in Human Neuroscience, 13, p.342",
			"doi:10.3389/fnhum.2019.00342"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08123.pdf"
	},
	"1305": {
		"title": "Effective Energy Efficiency of Ultra-reliable Low Latency Communication",
		"creator": [
			"Shehab, Mohammad",
			"Alves, Hirley",
			"Jorswieck, Eduard A.",
			"Dosti, Endrit",
			"Latva-aho, Matti"
		],
		"subject": "Computer Science - Information Theory",
		"description": "  Effective Capacity defines the maximum communication rate subject to a\nspecific delay constraint, while effective energy efficiency (EEE) indicates\nthe ratio between effective capacity and power consumption. We analyze the EEE\nof ultra-reliable networks operating in the finite blocklength regime. We\nobtain a closed form approximation for the EEE in quasi-static Nakagami-$m$\n(and Rayleigh as sub-case) fading channels as a function of power, error\nprobability, and latency. Furthermore, we characterize the QoS constrained EEE\nmaximization problem for different power consumption models, which shows a\nsignificant difference between finite and infinite blocklength coding with\nrespect to EEE and optimal power allocation strategy. As asserted in the\nliterature, achieving ultra-reliability using one transmission consumes huge\namount of power, which is not applicable for energy limited IoT devices. In\nthis context, accounting for empty buffer probability in machine type\ncommunication (MTC) and extending the maximum delay tolerance jointly enhances\nthe EEE and allows for adaptive retransmission of faulty packets. Our analysis\nreveals that obtaining the optimum error probability for each transmission by\nminimizing the non-empty buffer probability approaches EEE optimality, while\nbeing analytically tractable via Dinkelbach's algorithm. Furthermore, the\nresults illustrate the power saving and the significant EEE gain attained by\napplying adaptive retransmission protocols, while sacrificing a limited\nincrease in latency.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08129",
		"pdf_url": "http://arxiv.org/pdf/2101.08129.pdf"
	},
	"1306": {
		"title": "Machine learning for rapid discovery of laminar flow channel wall\n  modifications that enhance heat transfer",
		"creator": [
			"Schniewind, Matthias",
			"Stroh, Alexander",
			"Ladewig, Bradley P.",
			"Friederich, Pascal"
		],
		"subject": [
			"Physics - Fluid Dynamics",
			"Computer Science - Machine Learning"
		],
		"description": "  The calculation of heat transfer in fluid flow in simple flat channels is a\nrelatively easy task for various simulations methods. However, once the channel\ngeometry becomes more complex, numerical simulations become a bottleneck in\noptimizing wall geometries. We present a combination of accurate numerical\nsimulations of arbitrary, non-flat channels and machine learning models\npredicting drag coefficient and Stanton number. We show that convolutional\nneural networks can accurately predict the target properties at a fraction of\nthe time of numerical simulations. We use the CNN models in a virtual\nhigh-throughput screening approach to explore a large number of possible,\nrandomly generated wall architectures. We find that S-shaped channel geometries\nare Pareto-optimal, a result which seems intuitive, but was not obvious before\nanalysing the data. The general approach is not only applicable to simple flow\nsetups as presented here, but can be extended to more complex tasks, such as\nmultiphase or even reactive unit operations in chemical engineering.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08130",
		"pdf_url": "http://arxiv.org/pdf/2101.08130.pdf"
	},
	"1307": {
		"title": "On the curvature extrema of special cubic B\\'ezier curves",
		"creator": [
			"Miura, Kenjiro T.",
			"Salvi, Péter"
		],
		"subject": "Computer Science - Computational Geometry",
		"description": "  It is proved that special cubic B\\'ezier curves, generated from quadratic\ncurves by the use of a scalar parameter, have at most one local curvature\nextremum in the $(0,1)$ parameter interval.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08138",
		"pdf_url": "http://arxiv.org/pdf/2101.08138.pdf"
	},
	"1308": {
		"title": "Validation of the Virtual Reality Neuroscience Questionnaire: Maximum\n  Duration of Immersive Virtual Reality Sessions Without the Presence of\n  Pertinent Adverse Symptomatology",
		"creator": [
			"Kourtesis, Panagiotis",
			"Collina, Simona",
			"Doumas, Leonidas A. A.",
			"MacPherson, Sarah E."
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Computers and Society",
			"Computer Science - Multimedia",
			"B.8",
			"C.4",
			"D.0",
			"J.4"
		],
		"description": [
			"  Research suggests that the duration of a VR session modulates the presence\nand intensity of VRISE, but there are no suggestions regarding the appropriate\nmaximum duration of VR sessions. The implementation of high-end VR HMDs in\nconjunction with ergonomic VR software seems to mitigate the presence of VRISE\nsubstantially. However, a brief tool does not currently exist to appraise and\nreport both the quality of software features and VRISE intensity\nquantitatively. The VRNQ was developed to assess the quality of VR software in\nterms of user experience, game mechanics, in-game assistance, and VRISE. Forty\nparticipants aged between 28 and 43 years were recruited (18 gamers and 22\nnon-gamers) for the study. They participated in 3 different VR sessions until\nthey felt weary or discomfort and subsequently filled in the VRNQ. Our results\ndemonstrated that VRNQ is a valid tool for assessing VR software as it has good\nconvergent, discriminant, and construct validity. The maximum duration of VR\nsessions should be between 55-70 minutes when the VR software meets or exceeds\nthe parsimonious cut-offs of the VRNQ and the users are familiarized with the\nVR system. Also. the gaming experience does not seem to affect how long VR\nsessions should last. Also, while the quality of VR software substantially\nmodulates the maximum duration of VR sessions, age and education do not.\nFinally, deeper immersion, better quality of graphics and sound, and more\nhelpful in-game instructions and prompts were found to reduce VRISE intensity.\nThe VRNQ facilitates the brief assessment and reporting of the quality of VR\nsoftware features and/or the intensity of VRISE, while its minimum and\nparsimonious cut-offs may appraise the suitability of VR software. The findings\nof this study contribute to the establishment of rigorous VR methods that are\ncrucial for the viability of immersive VR as a research and clinical tool.\n",
			"Comment: Published in Frontier in Human Neuroscience"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08146",
			"2019.Frontiers in human neuroscience, 13, p.417",
			"doi:10.3389/fnhum.2019.00417"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08146.pdf"
	},
	"1309": {
		"title": "Fooling thermal infrared pedestrian detectors in real world using small\n  bulbs",
		"creator": [
			"Zhu, Xiaopei",
			"Li, Xiao",
			"Li, Jianmin",
			"Wang, Zheyao",
			"Hu, Xiaolin"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Thermal infrared detection systems play an important role in many areas such\nas night security, autonomous driving, and body temperature detection. They\nhave the unique advantages of passive imaging, temperature sensitivity and\npenetration. But the security of these systems themselves has not been fully\nexplored, which poses risks in applying these systems. We propose a physical\nattack method with small bulbs on a board against the state of-the-art\npedestrian detectors. Our goal is to make infrared pedestrian detectors unable\nto detect real-world pedestrians. Towards this goal, we first showed that it is\npossible to use two kinds of patches to attack the infrared pedestrian detector\nbased on YOLOv3. The average precision (AP) dropped by 64.12% in the digital\nworld, while a blank board with the same size caused the AP to drop by 29.69%\nonly. After that, we designed and manufactured a physical board and\nsuccessfully attacked YOLOv3 in the real world. In recorded videos, the\nphysical board caused AP of the target detector to drop by 34.48%, while a\nblank board with the same size caused the AP to drop by 14.91% only. With the\nensemble attack techniques, the designed physical board had good\ntransferability to unseen detectors.\n",
			"Comment: accepted by AAAI-21"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08154",
		"pdf_url": "http://arxiv.org/pdf/2101.08154.pdf"
	},
	"1310": {
		"title": "Video Relation Detection with Trajectory-aware Multi-modal Features",
		"creator": [
			"Xie, Wentao",
			"Ren, Guanghui",
			"Liu, Si"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Video relation detection problem refers to the detection of the relationship\nbetween different objects in videos, such as spatial relationship and action\nrelationship. In this paper, we present video relation detection with\ntrajectory-aware multi-modal features to solve this task.\n  Considering the complexity of doing visual relation detection in videos, we\ndecompose this task into three sub-tasks: object detection, trajectory proposal\nand relation prediction. We use the state-of-the-art object detection method to\nensure the accuracy of object trajectory detection and multi-modal feature\nrepresentation to help the prediction of relation between objects. Our method\nwon the first place on the video relation detection task of Video Relation\nUnderstanding Grand Challenge in ACM Multimedia 2020 with 11.74\\% mAP, which\nsurpasses other methods by a large margin.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08165",
			"doi:10.1145/3394171.3416284"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08165.pdf"
	},
	"1311": {
		"title": "Guidelines for the Development of Immersive Virtual Reality Software for\n  Cognitive Neuroscience and Neuropsychology: The Development of Virtual\n  Reality Everyday Assessment Lab (VR-EAL)",
		"creator": [
			"Kourtesis, Panagiotis",
			"Korre, Danai",
			"Collina, Simona",
			"Doumas, Leonidas A. A.",
			"MacPherson, Sarah E."
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Computers and Society",
			"Computer Science - Multimedia",
			"B.8",
			"C.4",
			"D.0",
			"J.4"
		],
		"description": [
			"  Virtual reality (VR) head-mounted displays (HMD) appear to be effective\nresearch tools, which may address the problem of ecological validity in\nneuropsychological testing. However, their widespread implementation is\nhindered by VR induced symptoms and effects (VRISE) and the lack of skills in\nVR software development. This study offers guidelines for the development of VR\nsoftware in cognitive neuroscience and neuropsychology, by describing and\ndiscussing the stages of the development of Virtual Reality Everyday Assessment\nLab (VR-EAL), the first neuropsychological battery in immersive VR. Techniques\nfor evaluating cognitive functions within a realistic storyline are discussed.\nThe utility of various assets in Unity, software development kits, and other\nsoftware are described so that cognitive scientists can overcome challenges\npertinent to VRISE and the quality of the VR software. In addition, this pilot\nstudy attempts to evaluate VR-EAL in accordance with the necessary criteria for\nVR software for research purposes. The VR neuroscience questionnaire (VRNQ;\nKourtesis et al., 2019b) was implemented to appraise the quality of the three\nversions of VR-EAL in terms of user experience, game mechanics, in-game\nassistance, and VRISE. Twenty-five participants aged between 20 and 45 years\nwith 12-16 years of full-time education evaluated various versions of VR-EAL.\nThe final version of VR-EAL achieved high scores in every sub-score of the VRNQ\nand exceeded its parsimonious cut-offs. It also appeared to have better in-game\nassistance and game mechanics, while its improved graphics substantially\nincreased the quality of the user experience and almost eradicated VRISE. The\nresults substantially support the feasibility of the development of effective\nVR research and clinical software without the presence of VRISE during a\n60-minute VR session.\n",
			"Comment: Published in Frontier in Computer Science"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08166",
			"Frontiers in Computer Science, 1, p.12 (2020)",
			"doi:10.3389/fcomp.2019.00012"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08166.pdf"
	},
	"1312": {
		"title": "Neural-based Modeling for Performance Tuning of Spark Data Analytics",
		"creator": [
			"Zaouk, Khaled",
			"Song, Fei",
			"Lyu, Chenghao",
			"Diao, Yanlei"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Databases",
			"Computer Science - Machine Learning"
		],
		"description": "  Cloud data analytics has become an integral part of enterprise business\noperations for data-driven insight discovery. Performance modeling of cloud\ndata analytics is crucial for performance tuning and other critical operations\nin the cloud. Traditional modeling techniques fail to adapt to the high degree\nof diversity in workloads and system behaviors in this domain. In this paper,\nwe bring recent Deep Learning techniques to bear on the process of automated\nperformance modeling of cloud data analytics, with a focus on Spark data\nanalytics as representative workloads. At the core of our work is the notion of\nlearning workload embeddings (with a set of desired properties) to represent\nfundamental computational characteristics of different jobs, which enable\nperformance prediction when used together with job configurations that control\nresource allocation and other system knobs. Our work provides an in-depth study\nof different modeling choices that suit our requirements. Results of extensive\nexperiments reveal the strengths and limitations of different modeling methods,\nas well as superior performance of our best performing method over a\nstate-of-the-art modeling tool for cloud analytics.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08167",
		"pdf_url": "http://arxiv.org/pdf/2101.08167.pdf"
	},
	"1313": {
		"title": "On Provable Backdoor Defense in Collaborative Learning",
		"creator": [
			"Qiao, Ximing",
			"Bai, Yuhua",
			"Hu, Siping",
			"Li, Ang",
			"Chen, Yiran",
			"Li, Hai"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Machine Learning"
		],
		"description": "  As collaborative learning allows joint training of a model using multiple\nsources of data, the security problem has been a central concern. Malicious\nusers can upload poisoned data to prevent the model's convergence or inject\nhidden backdoors. The so-called backdoor attacks are especially difficult to\ndetect since the model behaves normally on standard test data but gives wrong\noutputs when triggered by certain backdoor keys. Although Byzantine-tolerant\ntraining algorithms provide convergence guarantee, provable defense against\nbackdoor attacks remains largely unsolved. Methods based on randomized\nsmoothing can only correct a small number of corrupted pixels or labels;\nmethods based on subset aggregation cause a severe drop in classification\naccuracy due to low data utilization. We propose a novel framework that\ngeneralizes existing subset aggregation methods. The framework shows that the\nsubset selection process, a deciding factor for subset aggregation methods, can\nbe viewed as a code design problem. We derive the theoretical bound of data\nutilization ratio and provide optimal code construction. Experiments on non-IID\nversions of MNIST and CIFAR-10 show that our method with optimal codes\nsignificantly outperforms baselines using non-overlapping partition and random\nselection. Additionally, integration with existing coding theory results shows\nthat special codes can track the location of the attackers. Such capability\nprovides new countermeasures to backdoor attacks.\n",
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08177",
		"pdf_url": "http://arxiv.org/pdf/2101.08177.pdf"
	},
	"1314": {
		"title": "Fair Refinement for Asynchronous Session Types (extended version)",
		"creator": [
			"Bravetti, Mario",
			"Lange, Julien",
			"Zavattaro, Gianluigi"
		],
		"subject": [
			"Computer Science - Programming Languages",
			"Computer Science - Logic in Computer Science"
		],
		"description": "  Session types are widely used as abstractions of asynchronous message passing\nsystems. Refinement for such abstractions is crucial as it allows improvements\nof a given component without compromising its compatibility with the rest of\nthe system. In the context of session types, the most general notion of\nrefinement is the asynchronous session subtyping, which allows to anticipate\nmessage emissions but only under certain conditions. In particular,\nasynchronous session subtyping rules out candidates subtypes that occur\nnaturally in communication protocols where, e.g., two parties simultaneously\nsend each other a finite but unspecified amount of messages before removing\nthem from their respective buffers. To address this shortcoming, we study fair\ncompliance over asynchronous session types and fair refinement as the relation\nthat preserves it. This allows us to propose a novel variant of session\nsubtyping that leverages the notion of controllability from service contract\ntheory and that is a sound characterisation of fair refinement. In addition, we\nshow that both fair refinement and our novel subtyping are undecidable. We also\npresent a sound algorithm, and its implementation, which deals with examples\nthat feature potentially unbounded buffering.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08181",
		"pdf_url": "http://arxiv.org/pdf/2101.08181.pdf"
	},
	"1315": {
		"title": "Mask-GD Segmentation Based Robotic Grasp Detection",
		"creator": [
			"Dong, Mingshuai",
			"Wei, Shimin",
			"Yu, Xiuli",
			"Yin, Jianqin"
		],
		"subject": "Computer Science - Robotics",
		"description": "  The reliability of grasp detection for target objects in complex scenes is a\nchallenging task and a critical problem that needs to be solved urgently in\npractical application. At present, the grasp detection location comes from\nsearching the feature space of the whole image. However, the cluttered\nbackground information in the image impairs the accuracy of grasping detection.\nIn this paper, a robotic grasp detection algorithm named MASK-GD is proposed,\nwhich provides a feasible solution to this problem. MASK is a segmented image\nthat only contains the pixels of the target object. MASK-GD for grasp detection\nonly uses MASK features rather than the features of the entire image in the\nscene. It has two stages: the first stage is to provide the MASK of the target\nobject as the input image, and the second stage is a grasp detector based on\nthe MASK feature. Experimental results demonstrate that MASK-GD's performance\nis comparable with state-of-the-art grasp detection algorithms on Cornell\nDatasets and Jacquard Dataset. In the meantime, MASK-GD performs much better in\ncomplex scenes.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08183",
		"pdf_url": "http://arxiv.org/pdf/2101.08183.pdf"
	},
	"1316": {
		"title": "Onion under Microscope: An in-depth analysis of the Tor network",
		"creator": [
			"Bernaschi, Massimo",
			"Celestini, Alessandro",
			"Cianfriglia, Marco",
			"Guarino, Stefano",
			"Lombardi, Flavio",
			"Mastrostefano, Enrico"
		],
		"subject": "Computer Science - Social and Information Networks",
		"description": "  Tor is an anonymity network that allows offering and accessing various kinds\nof resources, known as hidden services, while guaranteeing sender and receiver\nanonymity. The Tor web is the set of web resources that exist on the Tor\nnetwork, and Tor websites are part of the so-called dark web. Recent research\nworks have evaluated Tor security, evolution over time, and thematic\norganization. Nevertheless, few information are available about the structure\nof the graph defined by the network of Tor websites. The limited number of Tor\nentry points that can be used to crawl the network renders the study of this\ngraph far from being simple. In this paper we aim at better characterizing the\nTor Web by analyzing three crawling datasets collected over a five-month time\nframe. On the one hand, we extensively study the global properties of the Tor\nWeb, considering two different graph representations and verifying the impact\nof Tor's renowned volatility. We present an in depth investigation of the key\nfeatures of the Tor Web graph showing what makes it different from the surface\nWeb graph. On the other hand, we assess the relationship between contents and\nstructural features. We analyse the local properties of the Tor Web to better\ncharacterize the role different services play in the network and to understand\nto which extent topological features are related to the contents of a service.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08194",
		"pdf_url": "http://arxiv.org/pdf/2101.08194.pdf"
	},
	"1317": {
		"title": "Open-Domain Conversational Search Assistant with Transformers",
		"creator": [
			"Ferreira, Rafael",
			"Leite, Mariana",
			"Semedo, David",
			"Magalhaes, Joao"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Computation and Language",
			"Computer Science - Machine Learning",
			"H.3.3",
			"I.2.7"
		],
		"description": "  Open-domain conversational search assistants aim at answering user questions\nabout open topics in a conversational manner. In this paper we show how the\nTransformer architecture achieves state-of-the-art results in key IR tasks,\nleveraging the creation of conversational assistants that engage in open-domain\nconversational search with single, yet informative, answers. In particular, we\npropose an open-domain abstractive conversational search agent pipeline to\naddress two major challenges: first, conversation context-aware search and\nsecond, abstractive search-answers generation. To address the first challenge,\nthe conversation context is modeled with a query rewriting method that unfolds\nthe context of the conversation up to a specific moment to search for the\ncorrect answers. These answers are then passed to a Transformer-based re-ranker\nto further improve retrieval performance. The second challenge, is tackled with\nrecent Abstractive Transformer architectures to generate a digest of the top\nmost relevant passages. Experiments show that Transformers deliver a solid\nperformance across all tasks in conversational search, outperforming the best\nTREC CAsT 2019 baseline.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08197",
		"pdf_url": "http://arxiv.org/pdf/2101.08197.pdf"
	},
	"1318": {
		"title": "Can Taxonomy Help? Improving Semantic Question Matching using Question\n  Taxonomy",
		"creator": [
			"Gupta, Deepak",
			"Pujari, Rajkumar",
			"Ekbal, Asif",
			"Bhattacharyya, Pushpak",
			"Maitra, Anutosh",
			"Jain, Tom",
			"Sengupta, Shubhashis"
		],
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  In this paper, we propose a hybrid technique for semantic question matching.\nIt uses our proposed two-layered taxonomy for English questions by augmenting\nstate-of-the-art deep learning models with question classes obtained from a\ndeep learning based question classifier. Experiments performed on three\nopen-domain datasets demonstrate the effectiveness of our proposed approach. We\nachieve state-of-the-art results on partial ordering question ranking (POQR)\nbenchmark dataset. Our empirical analysis shows that coupling standard\ndistributional features (provided by the question encoder) with knowledge from\ntaxonomy is more effective than either deep learning (DL) or taxonomy-based\nknowledge alone.\n",
			"Comment: Paper was accepted at COLING 2018, presented as a poster"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08201",
		"pdf_url": "http://arxiv.org/pdf/2101.08201.pdf"
	},
	"1319": {
		"title": "secureTF: A Secure TensorFlow Framework",
		"creator": [
			"Quoc, Do Le",
			"Gregor, Franz",
			"Arnautov, Sergei",
			"Kunkel, Roland",
			"Bhatotia, Pramod",
			"Fetzer, Christof"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Data-driven intelligent applications in modern online services have become\nubiquitous. These applications are usually hosted in the untrusted cloud\ncomputing infrastructure. This poses significant security risks since these\napplications rely on applying machine learning algorithms on large datasets\nwhich may contain private and sensitive information.\n  To tackle this challenge, we designed secureTF, a distributed secure machine\nlearning framework based on Tensorflow for the untrusted cloud infrastructure.\nsecureTF is a generic platform to support unmodified TensorFlow applications,\nwhile providing end-to-end security for the input data, ML model, and\napplication code. secureTF is built from ground-up based on the security\nproperties provided by Trusted Execution Environments (TEEs). However, it\nextends the trust of a volatile memory region (or secure enclave) provided by\nthe single node TEE to secure a distributed infrastructure required for\nsupporting unmodified stateful machine learning applications running in the\ncloud.\n  The paper reports on our experiences about the system design choices and the\nsystem deployment in production use-cases. We conclude with the lessons learned\nbased on the limitations of our commercially available platform, and discuss\nopen research problems for the future work.\n",
			"Comment: arXiv admin note: text overlap with arXiv:1902.04413"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08204",
			"Pages 44-59, 2020",
			"doi:10.1145/3423211.3425687"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08204.pdf"
	},
	"1320": {
		"title": "PiChu: Accelerating Block Broadcasting in Blockchain Networks with\n  Pipelining and Chunking",
		"creator": [
			"Ayinala, Kaushik",
			"Choi, Baek-Young",
			"Song, Sejun"
		],
		"subject": "Computer Science - Distributed, Parallel, and Cluster Computing",
		"description": [
			"  Blockchain technologies have been rapidly enhanced in recent years. However,\nits scalability still has limitations in terms of throughput and broadcast\ndelay as the network and the amount of transaction data increase. To improve\nscalability of blockchain networks, we propose a novel approach named PiChu\nthat accelerates block propagation in blockchain networks by pipelining and\nverifying chunks of a block in parallel. Accelerating block propagation reduces\nthe mining interval and chance of fork occurring, which in turn increases\nthroughput. Our approach can be applied to the blockchain networks either\ndirectly or with a minor modification to the consensus. Through an extensive\nand large scale simulations, we validate that the proposed PiChu scheme\nsignificantly enhances the scalability of blockchain networks. For instance, a\n64 MB block can be broadcasted in just 80 seconds in a blockchain network with\na million nodes. The efficiency of PiChu broadcasting increases with bigger\nblock sizes and a larger number of nodes in the network.\n",
			"Comment: 2020 IEEE International Conference on Blockchain"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08212",
			"doi:10.1109/Blockchain50366.2020.00035"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08212.pdf"
	},
	"1321": {
		"title": "SAR and Optical data fusion based on Anisotropic Diffusion with PCA and\n  Classification using Patch-based with LBP",
		"creator": [
			"Shakya, Achala",
			"Biswas, Mantosh",
			"Pal, Mahesh"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  SAR (VV and VH polarization) and optical data are widely used in image fusion\nto use the complimentary information of each other and to obtain the\nbetter-quality image (in terms of spatial and spectral features) for the\nimproved classification results. This paper uses anisotropic diffusion with PCA\nfor the fusion of SAR and optical data and patch-based SVM Classification with\nLBP (LBP-PSVM). Fusion results with VV polarization performed better than VH\npolarization using considered fusion method. For classification, the\nperformance of LBP-PSVM using S1 (VV) with S2, S1 (VH) with S2 is compared with\nSVM classifier (without patch) and PSVM classifier (with patch), respectively.\nClassification results suggests that the LBP-PSVM classifier is more effective\nin comparison to SVM and PSVM classifiers for considered data.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08215",
		"pdf_url": "http://arxiv.org/pdf/2101.08215.pdf"
	},
	"1322": {
		"title": "TaNTIN: Terrestrial and Non-Terrestrial Integrated Networks-A\n  collaborative technologies perspective for beyond 5G and 6G",
		"creator": [
			"Akhtar, Muhammad Waseem",
			"Hassan, Syed Ali"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": "  The world is moving toward globalization rapidly. Everybody has easy access\nto information with the spread of Internet technology. Businesses are growing\nbeyond national borders. Internationalization affects every aspect of life. In\nthis scenario, by dispersing functions and tasks across organizational borders,\ntime and space, global organizations have higher requirements for\ncollaboration. In order to allow decision-makers and knowledge workers,\nsituated at different times and spaces, to work more efficiently, collaborative\ntechnologies are needed. In this paper, we give an overview of potential\ncollaborative technologies, their benefits, risks and challenges, types, and\nelements. Based on the conceptualization of terrestrial and non-terrestrial\nintegrated networks (TaNTIN), we highlight artificial intelligence (AI),\nblockchains, tactile Internet, mobile edge computing (MEC)/fog computing,\naugmented reality and virtual reality, and so forth as the key features to\nensure quality-of-service (QoS) guarantee of futuristic collaborative services\nsuch as telemedicine, e-education, online gaming, online businesses, the\nentertainment industry. We also discuss how these technologies will impact\nhuman life in the near future.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08221",
		"pdf_url": "http://arxiv.org/pdf/2101.08221.pdf"
	},
	"1323": {
		"title": "Data Association Between Perception and V2V Communication Sensors",
		"creator": [
			"Cantas, Mustafa Ridvan",
			"Chand, Arpita",
			"Zhang, Hao",
			"Surnilla, Gopi Chandra",
			"Guvenc, Levent"
		],
		"subject": [
			"Computer Science - Robotics",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": "  The connectivity between vehicles, infrastructure, and other traffic\nparticipants brings a new dimension to automotive safety applications. Soon all\nthe newly produced cars will have Vehicle to Everything (V2X) communication\nmodems alongside the existing Advanced Driver Assistant Systems (ADAS). It is\nessential to identify the different sensor measurements for the same targets\n(Data Association) to use connectivity reliably as a safety feature alongside\nthe standard ADAS functionality. Considering the camera is the most common\nsensor available for ADAS systems, in this paper, we present an experimental\nimplementation of a Mahalanobis distance-based data association algorithm\nbetween the camera and the Vehicle to Vehicle (V2V) communication sensors. The\nimplemented algorithm has low computational complexity and the capability of\nrunning in real-time. One can use the presented algorithm for sensor fusion\nalgorithms or higher-level decision-making applications in ADAS modules.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08228",
		"pdf_url": "http://arxiv.org/pdf/2101.08228.pdf"
	},
	"1324": {
		"title": "Towards Understanding How Readers Integrate Charts and Captions: A Case\n  Study with Line Charts",
		"creator": [
			"Kim, Dae Hyun",
			"Setlur, Vidya",
			"Agrawala, Maneesh"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": [
			"  Charts often contain visually prominent features that draw attention to\naspects of the data and include text captions that emphasize aspects of the\ndata. Through a crowdsourced study, we explore how readers gather takeaways\nwhen considering charts and captions together. We first ask participants to\nmark visually prominent regions in a set of line charts. We then generate text\ncaptions based on the prominent features and ask participants to report their\ntakeaways after observing chart-caption pairs. We find that when both the chart\nand caption describe a high-prominence feature, readers treat the doubly\nemphasized high-prominence feature as the takeaway; when the caption describes\na low-prominence chart feature, readers rely on the chart and report a\nhigher-prominence feature as the takeaway. We also find that external\ninformation that provides context, helps further convey the caption's message\nto the reader. We use these findings to provide guidelines for authoring\neffective chart-caption pairs.\n",
			"Comment: To appear at CHI 2021"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08235",
			"doi:10.1145/3411764.3445443"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08235.pdf"
	},
	"1325": {
		"title": "Probabilistic Solar Power Forecasting: Long Short-Term Memory Network vs\n  Simpler Approaches",
		"creator": [
			"Sharma, Vinayak",
			"Ordiano, Jorge Angel Gonzalez",
			"Mikut, Ralf",
			"Cali, Umit"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Signal Processing"
		],
		"description": [
			"  The high penetration of volatile renewable energy sources such as solar make\nmethods for coping with the uncertainty associated with them of paramount\nimportance. Probabilistic forecasts are an example of these methods, as they\nassist energy planners in their decision-making process by providing them with\ninformation about the uncertainty of future power generation. Currently, there\nis a trend towards the use of deep learning probabilistic forecasting methods.\nHowever, the point at which the more complex deep learning methods should be\npreferred over more simple approaches is not yet clear. Therefore, the current\narticle presents a simple comparison between a long short-term memory neural\nnetwork and other more simple approaches. The comparison consists of training\nand comparing models able to provide one-day-ahead probabilistic forecasts for\na solar power system. Moreover, the current paper makes use of an open-source\ndataset provided during the Global Energy Forecasting Competition of 2014\n(GEFCom14).\n",
			"Comment: Submitted to the International Symposium of forecasting 2020"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08236",
		"pdf_url": "http://arxiv.org/pdf/2101.08236.pdf"
	},
	"1326": {
		"title": "Trajectory optimization for contact-rich motions using implicit\n  differential dynamic programming",
		"creator": [
			"Chatzinikolaidis, Iordanis",
			"Li, Zhibin"
		],
		"subject": [
			"Computer Science - Robotics",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": [
			"  This paper presents a novel approach using sensitivity analysis for\ngeneralizing Differential Dynamic Programming (DDP) to systems characterized by\nimplicit dynamics, such as those modelled via inverse dynamics and variational\nor implicit integrators. It leads to a more general formulation of DDP,\nenabling for example the use of the faster recursive Newton-Euler inverse\ndynamics. We leverage the implicit formulation for precise and exact contact\nmodelling in DDP, where we focus on two contributions: (1) Contact dynamics in\nacceleration level that enables high-order integration schemes; (2) Formulation\nusing an invertible contact model in the forward pass and a closed form\nsolution in the backward pass to improve the numerical resolution of contacts.\nThe performance of the proposed framework is validated (1) by comparing\nimplicit versus explicit DDP for the swing-up of a double pendulum, and (2) by\nplanning motions for two tasks using a single leg model making multi-body\ncontacts with the environment: standing up from ground, where a priori contact\nenumeration is challenging, and maintaining balance under an external\nperturbation.\n",
			"Comment: 9 pages, 6 figures, 1 table, submitted to IEEE Robotics and\n  Automation Letters; under review"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08246",
		"pdf_url": "http://arxiv.org/pdf/2101.08246.pdf"
	},
	"1327": {
		"title": "Program Repair for Hyperproperties",
		"creator": [
			"Bonakdarpour, Borzoo",
			"Finkbeiner, Bernd"
		],
		"subject": "Computer Science - Logic in Computer Science",
		"description": [
			"  We study the repair problem for hyperproperties specified in the temporal\nlogic HyperLTL. Hyperproperties are system properties that relate multiple\ncomputation traces. This class of properties includes information flow policies\nlike noninterference and observational determinism. The repair problem is to\nfind, for a given Kripke structure, a substructure that satisfies a given\nspecification. We show that the repair problem is decidable for HyperLTL\nspecifications and finite-state Kripke structures. We provide a detailed\ncomplexity analysis for different fragments of HyperLTL and different system\ntypes: tree-shaped, acyclic, and general Kripke structures.\n",
			"Comment: arXiv admin note: text overlap with arXiv:2101.07847"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08257",
			"doi:10.1007/978-3-030-31784-3_25"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08257.pdf"
	},
	"1328": {
		"title": "Autocart -- spatially-aware regression trees for ecological and spatial\n  modeling",
		"creator": [
			"Ancell, Ethan",
			"Bean, Brennan"
		],
		"subject": [
			"Quantitative Biology - Quantitative Methods",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Many ecological and spatial processes are complex in nature and are not\naccurately modeled by linear models. Regression trees promise to handle the\nhigh-order interactions that are present in ecological and spatial datasets,\nbut fail to produce physically realistic characterizations of the underlying\nlandscape. The \"autocart\" (autocorrelated regression trees) R package extends\nthe functionality of previously proposed spatial regression tree methods\nthrough a spatially aware splitting function and novel adaptive inverse\ndistance weighting method in each terminal node. The efficacy of these autocart\nmodels, including an autocart extension of random forest, is demonstrated on\nmultiple datasets. This highlights the ability of autocart to model complex\ninteractions between spatial variables while still providing physically\nrealistic representations of the landscape.\n",
			"Comment: 20 pages, 10 figures"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08258",
		"pdf_url": "http://arxiv.org/pdf/2101.08258.pdf"
	},
	"1329": {
		"title": "Acceleration Measurement Enhances the Bandwidth of Disturbance Observer\n  in Motion Control Systems",
		"creator": "Sariyildiz, Emre",
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  The trade-off between the noise-sensitivity and the performance of\ndisturbance estimation is well-known in the Disturbance Observer- (DOb-) based\nmotion control systems. As the bandwidth of the DOb increases, not only the\nperformance but also the frequency range of disturbance estimation improves yet\nthe motion controller becomes more sensitive to the noise of measurement\nsystem. This trade-off is generally explained by considering only the noise of\nsensors such as encoders. However, the digital implementation of the robust\nmotion controller may significantly influence the noise sensitivity and\nperformance of disturbance estimation in practice. This paper shows that the\nconventional DOb implemented by estimating velocity is subject to waterbed\neffect when the design parameters (i.e., sampling-time, nominal plant\nparameters and the bandwidth of the DOb) are not properly tuned in the digital\nmotion controller synthesis. Therefore, the bandwidth of disturbance estimation\nis limited by waterbed effect in addition to the noise of velocity measurement\nsystem. To facilitate the digital motion controller synthesis, the design\nconstraints of the conventional DOb are analytically derived in this paper.\nWhen the digital motion controller is implemented by estimating acceleration,\nwaterbed effect does not occur, and good robust stability and performance can\nbe achieved for all values of the design parameters of the acceleration\nmeasurement-based DOb. The bandwidth of disturbance estimation, however, cannot\nbe freely increased due to the noise of acceleration sensors in practice. By\nemploying Bode Integral Theorem in the discrete-time domain, the design\nconstraints of the DOb-based digital motion control systems are clearly\nexplained and it is shown that acceleration measurement can be used to enhance\nthe bandwidth of the DOb, i.e., the performance and frequency range of\ndisturbance estimation.\n",
			"Comment: IEEE International Conference on Mechatronics (ICM2021). arXiv admin\n  note: text overlap with arXiv:2101.07920"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08259",
		"pdf_url": "http://arxiv.org/pdf/2101.08259.pdf"
	},
	"1330": {
		"title": "Local discontinuous Galerkin method for the fractional diffusion\n  equation with integral fractional Laplacian",
		"creator": [
			"Nie, Daxin",
			"Deng, Weihua"
		],
		"subject": "Mathematics - Numerical Analysis",
		"description": [
			"  In this paper, we provide a framework of designing the local discontinuous\nGalerkin scheme for integral fractional Laplacian $(-\\Delta)^{s}$ with\n$s\\in(0,1)$ in two dimensions. We theoretically prove and numerically verify\nthe numerical stability and convergence of the scheme with the convergence rate\nno worse than $\\mathcal{O}(h^{k+\\frac{1}{2}})$.\n",
			"Comment: 11 pages"
		],
		"date": "2021-01-19",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08260",
		"pdf_url": "http://arxiv.org/pdf/2101.08260.pdf"
	},
	"1331": {
		"title": "The Diagnosis of Asthma using Hilbert-Huang Transform and Deep Learning\n  on Lung Sounds",
		"creator": [
			"Altan, Gökhan",
			"Kutlu, Yakup",
			"Pekmezci, Adnan Özhan",
			"Nural, Serkan"
		],
		"subject": [
			"Computer Science - Sound",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Audio and Speech Processing"
		],
		"description": [
			"  Lung auscultation is the most effective and indispensable method for\ndiagnosing various respiratory disorders by using the sounds from the airways\nduring inspirium and exhalation using a stethoscope. In this study, the\nstatistical features are calculated from intrinsic mode functions that are\nextracted by applying the HilbertHuang Transform to the lung sounds from 12\ndifferent auscultation regions on the chest and back. The classification of the\nlung sounds from asthma and healthy subjects is performed using Deep Belief\nNetworks (DBN). The DBN classifier model with two hidden layers has been tested\nusing 5-fold cross validation method. The proposed DBN separated lung sounds\nfrom asthmatic and healthy subjects with high classification performance rates\nof 84.61%, 85.83%, and 77.11% for overall accuracy, sensitivity, and\nselectivity, respectively using frequencytime analysis.\n",
			"Comment: 6 pages, in Turkish language, journal of intelligent systems with\n  applications"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08288",
		"pdf_url": "http://arxiv.org/pdf/2101.08288.pdf"
	},
	"1332": {
		"title": "Run-Time Safety Monitoring of Neural-Network-Enabled Dynamical Systems",
		"creator": "Xiang, Weiming",
		"subject": "Electrical Engineering and Systems Science - Systems and Control",
		"description": [
			"  Complex dynamical systems rely on the correct deployment and operation of\nnumerous components, with state-of-the-art methods relying on learning-enabled\ncomponents in various stages of modeling, sensing, and control at both offline\nand online levels. This paper addresses the run-time safety monitoring problem\nof dynamical systems embedded with neural network components. A run-time safety\nstate estimator in the form of an interval observer is developed to construct\nlower-bound and upper-bound of system state trajectories in run time. The\ndeveloped run-time safety state estimator consists of two auxiliary neural\nnetworks derived from the neural network embedded in dynamical systems, and\nobserver gains to ensure the positivity, namely the ability of estimator to\nbound the system state in run time, and the convergence of the corresponding\nerror dynamics. The design procedure is formulated in terms of a family of\nlinear programming feasibility problems. The developed method is illustrated by\na numerical example and is validated with evaluations on an adaptive cruise\ncontrol system.\n",
			"Comment: Accepted by IEEE Transactions on Cybernetics"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08297",
		"pdf_url": "http://arxiv.org/pdf/2101.08297.pdf"
	},
	"1333": {
		"title": "Text Line Segmentation for Challenging Handwritten Document Images Using\n  Fully Convolutional Network",
		"creator": [
			"Barakat, Berat",
			"Droby, Ahmad",
			"Kassis, Majeed",
			"El-Sana, Jihad"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  This paper presents a method for text line segmentation of challenging\nhistorical manuscript images. These manuscript images contain narrow interline\nspaces with touching components, interpenetrating vowel signs and inconsistent\nfont types and sizes. In addition, they contain curved, multi-skewed and\nmulti-directed side note lines within a complex page layout. Therefore,\nbounding polygon labeling would be very difficult and time consuming. Instead\nwe rely on line masks that connect the components on the same text line. Then\nthese line masks are predicted using a Fully Convolutional Network (FCN). In\nthe literature, FCN has been successfully used for text line segmentation of\nregular handwritten document images. The present paper shows that FCN is useful\nwith challenging manuscript images as well. Using a new evaluation metric that\nis sensitive to over segmentation as well as under segmentation, testing\nresults on a publicly available challenging handwritten dataset are comparable\nwith the results of a previous work on the same dataset.\n",
			"Comment: ICFHR 2018 16th International Conference on Frontiers in Handwriting\n  Recognition"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08299",
		"pdf_url": "http://arxiv.org/pdf/2101.08299.pdf"
	},
	"1334": {
		"title": "Aesthetics, Personalization and Recommendation: A survey on Deep\n  Learning in Fashion",
		"creator": [
			"Gong, Wei",
			"Khalid, Laila"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": "  Machine learning is completely changing the trends in the fashion industry.\nFrom big to small every brand is using machine learning techniques in order to\nimprove their revenue, increase customers and stay ahead of the trend. People\nare into fashion and they want to know what looks best and how they can improve\ntheir style and elevate their personality. Using Deep learning technology and\ninfusing it with Computer Vision techniques one can do so by utilizing\nBrain-inspired Deep Networks, and engaging into Neuroaesthetics, working with\nGANs and Training them, playing around with Unstructured Data,and infusing the\ntransformer architecture are just some highlights which can be touched with the\nFashion domain. Its all about designing a system that can tell us information\nregarding the fashion aspect that can come in handy with the ever growing\ndemand. Personalization is a big factor that impacts the spending choices of\ncustomers.The survey also shows remarkable approaches that encroach the subject\nof achieving that by divulging deep into how visual data can be interpreted and\nleveraged into different models and approaches. Aesthetics play a vital role in\nclothing recommendation as users' decision depends largely on whether the\nclothing is in line with their aesthetics, however the conventional image\nfeatures cannot portray this directly. For that the survey also highlights\nremarkable models like tensor factorization model, conditional random field\nmodel among others to cater the need to acknowledge aesthetics as an important\nfactor in Apparel recommendation.These AI inspired deep models can pinpoint\nexactly which certain style resonates best with their customers and they can\nhave an understanding of how the new designs will set in with the community.\nWith AI and machine learning your businesses can stay ahead of the fashion\ntrends.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08301",
		"pdf_url": "http://arxiv.org/pdf/2101.08301.pdf"
	},
	"1335": {
		"title": "Chest X-ray lung and heart segmentation based on minimal training sets",
		"creator": "Maga, Balázs",
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": [
			"  As the COVID-19 pandemic aggravated the excessive workload of doctors\nglobally, the demand for computer aided methods in medical imaging analysis\nincreased even further. Such tools can result in more robust diagnostic\npipelines which are less prone to human errors. In our paper, we present a deep\nneural network to which we refer to as Attention BCDU-Net, and apply it to the\ntask of lung and heart segmentation from chest X-ray (CXR) images, a basic but\nardous step in the diagnostic pipeline, for instance for the detection of\ncardiomegaly. We show that the fine-tuned model exceeds previous\nstate-of-the-art results, reaching $98.1\\pm 0.1\\%$ Dice score and $95.2\\pm\n0.1\\%$ IoU score on the dataset of Japanese Society of Radiological Technology\n(JSRT). Besides that, we demonstrate the relative simplicity of the task by\nattaining surprisingly strong results with training sets of size 10 and 20: in\nterms of Dice score, $97.0\\pm 0.8\\%$ and $97.3\\pm 0.5$, respectively, while in\nterms of IoU score, $92.2\\pm 1.2\\%$ and $93.3\\pm 0.4\\%$, respectively. To\nachieve these scores, we capitalize on the mixup augmentation technique, which\nyields a remarkable gain above $4\\%$ IoU score in the size 10 setup.\n",
			"Comment: Preprint. arXiv admin note: text overlap with arXiv:2003.10304"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08309",
		"pdf_url": "http://arxiv.org/pdf/2101.08309.pdf"
	},
	"1336": {
		"title": "Non-Convex Compressed Sensing with Training Data",
		"creator": "Welper, G.",
		"subject": [
			"Computer Science - Machine Learning",
			"Mathematics - Numerical Analysis",
			"94A12, 68Q32"
		],
		"description": "  Efficient algorithms for the sparse solution of under-determined linear\nsystems $Ax = b$ are known for matrices $A$ satisfying suitable assumptions\nlike the restricted isometry property (RIP). Without such assumptions little is\nknown and without any assumptions on $A$ the problem is $NP$-hard. A common\napproach is to replace $\\ell_1$ by $\\ell_p$ minimization for $0 < p < 1$, which\nis no longer convex and typically requires some form of local initial values\nfor provably convergent algorithms.\n  In this paper, we consider an alternative, where instead of suitable initial\nvalues we are provided with extra training problems $Ax = B_l$, $l=1, \\dots, p$\nthat are related to our compressed sensing problem. They allow us to find the\nsolution of the original problem $Ax = b$ with high probability in the range of\na one layer linear neural network with comparatively few assumptions on the\nmatrix $A$.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08310",
		"pdf_url": "http://arxiv.org/pdf/2101.08310.pdf"
	},
	"1337": {
		"title": "Partitions of an Integer into Powers",
		"creator": "Latapy, Matthieu",
		"subject": [
			"Mathematics - Combinatorics",
			"Computer Science - Discrete Mathematics"
		],
		"description": "  In this paper, we use a simple discrete dynamical model to study partitions\nof integers into powers of another integer. We extend and generalize some known\nresults about their enumeration and counting, and we give new structural\nresults. In particular, we show that the set of these partitions can be ordered\nin a natural way which gives the distributive lattice structure to this set. We\nalso give a tree structure which allow efficient and simple enumeration of the\npartitions of an integer.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08312",
			"DMTCS, Proceedings of Discrete Models: Combinatorics, Computation,\n  and Geometry (DM-CCG), 2001"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08312.pdf"
	},
	"1338": {
		"title": "Multi-Scale Games: Representing and Solving Games on Networks with Group\n  Structure",
		"creator": [
			"Jin, Kun",
			"Vorobeychik, Yevgeniy",
			"Liu, Mingyan"
		],
		"subject": [
			"Computer Science - Computational Engineering, Finance, and Science",
			"Economics - Theoretical Economics"
		],
		"description": [
			"  Network games provide a natural machinery to compactly represent strategic\ninteractions among agents whose payoffs exhibit sparsity in their dependence on\nthe actions of others. Besides encoding interaction sparsity, however, real\nnetworks often exhibit a multi-scale structure, in which agents can be grouped\ninto communities, those communities further grouped, and so on, and where\ninteractions among such groups may also exhibit sparsity. We present a general\nmodel of multi-scale network games that encodes such multi-level structure. We\nthen develop several algorithmic approaches that leverage this multi-scale\nstructure, and derive sufficient conditions for convergence of these to a Nash\nequilibrium. Our numerical experiments demonstrate that the proposed approaches\nenable orders of magnitude improvements in scalability when computing Nash\nequilibria in such games. For example, we can solve previously intractable\ninstances involving up to 1 million agents in under 15 minutes.\n",
			"Comment: Accepted in AAAI 2021 main conference"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08314",
		"pdf_url": "http://arxiv.org/pdf/2101.08314.pdf"
	},
	"1339": {
		"title": "Ensemble manifold based regularized multi-modal graph convolutional\n  network for cognitive ability prediction",
		"creator": [
			"Qu, Gang",
			"Xiao, Li",
			"Hu, Wenxing",
			"Zhang, Kun",
			"Calhoun, Vince D.",
			"Wang, Yu-Ping"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  Objective: Multi-modal functional magnetic resonance imaging (fMRI) can be\nused to make predictions about individual behavioral and cognitive traits based\non brain connectivity networks. Methods: To take advantage of complementary\ninformation from multi-modal fMRI, we propose an interpretable multi-modal\ngraph convolutional network (MGCN) model, incorporating the fMRI time series\nand the functional connectivity (FC) between each pair of brain regions.\nSpecifically, our model learns a graph embedding from individual brain networks\nderived from multi-modal data. A manifold-based regularization term is then\nenforced to consider the relationships of subjects both within and between\nmodalities. Furthermore, we propose the gradient-weighted regression activation\nmapping (Grad-RAM) and the edge mask learning to interpret the model, which is\nused to identify significant cognition-related biomarkers. Results: We validate\nour MGCN model on the Philadelphia Neurodevelopmental Cohort to predict\nindividual wide range achievement test (WRAT) score. Our model obtains superior\npredictive performance over GCN with a single modality and other competing\napproaches. The identified biomarkers are cross-validated from different\napproaches. Conclusion and Significance: This paper develops a new\ninterpretable graph deep learning framework for cognitive ability prediction,\nwith the potential to overcome the limitations of several current data-fusion\nmodels. The results demonstrate the power of MGCN in analyzing multi-modal fMRI\nand discovering significant biomarkers for human brain studies.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08316",
		"pdf_url": "http://arxiv.org/pdf/2101.08316.pdf"
	},
	"1340": {
		"title": "Communication Aid for Non-English Speaking Newcomers",
		"creator": [
			"Al-Ageili, Munira",
			"Mouhoub, Malek"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": [
			"  This research work is intended to assess the usability of Pictogram symbols\nand other visual symbols in an audio-visual strategy to facilitate and enhance\nthe use and learning of English as an additional language for Arabic-speaking\nSyrian refugees, with a potential for generalizing the process to speakers from\nother linguistic backgrounds. The adopted software for the project is\nPICTOPAGES, a versatile tool with 2,200 symbols, 78 animated symbols, and the\npotential for customization with photographs, thus augmenting its capability\nfor personalization and relevance. While PICTOPAGES is the intended basis for\nthis research, the concept and software will be adapted and modified as may be\nrequired. PICTOPAGES includes text, recorded speech, and symbols and is\ncurrently available for iPad. In the future, it may be adapted for use on\niPhone. A preliminary design using PICTOPAGES has been created for this\nresearch. The focus group includes, but is not limited to, newcomers who may\nhave limited to no English skills, limited resources, limited education, and\npotentially limited literacy in their native language, and perhaps high levels\nof distraction and frustration related to their recent experiences. Enhanced\ncommunication capability and confidence should enhance the participants\nemployment potential. Extensive interaction with respect to communication\nrequirements, selection or development of readily understandable symbols, and\nreal-world testing would be undertaken with an intended user group. A potential\nsubset of the focus group could involve members of the refugee community that,\nin addition to English language limitations, also have developmental or\nacquired disabilities that affect their ability to communicate verbally (per\nthe original intent of the software).\n",
			"Comment: 9 pages"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08319",
		"pdf_url": "http://arxiv.org/pdf/2101.08319.pdf"
	},
	"1341": {
		"title": "Zero-shot Generalization in Dialog State Tracking through Generative\n  Question Answering",
		"creator": [
			"Li, Shuyang",
			"Cao, Jin",
			"Sridhar, Mukund",
			"Zhu, Henghui",
			"Li, Shang-Wen",
			"Hamza, Wael",
			"McAuley, Julian"
		],
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  Dialog State Tracking (DST), an integral part of modern dialog systems, aims\nto track user preferences and constraints (slots) in task-oriented dialogs. In\nreal-world settings with constantly changing services, DST systems must\ngeneralize to new domains and unseen slot types. Existing methods for DST do\nnot generalize well to new slot names and many require known ontologies of slot\ntypes and values for inference. We introduce a novel ontology-free framework\nthat supports natural language queries for unseen constraints and slots in\nmulti-domain task-oriented dialogs. Our approach is based on generative\nquestion-answering using a conditional language model pre-trained on\nsubstantive English sentences. Our model improves joint goal accuracy in\nzero-shot domain adaptation settings by up to 9% (absolute) over the previous\nstate-of-the-art on the MultiWOZ 2.1 dataset.\n",
			"Comment: Accepted as a Long Paper at EACL 2021"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08333",
		"pdf_url": "http://arxiv.org/pdf/2101.08333.pdf"
	},
	"1342": {
		"title": "Density-based clustering of social networks",
		"creator": [
			"Menardi, Giovanna",
			"De Stefano, Domenico"
		],
		"subject": [
			"Computer Science - Social and Information Networks",
			"Statistics - Applications",
			"62P25"
		],
		"description": "  The idea underlying the modal formulation of density-based clustering is to\nassociate groups with the regions around the modes of the probability density\nfunction underlying the data. This correspondence between clusters and dense\nregions in the sample space is here exploited to discuss an extension of this\napproach to the analysis of social networks. Such extension seems particularly\nappealing: conceptually, the notion of high-density cluster fits well the one\nof community in a network, regarded to as a collection of individuals with\ndense local ties in its neighbourhood. The lack of a probabilistic notion of\ndensity in networks is turned into a major strength of the proposed method,\nwhere node-wise measures that quantify the role and position of actors may be\nused to derive different community configurations. The approach allows for the\nidentification of a hierarchical structure of clusters, which may catch\ndifferent degrees of resolution of the clustering structure. This feature well\nfits the nature of social networks, disentangling a different involvement of\nindividuals in social aggregations.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08334",
		"pdf_url": "http://arxiv.org/pdf/2101.08334.pdf"
	},
	"1343": {
		"title": "Learning Ultrasound Rendering from Cross-Sectional Model Slices for\n  Simulated Training",
		"creator": [
			"Zhang, Lin",
			"Portenier, Tiziano",
			"Goksel, Orcun"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition"
		],
		"description": "  Purpose. Given the high level of expertise required for navigation and\ninterpretation of ultrasound images, computational simulations can facilitate\nthe training of such skills in virtual reality. With ray-tracing based\nsimulations, realistic ultrasound images can be generated. However, due to\ncomputational constraints for interactivity, image quality typically needs to\nbe compromised.\n  Methods. We propose herein to bypass any rendering and simulation process at\ninteractive time, by conducting such simulations during a non-time-critical\noffline stage and then learning image translation from cross-sectional model\nslices to such simulated frames. We use a generative adversarial framework with\na dedicated generator architecture and input feeding scheme, which both\nsubstantially improve image quality without increase in network parameters.\nIntegral attenuation maps derived from cross-sectional model slices,\ntexture-friendly strided convolutions, providing stochastic noise and input\nmaps to intermediate layers in order to preserve locality are all shown herein\nto greatly facilitate such translation task.\n  Results. Given several quality metrics, the proposed method with only tissue\nmaps as input is shown to provide comparable or superior results to a\nstate-of-the-art that uses additional images of low-quality ultrasound\nrenderings. An extensive ablation study shows the need and benefits from the\nindividual contributions utilized in this work, based on qualitative examples\nand quantitative ultrasound similarity metrics. To that end, a local histogram\nstatistics based error metric is proposed and demonstrated for visualization of\nlocal dissimilarities between ultrasound images.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08339",
		"pdf_url": "http://arxiv.org/pdf/2101.08339.pdf"
	},
	"1344": {
		"title": "Nonparametric clustering for image segmentation",
		"creator": "Menardi, Giovanna",
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Statistics - Applications",
			"62P99"
		],
		"description": "  Image segmentation aims at identifying regions of interest within an image,\nby grouping pixels according to their properties. This task resembles the\nstatistical one of clustering, yet many standard clustering methods fail to\nmeet the basic requirements of image segmentation: segment shapes are often\nbiased toward predetermined shapes and their number is rarely determined\nautomatically. Nonparametric clustering is, in principle, free from these\nlimitations and turns out to be particularly suitable for the task of image\nsegmentation. This is also witnessed by several operational analogies, as, for\ninstance, the resort to topological data analysis and spatial tessellation in\nboth the frameworks. We discuss the application of nonparametric clustering to\nimage segmentation and provide an algorithm specific for this task. Pixel\nsimilarity is evaluated in terms of density of the color representation and the\nadjacency structure of the pixels is exploited to introduce a simple, yet\neffective method to identify image segments as disconnected high-density\nregions. The proposed method works both to segment an image and to detect its\nboundaries and can be seen as a generalization to color images of the class of\nthresholding methods.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08345",
			"Statistical Analysis and Data Mining, 13(1), 83-97 (2020)",
			"doi:10.1002/sam.11444"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08345.pdf"
	},
	"1345": {
		"title": "Generalized Tilings with Height Functions",
		"creator": [
			"Bodini, Olivier",
			"Latapy, Matthieu"
		],
		"subject": [
			"Mathematics - Combinatorics",
			"Condensed Matter - Statistical Mechanics",
			"Computer Science - Discrete Mathematics"
		],
		"description": "  In this paper, we introduce a generalization of a class of tilings which\nappear in the literature: the tilings over which a height function can be\ndefined (for example, the famous tilings of polyominoes with dominoes). We show\nthat many properties of these tilings can be seen as the consequences of\nproperties of the generalized tilings we introduce. In particular, we show that\nany tiling problem which can be modelized in our generalized framework has the\nfollowing properties: the tilability of a region can be constructively decided\nin polynomial time, the number of connected components in the undirected\nflip-accessibility graph can be determined, and the directed flip-accessibility\ngraph induces a distributive lattice structure. Finally, we give a few examples\nof known tiling problems which can be viewed as particular cases of the new\nnotions we introduce.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08347",
			"Morfismos, Vol 7, No 1, 2003"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08347.pdf"
	},
	"1346": {
		"title": "Physical Reservoir Computing with Origami and its Application to Robotic\n  Crawling",
		"creator": [
			"Bhovad, Priyanka",
			"Li, Suyi"
		],
		"subject": "Computer Science - Robotics",
		"description": "  A new paradigm called physical reservoir computing has recently emerged,\nwhere the nonlinear dynamics of high-dimensional and fixed physical systems are\nharnessed as a computational resource to achieve complex tasks. Via extensive\nsimulations based on a dynamic truss-frame model, this study shows that an\norigami structure can perform as a dynamic reservoir with sufficient computing\npower to emulate high-order nonlinear systems, generate stable limit cycles,\nand modulate outputs according to dynamic inputs. This study also uncovers the\nlinkages between the origami reservoir's physical designs and its computing\npower, offering a guideline to optimize the computing performance.\nComprehensive parametric studies show that selecting optimal feedback crease\ndistribution and fine-tuning the underlying origami folding designs are the\nmost effective approach to improve computing performance. Furthermore, this\nstudy shows how origami's physical reservoir computing power can apply to soft\nrobotic control problems by a case study of earthworm-like peristaltic crawling\nwithout traditional controllers. These results can pave the way for\norigami-based robots with embodied mechanical intelligence.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08348",
		"pdf_url": "http://arxiv.org/pdf/2101.08348.pdf"
	},
	"1347": {
		"title": "Do we need to go Deep? Knowledge Tracing with Big Data",
		"creator": [
			"Mandalapu, Varun",
			"Gong, Jiaqi",
			"Chen, Lujie"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Interactive Educational Systems (IES) enabled researchers to trace student\nknowledge in different skills and provide recommendations for a better learning\npath. To estimate the student knowledge and further predict their future\nperformance, the interest in utilizing the student interaction data captured by\nIES to develop learner performance models is increasing rapidly. Moreover, with\nthe advances in computing systems, the amount of data captured by these IES\nsystems is also increasing that enables deep learning models to compete with\ntraditional logistic models and Markov processes. However, it is still not\nempirically evident if these deep models outperform traditional models on the\ncurrent scale of datasets with millions of student interactions. In this work,\nwe adopt EdNet, the largest student interaction dataset publicly available in\nthe education domain, to understand how accurately both deep and traditional\nmodels predict future student performances. Our work observes that logistic\nregression models with carefully engineered features outperformed deep models\nfrom extensive experimentation. We follow this analysis with interpretation\nstudies based on Locally Interpretable Model-agnostic Explanation (LIME) to\nunderstand the impact of various features on best performing model\npre-dictions.\n",
			"Comment: 9 Pages, 4 figures, AAAI Workshop on AI in Education (Imagining\n  Post-COVID Education with AI)"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08349",
		"pdf_url": "http://arxiv.org/pdf/2101.08349.pdf"
	},
	"1348": {
		"title": "Enhancing Generative Models via Quantum Correlations",
		"creator": [
			"Gao, Xun",
			"Anschuetz, Eric R.",
			"Wang, Sheng-Tao",
			"Cirac, J. Ignacio",
			"Lukin, Mikhail D."
		],
		"subject": [
			"Quantum Physics",
			"Condensed Matter - Statistical Mechanics",
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Generative modeling using samples drawn from the probability distribution\nconstitutes a powerful approach for unsupervised machine learning. Quantum\nmechanical systems can produce probability distributions that exhibit quantum\ncorrelations which are difficult to capture using classical models. We show\ntheoretically that such quantum correlations provide a powerful resource for\ngenerative modeling. In particular, we provide an unconditional proof of\nseparation in expressive power between a class of widely-used generative\nmodels, known as Bayesian networks, and its minimal quantum extension. We show\nthat this expressivity advantage is associated with quantum nonlocality and\nquantum contextuality. Furthermore, we numerically test this separation on\nstandard machine learning data sets and show that it holds for practical\nproblems. The possibility of quantum advantage demonstrated in this work not\nonly sheds light on the design of useful quantum machine learning protocols but\nalso provides inspiration to draw on ideas from quantum foundations to improve\npurely classical algorithms.\n",
			"Comment: 25 pages, 13 figures"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08354",
		"pdf_url": "http://arxiv.org/pdf/2101.08354.pdf"
	},
	"1349": {
		"title": "Factorization in Call-by-Name and Call-by-Value Calculi via Linear Logic\n  (long version)",
		"creator": [
			"Faggian, Claudia",
			"Guerrieri, Giulio"
		],
		"subject": [
			"Computer Science - Logic in Computer Science",
			"03B40, 68N18, 03B70"
		],
		"description": "  In each variant of the lambda-calculus, factorization and normalization are\ntwo key-properties that show how results are computed. Instead of proving\nfactorization/normalization for the call-by-name (CbN) and call-by-value (CbV)\nvariants separately, we prove them only once, for the bang calculus (an\nextension of the lambda-calculus inspired by linear logic and subsuming CbN and\nCbV), and then we transfer the result via translations, obtaining\nfactorization/normalization for CbN and CbV. The approach is robust: it still\nholds when extending the calculi with operators and extra rules to model some\nadditional computational features.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08364",
		"pdf_url": "http://arxiv.org/pdf/2101.08364.pdf"
	},
	"1350": {
		"title": "Evaluating Multilingual Text Encoders for Unsupervised Cross-Lingual\n  Retrieval",
		"creator": [
			"Litschko, Robert",
			"Vulić, Ivan",
			"Ponzetto, Simone Paolo",
			"Glavaš, Goran"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Information Retrieval",
			"H.3.3",
			"I.2.7"
		],
		"description": [
			"  Pretrained multilingual text encoders based on neural Transformer\narchitectures, such as multilingual BERT (mBERT) and XLM, have achieved strong\nperformance on a myriad of language understanding tasks. Consequently, they\nhave been adopted as a go-to paradigm for multilingual and cross-lingual\nrepresentation learning and transfer, rendering cross-lingual word embeddings\n(CLWEs) effectively obsolete. However, questions remain to which extent this\nfinding generalizes 1) to unsupervised settings and 2) for ad-hoc cross-lingual\nIR (CLIR) tasks. Therefore, in this work we present a systematic empirical\nstudy focused on the suitability of the state-of-the-art multilingual encoders\nfor cross-lingual document and sentence retrieval tasks across a large number\nof language pairs. In contrast to supervised language understanding, our\nresults indicate that for unsupervised document-level CLIR -- a setup with no\nrelevance judgments for IR-specific fine-tuning -- pretrained encoders fail to\nsignificantly outperform models based on CLWEs. For sentence-level CLIR, we\ndemonstrate that state-of-the-art performance can be achieved. However, the\npeak performance is not met using the general-purpose multilingual text\nencoders `off-the-shelf', but rather relying on their variants that have been\nfurther specialized for sentence understanding tasks.\n",
			"Comment: accepted at ECIR'21 (preprint)"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08370",
		"pdf_url": "http://arxiv.org/pdf/2101.08370.pdf"
	},
	"1351": {
		"title": "Personalised Recommendations in Mental Health Apps: The Impact of\n  Autonomy and Data Sharing",
		"creator": [
			"Pieritz, Svenja",
			"Khwaja, Mohammed",
			"Faisal, A. Aldo",
			"Matic, Aleksandar"
		],
		"subject": "Computer Science - Human-Computer Interaction",
		"description": [
			"  The recent growth of digital interventions for mental well-being prompts a\ncall-to-arms to explore the delivery of personalised recommendations from a\nuser's perspective. In a randomised placebo study with a two-way factorial\ndesign, we analysed the difference between an autonomous user experience as\nopposed to personalised guidance, with respect to both users' preference and\ntheir actual usage of a mental well-being app. Furthermore, we explored users'\npreference in sharing their data for receiving personalised recommendations, by\njuxtaposing questionnaires and mobile sensor data. Interestingly, self-reported\nresults indicate the preference for personalised guidance, whereas behavioural\ndata suggests that a blend of autonomous choice and recommended activities\nresults in higher engagement. Additionally, although users reported a strong\npreference of filling out questionnaires instead of sharing their mobile data,\nthe data source did not have any impact on the actual app use. We discuss the\nimplications of our findings and provide takeaways for designers of mental\nwell-being applications.\n",
			"Comment: To appear in the proceedings of the 2021 CHI Conference on Human\n  Factors in Computing Systems; 12 pages, 4 figures, 2 tables"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08375",
		"pdf_url": "http://arxiv.org/pdf/2101.08375.pdf"
	},
	"1352": {
		"title": "Better Short than Greedy: Interpretable Models through Optimal Rule\n  Boosting",
		"creator": [
			"Boley, Mario",
			"Teshuva, Simon",
			"Bodic, Pierre Le",
			"Webb, Geoffrey I"
		],
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  Rule ensembles are designed to provide a useful trade-off between predictive\naccuracy and model interpretability. However, the myopic and random search\ncomponents of current rule ensemble methods can compromise this goal: they\noften need more rules than necessary to reach a certain accuracy level or can\neven outright fail to accurately model a distribution that can actually be\ndescribed well with a few rules. Here, we present a novel approach aiming to\nfit rule ensembles of maximal predictive power for a given ensemble size (and\nthus model comprehensibility). In particular, we present an efficient\nbranch-and-bound algorithm that optimally solves the per-rule objective\nfunction of the popular second-order gradient boosting framework. Our main\ninsight is that the boosting objective can be tightly bounded in linear time of\nthe number of covered data points. Along with an additional novel pruning\ntechnique related to rule redundancy, this leads to a computationally feasible\napproach for boosting optimal rules that, as we demonstrate on a wide range of\ncommon benchmark problems, consistently outperforms the predictive performance\nof boosting greedy rules.\n",
			"Comment: SDM 2021"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08380",
		"pdf_url": "http://arxiv.org/pdf/2101.08380.pdf"
	},
	"1353": {
		"title": "Motif Identification using CNN-based Pairwise Subsequence Alignment\n  Score Prediction",
		"creator": [
			"Moyer, Ethan Jacob",
			"Das, Anup"
		],
		"subject": [
			"Quantitative Biology - Genomics",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  A common problem in bioinformatics is related to identifying gene regulatory\nregions marked by relatively high frequencies of motifs, or deoxyribonucleic\nacid sequences that often code for transcription and enhancer proteins.\nPredicting alignment scores between subsequence k-mers and a given motif\nenables the identification of candidate regulatory regions in a gene, which\ncorrespond to the transcription of these proteins. We propose a one-dimensional\n(1-D) Convolution Neural Network trained on k-mer formatted sequences\ninterspaced with the given motif pattern to predict pairwise alignment scores\nbetween the consensus motif and subsequence k-mers. Our model consists of\nfifteen layers with three rounds of a one-dimensional convolution layer, a\nbatch normalization layer, a dense layer, and a 1-D maximum pooling layer. We\ntrain the model using mean squared error loss on four different data sets each\nwith a different motif pattern randomly inserted in DNA sequences: the first\nthree data sets have zero, one, and two mutations applied on each inserted\nmotif, and the fourth data set represents the inserted motif as a\nposition-specific probability matrix. We use a novel proposed metric in order\nto evaluate the model's performance, $S_{\\alpha}$, which is based on the\nJaccard Index. We use 10-fold cross validation to evaluate out model. Using\n$S_{\\alpha}$, we measure the accuracy of the model by identifying the 15\nhighest-scoring 15-mer indices of the predicted scores that agree with that of\nthe actual scores within a selected $\\alpha$ region. For the best performing\ndata set, our results indicate on average 99.3% of the top 15 motifs were\nidentified correctly within a one base pair stride ($\\alpha = 1$) in the out of\nsample data. To the best of our knowledge, this is a novel approach that\nillustrates how data formatted in an intelligent way can be extrapolated using\nmachine learning.\n",
			"Comment: 7 pages, 4 figures, submitted to the 2021 International Joint\n  Conference on Neural Networks"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08385",
		"pdf_url": "http://arxiv.org/pdf/2101.08385.pdf"
	},
	"1354": {
		"title": "Deep Reinforcement Learning with Spatio-temporal Traffic Forecasting for\n  Data-Driven Base Station Sleep Control",
		"creator": [
			"Wu, Qiong",
			"Chen, Xu",
			"Zhou, Zhi",
			"Chen, Liang",
			"Zhang, Junshan"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Distributed, Parallel, and Cluster Computing"
		],
		"description": [
			"  To meet the ever increasing mobile traffic demand in 5G era, base stations\n(BSs) have been densely deployed in radio access networks (RANs) to increase\nthe network coverage and capacity. However, as the high density of BSs is\ndesigned to accommodate peak traffic, it would consume an unnecessarily large\namount of energy if BSs are on during off-peak time. To save the energy\nconsumption of cellular networks, an effective way is to deactivate some idle\nbase stations that do not serve any traffic demand. In this paper, we develop a\ntraffic-aware dynamic BS sleep control framework, named DeepBSC, which presents\na novel data-driven learning approach to determine the BS active/sleep modes\nwhile meeting lower energy consumption and satisfactory Quality of Service\n(QoS) requirements. Specifically, the traffic demands are predicted by the\nproposed GS-STN model, which leverages the geographical and semantic\nspatial-temporal correlations of mobile traffic. With accurate mobile traffic\nforecasting, the BS sleep control problem is cast as a Markov Decision Process\nthat is solved by Actor-Critic reinforcement learning methods. To reduce the\nvariance of cost estimation in the dynamic environment, we propose a benchmark\ntransformation method that provides robust performance indicator for policy\nupdate. To expedite the training process, we adopt a Deep Deterministic Policy\nGradient (DDPG) approach, together with an explorer network, which can\nstrengthen the exploration further. Extensive experiments with a real-world\ndataset corroborate that our proposed framework significantly outperforms the\nexisting methods.\n",
			"Comment: Accepted by IEEE/ACM Transactions on Networking, Jan. 2021"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08391",
		"pdf_url": "http://arxiv.org/pdf/2101.08391.pdf"
	},
	"1355": {
		"title": "Blocked and Hierarchical Disentangled Representation From Information\n  Theory Perspective",
		"creator": [
			"Liu, Ziwen",
			"Li, Mingqiang",
			"Han, Congying"
		],
		"subject": [
			"Computer Science - Information Theory",
			"Computer Science - Machine Learning"
		],
		"description": "  We propose a novel and theoretical model, blocked and hierarchical\nvariational autoencoder (BHiVAE), to get better-disentangled representation. It\nis well known that information theory has an excellent explanatory meaning for\nthe network, so we start to solve the disentanglement problem from the\nperspective of information theory. BHiVAE mainly comes from the information\nbottleneck theory and information maximization principle. Our main idea is that\n(1) Neurons block not only one neuron node is used to represent attribute,\nwhich can contain enough information; (2) Create a hierarchical structure with\ndifferent attributes on different layers, so that we can segment the\ninformation within each layer to ensure that the final representation is\ndisentangled. Furthermore, we present supervised and unsupervised BHiVAE,\nrespectively, where the difference is mainly reflected in the separation of\ninformation between different blocks. In supervised BHiVAE, we utilize the\nlabel information as the standard to separate blocks. In unsupervised BHiVAE,\nwithout extra information, we use the Total Correlation (TC) measure to achieve\nindependence, and we design a new prior distribution of the latent space to\nguide the representation learning. It also exhibits excellent disentanglement\nresults in experiments and superior classification accuracy in representation\nlearning.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08408",
		"pdf_url": "http://arxiv.org/pdf/2101.08408.pdf"
	},
	"1356": {
		"title": "Finger Vein Recognition by Generating Code",
		"creator": [
			"Zhang, Zhongxia",
			"Wang, Mingwen"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Information Theory",
			"Computing methodologies for image processing",
			"I.4"
		],
		"description": [
			"  Finger vein recognition has drawn increasing attention as one of the most\npopular and promising biometrics due to its high distinguishes ability,\nsecurity and non-invasive procedure. The main idea of traditional schemes is to\ndirectly extract features from finger vein images or patterns and then compare\nfeatures to find the best match. However, the features extracted from images\ncontain much redundant data, while the features extracted from patterns are\ngreatly influenced by image segmentation methods. To tack these problems, this\npaper proposes a new finger vein recognition by generating code. The proposed\nmethod does not require an image segmentation algorithm, is simple to calculate\nand has a small amount of data. Firstly, the finger vein images were divided\ninto blocks to calculate the mean value. Then the centrosymmetric coding is\nperformed by using the generated eigenmatrix. The obtained codewords are\nconcatenated as the feature codewords of the image. The similarity between vein\ncodes is measured by the ratio of minimum Hamming distance to codeword length.\nExtensive experiments on two public finger vein databases verify the\neffectiveness of the proposed method. The results indicate that our method\noutperforms the state-of-theart methods and has competitive potential in\nperforming the matching task.\n",
			"Comment: 11pages,1 figure, 6 tables"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08415",
		"pdf_url": "http://arxiv.org/pdf/2101.08415.pdf"
	},
	"1357": {
		"title": "Rethinking Semantic Segmentation Evaluation for Explainability and Model\n  Selection",
		"creator": [
			"Zhang, Yuxiang",
			"Mehta, Sachin",
			"Caspi, Anat"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Semantic segmentation aims to robustly predict coherent class labels for\nentire regions of an image. It is a scene understanding task that powers\nreal-world applications (e.g., autonomous navigation). One important\napplication, the use of imagery for automated semantic understanding of\npedestrian environments, provides remote mapping of accessibility features in\nstreet environments. This application (and others like it) require detailed\ngeometric information of geographical objects. Semantic segmentation is a\nprerequisite for this task since it maps contiguous regions of the same class\nas single entities. Importantly, semantic segmentation uses like ours are not\npixel-wise outcomes; however, most of their quantitative evaluation metrics\n(e.g., mean Intersection Over Union) are based on pixel-wise similarities to a\nground-truth, which fails to emphasize over- and under-segmentation properties\nof a segmentation model. Here, we introduce a new metric to assess region-based\nover- and under-segmentation. We analyze and compare it to other metrics,\ndemonstrating that the use of our metric lends greater explainability to\nsemantic segmentation model performance in real-world applications.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08418",
		"pdf_url": "http://arxiv.org/pdf/2101.08418.pdf"
	},
	"1358": {
		"title": "Understand Volatility of Algorithmic Stablecoin: Modeling, Verification\n  and Empirical Analysis",
		"creator": [
			"Zhao, Wenqi",
			"Li, Hui",
			"Yuan, Yuming"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Computer Science and Game Theory"
		],
		"description": "  An algorithmic stablecoin is a type of cryptocurrency managed by algorithms\n(i.e., smart contracts) to dynamically minimize the volatility of its price\nrelative to a specific form of asset, e.g., US dollar. As algorithmic\nstablecoins have been growing rapidly in recent years, they become much more\nvolatile than expected. In this paper, we took a deep dive into the core of\nalgorithmic stablecoins and shared our answer to two fundamental research\nquestions, i.e., Are algorithmic stablecoins volatile by design? Are they\nvolatile in practice? Specifically, we introduced an in-depth study on three\npopular types of algorithmic stablecoins and developed a modeling framework to\nformalize their key design protocols. Through formal verification, the\nframework can identify critical conditions under which stablecoins might become\nvolatile. Furthermore, we performed a systematic empirical analysis on real\ntransaction activities of the Basis Cash stablecoin to relate theoretical\npossibilities to market observations. Lastly, we highlighted key design\ndecisions for future development of algorithmic stablecoins.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08423",
		"pdf_url": "http://arxiv.org/pdf/2101.08423.pdf"
	},
	"1359": {
		"title": "Some punctured codes of several families of binary linear codes",
		"creator": [
			"Wang, Xiaoqiang",
			"Zheng, Dabin",
			"Ding, Cunsheng"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  Two general constructions of linear codes with functions over finite fields\nhave been extensively studied in the literature. The first one is given by\n$\\mathcal{C}(f)=\\left\\{ {\\rm Tr}(af(x)+bx)_{x \\in \\mathbb{F}_{q^m}^*}: a,b \\in\n\\mathbb{F}_{q^m} \\right\\}$, where $q$ is a prime power, $\\bF_{q^m}^*=\\bF_{q^m}\n\\setminus \\{0\\}$, $\\tr$ is the trace function from $\\bF_{q^m}$ to $\\bF_q$, and\n$f(x)$ is a function from $\\mathbb{F}_{q^m}$ to $\\mathbb{F}_{q^m}$ with\n$f(0)=0$. Almost bent functions, quadratic functions and some monomials on\n$\\bF_{2^m}$ were used in the first construction, and many families of binary\nlinear codes with few weights were obtained in the literature. This paper\nstudies some punctured codes of these binary codes. Several families of binary\nlinear codes with few weights and new parameters are obtained in this paper.\nSeveral families of distance-optimal binary linear codes with new parameters\nare also produced in this paper.\n",
			"Comment: Boolean function, linear code, punctured code, distance-optimal code,\n  weight distribution"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08425",
		"pdf_url": "http://arxiv.org/pdf/2101.08425.pdf"
	},
	"1360": {
		"title": "Content Selection Network for Document-grounded Retrieval-based Chatbots",
		"creator": [
			"Zhu, Yutao",
			"Nie, Jian-Yun",
			"Zhou, Kun",
			"Du, Pan",
			"Dou, Zhicheng"
		],
		"subject": "Computer Science - Computation and Language",
		"description": [
			"  Grounding human-machine conversation in a document is an effective way to\nimprove the performance of retrieval-based chatbots. However, only a part of\nthe document content may be relevant to help select the appropriate response at\na round. It is thus crucial to select the part of document content relevant to\nthe current conversation context. In this paper, we propose a document content\nselection network (CSN) to perform explicit selection of relevant document\ncontents, and filter out the irrelevant parts. We show in experiments on two\npublic document-grounded conversation datasets that CSN can effectively help\nselect the relevant document contents to the conversation context, and it\nproduces better results than the state-of-the-art approaches. Our code and\ndatasets are available at https://github.com/DaoD/CSN.\n",
			"Comment: ECIR 2021 Camera Ready"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08426",
		"pdf_url": "http://arxiv.org/pdf/2101.08426.pdf"
	},
	"1361": {
		"title": "Introducing the Unitychain Structure: A novel blockchain-like structure\n  that enables greater parallel processing, security, and performance for\n  networks that leverage distributed key generation and classical consensus\n  protocols",
		"creator": "Tobkin, Joshua D.",
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Distributed, Parallel, and Cluster Computing"
		],
		"description": [
			"  A Unitychain is a novel blockchain-like structure that drastically improves\ntransaction scalability and security while maintaining ongoing network\nperformance, even if participating nodes are required to perform a new\nDistributed Key Generation procedure for security purposes. The Unitychain\nstructure, furthermore, enables greater parallel processing by the assignment\nof different network node configurations for various database and compute\nranges into multiple strands of blockchains that intersect, creating a\nmulti-helix structure, which we call a Unitychain. This thereby enables the\nnetwork to further bifurcate the roles of nodes into arbitrary yet\ndeterministic network responsibilities in order to maximize the global compute\npotential.\n",
			"Comment: 16 pages, 7 Figures"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08428",
		"pdf_url": "http://arxiv.org/pdf/2101.08428.pdf"
	},
	"1362": {
		"title": "Malware Detection and Analysis: Challenges and Research Opportunities",
		"creator": "Akhtar, Zahid",
		"subject": "Computer Science - Cryptography and Security",
		"description": "  Malwares are continuously growing in sophistication and numbers. Over the\nlast decade, remarkable progress has been achieved in anti-malware mechanisms.\nHowever, several pressing issues (e.g., unknown malware samples detection)\nstill need to be addressed adequately. This article first presents a concise\noverview of malware along with anti-malware and then summarizes various\nresearch challenges. This is a theoretical and perspective article that is\nhoped to complement earlier articles and works.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08429",
		"pdf_url": "http://arxiv.org/pdf/2101.08429.pdf"
	},
	"1363": {
		"title": "Generative Zero-shot Network Quantization",
		"creator": [
			"He, Xiangyu",
			"Hu, Qinghao",
			"Wang, Peisong",
			"Cheng, Jian"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Convolutional neural networks are able to learn realistic image priors from\nnumerous training samples in low-level image generation and restoration. We\nshow that, for high-level image recognition tasks, we can further reconstruct\n\"realistic\" images of each category by leveraging intrinsic Batch Normalization\n(BN) statistics without any training data. Inspired by the popular VAE/GAN\nmethods, we regard the zero-shot optimization process of synthetic images as\ngenerative modeling to match the distribution of BN statistics. The generated\nimages serve as a calibration set for the following zero-shot network\nquantizations. Our method meets the needs for quantizing models based on\nsensitive information, \\textit{e.g.,} due to privacy concerns, no data is\navailable. Extensive experiments on benchmark datasets show that, with the help\nof generated data, our approach consistently outperforms existing data-free\nquantization methods.\n",
			"Comment: Technical report"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08430",
		"pdf_url": "http://arxiv.org/pdf/2101.08430.pdf"
	},
	"1364": {
		"title": "A fast two-stage algorithm for non-negative matrix factorization in\n  streaming data",
		"creator": [
			"Gu, Ran",
			"Du, Qiang",
			"Billinge, Simon J. L."
		],
		"subject": [
			"Mathematics - Optimization and Control",
			"Mathematics - Numerical Analysis",
			"65K10, 90C26",
			"G.1.6",
			"F.2.1"
		],
		"description": [
			"  In this article, we study algorithms for nonnegative matrix factorization\n(NMF) in various applications involving streaming data. Utilizing the continual\nnature of the data, we develop a fast two-stage algorithm for highly efficient\nand accurate NMF. In the first stage, an alternating non-negative least squares\n(ANLS) framework is used, in combination with active set method with warm-start\nstrategy for the solution of subproblems. In the second stage, an interior\npoint method is adopted to accelerate the local convergence. The convergence of\nthe proposed algorithm is proved. The new algorithm is compared with some\nexisting algorithms in benchmark tests using both real-world data and synthetic\ndata. The results demonstrate the advantage of our algorithm in finding\nhigh-precision solutions.\n",
			"Comment: 10 pages, 3 figures"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08431",
		"pdf_url": "http://arxiv.org/pdf/2101.08431.pdf"
	},
	"1365": {
		"title": "Walking Through the Method Zoo: Does Higher Education really meet\n  Software Industry Demands?",
		"creator": [
			"Kuhrmann, Marco",
			"Nakatumba-Nabende, Joyce",
			"Pfeiffer, Rolf-Helge",
			"Tell, Paolo",
			"Klünder, Jil",
			"Conte, Tayana",
			"MacDonell, Stephen G.",
			"Hebig, Regina"
		],
		"subject": "Computer Science - Software Engineering",
		"description": [
			"  Software engineering educators are continually challenged by rapidly evolving\nconcepts, technologies, and industry demands. Due to the omnipresence of\nsoftware in a digitalized society, higher education institutions (HEIs) have to\neducate the students such that they learn how to learn, and that they are\nequipped with a profound basic knowledge and with latest knowledge about modern\nsoftware and system development. Since industry demands change constantly, HEIs\nare challenged in meeting such current and future demands in a timely manner.\nThis paper analyzes the current state of practice in software engineering\neducation. Specifically, we want to compare contemporary education with\nindustrial practice to understand if frameworks, methods and practices for\nsoftware and system development taught at HEIs reflect industrial practice. For\nthis, we conducted an online survey and collected information about 67 software\nengineering courses. Our findings show that development approaches taught at\nHEIs quite closely reflect industrial practice. We also found that the choice\nof what process to teach is sometimes driven by the wish to make a course\nsuccessful. Especially when this happens for project courses, it could be\nbeneficial to put more emphasis on building learning sequences with other\ncourses.\n",
			"Comment: Conference, 11 pages, 7 figures, 3 tables"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08432",
			"Proceedings of the International Conference on Software\n  Engineering -- Software Engineering Education and Training (ICSE-SEET2019).\n  Montr\\'eal, Canada, IEEE Computer Society Press, pp.1-11",
			"doi:10.1109/ICSE-SEET.2019.00009"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08432.pdf"
	},
	"1366": {
		"title": "Successive-Cancellation Decoding of Binary Polar Codes Based on\n  Symmetric Parametrization",
		"creator": "Muramatsu, Jun",
		"subject": "Computer Science - Information Theory",
		"description": [
			"  This paper introduces algorithms for the successive-cancellation decoding and\nthe successive-cancellation list decoding of binary polar source/channel codes.\nBy using the symmetric parametrization of conditional probability, we reduce\nboth space and time complexity compared to the original algorithm introduced by\nTal and Vardy.\n",
			"Comment: 14 pages, this is the extended version of the paper submitted to 2021\n  IEEE International Symposium on Information Theory"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08433",
		"pdf_url": "http://arxiv.org/pdf/2101.08433.pdf"
	},
	"1367": {
		"title": "Video Summarization: Study of various techniques",
		"creator": [
			"Raj, Ravi",
			"Bhatnagar, Varad",
			"Singh, Aman Kumar",
			"Mane, Sneha",
			"Walde, Nilima"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  A comparative study of various techniques which can be used for summarization\nof Videos i.e. Video to Video conversion is presented along with respective\narchitecture, results, strengths and shortcomings. In all approaches, a lengthy\nvideo is converted into a shorter video which aims to capture all important\nevents that are present in the original video. The definition of 'important\nevent' may vary according to the context, such as a sports video and a\ndocumentary may have different events which are classified as important.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08434",
			"Video Summarization: Study of Various Techniques Proceedings of\n  IRAJ International Conference, 26th May, 2019, Pune, India"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08434.pdf"
	},
	"1368": {
		"title": "Learning based signal detection for MIMO systems with unknown noise\n  statistics",
		"creator": [
			"He, Ke",
			"He, Le",
			"Fan, Lisheng",
			"Deng, Yansha",
			"Karagiannidis, George K.",
			"Nallanathan, Arumugam"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Information Theory"
		],
		"description": "  This paper aims to devise a generalized maximum likelihood (ML) estimator to\nrobustly detect signals with unknown noise statistics in multiple-input\nmultiple-output (MIMO) systems. In practice, there is little or even no\nstatistical knowledge on the system noise, which in many cases is non-Gaussian,\nimpulsive and not analyzable. Existing detection methods have mainly focused on\nspecific noise models, which are not robust enough with unknown noise\nstatistics. To tackle this issue, we propose a novel ML detection framework to\neffectively recover the desired signal. Our framework is a fully probabilistic\none that can efficiently approximate the unknown noise distribution through a\nnormalizing flow. Importantly, this framework is driven by an unsupervised\nlearning approach, where only the noise samples are required. To reduce the\ncomputational complexity, we further present a low-complexity version of the\nframework, by utilizing an initial estimation to reduce the search space.\nSimulation results show that our framework outperforms other existing\nalgorithms in terms of bit error rate (BER) in non-analytical noise\nenvironments, while it can reach the ML performance bound in analytical noise\nenvironments. The code of this paper is available at\nhttps://github.com/skypitcher/manfe.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08435",
		"pdf_url": "http://arxiv.org/pdf/2101.08435.pdf"
	},
	"1369": {
		"title": "Effect of Deep Learning Feature Inference Techniques on Respiratory\n  Sounds",
		"creator": [
			"Balli, Osman",
			"Kutlu, Yakup"
		],
		"subject": [
			"Computer Science - Sound",
			"Electrical Engineering and Systems Science - Audio and Speech Processing"
		],
		"description": [
			"  Analysis of respiratory sounds increases its importance every day. Many\ndifferent methods are available in the analysis, and new techniques are\ncontinuing to be developed to further improve these methods. Features are\nextracted from audio signals and trained using different machine learning\ntechniques. The use of deep learning, which is a different method and has\nincreased in recent years, also shows its influence in this field. Deep\nlearning techniques applied to the image of audio signals give good results and\ncontinue to be developed. In this study, image filters were applied to the\nvalues obtained from audio signals and the results of the features formed from\nthis were examined in machine learning and deep learning techniques. Their\nresults were compared with the results of methods that had previously achieved\ngood results.\n",
			"Comment: 4 pages, journal of intelligent systems with applications"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08438",
			"journal of intelligent systems with applications, 2020"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08438.pdf"
	},
	"1370": {
		"title": "Turkish Voice Commands based Chess Game using Gammatone Cepstral\n  Coefficients",
		"creator": [
			"Karaca, Gizem",
			"Kutlu, Yakup"
		],
		"subject": [
			"Computer Science - Sound",
			"Electrical Engineering and Systems Science - Audio and Speech Processing"
		],
		"description": [
			"  This study was carried out to enable individuals with limited mobility skills\nto play chess in real time and to play games with the individuals around them\nwithout being under any social distress or stress. Voice recordings were taken\nfrom 50 people (23 men and 27 women). While recording the sound, 29 words from\neach person were used which are determined as necessary for playing the game.\nMel Frequency Coefficients (MFCC) and Gammatone Cepstral Coefficients (GTCC)\nqualification methods were used. In addition, k-NN, Naive Bayes and Neural\nNetwork classification methods were used for classification. Two different\nclassification procedures were applied, namely, person-based and general. While\nthe performance rate in person-based classification ranged from 75% to 98%, a\nperformance over 84% was achieved in general classification.\n",
			"Comment: 5 pages, Journal of Artificial Intelligence with Application"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08441",
			"Journal of Artificial Intelligence with Application, 2020"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08441.pdf"
	},
	"1371": {
		"title": "Factors that Affect Software Systems Development Project Outcomes: A\n  Survey of Research",
		"creator": [
			"McLeod, Laurie",
			"MacDonell, Stephen G."
		],
		"subject": "Computer Science - Software Engineering",
		"description": [
			"  Determining the factors that have an influence on software systems\ndevelopment and deployment project outcomes has been the focus of extensive and\nongoing research for more than 30 years. We provide here a survey of the\nresearch literature that has addressed this topic in the period 1996-2006, with\na particular focus on empirical analyses. On the basis of this survey we\npresent a new classification framework that represents an abstracted and\nsynthesized view of the types of factors that have been asserted as influencing\nproject outcomes.\n",
			"Comment: Journal paper, 40 pages, 5 pages Appendix, 6 figures, 3 tables"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08442",
			"ACM Computing Surveys 43(4)(2011), pp.24-56",
			"doi:10.1145/1978802.1978803"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08442.pdf"
	},
	"1372": {
		"title": "Qualitative Research on Software Development: A Longitudinal Case Study\n  Methodology",
		"creator": [
			"McLeod, Laurie",
			"MacDonell, Stephen G.",
			"Doolin, Bill"
		],
		"subject": "Computer Science - Software Engineering",
		"description": [
			"  This paper reports the use of a qualitative methodology for conducting\nlongitudinal case study research on software development. We provide a detailed\ndescription and explanation of appropriate methods of qualitative data\ncollection and analysis that can be utilized by other researchers in the\nsoftware engineering field. Our aim is to illustrate the utility of\nlongitudinal case study research, as a complement to existing methodologies for\nstudying software development, so as to enable the community to develop a\nfuller and richer understanding of this complex, multi-dimensional phenomenon.\nWe discuss the insights gained and lessons learned from applying a longitudinal\nqualitative approach to an empirical case study of a software development\nproject in a large multi-national organization. We evaluate the methodology\nused to emphasize its strengths and to address the criticisms traditionally\nmade of qualitative research.\n",
			"Comment: Journal Paper, 18 pages, 2 figures, 6 tables"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08444",
			"Empirical Software Engineering 16(4)(2011), pp.430-459",
			"doi:10.1007/s10664-010-9153-5"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08444.pdf"
	},
	"1373": {
		"title": "Allocating Opportunities in a Dynamic Model of Intergenerational\n  Mobility",
		"creator": [
			"Heidari, Hoda",
			"Kleinberg, Jon"
		],
		"subject": [
			"Computer Science - Computers and Society",
			"Physics - Physics and Society"
		],
		"description": "  Opportunities such as higher education can promote intergenerational\nmobility, leading individuals to achieve levels of socioeconomic status above\nthat of their parents. We develop a dynamic model for allocating such\nopportunities in a society that exhibits bottlenecks in mobility; the problem\nof optimal allocation reflects a trade-off between the benefits conferred by\nthe opportunities in the current generation and the potential to elevate the\nsocioeconomic status of recipients, shaping the composition of future\ngenerations in ways that can benefit further from the opportunities. We show\nhow optimal allocations in our model arise as solutions to continuous\noptimization problems over multiple generations, and we find in general that\nthese optimal solutions can favor recipients of low socioeconomic status over\nslightly higher-performing individuals of high socioeconomic status -- a form\nof socioeconomic affirmative action that the society in our model discovers in\nthe pursuit of purely payoff-maximizing goals. We characterize how the\nstructure of the model can lead to either temporary or persistent affirmative\naction, and we consider extensions of the model with more complex processes\nmodulating the movement between different levels of socioeconomic status.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08451",
			"doi:10.1145/3442188.3445867"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08451.pdf"
	},
	"1374": {
		"title": "Robust Reinforcement Learning on State Observations with Learned Optimal\n  Adversary",
		"creator": [
			"Zhang, Huan",
			"Chen, Hongge",
			"Boning, Duane",
			"Hsieh, Cho-Jui"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Statistics - Machine Learning"
		],
		"description": [
			"  We study the robustness of reinforcement learning (RL) with adversarially\nperturbed state observations, which aligns with the setting of many adversarial\nattacks to deep reinforcement learning (DRL) and is also important for rolling\nout real-world RL agent under unpredictable sensing noise. With a fixed agent\npolicy, we demonstrate that an optimal adversary to perturb state observations\ncan be found, which is guaranteed to obtain the worst case agent reward. For\nDRL settings, this leads to a novel empirical adversarial attack to RL agents\nvia a learned adversary that is much stronger than previous ones. To enhance\nthe robustness of an agent, we propose a framework of alternating training with\nlearned adversaries (ATLA), which trains an adversary online together with the\nagent using policy gradient following the optimal adversarial attack framework.\nAdditionally, inspired by the analysis of state-adversarial Markov decision\nprocess (SA-MDP), we show that past states and actions (history) can be useful\nfor learning a robust agent, and we empirically find a LSTM based policy can be\nmore robust under adversaries. Empirical evaluations on a few continuous\ncontrol environments show that ATLA achieves state-of-the-art performance under\nstrong adversaries. Our code is available at\nhttps://github.com/huanzhang12/ATLA_robust_RL.\n",
			"Comment: Accepted by ICLR 2021. Huan Zhang and Hongge Chen contributed equally"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08452",
		"pdf_url": "http://arxiv.org/pdf/2101.08452.pdf"
	},
	"1375": {
		"title": "Fire Threat Detection From Videos with Q-Rough Sets",
		"creator": [
			"Chakrabortya, Debarati B.",
			"Detania, Vinay",
			"Jigneshkumar, Shah Parshv"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  This article defines new methods for unsupervised fire region segmentation\nand fire threat detection from video stream. Fire in control serves a number of\npurposes to human civilization, but it could simultaneously be a threat once\nits spread becomes uncontrolled. There exists many methods on fire region\nsegmentation and fire non-fire classification. But the approaches to determine\nthe threat associated with fire is relatively scare, and no such unsupervised\nmethod has been formulated yet. Here we focus on developing an unsupervised\nmethod with which the threat of fire can be quantified and accordingly generate\nan alarm in automated surveillance systems in indoor as well as in outdoors.\nFire region segmentation without any manual intervention/ labelled data set is\na major challenge while formulating such a method. Here we have used rough\napproximations to approximate the fire region, and to manage the incompleteness\nof the knowledge base, due to absence of any prior information. Utility\nmaximization of Q-learning has been used to minimize ambiguities in the rough\napproximations. The new set approximation method, thus developed here, is named\nas Q-rough set. It is used for fire region segmentation from video frames. The\nthreat index of fire flame over the input video stream has been defined in sync\nwith the relative growth in the fire segments on the recent frames. All\ntheories and indices defined here have been experimentally validated with\ndifferent types of fire videos, through demonstrations and comparisons, as\nsuperior to the state of the art.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08459",
		"pdf_url": "http://arxiv.org/pdf/2101.08459.pdf"
	},
	"1376": {
		"title": "COLLIDE-PRED: Prediction of On-Road Collision From Surveillance Videos",
		"creator": [
			"Chavan, Deesha",
			"Saad, Dev",
			"Chakraborty, Debarati B."
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  Predicting on-road abnormalities such as road accidents or traffic violations\nis a challenging task in traffic surveillance. If such predictions can be done\nin advance, many damages can be controlled. Here in our wok, we tried to\nformulate a solution for automated collision prediction in traffic surveillance\nvideos with computer vision and deep networks. It involves object detection,\ntracking, trajectory estimation, and collision prediction. We propose an\nend-to-end collision prediction system, named as COLLIDE-PRED, that\nintelligently integrates the information of past and future trajectories of\nmoving objects to predict collisions in videos. It is a pipeline that starts\nwith object detection, which is used for object tracking, and then trajectory\nprediction is performed which concludes by collision detection. The probable\nplace of collision, and the objects those may cause the collision, both can be\nidentified correctly with COLLIDE-PRED. The proposed method is experimentally\nvalidated with a number of different videos and proves to be effective in\nidentifying accident in advance.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08463",
		"pdf_url": "http://arxiv.org/pdf/2101.08463.pdf"
	},
	"1377": {
		"title": "FWB-Net:Front White Balance Network for Color Shift Correction in Single\n  Image Dehazing via Atmospheric Light Estimation",
		"creator": [
			"Wang, Cong",
			"Huang, Yan",
			"Zou, Yuexian",
			"Xu, Yong"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": "  In recent years, single image dehazing deep models based on Atmospheric\nScattering Model (ASM) have achieved remarkable results. But the dehazing\noutputs of those models suffer from color shift. Analyzing the ASM model shows\nthat the atmospheric light factor (ALF) is set as a scalar which indicates ALF\nis constant for whole image. However, for images taken in real-world, the\nillumination is not uniformly distributed over whole image which brings model\nmismatch and possibly results in color shift of the deep models using ASM.\nBearing this in mind, in this study, first, a new non-homogeneous atmospheric\nscattering model (NH-ASM) is proposed for improving image modeling of hazy\nimages taken under complex illumination conditions. Second, a new U-Net based\nfront white balance module (FWB-Module) is dedicatedly designed to correct\ncolor shift before generating dehazing result via atmospheric light estimation.\nThird, a new FWB loss is innovatively developed for training FWB-Module, which\nimposes penalty on color shift. In the end, based on NH-ASM and front white\nbalance technology, an end-to-end CNN-based color-shift-restraining dehazing\nnetwork is developed, termed as FWB-Net. Experimental results demonstrate the\neffectiveness and superiority of our proposed FWB-Net for dehazing on both\nsynthetic and real-world images.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08465",
		"pdf_url": "http://arxiv.org/pdf/2101.08465.pdf"
	},
	"1378": {
		"title": "A Study of F0 Modification for X-Vector Based Speech Pseudonymization\n  Across Gender",
		"creator": [
			"Champion, Pierre",
			"Jouvet, Denis",
			"Larcher, Anthony"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Audio and Speech Processing",
			"Computer Science - Cryptography and Security",
			"Computer Science - Sound"
		],
		"description": "  Speech pseudonymization aims at altering a speech signal to map the\nidentifiable personal characteristics of a given speaker to another identity.\nIn other words, it aims to hide the source speaker identity while preserving\nthe intelligibility of the spoken content. This study takes place in the\nVoicePrivacy 2020 challenge framework, where the baseline system performs\npseudonymization by modifying x-vector information to match a target speaker\nwhile keeping the fundamental frequency (F0) unchanged. We propose to alter\nother paralin-guistic features, here F0, and analyze the impact of this\nmodification across gender. We found that the proposed F0 modification always\nimproves pseudonymization We observed that both source and target speaker\ngenders affect the performance gain when modifying the F0.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08478",
			"The Second AAAI Workshop on Privacy-Preserving Artificial\n  Intelligence, Feb 2021, Nancy, France"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08478.pdf"
	},
	"1379": {
		"title": "Comparison and Improvement for Delay Analysis Approaches: Theoretical\n  Models and Experimental Tests",
		"creator": [
			"Gao, Yue Hong",
			"Hong, Xiao",
			"Yang, Hao Tian",
			"Chen, Lu",
			"Zhang, Xiao Nan"
		],
		"subject": [
			"Computer Science - Networking and Internet Architecture",
			"Computer Science - Performance"
		],
		"description": "  Computer network tends to be subjected to the proliferation of mobile demands\nand increasingly multifarious, therefore it poses a great challenge to\nguarantee the quality of network service. By designing the model according to\ndifferent requirements, we may get some related indicators such as delay and\npacket loss rate in order to evaluate the quality of network service and verify\nthe user data surface and capacity of the network environment. In this paper,\nwe describe an analytical model based on the measurement for the delay of each\npacket passing through the single existing routers in the network environment.\nIn previous studies, the emulation of real network service behaviors was\ngenerally under ideal condition. In our work, the test environment is built to\nget the relevant test results of the actual network, and the corresponding\ntheoretical results are obtained by our model. The test results are compared\nwith the theoretical results, analyzed and corrected, in order to verify the\nfeasibility of our analysis model for the performance analysis of the actual\nnetwork. With this concern, calculation results are modified with different\nschemes to realize more precise calculation of delay boundary with the\ncomparison with the experimental test results. The results show the analysis\nmethods after the amendment can realistically estimate the performance of\nnetwork element.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08479",
		"pdf_url": "http://arxiv.org/pdf/2101.08479.pdf"
	},
	"1380": {
		"title": "Differential Euler: Designing a Neural Network approximator to solve the\n  Chaotic Three Body Problem",
		"creator": [
			"Kumar, Pratyush",
			"Das, Aishwarya",
			"Gupta, Debayan"
		],
		"subject": "Computer Science - Machine Learning",
		"description": "  The three body problem is a special case of the n body problem where one\ntakes the initial positions and velocities of three point masses and attempts\nto predict their motion over time according to Newtonian laws of motion and\nuniversal gravitation. Though analytical solutions have been found for special\ncases, the general problem remains unsolved; the solutions that do exist are\nimpractical. Fortunately, for many applications, we may not need to solve the\nproblem completely, i.e., predicting with reasonable accuracy for some time\nsteps, may be sufficient. Recently, Breen et al attempted to approximately\nsolve the three body problem using a simple neural network. Although their\nmethods appear to achieve some success in reducing the computational overhead,\ntheir model is extremely restricted, applying to a specialized 2D case. The\nauthors do not provide explanations for critical decisions taken in their\nexperimental design, no details on their model or architecture, and nor do they\npublish their code. Moreover, the model does not generalize well to unseen\ncases. In this paper, we propose a detailed experimental setup to determine the\nfeasibility of using neural networks to solve the three body problem up to a\ncertain number of time steps. We establish a benchmark on the dataset size and\nset an accuracy threshold to measure the viability of our results for practical\napplications. Then, we build our models according to the listed class of NNs\nusing a dataset generated from standard numerical integrators. We gradually\nincrease the complexity of our data set to determine whether NNs can learn a\nrepresentation of the chaotic three body problem well enough to replace\nnumerical integrators in real life scenarios.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08486",
		"pdf_url": "http://arxiv.org/pdf/2101.08486.pdf"
	},
	"1381": {
		"title": "Complete trace models of state and control",
		"creator": [
			"Jaber, Guilhem",
			"Murawski, Andrzej S."
		],
		"subject": [
			"Computer Science - Logic in Computer Science",
			"Computer Science - Programming Languages"
		],
		"description": "  We consider a hierarchy of four typed call-by-value languages with either\nhigher-order or ground-type references and with either callcc or no control\noperator.Our first result is a fully abstract trace model for the most\nexpressive setting, featuring both higher-order references and callcc,\nconstructed in the spirit of operational game semantics. Next we examine the\nimpact of suppressing higher-order references and callcc in contexts and\nprovide an operational explanation for the game-semantic conditions known as\nvisibility and bracketing respectively.This allows us to refine the original\nmodel to provide fully abstract trace models of interaction with contexts that\nneed not use higher-order references or callcc. Along the way, we discuss the\nrelationship between error- and termination-based contextual testing in each\ncase, and relate the two to trace and complete trace equivalence\nrespectively.Overall, the paper provides a systematic development of\noperational game semantics for all four cases, which represent the state-based\nface of the so-called semantic cube.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08491",
		"pdf_url": "http://arxiv.org/pdf/2101.08491.pdf"
	},
	"1382": {
		"title": "Effect of Window Size for Detection of Abnormalities in Respiratory\n  Sounds",
		"creator": [
			"Balli, Osman",
			"Kutlu, Yakup"
		],
		"subject": [
			"Computer Science - Sound",
			"Electrical Engineering and Systems Science - Audio and Speech Processing"
		],
		"description": [
			"  The recording of respiratory sounds was of significant benefit in the\ndiagnosis of abnormalities in respiratory sounds. The duration of the sounds\nused in the diagnosis affects the speed of the diagnosis. In this study, the\neffect of window size on diagnosis of abnormalities in respiratory sounds and\nthe most efficient recording time for diagnosis were analyzed. First, window\nsize was applied to each sound in the data set consisting of normal and\nabnormal breathing sounds, 0.5 second and from 1 to 20 seconds Increased by 1\nsecond. Then, the data applied to window size was inferred feature extraction\nwith Mel Frequency Cepstral Coefficient (MFCC) and the performance of each\nwindow was calculated using the leave one-out classifier and the k-nearest\nneighbor (KNN) algorithm. As a result, it was determined that the data was\nsignificant with an average performance of 92.06% in the records between 2 and\n10 seconds.\n",
			"Comment: 6 pages, 3 figures, Natural and Engineering Sciences"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08495",
			"Natural and Engineering Sciences, 2019"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08495.pdf"
	},
	"1383": {
		"title": "Weighted Fuzzy-Based PSNR for Watermarking",
		"creator": [
			"Jamali, Maedeh",
			"Karimi, Nader",
			"Samavi, Shadrokh"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Image and Video Processing",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Multimedia"
		],
		"description": [
			"  One of the problems of conventional visual quality evaluation criteria such\nas PSNR and MSE is the lack of appropriate standards based on the human visual\nsystem (HVS). They are calculated based on the difference of the corresponding\npixels in the original and manipulated image. Hence, they practically do not\nprovide a correct understanding of the image quality. Watermarking is an image\nprocessing application in which the image's visual quality is an essential\ncriterion for its evaluation. Watermarking requires a criterion based on the\nHVS that provides more accurate values than conventional measures such as PSNR.\nThis paper proposes a weighted fuzzy-based criterion that tries to find\nessential parts of an image based on the HVS. Then these parts will have larger\nweights in computing the final value of PSNR. We compare our results against\nstandard PSNR, and our experiments show considerable consequences.\n",
			"Comment: Five pages, 8 figures"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08502",
		"pdf_url": "http://arxiv.org/pdf/2101.08502.pdf"
	},
	"1384": {
		"title": "Pre-training without Natural Images",
		"creator": [
			"Kataoka, Hirokatsu",
			"Okayasu, Kazushige",
			"Matsumoto, Asato",
			"Yamagata, Eisuke",
			"Yamada, Ryosuke",
			"Inoue, Nakamasa",
			"Nakamura, Akio",
			"Satoh, Yutaka"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Is it possible to use convolutional neural networks pre-trained without any\nnatural images to assist natural image understanding? The paper proposes a\nnovel concept, Formula-driven Supervised Learning. We automatically generate\nimage patterns and their category labels by assigning fractals, which are based\non a natural law existing in the background knowledge of the real world.\nTheoretically, the use of automatically generated images instead of natural\nimages in the pre-training phase allows us to generate an infinite scale\ndataset of labeled images. Although the models pre-trained with the proposed\nFractal DataBase (FractalDB), a database without natural images, does not\nnecessarily outperform models pre-trained with human annotated datasets at all\nsettings, we are able to partially surpass the accuracy of ImageNet/Places\npre-trained models. The image representation with the proposed FractalDB\ncaptures a unique feature in the visualization of convolutional layers and\nattentions.\n",
			"Comment: ACCV 2020 Best Paper Honorable Mention Award, Codes are publicly\n  available:\n  https://github.com/hirokatsukataoka16/FractalDB-Pretrained-ResNet-PyTorch"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08515",
		"pdf_url": "http://arxiv.org/pdf/2101.08515.pdf"
	},
	"1385": {
		"title": "Out-of-Distribution Generalization Analysis via Influence Function",
		"creator": [
			"Ye, Haotian",
			"Xie, Chuanlong",
			"Liu, Yue",
			"Li, Zhenguo"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  The mismatch between training and target data is one major challenge for\ncurrent machine learning systems. When training data is collected from multiple\ndomains and the target domains include all training domains and other new\ndomains, we are facing an Out-of-Distribution (OOD) generalization problem that\naims to find a model with the best OOD accuracy. One of the definitions of OOD\naccuracy is worst-domain accuracy. In general, the set of target domains is\nunknown, and the worst over target domains may be unseen when the number of\nobserved domains is limited. In this paper, we show that the worst accuracy\nover the observed domains may dramatically fail to identify the OOD accuracy.\nTo this end, we introduce Influence Function, a classical tool from robust\nstatistics, into the OOD generalization problem and suggest the variance of\ninfluence function to monitor the stability of a model on training domains. We\nshow that the accuracy on test domains and the proposed index together can help\nus discern whether OOD algorithms are needed and whether a model achieves good\nOOD generalization.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08521",
		"pdf_url": "http://arxiv.org/pdf/2101.08521.pdf"
	},
	"1386": {
		"title": "Modelling and discretization of flow in porous media with thin,\n  full-tensor permeability inclusions",
		"creator": [
			"Starnoni, Michele",
			"Berre, Inga",
			"Keilegavlen, Eirik",
			"Nordbotten, Jan M."
		],
		"subject": "Mathematics - Numerical Analysis",
		"description": "  When modelling fluid flow in fractured reservoirs, it is common to represent\nthe fracturesas lower-dimensional inclusions embedded in the host medium.\nExisting discretizationsof flow in porous media with thin inclusions assume\nthat the principal directions of theinclusion permeability tensor are aligned\nwith the inclusion orientation. While this mod-elling assumption works well\nwith tensile fractures, it may fail in the context of faults,where the damage\nzone surrounding the main slip surface may introduce anisotropy thatis not\naligned with the main fault orientation. In this paper, we introduce a\ngeneralizeddimensional reduced model which preserves full-tensor permeability\neffects also in theout-of-plane direction of the inclusion. The governing\nequations of flow for the lower-dimensional objects are obtained through\nvertical averaging. We present a framework fordiscretization of the resulting\nmixed-dimensional problem, aimed at easy adaptation ofexisting simulation\ntools. We give numerical examples that show the failure of existingformulations\nwhen applied to anisotropic faulted porous media, and go on to show\ntheconvergence of our method in both 2D and 3D\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08522",
		"pdf_url": "http://arxiv.org/pdf/2101.08522.pdf"
	},
	"1387": {
		"title": "Adv-OLM: Generating Textual Adversaries via OLM",
		"creator": [
			"Malik, Vijit",
			"Bhat, Ashwani",
			"Modi, Ashutosh"
		],
		"subject": [
			"Computer Science - Computation and Language",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Deep learning models are susceptible to adversarial examples that have\nimperceptible perturbations in the original input, resulting in adversarial\nattacks against these models. Analysis of these attacks on the state of the art\ntransformers in NLP can help improve the robustness of these models against\nsuch adversarial inputs. In this paper, we present Adv-OLM, a black-box attack\nmethod that adapts the idea of Occlusion and Language Models (OLM) to the\ncurrent state of the art attack methods. OLM is used to rank words of a\nsentence, which are later substituted using word replacement strategies. We\nexperimentally show that our approach outperforms other attack methods for\nseveral text classification tasks.\n",
			"Comment: 5 Pages + 1 Page references + 3 Pages Appendix, Accepted at EACL 2021"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08523",
		"pdf_url": "http://arxiv.org/pdf/2101.08523.pdf"
	},
	"1388": {
		"title": "Efficient Pure Exploration for Combinatorial Bandits with Semi-Bandit\n  Feedback",
		"creator": [
			"Jourdan, Marc",
			"Mutný, Mojmír",
			"Kirschner, Johannes",
			"Krause, Andreas"
		],
		"subject": [
			"Statistics - Machine Learning",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Combinatorial bandits with semi-bandit feedback generalize multi-armed\nbandits, where the agent chooses sets of arms and observes a noisy reward for\neach arm contained in the chosen set. The action set satisfies a given\nstructure such as forming a base of a matroid or a path in a graph. We focus on\nthe pure-exploration problem of identifying the best arm with fixed confidence,\nas well as a more general setting, where the structure of the answer set\ndiffers from the one of the action set. Using the recently popularized game\nframework, we interpret this problem as a sequential zero-sum game and develop\na CombGame meta-algorithm whose instances are asymptotically optimal algorithms\nwith finite time guarantees. In addition to comparing two families of learners\nto instantiate our meta-algorithm, the main contribution of our work is a\nspecific oracle efficient instance for best-arm identification with\ncombinatorial actions. Based on a projection-free online learning algorithm for\nconvex polytopes, it is the first computationally efficient algorithm which is\nasymptotically optimal and has competitive empirical performance.\n",
			"Comment: 45 pages. 3 tables. Appendices: from A to I. Figures: 1(a), 1(b),\n  2(a), 2(b), 3(a), 3(b), 3(c), 4(a), 4(b), 5(a), 5(b), 5(c), 5(d), 6(a), 6(b).\n  To be published in the 32nd International Conference on Algorithmic Learning\n  Theory and the Proceedings of Machine Learning Research vol 132:1-45, 2021"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08534",
		"pdf_url": "http://arxiv.org/pdf/2101.08534.pdf"
	},
	"1389": {
		"title": "Variable Division and Optimization for Constrained Multiobjective\n  Portfolio Problems",
		"creator": [
			"Chen, Yi",
			"Zhou, Aimin"
		],
		"subject": [
			"Computer Science - Neural and Evolutionary Computing",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  Variable division and optimization (D\\&O) is a frequently utilized algorithm\ndesign paradigm in Evolutionary Algorithms (EAs). A D\\&O EA divides a variable\ninto partial variables and then optimize them respectively. A complicated\nproblem is thus divided into simple subtasks. For example, a variable of\nportfolio problem can be divided into two partial variables, i.e. the selection\nof assets and the allocation of capital. Thereby, we optimize these two partial\nvariables respectively. There is no formal discussion about how are the partial\nvariables iteratively optimized and why can it work for both single- and\nmulti-objective problems in D\\&O. In this paper, this gap is filled. According\nto the discussion, an elitist selection method for partial variables in\nmultiobjective problems is developed. Then this method is incorporated into the\nDecomposition-Based Multiobjective Evolutionary Algorithm (D\\&O-MOEA/D). With\nthe help of a mathematical programming optimizer, it is achieved on the\nconstrained multiobjective portfolio problems. In the empirical study,\nD\\&O-MOEA/D is implemented for 20 instances and recent Chinese stock markets.\nThe results show the superiority and versatility of D\\&O-MOEA/D on large-scale\ninstances while the performance of it on small-scale problems is also not bad.\nThe former targets convergence towards the Pareto front and the latter helps\npromote diversity among the non-dominated solutions during the search process.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08552",
		"pdf_url": "http://arxiv.org/pdf/2101.08552.pdf"
	},
	"1390": {
		"title": "A Fast Optimal Double Row Legalization Algorithm",
		"creator": [
			"Hougardy, Stefan",
			"Neuwohner, Meike",
			"Schorr, Ulrike"
		],
		"subject": [
			"Computer Science - Data Structures and Algorithms",
			"B.7.2"
		],
		"description": [
			"  In Placement Legalization, it is often assumed that (almost) all standard\ncells possess the same height and can therefore be aligned in cell rows, which\ncan then be treated independently. However, this is no longer true for recent\ntechnologies, where a substantial number of cells of double- or even arbitrary\nmultiple-row height is to be expected. Due to interdependencies between the\ncell placements within several rows, the legalization task becomes considerably\nharder. In this paper, we show how to optimize quadratic cell movement for\npairs of adjacent rows comprising cells of single- as well as double-row height\nwith a fixed left-to-right ordering in time $\\mathcal{O}(n\\cdot\\log(n))$,\nwhereby $n$ denotes the number of cells involved. Opposed to prior works, we\nthereby do not artificially bound the maximum cell movement and can guarantee\nto find an optimum solution. Experimental results show an average percental\ndecrease of over $26\\%$ in the total quadratic movement when compared to a\nlegalization approach that fixes cells of more than single-row height after\nGlobal Placement.\n",
			"Comment: 8 pages, 3 figures, to be published in ISPD'21"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08561",
		"pdf_url": "http://arxiv.org/pdf/2101.08561.pdf"
	},
	"1391": {
		"title": "A Joint Diagonalization Based Efficient Approach to Underdetermined\n  Blind Audio Source Separation Using the Multichannel Wiener Filter",
		"creator": [
			"Ito, Nobutaka",
			"Ikeshita, Rintaro",
			"Sawada, Hiroshi",
			"Nakatani, Tomohiro"
		],
		"subject": [
			"Computer Science - Sound",
			"Electrical Engineering and Systems Science - Audio and Speech Processing"
		],
		"description": [
			"  This paper presents a computationally efficient approach to blind source\nseparation (BSS) of audio signals, applicable even when there are more sources\nthan microphones (i.e., the underdetermined case). When there are as many\nsources as microphones (i.e., the determined case), BSS can be performed\ncomputationally efficiently by independent component analysis (ICA).\nUnfortunately, however, ICA is basically inapplicable to the underdetermined\ncase. Another BSS approach using the multichannel Wiener filter (MWF) is\napplicable even to this case, and encompasses full-rank spatial covariance\nanalysis (FCA) and multichannel non-negative matrix factorization (MNMF).\nHowever, these methods require massive numbers of matrix inversions to design\nthe MWF, and are thus computationally inefficient. To overcome this drawback,\nwe exploit the well-known property of diagonal matrices that matrix inversion\namounts to mere inversion of the diagonal elements and can thus be performed\ncomputationally efficiently. This makes it possible to drastically reduce the\ncomputational cost of the above matrix inversions based on a joint\ndiagonalization (JD) idea, leading to computationally efficient BSS.\nSpecifically, we restrict the N spatial covariance matrices (SCMs) of all N\nsources to a class of (exactly) jointly diagonalizable matrices. Based on this\napproach, we present FastFCA, a computationally efficient extension of FCA. We\nalso present a unified framework for underdetermined and determined audio BSS,\nwhich highlights a theoretical connection between FastFCA and other methods.\nMoreover, we reveal that FastFCA can be regarded as a regularized version of\napproximate joint diagonalization (AJD).\n",
			"Comment: submitted to IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08563",
		"pdf_url": "http://arxiv.org/pdf/2101.08563.pdf"
	},
	"1392": {
		"title": "Discovering Multi-Label Actor-Action Association in a Weakly Supervised\n  Setting",
		"creator": [
			"Biswas, Sovan",
			"Gall, Juergen"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  Since collecting and annotating data for spatio-temporal action detection is\nvery expensive, there is a need to learn approaches with less supervision.\nWeakly supervised approaches do not require any bounding box annotations and\ncan be trained only from labels that indicate whether an action occurs in a\nvideo clip. Current approaches, however, cannot handle the case when there are\nmultiple persons in a video that perform multiple actions at the same time. In\nthis work, we address this very challenging task for the first time. We propose\na baseline based on multi-instance and multi-label learning. Furthermore, we\npropose a novel approach that uses sets of actions as representation instead of\nmodeling individual action classes. Since computing, the probabilities for the\nfull power set becomes intractable as the number of action classes increases,\nwe assign an action set to each detected person under the constraint that the\nassignment is consistent with the annotation of the video clip. We evaluate the\nproposed approach on the challenging AVA dataset where the proposed approach\noutperforms the MIML baseline and is competitive to fully supervised\napproaches.\n",
			"Comment: Accepted in ACCV 2020"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08567",
		"pdf_url": "http://arxiv.org/pdf/2101.08567.pdf"
	},
	"1393": {
		"title": "A Note on Connectivity of Sublevel Sets in Deep Learning",
		"creator": "Nguyen, Quynh",
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  It is shown that for deep neural networks, a single wide layer of width $N+1$\n($N$ being the number of training samples) suffices to prove the connectivity\nof sublevel sets of the training loss function. In the two-layer setting, the\nsame property may not hold even if one has just one neuron less (i.e. width $N$\ncan lead to disconnected sublevel sets).\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08576",
		"pdf_url": "http://arxiv.org/pdf/2101.08576.pdf"
	},
	"1394": {
		"title": "Monitoring nonstationary processes based on recursive cointegration\n  analysis and elastic weight consolidation",
		"creator": [
			"Zhang, Jingxin",
			"Zhou, Donghua",
			"Chen, Maoyin"
		],
		"subject": [
			"Electrical Engineering and Systems Science - Systems and Control",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  This paper considers the problem of nonstationary process monitoring under\nfrequently varying operating conditions. Traditional approaches generally\nmisidentify the normal dynamic deviations as faults and thus lead to high false\nalarms. Besides, they generally consider single relatively steady operating\ncondition and suffer from the catastrophic forgetting issue when learning\nsuccessive operating conditions. In this paper, recursive cointegration\nanalysis (RCA) is first proposed to distinguish the real faults from normal\nsystems changes, where the model is updated once a new normal sample arrives\nand can adapt to slow change of cointegration relationship. Based on the\nlong-term equilibrium information extracted by RCA, the remaining short-term\ndynamic information is monitored by recursive principal component analysis\n(RPCA). Thus a comprehensive monitoring framework is built. When the system\nenters a new operating condition, the RCA-RPCA model is rebuilt to deal with\nthe new condition. Meanwhile, elastic weight consolidation (EWC) is employed to\nsettle the `catastrophic forgetting' issue inherent in RPCA, where significant\ninformation of influential parameters is enhanced to avoid the abrupt\nperformance degradation for similar modes. The effectiveness of the proposed\nmethod is illustrated by a practical industrial system.\n",
			"Comment: This paper has been submitted to IEEE Transaction on Cybernetics for\n  potential publication"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08579",
		"pdf_url": "http://arxiv.org/pdf/2101.08579.pdf"
	},
	"1395": {
		"title": "Hierarchical Graph-RNNs for Action Detection of Multiple Activities",
		"creator": [
			"Biswas, Sovan",
			"Souri, Yaser",
			"Gall, Juergen"
		],
		"subject": "Computer Science - Computer Vision and Pattern Recognition",
		"description": [
			"  In this paper, we propose an approach that spatially localizes the activities\nin a video frame where each person can perform multiple activities at the same\ntime. Our approach takes the temporal scene context as well as the relations of\nthe actions of detected persons into account. While the temporal context is\nmodeled by a temporal recurrent neural network (RNN), the relations of the\nactions are modeled by a graph RNN. Both networks are trained together and the\nproposed approach achieves state of the art results on the AVA dataset.\n",
			"Comment: Accepted at ICIP 2019"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08581",
		"pdf_url": "http://arxiv.org/pdf/2101.08581.pdf"
	},
	"1396": {
		"title": "Crossbreeding in Random Forest",
		"creator": [
			"Nadi, Abolfazl",
			"Moradi, Hadi",
			"Taheri, Khalil"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Ensemble learning methods are designed to benefit from multiple learning\nalgorithms for better predictive performance. The tradeoff of this improved\nperformance is slower speed and larger size of ensemble learning systems\ncompared to single learning systems. In this paper, we present a novel approach\nto deal with this problem in Random Forest (RF) as one of the most powerful\nensemble methods. The method is based on crossbreeding of the best tree\nbranches to increase the performance of RF in space and speed while keeping the\nperformance in the classification measures. The proposed approach has been\ntested on a group of synthetic and real datasets and compared to the standard\nRF approach. Several evaluations have been conducted to determine the effects\nof the Crossbred RF (CRF) on the accuracy and the number of trees in a forest.\nThe results show better performance of CRF compared to RF.\n",
			"Comment: 21 pages, 5301 words, 9 Figures"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08585",
		"pdf_url": "http://arxiv.org/pdf/2101.08585.pdf"
	},
	"1397": {
		"title": "Positive Geometries for Barycentric Interpolation",
		"creator": "Vaitkus, Márton",
		"subject": [
			"Computer Science - Computational Geometry",
			"Mathematical Physics",
			"Mathematics - Numerical Analysis"
		],
		"description": [
			"  We propose a novel theoretical framework for barycentric interpolation, using\nconcepts recently developed in mathematical physics. Generalized barycentric\ncoordinates are defined similarly to Shepard's method, using positive\ngeometries - subsets which possess a rational function naturally associated to\ntheir boundaries. Positive geometries generalize certain properties of\nsimplices and convex polytopes to a large variety of geometric objects. Our\nframework unifies several previous constructions, including the definition of\nWachspress coordinates over polytopes in terms of adjoints and dual polytopes.\nWe also discuss potential applications to interpolation in 3D line space,\nmean-value coordinates and splines.\n",
			"Comment: 4 pages, 5 figures. Presented as a poster at the 2019 International\n  Geometry Summit. Comments are welcome!"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08589",
		"pdf_url": "http://arxiv.org/pdf/2101.08589.pdf"
	},
	"1398": {
		"title": "Fast Clustering of Short Text Streams Using Efficient Cluster Indexing\n  and Dynamic Similarity Thresholds",
		"creator": [
			"Rakib, Md Rashadul Hasan",
			"Asaduzzaman, Muhammad"
		],
		"subject": "Computer Science - Information Retrieval",
		"description": [
			"  Short text stream clustering is an important but challenging task since\nmassive amount of text is generated from different sources such as\nmicro-blogging, question-answering, and social news aggregation websites. One\nof the major challenges of clustering such massive amount of text is to cluster\nthem within a reasonable amount of time. The existing state-of-the-art short\ntext stream clustering methods can not cluster such massive amount of text\nwithin a reasonable amount of time as they compute similarities between a text\nand all the existing clusters to assign that text to a cluster. To overcome\nthis challenge, we propose a fast short text stream clustering method (called\nFastStream) that efficiently index the clusters using inverted index and\ncompute similarity between a text and a selected number of clusters while\nassigning a text to a cluster. In this way, we not only reduce the running time\nof our proposed method but also reduce the running time of several\nstate-of-the-art short text stream clustering methods. FastStream assigns a\ntext to a cluster (new or existing) using the dynamically computed similarity\nthresholds based on statistical measure. Thus our method efficiently deals with\nthe concept drift problem. Experimental results demonstrate that FastStream\noutperforms the state-of-the-art short text stream clustering methods by a\nsignificant margin on several short text datasets. In addition, the running\ntime of FastStream is several orders of magnitude faster than that of the\nstate-of-the-art methods.\n",
			"Comment: 6"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08595",
		"pdf_url": "http://arxiv.org/pdf/2101.08595.pdf"
	},
	"1399": {
		"title": "LEAF: A Learnable Frontend for Audio Classification",
		"creator": [
			"Zeghidour, Neil",
			"Teboul, Olivier",
			"Quitry, Félix de Chaumont",
			"Tagliasacchi, Marco"
		],
		"subject": [
			"Computer Science - Sound",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Audio and Speech Processing"
		],
		"description": [
			"  Mel-filterbanks are fixed, engineered audio features which emulate human\nperception and have been used through the history of audio understanding up to\ntoday. However, their undeniable qualities are counterbalanced by the\nfundamental limitations of handmade representations. In this work we show that\nwe can train a single learnable frontend that outperforms mel-filterbanks on a\nwide range of audio signals, including speech, music, audio events and animal\nsounds, providing a general-purpose learned frontend for audio classification.\nTo do so, we introduce a new principled, lightweight, fully learnable\narchitecture that can be used as a drop-in replacement of mel-filterbanks. Our\nsystem learns all operations of audio features extraction, from filtering to\npooling, compression and normalization, and can be integrated into any neural\nnetwork at a negligible parameter cost. We perform multi-task training on eight\ndiverse audio classification tasks, and show consistent improvements of our\nmodel over mel-filterbanks and previous learnable alternatives. Moreover, our\nsystem outperforms the current state-of-the-art learnable frontend on Audioset,\nwith orders of magnitude fewer parameters.\n",
			"Comment: Accepted at ICLR 2021"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08596",
		"pdf_url": "http://arxiv.org/pdf/2101.08596.pdf"
	},
	"1400": {
		"title": "Learning rich touch representations through cross-modal self-supervision",
		"creator": [
			"Zambelli, Martina",
			"Aytar, Yusuf",
			"Visin, Francesco",
			"Zhou, Yuxiang",
			"Hadsell, Raia"
		],
		"subject": "Computer Science - Robotics",
		"description": "  The sense of touch is fundamental in several manipulation tasks, but rarely\nused in robot manipulation. In this work we tackle the problem of learning rich\ntouch features from cross-modal self-supervision. We evaluate them identifying\nobjects and their properties in a few-shot classification setting. Two new\ndatasets are introduced using a simulated anthropomorphic robotic hand equipped\nwith tactile sensors on both synthetic and daily life objects. Several\nself-supervised learning methods are benchmarked on these datasets, by\nevaluating few-shot classification on unseen objects and poses. Our experiments\nindicate that cross-modal self-supervision effectively improves touch\nrepresentation, and in turn has great potential to enhance robot manipulation\nskills.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08616",
		"pdf_url": "http://arxiv.org/pdf/2101.08616.pdf"
	},
	"1401": {
		"title": "Mindless Attractor: A False-Positive Resistant Intervention for Drawing\n  Attention Using Auditory Perturbation",
		"creator": [
			"Arakawa, Riku",
			"Yakura, Hiromu"
		],
		"subject": [
			"Computer Science - Human-Computer Interaction",
			"Computer Science - Artificial Intelligence"
		],
		"description": [
			"  Explicitly alerting users is not always an optimal intervention, especially\nwhen they are not motivated to obey. For example, in video-based learning,\nlearners who are distracted from the video would not follow an alert asking\nthem to pay attention. Inspired by the concept of Mindless Computing, we\npropose a novel intervention approach, Mindless Attractor, that leverages the\nnature of human speech communication to help learners refocus their attention\nwithout relying on their motivation. Specifically, it perturbs the voice in the\nvideo to direct their attention without consuming their conscious awareness.\nOur experiments not only confirmed the validity of the proposed approach but\nalso emphasized its advantages in combination with a machine learning-based\nsensing module. Namely, it would not frustrate users even though the\nintervention is activated by false-positive detection of their attentive state.\nOur intervention approach can be a reliable way to induce behavioral change in\nhuman-AI symbiosis.\n",
			"Comment: To appear in ACM CHI Conference on Human Factors in Computing Systems\n  (CHI '21), May 8-13, 2021, Yokohama, Japan"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08621",
			"doi:10.1145/3411764.3445339"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08621.pdf"
	},
	"1402": {
		"title": "Commutative Event Sourcing vs. Triple Graph Grammars",
		"creator": [
			"Copei, Sebastian",
			"Zündorf, Albert"
		],
		"subject": [
			"Computer Science - Software Engineering",
			"D.2"
		],
		"description": "  This paper proposes Commutative Event Sourcing as a simple and reliable\nmechanism for model synchronisation, bidirectional model to model\ntransformations, incremental updates, and collaborative editing. Commutative\nEvent Sourcing is a restricted form of a Triple Graph Grammar where the rules\nor editing commands are either overwriting or commutative. This restriction\ngets rid of a lot of Triple Graph Grammar complexity and it becomes possible to\nimplement model synchronisation manually. Thus, you are not restricted to Java\nas your programming language and you do not need to use a proprietary library,\nframework, or tool. You do not even have to dig into graph grammar theory.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08626",
		"pdf_url": "http://arxiv.org/pdf/2101.08626.pdf"
	},
	"1403": {
		"title": "Neural Networks, Artificial Intelligence and the Computational Brain",
		"creator": "Nwadiugwu, Martin C.",
		"subject": [
			"Quantitative Biology - Neurons and Cognition",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  In recent years, several studies have provided insight on the functioning of\nthe brain which consists of neurons and form networks via interconnection among\nthem by synapses. Neural networks are formed by interconnected systems of\nneurons, and are of two types, namely, the Artificial Neural Network (ANNs) and\nBiological Neural Network (interconnected nerve cells). The ANNs are\ncomputationally influenced by human neurons and are used in modelling neural\nsystems. The reasoning foundations of ANNs have been useful in anomaly\ndetection, in areas of medicine such as instant physician, electronic noses,\npattern recognition, and modelling biological systems. Advancing research in\nartificial intelligence using the architecture of the human brain seeks to\nmodel systems by studying the brain rather than looking to technology for brain\nmodels. This study explores the concept of ANNs as a simulator of the\nbiological neuron, and its area of applications. It also explores why\nbrain-like intelligence is needed and how it differs from computational\nframework by comparing neural networks to contemporary computers and their\nmodern day implementation.\n",
		"date": "2020-12-25",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08635",
		"pdf_url": "http://arxiv.org/pdf/2101.08635.pdf"
	},
	"1404": {
		"title": "Dive into Decision Trees and Forests: A Theoretical Demonstration",
		"creator": "Zhang, Jinxiong",
		"subject": [
			"Computer Science - Machine Learning",
			"Statistics - Machine Learning"
		],
		"description": "  Based on decision trees, many fields have arguably made tremendous progress\nin recent years. In simple words, decision trees use the strategy of\n\"divide-and-conquer\" to divide the complex problem on the dependency between\ninput features and labels into smaller ones. While decision trees have a long\nhistory, recent advances have greatly improved their performance in\ncomputational advertising, recommender system, information retrieval, etc. We\nintroduce common tree-based models (e.g., Bayesian CART, Bayesian regression\nsplines) and training techniques (e.g., mixed integer programming, alternating\noptimization, gradient descent). Along the way, we highlight probabilistic\ncharacteristics of tree-based models and explain their practical and\ntheoretical benefits. Except machine learning and data mining, we try to show\ntheoretical advances on tree-based models from other fields such as statistics\nand operation research. We list the reproducible resource at the end of each\nmethod.\n",
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08656",
		"pdf_url": "http://arxiv.org/pdf/2101.08656.pdf"
	},
	"1405": {
		"title": "Free congruence: an exploration of expanded similarity measures for time\n  series data",
		"creator": "Jacaruso, Lucas Cassiel",
		"subject": "Computer Science - Machine Learning",
		"description": "  Time series similarity measures are highly relevant in a wide range of\nemerging applications including training machine learning models,\nclassification, and predictive modeling. Standard similarity measures for time\nseries most often involve point-to-point distance measures including Euclidean\ndistance and Dynamic Time Warping. Such similarity measures fundamentally\nrequire the fluctuation of values in the time series being compared to follow a\ncorresponding order or cadence for similarity to be established. This paper is\nspurred by the exploration of a broader definition of similarity, namely one\nthat takes into account the sheer numerical resemblance between sets of\nstatistical properties for time series segments irrespectively of value\nlabeling. Further, the presence of common pattern components between time\nseries segments was examined even if they occur in a permuted order, which\nwould not necessarily satisfy the criteria of more conventional point-to-point\ndistance measures. Results were compared with those of Dynamic Time Warping on\nthe same data for context. Surprisingly, the test for the numerical resemblance\nbetween sets of statistical properties established a stronger resemblance for\npairings of decline years with greater statistical significance than Dynamic\nTime Warping on the particular data and sample size used.\n",
		"date": "2021-01-17",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08659",
		"pdf_url": "http://arxiv.org/pdf/2101.08659.pdf"
	},
	"1406": {
		"title": "Regularization via deep generative models: an analysis point of view",
		"creator": [
			"Oberlin, Thomas",
			"Verm, Mathieu"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Image and Video Processing"
		],
		"description": "  This paper proposes a new way of regularizing an inverse problem in imaging\n(e.g., deblurring or inpainting) by means of a deep generative neural network.\nCompared to end-to-end models, such approaches seem particularly interesting\nsince the same network can be used for many different problems and experimental\nconditions, as soon as the generative model is suited to the data. Previous\nworks proposed to use a synthesis framework, where the estimation is performed\non the latent vector, the solution being obtained afterwards via the decoder.\nInstead, we propose an analysis formulation where we directly optimize the\nimage itself and penalize the latent vector. We illustrate the interest of such\na formulation by running experiments of inpainting, deblurring and\nsuper-resolution. In many cases our technique achieves a clear improvement of\nthe performance and seems to be more robust, in particular with respect to\ninitialization.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08661",
		"pdf_url": "http://arxiv.org/pdf/2101.08661.pdf"
	},
	"1407": {
		"title": "Probabilistic Placement Optimization for Non-coherent and Coherent Joint\n  Transmission in Cache-Enabled Cellular Networks",
		"creator": [
			"Feng, Tianming",
			"Shi, Shuo",
			"Gu, Shushi",
			"Xiang, Wei",
			"Gu, Xuemai"
		],
		"subject": "Computer Science - Information Theory",
		"description": "  How to design proper content placement strategies is one of the major areas\nof interest in cache-enabled cellular networks. In this paper, we study the\nprobabilistic content placement optimization of base station (BS) caching with\ncooperative transmission in the downlink of cellular networks. With placement\nprobability vector being the design parameter, non-coherent joint transmission\n(NC-JT) and coherent joint transmission (C-JT) schemes are investigated\naccording to whether channel state information (CSI) is available. Using\nstochastic geometry, we derive an integral expression for the successful\ntransmission probability (STP) in NC-JT scheme, and present an upper bound and\na tight approximation for the STP of the C-JT scheme. Next, we maximize the STP\nin NC-JT and the approximation of STP in C-JT by optimizing the placement\nprobability vector, respectively. An algorithm is proposed and applied to both\noptimization problems. By utilizing some properties of the STP, we obtain\nglobally optimal solutions in certain cases. Moreover, locally optimal\nsolutions in general cases are obtained by using the interior point method.\nFinally, numerical results show the optimized placement strategy achieves\nsignificant gains in STP over several comparative baselines both in NC-JT and\nC-JT. The optimal STP in C-JT outperforms the one in NC-JT, indicating the\nbenefits of knowing CSI in cooperative transmission.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08669",
		"pdf_url": "http://arxiv.org/pdf/2101.08669.pdf"
	},
	"1408": {
		"title": "DAF:re: A Challenging, Crowd-Sourced, Large-Scale, Long-Tailed Dataset\n  For Anime Character Recognition",
		"creator": [
			"Rios, Edwin Arkel",
			"Cheng, Wen-Huang",
			"Lai, Bo-Cheng"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"I.2",
			"I.4"
		],
		"description": [
			"  In this work we tackle the challenging problem of anime character\nrecognition. Anime, referring to animation produced within Japan and work\nderived or inspired from it. For this purpose we present DAF:re\n(DanbooruAnimeFaces:revamped), a large-scale, crowd-sourced, long-tailed\ndataset with almost 500 K images spread across more than 3000 classes.\nAdditionally, we conduct experiments on DAF:re and similar datasets using a\nvariety of classification models, including CNN based ResNets and\nself-attention based Vision Transformer (ViT). Our results give new insights\ninto the generalization and transfer learning properties of ViT models on\nsubstantially different domain datasets from those used for the upstream\npre-training, including the influence of batch and image size in their\ntraining. Additionally, we share our dataset, source-code, pre-trained\ncheckpoints and results, as Animesion, the first end-to-end framework for\nlarge-scale anime character recognition: https://github.com/arkel23/animesion\n",
			"Comment: 5 pages, 3 figures, 4 tables"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08674",
		"pdf_url": "http://arxiv.org/pdf/2101.08674.pdf"
	},
	"1409": {
		"title": "Adversarial Machine Learning in Text Analysis and Generation",
		"creator": "Alsmadi, Izzat",
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Cryptography and Security"
		],
		"description": "  The research field of adversarial machine learning witnessed a significant\ninterest in the last few years. A machine learner or model is secure if it can\ndeliver main objectives with acceptable accuracy, efficiency, etc. while at the\nsame time, it can resist different types and/or attempts of adversarial\nattacks. This paper focuses on studying aspects and research trends in\nadversarial machine learning specifically in text analysis and generation. The\npaper summarizes main research trends in the field such as GAN algorithms,\nmodels, types of attacks, and defense against those attacks.\n",
		"date": "2021-01-13",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08675",
		"pdf_url": "http://arxiv.org/pdf/2101.08675.pdf"
	},
	"1410": {
		"title": "Conceptualization and cases of study on cyber operations against the\n  sustainability of the tactical edge",
		"creator": [
			"Monge, Marco Antonio Sotelo",
			"Vidal, Jorge Maestre"
		],
		"subject": "Computer Science - Networking and Internet Architecture",
		"description": "  The last decade consolidated the cyberspace as fifth domain of operations,\nwhich extends its preliminarily intelligence and information exchange purposes\ntowards enabling complex offensive and defensive operations\nsupported/supportively of parallel kinetic domain actuations. Although there is\na plethora of well documented cases on strategic and operational interventions\nof cyber commands, the cyber tactical military edge is still a challenge, where\ncyber fires barely integrate to the traditional joint targeting cycle due among\nothers to long planning/development times, asymmetric effects, strict target\nreachability requirements, or the fast propagation of collateral damage; the\nlatter rapidly deriving on hybrid impacts (political, economic, social, etc.)\nand evidencing significant socio-technical gaps. In this context, it is\nexpected that tactical clouds disruptively facilitate cyber operations at the\nedge while exposing the rest of the digital assets of the operation to them. On\nthese grounds, the main purpose of the conducted research is to review and in\ndepth analyze the risks and opportunities of jeopardizing the sustainability of\nthe military tactical clouds at the edge by cyber operations. Along with a 1)\ncomprehensively formulation of the researched problematic, the study 2)\nformalizes the Tactical Denial of Sustainability (TDoS) concept; 3) introduces\nthe phasing, potential attack surfaces, terrains and impact of TDoS attacks; 4)\nemphasizes the related human and socio-technical aspects; 5) analyzes the\nthreats/opportunities inherent to their impact on the cloud energy efficiency;\n6) reviews their implications at the military cyber thinking for tactical\noperations; 7) illustrates five extensive CONOPS that facilitate the\nunderstanding of the TDoS concept; and given the high novelty of the discussed\ntopics, it 8) paves the way for further research and development actions.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08676",
		"pdf_url": "http://arxiv.org/pdf/2101.08676.pdf"
	},
	"1411": {
		"title": "Quantitative Security Risk Modeling and Analysis with RisQFLan",
		"creator": [
			"ter Beek, Maurice H.",
			"Legay, Axel",
			"Lafuente, Alberto Lluch",
			"Vandin, Andrea"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Software Engineering"
		],
		"description": "  Domain-specific quantitative modeling and analysis approaches are fundamental\nin scenarios in which qualitative approaches are inappropriate or unfeasible.\nIn this paper, we present a tool-supported approach to quantitative graph-based\nsecurity risk modeling and analysis based on attack-defense trees. Our approach\nis based on QFLan, a successful domain-specific approach to support\nquantitative modeling and analysis of highly configurable systems, whose\ndomain-specific components have been decoupled to facilitate the instantiation\nof the QFLan approach in the domain of graph-based security risk modeling and\nanalysis. Our approach incorporates distinctive features from three popular\nkinds of attack trees, namely enhanced attack trees, capabilities-based attack\ntrees and attack countermeasure trees, into the domain-specific modeling\nlanguage. The result is a new framework, called RisQFLan, to support\nquantitative security risk modeling and analysis based on attack-defense\ndiagrams. By offering either exact or statistical verification of probabilistic\nattack scenarios, RisQFLan constitutes a significant novel contribution to the\nexisting toolsets in that domain. We validate our approach by highlighting the\nadditional features offered by RisQFLan in three illustrative case studies from\nseminal approaches to graph-based security risk modeling analysis based on\nattack trees.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08677",
		"pdf_url": "http://arxiv.org/pdf/2101.08677.pdf"
	},
	"1412": {
		"title": "A two-stage data association approach for 3D Multi-object Tracking",
		"creator": [
			"Dao, Minh-Quan",
			"Frémont, Vincent"
		],
		"subject": [
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Artificial Intelligence",
			"Computer Science - Robotics"
		],
		"description": "  Multi-object tracking (MOT) is an integral part of any autonomous driving\npipelines because itproduces trajectories which has been taken by other moving\nobjects in the scene and helps predicttheir future motion. Thanks to the recent\nadvances in 3D object detection enabled by deep learning,track-by-detection has\nbecome the dominant paradigm in 3D MOT. In this paradigm, a MOT systemis\nessentially made of an object detector and a data association algorithm which\nestablishes track-to-detection correspondence. While 3D object detection has\nbeen actively researched, associationalgorithms for 3D MOT seem to settle at a\nbipartie matching formulated as a linear assignmentproblem (LAP) and solved by\nthe Hungarian algorithm. In this paper, we adapt a two-stage dataassociation\nmethod which was successful in image-based tracking to the 3D setting, thus\nprovidingan alternative for data association for 3D MOT. Our method outperforms\nthe baseline using one-stagebipartie matching for data association by achieving\n0.587 AMOTA in NuScenes validation set.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08684",
		"pdf_url": "http://arxiv.org/pdf/2101.08684.pdf"
	},
	"1413": {
		"title": "Multi-robot energy autonomy with wind and constrained resources",
		"creator": [
			"Fouad, Hassan",
			"Beltrame, Giovanni"
		],
		"subject": [
			"Computer Science - Robotics",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": "  One aspect of the ever-growing need for long term autonomy of multi-robot\nsystems, is ensuring energy sufficiency. In particular, in scenarios where\ncharging facilities are limited, battery-powered robots need to coordinate to\nshare access. In this work we extend previous results by considering robots\nthat carry out a generic mission while sharing a single charging station, while\nbeing affected by air drag and wind fields. Our mission-agnostic framework\nbased on control barrier functions (CBFs) ensures energy sufficiency (i.e.,\nmaintaining all robots above a certain voltage threshold) and proper\ncoordination (i.e., ensuring mutually exclusive use of the available charging\nstation). Moreover, we investigate the feasibility requirements of the system\nin relation to individual robots' properties, as well as air drag and wind\neffects. We show simulation results that demonstrate the effectiveness of the\nproposed framework.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08697",
		"pdf_url": "http://arxiv.org/pdf/2101.08697.pdf"
	},
	"1414": {
		"title": "Multi-sense embeddings through a word sense disambiguation process",
		"creator": [
			"Ruas, Terry",
			"Grosky, William",
			"Aizawa, Aiko"
		],
		"subject": "Computer Science - Computation and Language",
		"description": "  Natural Language Understanding has seen an increasing number of publications\nin the last few years, especially after robust word embeddings models became\nprominent, when they proved themselves able to capture and represent semantic\nrelationships from massive amounts of data. Nevertheless, traditional models\noften fall short in intrinsic issues of linguistics, such as polysemy and\nhomonymy. Any expert system that makes use of natural language in its core, can\nbe affected by a weak semantic representation of text, resulting in inaccurate\noutcomes based on poor decisions. To mitigate such issues, we propose a novel\napproach called Most Suitable Sense Annotation (MSSA), that disambiguates and\nannotates each word by its specific sense, considering the semantic effects of\nits context. Our approach brings three main contributions to the semantic\nrepresentation scenario: (i) an unsupervised technique that disambiguates and\nannotates words by their senses, (ii) a multi-sense embeddings model that can\nbe extended to any traditional word embeddings algorithm, and (iii) a recurrent\nmethodology that allows our models to be re-used and their representations\nrefined. We test our approach on six different benchmarks for the word\nsimilarity task, showing that our approach can produce state-of-the-art results\nand outperforms several more complex state-of-the-art systems.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08700",
			"Expert Systems with Applications. Volume 136, 1 December 2019,\n  Pages 288-303",
			"doi:10.1016/j.eswa.2019.06.026"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08700.pdf"
	},
	"1415": {
		"title": "Assessing the Benefits of Model Ensembles in Neural Re-Ranking for\n  Passage Retrieval",
		"creator": [
			"Borges, Luís",
			"Martins, Bruno",
			"Callan, Jamie"
		],
		"subject": "Computer Science - Information Retrieval",
		"description": [
			"  Our work aimed at experimentally assessing the benefits of model ensembling\nwithin the context of neural methods for passage reranking. Starting from\nrelatively standard neural models, we use a previous technique named Fast\nGeometric Ensembling to generate multiple model instances from particular\ntraining schedules, then focusing or attention on different types of approaches\nfor combining the results from the multiple model instances (e.g., averaging\nthe ranking scores, using fusion methods from the IR literature, or using\nsupervised learning-to-rank). Tests with the MS-MARCO dataset show that model\nensembling can indeed benefit the ranking quality, particularly with supervised\nlearning-to-rank although also with unsupervised rank aggregation.\n",
			"Comment: ECIR 2021 short paper"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08705",
		"pdf_url": "http://arxiv.org/pdf/2101.08705.pdf"
	},
	"1416": {
		"title": "Cain: Automatic Code Generation for Simultaneous Convolutional Kernels\n  on Focal-plane Sensor-processors",
		"creator": [
			"Stow, Edward",
			"Murai, Riku",
			"Saeedi, Sajad",
			"Kelly, Paul H. J."
		],
		"subject": [
			"Computer Science - Hardware Architecture",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"D.3.4",
			"I.4.m"
		],
		"description": [
			"  Focal-plane Sensor-processors (FPSPs) are a camera technology that enable low\npower, high frame rate computation, making them suitable for edge computation.\nUnfortunately, these devices' limited instruction sets and registers make\ndeveloping complex algorithms difficult. In this work, we present Cain - a\ncompiler that targets SCAMP-5, a general-purpose FPSP - which generates code\nfrom multiple convolutional kernels. As an example, given the convolutional\nkernels for an MNIST digit recognition neural network, Cain produces code that\nis half as long, when compared to the other available compilers for SCAMP-5.\n",
			"Comment: 17 pages, 4 figures, Accepted at LCPC 2020 to be published by\n  Springer"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08715",
		"pdf_url": "http://arxiv.org/pdf/2101.08715.pdf"
	},
	"1417": {
		"title": "Copycat CNN: Are Random Non-Labeled Data Enough to Steal Knowledge from\n  Black-box Models?",
		"creator": [
			"Correia-Silva, Jacson Rodrigues",
			"Berriel, Rodrigo F.",
			"Badue, Claudine",
			"De Souza, Alberto F.",
			"Oliveira-Santos, Thiago"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Computer Vision and Pattern Recognition",
			"Computer Science - Machine Learning"
		],
		"description": [
			"  Convolutional neural networks have been successful lately enabling companies\nto develop neural-based products, which demand an expensive process, involving\ndata acquisition and annotation; and model generation, usually requiring\nexperts. With all these costs, companies are concerned about the security of\ntheir models against copies and deliver them as black-boxes accessed by APIs.\nNonetheless, we argue that even black-box models still have some\nvulnerabilities. In a preliminary work, we presented a simple, yet powerful,\nmethod to copy black-box models by querying them with natural random images. In\nthis work, we consolidate and extend the copycat method: (i) some constraints\nare waived; (ii) an extensive evaluation with several problems is performed;\n(iii) models are copied between different architectures; and, (iv) a deeper\nanalysis is performed by looking at the copycat behavior. Results show that\nnatural random images are effective to generate copycats for several problems.\n",
			"Comment: The code is available at https://github.com/jeiks/Stealing_DL_Models"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": [
			"http://arxiv.org/abs/2101.08717",
			"Pattern Recognition 113 (2021) 107830",
			"doi:10.1016/j.patcog.2021.107830"
		],
		"pdf_url": "http://arxiv.org/pdf/2101.08717.pdf"
	},
	"1418": {
		"title": "Leafy Automata for Higher-Order Concurrency",
		"creator": [
			"Dixon, Alex",
			"Lazić, Ranko",
			"Murawski, Andrzej S.",
			"Walukiewicz, Igor"
		],
		"subject": [
			"Computer Science - Formal Languages and Automata Theory",
			"Computer Science - Programming Languages"
		],
		"description": [
			"  Finitary Idealized Concurrent Algol (FICA) is a prototypical programming\nlanguage combining functional, imperative, and concurrent computation. There\nexists a fully abstract game model of FICA, which in principle can be used to\nprove equivalence and safety of FICA programs. Unfortunately, the problems are\nundecidable for the whole language, and only very rudimentary decidable\nsub-languages are known. We propose leafy automata as a dedicated\nautomata-theoretic formalism for representing the game semantics of FICA. The\nautomata use an infinite alphabet with a tree structure. We show that the game\nsemantics of any FICA term can be represented by traces of a leafy automaton.\nConversely, the traces of any leafy automaton can be represented by a FICA\nterm. Because of the close match with FICA, we view leafy automata as a\npromising starting point for finding decidable subclasses of the language and,\nmore generally, to provide a new perspective on models of higher-order\nconcurrent computation. Moreover, we identify a fragment of FICA that is\namenable to verification by translation into a particular class of leafy\nautomata. Using a locality property of the latter class, where communication\nbetween levels is restricted and every other level is bounded, we show that\ntheir emptiness problem is decidable by reduction to Petri net reachability.\n",
			"Comment: 18 pages plus appendices"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08720",
		"pdf_url": "http://arxiv.org/pdf/2101.08720.pdf"
	},
	"1419": {
		"title": "Mechanism Design for Cumulative Prospect Theoretic Agents: A General\n  Framework and the Revelation Principle",
		"creator": [
			"Phade, Soham R.",
			"Anantharam, Venkat"
		],
		"subject": [
			"Computer Science - Computer Science and Game Theory",
			"Economics - Theoretical Economics"
		],
		"description": "  This paper initiates a discussion of mechanism design when the participating\nagents exhibit preferences that deviate from expected utility theory (EUT). In\nparticular, we consider mechanism design for systems where the agents are\nmodeled as having cumulative prospect theory (CPT) preferences, which is a\ngeneralization of EUT preferences. We point out some of the key modifications\nneeded in the theory of mechanism design that arise from agents having CPT\npreferences and some of the shortcomings of the classical mechanism design\nframework. In particular, we show that the revelation principle, which has\ntraditionally played a fundamental role in mechanism design, does not continue\nto hold under CPT. We develop an appropriate framework that we call mediated\nmechanism design which allows us to recover the revelation principle for CPT\nagents. We conclude with some interesting directions for future work.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08722",
		"pdf_url": "http://arxiv.org/pdf/2101.08722.pdf"
	},
	"1420": {
		"title": "Joint Autoregressive and Graph Models for Software and Developer Social\n  Networks",
		"creator": [
			"Hazra, Rima",
			"Aggarwal, Hardik",
			"Goyal, Pawan",
			"Mukherjee, Animesh",
			"Chakrabarti, Soumen"
		],
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Software Engineering"
		],
		"description": [
			"  Social network research has focused on hyperlink graphs, bibliographic\ncitations, friend/follow patterns, influence spread, etc. Large software\nrepositories also form a highly valuable networked artifact, usually in the\nform of a collection of packages, their developers, dependencies among them,\nand bug reports. This \"social network of code\" is rarely studied by social\nnetwork researchers. We introduce two new problems in this setting. These\nproblems are well-motivated in the software engineering community but not\nclosely studied by social network scientists. The first is to identify packages\nthat are most likely to be troubled by bugs in the immediate future, thereby\ndemanding the greatest attention. The second is to recommend developers to\npackages for the next development cycle. Simple autoregression can be applied\nto historical data for both problems, but we propose a novel method to\nintegrate network-derived features and demonstrate that our method brings\nadditional benefits. Apart from formalizing these problems and proposing new\nbaseline approaches, we prepare and contribute a substantial dataset connecting\nmultiple attributes built from the long-term history of 20 releases of Ubuntu,\ngrowing to over 25,000 packages with their dependency links, maintained by over\n3,800 developers, with over 280k bug reports.\n",
			"Comment: Accepted at ECIR 2021"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08729",
		"pdf_url": "http://arxiv.org/pdf/2101.08729.pdf"
	},
	"1421": {
		"title": "Deductive Verification of Floating-Point Java Programs in KeY",
		"creator": [
			"Boroujeni, Rosa Abbasi",
			"Schiffl, Jonas",
			"Darulova, Eva",
			"Ulbrich, Mattias",
			"Ahrendt, Wolfgang"
		],
		"subject": "Computer Science - Programming Languages",
		"description": "  Deductive verification has been successful in verifying interesting\nproperties of real-world programs. One notable gap is the limited support for\nfloating-point reasoning. This is unfortunate, as floating-point arithmetic is\nparticularly unintuitive to reason about due to rounding as well as the\npresence of the special values infinity and `Not a Number' (NaN). In this\npaper, we present the first floating-point support in a deductive verification\ntool for the Java programming language. Our support in the KeY verifier handles\narithmetic via floating-point decision procedures inside SMT solvers and\ntranscendental functions via axiomatization. We evaluate this integration on\nnew benchmarks, and show that this approach is powerful enough to prove the\nabsence of floating-point special values -- often a prerequisite for further\nreasoning about numerical computations -- as well as certain functional\nproperties for realistic benchmarks.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08733",
		"pdf_url": "http://arxiv.org/pdf/2101.08733.pdf"
	},
	"1422": {
		"title": "Work-sensitive Dynamic Complexity of Formal Languages",
		"creator": [
			"Schmidt, Jonas",
			"Schwentick, Thomas",
			"Tantau, Till",
			"Vortmeier, Nils",
			"Zeume, Thomas"
		],
		"subject": [
			"Computer Science - Logic in Computer Science",
			"Computer Science - Computational Complexity",
			"Computer Science - Data Structures and Algorithms"
		],
		"description": "  Which amount of parallel resources is needed for updating a query result\nafter changing an input? In this work we study the amount of work required for\ndynamically answering membership and range queries for formal languages in\nparallel constant time with polynomially many processors. As a prerequisite, we\npropose a framework for specifying dynamic, parallel, constant-time programs\nthat require small amounts of work. This framework is based on the dynamic\ndescriptive complexity framework by Patnaik and Immerman.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08735",
		"pdf_url": "http://arxiv.org/pdf/2101.08735.pdf"
	},
	"1423": {
		"title": "Rack-Aware Regenerating Codes with Fewer Helper Racks",
		"creator": [
			"Zhang, Zhifang",
			"Zhou, Liyang"
		],
		"subject": "Computer Science - Information Theory",
		"description": [
			"  We consider the rack-aware storage system where \\(n\\) nodes are organized in\n\\(\\bar{n}\\) racks each containing \\(u\\) nodes, and any \\(k\\) nodes can retrieve\nthe stored file. Moreover, any single node erasure can be recovered by\ndownloading data from \\(\\bar{d}\\) helper racks as well as the remaining\n\\(u\\!-\\!1\\) nodes in the same rack. Previous work mostly focuses on minimizing\nthe cross-rack repair bandwidth under the condition \\(\\bar{d}\\geq \\bar{k}\\),\nwhere \\(\\bar{k}=\\lfloor\\frac{k}{u}\\rfloor\\). However, \\(\\bar{d}\\geq \\bar{k}\\)\nis not an intrinsic condition for the rack-aware storage model. In this paper,\nwe establish a tradeoff between the storage overhead and cross-rack repair\nbandwidth for the particularly interesting case \\(\\bar{d}\\!<\\!\\bar{k}\\).\nFurthermore, we present explicit constructions of codes with parameters lying\non the tradeoff curve respectively at the minimum storage point and minimum\nbandwidth point. The codes are scalar or have sub-packetization \\(\\bar{d}\\),\nand operate over finite fields of size comparable to \\(n\\). Regarding\n\\(\\bar{d}\\) as the repair degree, these codes combine the advantage of\nregenerating codes in minimizing the repair bandwidth and that of locally\nrepairable codes in reducing the repair degree. Moreover, they also abandon the\nrestriction of MBR codes having storage overhead no less than \\(2\\times\\) and\nthat of high-rate MSR codes having exponential sub-packetization level.\n",
			"Comment: 5 pages, 1 figures, submitted to ISIT 2021"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08738",
		"pdf_url": "http://arxiv.org/pdf/2101.08738.pdf"
	},
	"1424": {
		"title": "Model-based Policy Search for Partially Measurable Systems",
		"creator": [
			"Amadio, Fabio",
			"Libera, Alberto Dalla",
			"Carli, Ruggero",
			"Nikovski, Daniel",
			"Romeres, Diego"
		],
		"subject": [
			"Computer Science - Robotics",
			"Computer Science - Machine Learning",
			"Electrical Engineering and Systems Science - Systems and Control"
		],
		"description": [
			"  In this paper, we propose a Model-Based Reinforcement Learning (MBRL)\nalgorithm for Partially Measurable Systems (PMS), i.e., systems where the state\ncan not be directly measured, but must be estimated through proper state\nobservers. The proposed algorithm, named Monte Carlo Probabilistic Inference\nfor Learning COntrol for Partially Measurable Systems (MC-PILCO4PMS), relies on\nGaussian Processes (GPs) to model the system dynamics, and on a Monte Carlo\napproach to update the policy parameters. W.r.t. previous GP-based MBRL\nalgorithms, MC-PILCO4PMS models explicitly the presence of state observers\nduring policy optimization, allowing to deal PMS. The effectiveness of the\nproposed algorithm has been tested both in simulation and in two real systems.\n",
			"Comment: Accepted to 3rd Robot Learning Workshop: Grounding Machine Learning\n  Development in the Real World (NeurIPS 2020)"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08740",
		"pdf_url": "http://arxiv.org/pdf/2101.08740.pdf"
	},
	"1425": {
		"title": "Soft Genetic Programming Binary Classifiers",
		"creator": "Gridin, Ivan",
		"subject": "Computer Science - Machine Learning",
		"description": [
			"  The study of the classifier's design and it's usage is one of the most\nimportant machine learning areas. With the development of automatic machine\nlearning methods, various approaches are used to build a robust classifier\nmodel. Due to some difficult implementation and customization complexity,\ngenetic programming (GP) methods are not often used to construct classifiers.\nGP classifiers have several limitations and disadvantages. However, the concept\nof \"soft\" genetic programming (SGP) has been developed, which allows the\nlogical operator tree to be more flexible and find dependencies in datasets,\nwhich gives promising results in most cases. This article discusses a method\nfor constructing binary classifiers using the SGP technique. The test results\nare presented. Source code - https://github.com/survexman/sgp_classifier.\n",
			"Comment: 21 pages, 12 figures"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08742",
		"pdf_url": "http://arxiv.org/pdf/2101.08742.pdf"
	},
	"1426": {
		"title": "A New Knowledge Gradient-based Method for Constrained Bayesian\n  Optimization",
		"creator": [
			"Chen, Wenjie",
			"Liu, Shengcai",
			"Tang, Ke"
		],
		"subject": [
			"Computer Science - Machine Learning",
			"Computer Science - Artificial Intelligence",
			"Statistics - Machine Learning"
		],
		"description": [
			"  Black-box problems are common in real life like structural design, drug\nexperiments, and machine learning. When optimizing black-box systems,\ndecision-makers always consider multiple performances and give the final\ndecision by comprehensive evaluations. Motivated by such practical needs, we\nfocus on constrained black-box problems where the objective and constraints\nlack known special structure, and evaluations are expensive and even with\nnoise. We develop a novel constrained Bayesian optimization approach based on\nthe knowledge gradient method ($c-\\rm{KG}$). A new acquisition function is\nproposed to determine the next batch of samples considering optimality and\nfeasibility. An unbiased estimator of the gradient of the new acquisition\nfunction is derived to implement the $c-\\rm{KG}$ approach.\n",
			"Comment: 14 pages, 0 figures"
		],
		"date": "2021-01-20",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08743",
		"pdf_url": "http://arxiv.org/pdf/2101.08743.pdf"
	},
	"1427": {
		"title": "Rethink Training of BERT Rerankers in Multi-Stage Retrieval Pipeline",
		"creator": [
			"Gao, Luyu",
			"Dai, Zhuyun",
			"Callan, Jamie"
		],
		"subject": "Computer Science - Information Retrieval",
		"description": [
			"  Pre-trained deep language models~(LM) have advanced the state-of-the-art of\ntext retrieval. Rerankers fine-tuned from deep LM estimates candidate relevance\nbased on rich contextualized matching signals. Meanwhile, deep LMs can also be\nleveraged to improve search index, building retrievers with better recall. One\nwould expect a straightforward combination of both in a pipeline to have\nadditive performance gain. In this paper, we discover otherwise and that\npopular reranker cannot fully exploit the improved retrieval result. We,\ntherefore, propose a Localized Contrastive Estimation (LCE) for training\nrerankers and demonstrate it significantly improves deep two-stage models.\n",
			"Comment: ECIR 2021"
		],
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08751",
		"pdf_url": "http://arxiv.org/pdf/2101.08751.pdf"
	},
	"1428": {
		"title": "An Efficient Communication Protocol for FPGA IP Protection",
		"creator": [
			"Khajuyi, Farzane",
			"Ghavami, Behnam",
			"Nikmehr, Human"
		],
		"subject": [
			"Computer Science - Cryptography and Security",
			"Computer Science - Hardware Architecture"
		],
		"description": "  We introduce a protection-based IP security scheme to protect soft and firm\nIP cores which are used on FPGA devices. The scheme is based on Finite State\nMachin (FSM) obfuscation and exploits Physical Unclonable Function (PUF) for\nFPGA unique identification (ID) generation which help pay-per-device licensing.\nWe introduce a communication protocol to protect the rights of parties in this\nmarket. On standard benchmark circuits, the experimental results show that our\nscheme is secure, attack-resilient and can be implemented with low area, power\nand delay overheads.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08754",
		"pdf_url": "http://arxiv.org/pdf/2101.08754.pdf"
	},
	"1429": {
		"title": "GPU-Accelerated Optimizer-Aware Evaluation of Submodular Exemplar\n  Clustering",
		"creator": [
			"Honysz, Philipp-Jan",
			"Buschjäger, Sebastian",
			"Morik, Katharina"
		],
		"subject": [
			"Computer Science - Distributed, Parallel, and Cluster Computing",
			"Computer Science - Artificial Intelligence"
		],
		"description": "  The optimization of submodular functions constitutes a viable way to perform\nclustering. Strong approximation guarantees and feasible optimization w.r.t.\nstreaming data make this clustering approach favorable. Technically, submodular\nfunctions map subsets of data to real values, which indicate how\n\"representative\" a specific subset is. Optimal sets might then be used to\npartition the data space and to infer clusters. Exemplar-based clustering is\none of the possible submodular functions, but suffers from high computational\ncomplexity. However, for practical applications, the particular real-time or\nwall-clock run-time is decisive. In this work, we present a novel way to\nevaluate this particular function on GPUs, which keeps the necessities of\noptimizers in mind and reduces wall-clock run-time. To discuss our GPU\nalgorithm, we investigated both the impact of different run-time critical\nproblem properties, like data dimensionality and the number of data points in a\nsubset, and the influence of required floating-point precision. In reproducible\nexperiments, our GPU algorithm was able to achieve competitive speedups of up\nto 72x depending on whether multi-threaded computation on CPUs was used for\ncomparison and the type of floating-point precision required. Half-precision\nGPU computation led to large speedups of up to 452x compared to\nsingle-precision, single-thread CPU computations.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08763",
		"pdf_url": "http://arxiv.org/pdf/2101.08763.pdf"
	},
	"1430": {
		"title": "Item Recommendation from Implicit Feedback",
		"creator": "Rendle, Steffen",
		"subject": [
			"Computer Science - Information Retrieval",
			"Computer Science - Machine Learning"
		],
		"description": "  The task of item recommendation is to select the best items for a user from a\nlarge catalogue of items. Item recommenders are commonly trained from implicit\nfeedback which consists of past actions that are positive only. Core challenges\nof item recommendation are (1) how to formulate a training objective from\nimplicit feedback and (2) how to efficiently train models over a large item\ncatalogue. This article provides an overview of item recommendation, its unique\ncharacteristics and some common approaches. It starts with an introduction to\nthe problem and discusses different training objectives. The main body deals\nwith learning algorithms and presents sampling based algorithms for general\nrecommenders and more efficient algorithms for dot product models. Finally, the\napplication of item recommenders for retrieval tasks is discussed.\n",
		"date": "2021-01-21",
		"type": "text",
		"identifier": "http://arxiv.org/abs/2101.08769",
		"pdf_url": "http://arxiv.org/pdf/2101.08769.pdf"
	}
}